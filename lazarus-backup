#!/bin/bash

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
VERSION="4.27.0"
SCRIPT_NAME="lazarus"
INSTALL_DIR="/opt/lazarus-backup"
BACKUP_DIR="$INSTALL_DIR/backup"
CONFIG_FILE="$INSTALL_DIR/config.env"
SYMLINK_PATH="/usr/local/bin/$SCRIPT_NAME"
REMOTE_URL="https://raw.githubusercontent.com/UnderGut/LAZARUS-Backup-Manager/main/lazarus-backup"

# --- –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê –î–õ–Ø –ü–û–ò–°–ö–ê –ë–û–¢–ê (–ù–ï –ü–ê–ù–ï–õ–ò!) ---
# –°–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: rwp_shop, rwp_shop_db
# –¢–∞–∫–∂–µ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ legacy: telegram-shop, shop-bot, shopbot
# –ü–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω: —Å–Ω–∞—á–∞–ª–∞ –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
KEYWORDS=("rwp_shop" "telegram-shop" "shop-bot" "shopbot")

# --- –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ---
BOT_PATH=""
BOT_TOKEN=""
CHAT_ID=""
TG_MESSAGE_THREAD_ID=""
DB_USER="postgres"
IGNORE_MISMATCH="false"
EXCLUDE_DIRS=""
MAX_FILE_SIZE_MB="1"

# –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª–∏ –æ—Ç–ø—Ä–∞–≤–∫–∏
SEND_TO_TELEGRAM="true"      # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram
TG_SEND_FILE="true"          # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –±—ç–∫–∞–ø–∞ –≤ Telegram
SEND_TO_REMOTE="true"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–æ—Ç–∞—Ü–∏–∏ (–ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É)
MAX_BACKUPS_COUNT="100"

# –£–¥–∞–ª—è—Ç—å —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã: "time" –∏–ª–∏ "count" (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é time)
DELETE_MODE="time"
# –°—Ä–æ–∫ —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –¥–Ω—è—Ö –ø—Ä–∏ —Ä–µ–∂–∏–º–µ time (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 7 –¥–Ω–µ–π)
RETENTION_DAYS="7"

# –õ–∏–º–∏—Ç —Ä–∞–∑–º–µ—Ä–∞ –≤—Å–µ—Ö –±—ç–∫–∞–ø–æ–≤ (–≤ MB). 0 = –±–µ–∑ –ª–∏–º–∏—Ç–∞
MAX_BACKUP_SIZE_MB="0"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
REMOTE_STORAGE_TYPE="off" # off, ftp, webdav
REMOTE_STORAGE_URL=""
REMOTE_STORAGE_USER=""
REMOTE_STORAGE_PASS=""
REMOTE_UPLOAD_STATUS_TEXT=""

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
BACKUP_PASSWORD=""

# –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
BOT_CONTAINER_NAME="" 
DB_CONTAINER_NAME=""
# –ü—É—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–∏–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏)
DEFAULT_BOT_PATH="/opt/private-remnawave-telegram-shop-bot"
# –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: rwp_shop, rwp_shop_db
DEFAULT_BOT_CONTAINER="rwp_shop"
DEFAULT_DB_CONTAINER="rwp_shop_db"
# Volume –∏–º–µ–Ω–∞ (–æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
DB_VOLUME_NAME=""  # –ë—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä rwp_shop_db_data)
DB_SERVICE_NAME="db"  # –ò–º—è —Å–µ—Ä–≤–∏—Å–∞ –≤ compose.yaml 

# –°—Ç–∞—Ç—É—Å—ã —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π
SCHEDULE_FULL="–í—ã–∫–ª"
SCHEDULE_DB="–í—ã–∫–ª"
SCHEDULE_FILES="–í—ã–∫–ª"

# –§–ª–∞–≥ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
IS_INTERACTIVE=true
if [[ ! -t 0 ]]; then IS_INTERACTIVE=false; fi

# –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ (--debug)
DEBUG_MODE=false
SILENT_LOG="/dev/null"
CURL_SILENT="-s"
WGET_SILENT="-q"

# –ê–≤—Ç–æ-–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –¥–ª—è –Ω–µ–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, cron --yes)
AUTO_CONFIRM="false"

# –õ–æ–≥-—Ñ–∞–π–ª –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω—ã—Ö –ª–æ–≥–æ–≤
LOG_FILE="/var/log/lazarus_backup.log"

# Lock-—Ñ–∞–π–ª –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
LOCK_FILE="/var/run/lazarus_backup.lock"
LOCK_FD=200  # File descriptor –¥–ª—è flock

# Trap –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ (–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ + –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã)
cleanup_on_exit() {
    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –µ—Å–ª–∏ –±—ã–ª–∞ –ø–æ–ª—É—á–µ–Ω–∞
    # NOTE: debug_log –º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å –∑–¥–µ—Å—å –µ—Å–ª–∏ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–∫—Ä—ã—Ç–∏—è stdout
    if [[ -n "$LOCK_FD" ]]; then
        flock -u "$LOCK_FD" 2>/dev/null || true
        eval "exec $LOCK_FD>&-" 2>/dev/null || true
    fi
    rm -f "$LOCK_FILE" 2>/dev/null || true
    
    # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–∏–≥—Ä–∞—Ü–∏–∏
    if [[ ${#TEMP_DIRS[@]} -gt 0 ]]; then
        for temp_dir in "${TEMP_DIRS[@]}"; do
            [[ -d "$temp_dir" ]] && rm -rf "$temp_dir" 2>/dev/null || true
        done
    fi
}
trap cleanup_on_exit EXIT INT TERM

# –¶–≤–µ—Ç–∞
if [[ -t 0 ]]; then
    RED=$'\e[31m'; GREEN=$'\e[32m'; YELLOW=$'\e[33m'; GRAY=$'\e[90m'; CYAN=$'\e[36m'; MAGENTA=$'\e[35m'; RESET=$'\e[0m'; BOLD=$'\e[1m'
else
    RED=""; GREEN=""; YELLOW=""; GRAY=""; CYAN=""; MAGENTA=""; RESET=""; BOLD=""
fi

# --- –§–£–ù–ö–¶–ò–ò –ò–ù–¢–ï–†–§–ï–ô–°–ê ---

# –û—á–∏—Å—Ç–∫–∞ —ç–∫—Ä–∞–Ω–∞ (–ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ debug —Ä–µ–∂–∏–º–µ)
clear_screen() {
    if [[ "$DEBUG_MODE" == true ]]; then
        echo ""
        echo -e "${MAGENTA}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê [DEBUG: clear skipped] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
        echo ""
    else
        clear
    fi
}

# –û—Ç–ª–∞–¥–æ—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: debug_log "message" –∏–ª–∏ debug_log "CATEGORY" "message"
debug_log() {
    if [[ "$DEBUG_MODE" == true ]]; then
        local ts=$(date '+%H:%M:%S.%3N')
        if [[ $# -eq 1 ]]; then
            echo -e "${MAGENTA}[$ts DEBUG]${RESET} $1"
        else
            local category="$1"
            shift
            echo -e "${MAGENTA}[$ts DEBUG]${RESET} ${CYAN}[$category]${RESET} $*"
        fi
    fi
}

escape_markdown_v2() {
    echo "$1" | sed -e 's/\\/\\\\/g' -e 's/_/\\_/g' -e 's/\[/\\[/g' -e 's/\]/\\]/g' \
        -e 's/(/\\(/g' -e 's/)/\\)/g' -e 's/~/\~/g' -e 's/`/\\`/g' -e 's/>/\\>/g' \
        -e 's/#/\\#/g' -e 's/+/\\+/g' -e 's/-/\\-/g' -e 's/=/\\=/g' -e 's/|/\\|/g' \
        -e 's/{/\\{/g' -e 's/}/\\}/g' -e 's/\./\\./g' -e 's/!/\\!/g'
}

send_telegram_notification() {
    local msg="$1"
    debug_log "TG" "=== send_telegram_notification ==="
    debug_log "TG" "SEND_TO_TELEGRAM=$SEND_TO_TELEGRAM"
    if [[ "$SEND_TO_TELEGRAM" == "true" && -n "$BOT_TOKEN" && -n "$CHAT_ID" ]]; then
        if command -v curl > "$SILENT_LOG" 2>&1; then
            local escaped_msg
            escaped_msg=$(escape_markdown_v2 "$msg")
            local thread_param=""
            [[ -n "$TG_MESSAGE_THREAD_ID" ]] && thread_param="-d message_thread_id=$TG_MESSAGE_THREAD_ID"
            local full_text="üö® *Lazarus Error* üö®

${escaped_msg}"
            debug_log "TG" "Sending error notification to chat_id=$CHAT_ID"
            curl $CURL_SILENT -X POST "https://api.telegram.org/bot$BOT_TOKEN/sendMessage" \
                -d chat_id="$CHAT_ID" \
                -d parse_mode="MarkdownV2" \
                --data-urlencode text="$full_text" \
                $thread_param > "$SILENT_LOG" 2>&1 || true
            debug_log "TG" "Notification sent"
        else
            debug_log "TG" "curl not available, skipping notification"
        fi
    else
        debug_log "TG" "Notifications disabled or credentials missing"
    fi
}

print_message() {
    local type="$1"; local message="$2"; local color_code="$RESET"
    case "$type" in
        "INFO") color_code="$GRAY" ;;
        "SUCCESS") color_code="$GREEN" ;;
        "WARN") color_code="$YELLOW" ;;
        "ERROR") color_code="$RED" ;;
        "ACTION") color_code="$CYAN" ;;
    esac
    echo -e "${color_code}[$type]${RESET} $message"

    if [[ "$type" == "ERROR" ]]; then
        send_telegram_notification "$message"
    fi
}

log_message() {
    # Level, Message
    local level="$1"; local message="$2"
    # Ensure log dir exists and file is writable
    local logdir
    logdir=$(dirname "$LOG_FILE")
    if [[ ! -d "$logdir" ]]; then mkdir -p "$logdir" 2> "$SILENT_LOG" || true; fi
    if [[ ! -f "$LOG_FILE" ]]; then touch "$LOG_FILE" 2> "$SILENT_LOG" || true; fi
    local ts
    ts=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[$ts] [$level] $message" >> "$LOG_FILE" 2> "$SILENT_LOG" || true
}

rotate_internal_log() {
    # Rotate log if > 10MB
    local MAX_LOG_SIZE=$((10 * 1024 * 1024))
    if [[ -f "$LOG_FILE" ]]; then
        local size
        size=$(stat -c%s "$LOG_FILE" 2> "$SILENT_LOG" || echo 0)
        if [[ "$size" -gt "$MAX_LOG_SIZE" ]]; then
            mv "$LOG_FILE" "${LOG_FILE}.old"
            echo "Log rotated on $(date)" > "$LOG_FILE"
        fi
    fi
}

# --- –ë–õ–û–ö–ò–†–û–í–ö–ê –û–¢ –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û–ì–û –ó–ê–ü–£–°–ö–ê ---

acquire_lock() {
    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —ç–∫—Å–∫–ª—é–∑–∏–≤–Ω—É—é –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
    # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∏–∑ cron
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0 –µ—Å–ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ø–æ–ª—É—á–µ–Ω–∞, 1 –µ—Å–ª–∏ –∑–∞–Ω—è—Ç–æ
    debug_log "LOCK" "=== acquire_lock ==="
    debug_log "LOCK" "Lock file: $LOCK_FILE"
    
    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è lock-—Ñ–∞–π–ª–∞ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    local lock_dir=$(dirname "$LOCK_FILE")
    if [[ ! -d "$lock_dir" ]]; then
        debug_log "LOCK" "Creating lock directory: $lock_dir"
        mkdir -p "$lock_dir" 2> "$SILENT_LOG" || true
    fi
    
    # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –Ω–∞ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä LOCK_FD
    debug_log "LOCK" "Opening lock file on FD $LOCK_FD"
    eval "exec $LOCK_FD>\"$LOCK_FILE\""
    
    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â—É—é —ç–∫—Å–∫–ª—é–∑–∏–≤–Ω—É—é –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
    debug_log "LOCK" "Attempting flock..."
    if ! flock -n "$LOCK_FD" 2> "$SILENT_LOG"; then
        debug_log "LOCK" "FAILED - lock already held by another process"
        return 1  # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —É–∂–µ –∑–∞–Ω—è—Ç–∞ –¥—Ä—É–≥–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º
    fi
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º PID –≤ lock-—Ñ–∞–π–ª –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    echo "$$" >&$LOCK_FD
    debug_log "LOCK" "Lock acquired, PID=$$ written to lock file"
    
    return 0
}

release_lock() {
    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
    debug_log "LOCK" "=== release_lock ==="
    debug_log "LOCK" "Releasing FD $LOCK_FD"
    flock -u "$LOCK_FD" 2> "$SILENT_LOG" || true
    eval "exec $LOCK_FD>&-" 2> "$SILENT_LOG" || true
    rm -f "$LOCK_FILE" 2> "$SILENT_LOG" || true
    debug_log "LOCK" "Lock released and file removed"
}

check_lock_owner() {
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç PID –ø—Ä–æ—Ü–µ—Å—Å–∞, –≤–ª–∞–¥–µ—é—â–µ–≥–æ –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π
    debug_log "LOCK" "Checking lock owner..."
    if [[ -f "$LOCK_FILE" ]]; then
        local owner
        owner=$(cat "$LOCK_FILE" 2> "$SILENT_LOG" || echo "unknown")
        debug_log "LOCK" "Lock owner PID: $owner"
        echo "$owner"
    else
        debug_log "LOCK" "No lock file found"
        echo "none"
    fi
}

check_dependencies() {
    local deps=("tar" "gzip" "openssl" "docker" "find" "du" "date")
    local missing=()
    
    # Check for curl OR wget
    if ! command -v curl > "$SILENT_LOG" 2>&1 && ! command -v wget > "$SILENT_LOG" 2>&1; then
        missing+=("curl (or wget)")
    fi

    for cmd in "${deps[@]}"; do
        if ! command -v "$cmd" > "$SILENT_LOG" 2>&1; then
            missing+=("$cmd")
        fi
    done
    
    # Check for docker compose (v2)
    if command -v docker > "$SILENT_LOG" 2>&1; then
        if ! docker compose version > "$SILENT_LOG" 2>&1; then
             echo -e "${RED}[ERROR]${RESET} 'docker compose' plugin is required but not found."
             echo -e "${CYAN}[ACTION]${RESET} Please install docker-compose-plugin (v2)."
             exit 1
        fi
    fi

    if [[ ${#missing[@]} -gt 0 ]]; then
        echo -e "${RED}[ERROR]${RESET} Missing dependencies: ${missing[*]}"
        echo -e "${CYAN}[ACTION]${RESET} Please install them (e.g., apt install ${missing[*]})"
        exit 1
    fi
}

# --- –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–≠–ö–ê–ü–û–í ---

get_backup_stats() {
    # –ü–æ–¥—Å—á—ë—Ç —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    local n_full=$(find "$BACKUP_DIR" -maxdepth 1 -type f \( -name "lazarus_full_*.tar.gz" -o -name "lazarus_full_*.tar.gz.enc" \) 2> "$SILENT_LOG" | wc -l)
    local n_db=$(find "$BACKUP_DIR" -maxdepth 1 -type f \( -name "lazarus_db_*.tar.gz" -o -name "lazarus_db_*.tar.gz.enc" \) 2> "$SILENT_LOG" | wc -l)
    local n_files=$(find "$BACKUP_DIR" -maxdepth 1 -type f \( -name "lazarus_files_*.tar.gz" -o -name "lazarus_files_*.tar.gz.enc" \) 2> "$SILENT_LOG" | wc -l)
    
    # –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –ø–∞–ø–∫–∏ –±—ç–∫–∞–ø–æ–≤
    local total_size="0B"
    if [[ -d "$BACKUP_DIR" ]]; then
        total_size=$(du -sh "$BACKUP_DIR" 2> "$SILENT_LOG" | awk '{print $1}')
    fi
    
    # –ü–æ—Å–ª–µ–¥–Ω–∏–π –±—ç–∫–∞–ø (–ª—é–±–æ–π —Ç–∏–ø)
    local last_backup=""
    local last_backup_ago=""
    local latest_file=$(find "$BACKUP_DIR" -maxdepth 1 -type f \( -name "lazarus_*.tar.gz" -o -name "lazarus_*.tar.gz.enc" \) -printf '%T@ %p\n' 2> "$SILENT_LOG" | sort -rn | head -1 | awk '{print $2}')
    
    if [[ -n "$latest_file" && -f "$latest_file" ]]; then
        local filename=$(basename "$latest_file")
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: lazarus_type_YYYY-MM-DD_HH_MM_SS.tar.gz
        if [[ $filename =~ _([0-9]{4})-([0-9]{2})-([0-9]{2})_([0-9]{2})_([0-9]{2}) ]]; then
            local file_date="${BASH_REMATCH[3]}.${BASH_REMATCH[2]} ${BASH_REMATCH[4]}:${BASH_REMATCH[5]}"
            last_backup="$file_date"
            
            # –í—ã—á–∏—Å–ª—è–µ–º "—Å–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞–∑–∞–¥"
            local file_ts=$(stat -c %Y "$latest_file" 2> "$SILENT_LOG")
            local now_ts=$(date +%s)
            if [[ -n "$file_ts" ]]; then
                local diff_sec=$((now_ts - file_ts))
                if [[ $diff_sec -lt 60 ]]; then
                    last_backup_ago="—Ç–æ–ª—å–∫–æ —á—Ç–æ"
                elif [[ $diff_sec -lt 3600 ]]; then
                    local mins=$((diff_sec / 60))
                    last_backup_ago="${mins} –º–∏–Ω –Ω–∞–∑–∞–¥"
                elif [[ $diff_sec -lt 86400 ]]; then
                    local hours=$((diff_sec / 3600))
                    last_backup_ago="${hours} —á –Ω–∞–∑–∞–¥"
                else
                    local days=$((diff_sec / 86400))
                    last_backup_ago="${days} –¥–Ω –Ω–∞–∑–∞–¥"
                fi
            fi
        fi
    fi
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —á–µ—Ä–µ–∑ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (bash –Ω–µ —É–º–µ–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏–π)
    STATS_FULL="$n_full"
    STATS_DB="$n_db"
    STATS_FILES="$n_files"
    STATS_SIZE="$total_size"
    STATS_LAST="$last_backup"
    STATS_LAST_AGO="$last_backup_ago"
}

# --- –°–ò–°–¢–ï–ú–ê –û–ë–ù–û–í–õ–ï–ù–ò–Ø ---

check_for_updates() {
    clear_screen
    echo -e "${CYAN}–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π...${RESET}"
    
    local REMOTE_CONTENT=""
    local DOWNLOAD_OK=false
    local MAX_RETRIES=3
    local TIMEOUT=15
    
    for attempt in $(seq 1 $MAX_RETRIES); do
        if command -v curl > "$SILENT_LOG" 2>&1; then
            REMOTE_CONTENT=$(curl $CURL_SILENT -L --connect-timeout $TIMEOUT --max-time 30 "$REMOTE_URL" 2> "$SILENT_LOG")
        elif command -v wget > "$SILENT_LOG" 2>&1; then
            REMOTE_CONTENT=$(wget $WGET_SILENT -O- --timeout=$TIMEOUT "$REMOTE_URL" 2> "$SILENT_LOG")
        else
            print_message "ERROR" "–ù–µ—Ç curl –∏–ª–∏ wget –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π."
            read -erp "Enter..." dummy; return
        fi
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ –≤–∞–ª–∏–¥–Ω—ã–π —Å–∫—Ä–∏–ø—Ç
        if [[ -n "$REMOTE_CONTENT" ]] && echo "$REMOTE_CONTENT" | head -1 | grep -q "^#!/bin/bash"; then
            DOWNLOAD_OK=true
            break
        fi
        
        [[ $attempt -lt $MAX_RETRIES ]] && echo -e "${YELLOW}–ü–æ–ø—ã—Ç–∫–∞ $attempt/$MAX_RETRIES –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø–æ–≤—Ç–æ—Ä...${RESET}" && sleep 2
    done
    
    if [[ "$DOWNLOAD_OK" != "true" ]]; then
        print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π."
        echo -e "${GRAY}URL: $REMOTE_URL${RESET}"
        read -erp "Enter..." dummy; return
    fi

    local REMOTE_VERSION=$(echo "$REMOTE_CONTENT" | grep '^VERSION=' | head -1 | cut -d'"' -f2)

    if [[ -z "$REMOTE_VERSION" ]]; then
        print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–µ—Ä—Å–∏–∏."
        echo -e "${GRAY}–§–∞–π–ª –ø–æ–ª—É—á–µ–Ω, –Ω–æ VERSION= –Ω–µ –Ω–∞–π–¥–µ–Ω${RESET}"
        read -erp "Enter..." dummy; return
    fi

    local V_LOCAL=$(echo "$VERSION" | cut -d'-' -f1)
    local V_REMOTE=$(echo "$REMOTE_VERSION" | cut -d'-' -f1)
    local SUFFIX_LOCAL=$(echo "$VERSION" | grep -oE '\-.*$' || echo "")
    local SUFFIX_REMOTE=$(echo "$REMOTE_VERSION" | grep -oE '\-.*$' || echo "")

    echo -e "–¢–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è: ${BOLD}$VERSION${RESET}"
    echo -e "–ê–∫—Ç—É–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è: ${BOLD}$REMOTE_VERSION${RESET}"
    echo ""

    if [[ "$VERSION" == "$REMOTE_VERSION" ]]; then
        print_message "SUCCESS" "–£ –≤–∞—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è –≤–µ—Ä—Å–∏—è."
        read -erp "Enter..." dummy
        return
    fi

    local IS_UPGRADE=false
    # –°–Ω–∞—á–∞–ª–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –≤–µ—Ä—Å–∏—é (X.Y.Z)
    if [[ "$(printf '%s\n' "$V_LOCAL" "$V_REMOTE" | sort -V | head -n1)" == "$V_LOCAL" && "$V_LOCAL" != "$V_REMOTE" ]]; then
        IS_UPGRADE=true
    # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ —Ä–∞–≤–Ω—ã, –Ω–æ –µ—Å—Ç—å —Ä–∞–∑–Ω–∏—Ü–∞ –≤ —Å—É—Ñ—Ñ–∏–∫—Å–∞—Ö ‚Äî —ç—Ç–æ —Ç–æ–∂–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
    elif [[ "$V_LOCAL" == "$V_REMOTE" && "$SUFFIX_LOCAL" != "$SUFFIX_REMOTE" ]]; then
        IS_UPGRADE=true
    fi

    if [[ "$IS_UPGRADE" == "true" ]]; then
        print_message "WARN" "–î–æ—Å—Ç—É–ø–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ!"
        read -erp "–û–±–Ω–æ–≤–∏—Ç—å —Å–∫—Ä–∏–ø—Ç —Å–µ–π—á–∞—Å? (y/N): " choice
        if [[ "$choice" =~ ^[Yy]$ ]]; then
            perform_update "$REMOTE_CONTENT"
        else
            print_message "INFO" "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ."
            read -erp "Enter..." dummy
        fi
    else
        echo -e "${YELLOW}‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –í–µ—Ä—Å–∏—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ —Å—Ç–∞—Ä–µ–µ –∏–ª–∏ —Ç–∞–∫–∞—è –∂–µ.${RESET}"
        read -erp "–í—Å–µ —Ä–∞–≤–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ—Ä—Å–∏—é —Å —Å–µ—Ä–≤–µ—Ä–∞? (y/N): " choice
        if [[ "$choice" =~ ^[Yy]$ ]]; then
            perform_update "$REMOTE_CONTENT"
        else
            print_message "INFO" "–û—Ç–º–µ–Ω–µ–Ω–æ."
            read -erp "Enter..." dummy
        fi
    fi
}

perform_update() {
    local CONTENT="$1"
    local SCRIPT_PATH="$INSTALL_DIR/$SCRIPT_NAME"
    local BACKUP_PATH="$INSTALL_DIR/${SCRIPT_NAME}.backup"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
    if ! echo "$CONTENT" | head -n 1 | grep -q "^#!/bin/bash"; then
        print_message "ERROR" "–û—à–∏–±–∫–∞: –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è bash-—Å–∫—Ä–∏–ø—Ç–æ–º."
        read -erp "Enter..." dummy
        return 1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä (–∑–∞—â–∏—Ç–∞ –æ—Ç –æ–±—Ä–µ–∑–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤)
    local CONTENT_SIZE=${#CONTENT}
    if [[ $CONTENT_SIZE -lt 10000 ]]; then
        print_message "ERROR" "–û—à–∏–±–∫–∞: –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª ($CONTENT_SIZE –±–∞–π—Ç)."
        print_message "ERROR" "–í–æ–∑–º–æ–∂–Ω–æ, —Ñ–∞–π–ª –±—ã–ª –ø–æ–≤—Ä–µ–∂–¥—ë–Ω –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ."
        read -erp "Enter..." dummy
        return 1
    fi
    
    # –°–æ–∑–¥–∞—ë–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏
    if [[ -f "$SCRIPT_PATH" ]]; then
        cp "$SCRIPT_PATH" "$BACKUP_PATH"
        print_message "INFO" "–°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: ${SCRIPT_NAME}.backup"
    fi
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é
    if echo "$CONTENT" > "$SCRIPT_PATH"; then
        chmod +x "$SCRIPT_PATH"
        print_message "SUCCESS" "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!"
        log_message "SUCCESS" "Script updated to new version"
        echo ""
        echo -e "${CYAN}–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞...${RESET}"
        sleep 1
        exec "$SCRIPT_PATH"
    else
        print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å —Ñ–∞–π–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è!"
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–∑ –±—ç–∫–∞–ø–∞
        if [[ -f "$BACKUP_PATH" ]]; then
            mv "$BACKUP_PATH" "$SCRIPT_PATH"
            print_message "WARN" "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∞—è –≤–µ—Ä—Å–∏—è –∏–∑ –±—ç–∫–∞–ø–∞."
        fi
        read -erp "Enter..." dummy
        return 1
    fi
}

# --- –°–ò–°–¢–ï–ú–ê –£–°–¢–ê–ù–û–í–ö–ò ---

install_script() {
    if [[ "$EUID" -ne 0 ]]; then
        echo -e "${RED}–û—à–∏–±–∫–∞: –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç —Å –ø—Ä–∞–≤–∞–º–∏ root (sudo)!${RESET}"
        exit 1
    fi

    local CURRENT_SCRIPT_PATH=$(realpath "$0" 2> "$SILENT_LOG")
    local INSTALLED_SCRIPT_PATH="$INSTALL_DIR/$SCRIPT_NAME"

    if [[ "$CURRENT_SCRIPT_PATH" == "$INSTALLED_SCRIPT_PATH" ]]; then
        return
    fi

    echo -e "${CYAN}--- –£–°–¢–ê–ù–û–í–ö–ê LAZARUS BACKUP ---${RESET}"
    if [[ ! -d "$INSTALL_DIR" ]]; then
        mkdir -p "$INSTALL_DIR"
        print_message "SUCCESS" "–°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞: $INSTALL_DIR"
    fi

    local DOWNLOAD_SUCCESS=false
    local TEMP_FILE="/tmp/lazarus_install_tmp"

    if [[ -f "$0" && "$0" != "bash" && "$0" != "/dev/fd/"* ]]; then
        cp "$(realpath "$0")" "$INSTALLED_SCRIPT_PATH"
        DOWNLOAD_SUCCESS=true
    else
        print_message "INFO" "–ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤–µ—Ä—Å–∏–∏..."
        if command -v curl > "$SILENT_LOG" 2>&1; then
            curl $CURL_SILENT -L --connect-timeout 15 --max-time 60 "$REMOTE_URL" -o "$TEMP_FILE"
        elif command -v wget > "$SILENT_LOG" 2>&1; then
            wget $WGET_SILENT -O "$TEMP_FILE" --timeout=15 "$REMOTE_URL"
        else
            print_message "ERROR" "–î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω—É–∂–µ–Ω curl –∏–ª–∏ wget!"
            exit 1
        fi

        if [[ -f "$TEMP_FILE" ]]; then
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ bash-—Å–∫—Ä–∏–ø—Ç
            if head -n 1 "$TEMP_FILE" | grep -q "^#!/bin/bash"; then
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                local FILE_SIZE=$(stat -c%s "$TEMP_FILE" 2> "$SILENT_LOG" || stat -f%z "$TEMP_FILE" 2> "$SILENT_LOG" || echo "0")
                if [[ $FILE_SIZE -lt 10000 ]]; then
                    print_message "ERROR" "–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª ($FILE_SIZE –±–∞–π—Ç)."
                    rm -f "$TEMP_FILE"
                    exit 1
                fi
                mv "$TEMP_FILE" "$INSTALLED_SCRIPT_PATH"
                DOWNLOAD_SUCCESS=true
            else
                print_message "ERROR" "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏! –°–µ—Ä–≤–µ—Ä –≤–µ—Ä–Ω—É–ª –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–∞–π–ª."
                rm -f "$TEMP_FILE"
                exit 1
            fi
        else
            print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª."
            exit 1
        fi
    fi

    if [[ "$DOWNLOAD_SUCCESS" == "true" ]]; then
        chmod +x "$INSTALLED_SCRIPT_PATH"
        if [[ -L "$SYMLINK_PATH" || -f "$SYMLINK_PATH" ]]; then rm -f "$SYMLINK_PATH"; fi
        ln -s "$INSTALLED_SCRIPT_PATH" "$SYMLINK_PATH"
        
        print_message "SUCCESS" "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ó–∞–ø—É—Å–∫..."
        echo ""
        exec "$INSTALLED_SCRIPT_PATH"
        exit 0
    fi
}

# --- –Ø–î–†–û –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–û–ì–û –ü–û–ò–°–ö–ê ---

scan_system_for_bot() {
    FOUND_PATH=""; FOUND_BOT=""; FOUND_DB=""
    debug_log "SCAN" "=== scan_system_for_bot ==="
    local running_containers=$(docker ps --format '{{.Names}}|{{.Image}}')
    debug_log "SCAN" "Running containers: $(echo "$running_containers" | wc -l)"
    
    # –°–ø–∏—Å–æ–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–ò–°–ö–õ–Æ–ß–ê–ï–ú –∏–∑ –ø–æ–∏—Å–∫–∞)
    local PANEL_CONTAINERS=(
        "remnawave"              # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –ø–∞–Ω–µ–ª–∏
        "remnawave-db"           # –ë–î –ø–∞–Ω–µ–ª–∏
        "remnawave-redis"        # Redis –ø–∞–Ω–µ–ª–∏
        "remnawave-nginx"        # Nginx –ø–∞–Ω–µ–ª–∏
        "remnawave-subscription-page"   # –°—Ç—Ä–∞–Ω–∏—Ü–∞ –ø–æ–¥–ø–∏—Å–æ–∫ –ø–∞–Ω–µ–ª–∏
        "remnawave-telegram-mini-app"   # Mini App –ø–∞–Ω–µ–ª–∏
        "certwardenclient"       # Cert Warden
    )
    
    for container in $running_containers; do
        local c_name=$(echo "$container" | cut -d'|' -f1)
        local c_image=$(echo "$container" | cut -d'|' -f2)
        debug_log "SCAN" "Checking: $c_name ($c_image)"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –ø–∞–Ω–µ–ª–∏
        local is_panel=false
        for panel_c in "${PANEL_CONTAINERS[@]}"; do
            if [[ "$c_name" == "$panel_c" ]]; then
                is_panel=true
                debug_log "SCAN" "  -> Skip (panel container: $panel_c)"
                break
            fi
        done
        
        # –ò—Å–∫–ª—é—á–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –ø–∞–Ω–µ–ª–∏ –ø–æ image
        if [[ "$c_image" == *"remnawave/backend"* ]]; then is_panel=true; debug_log "SCAN" "  -> Skip (remnawave/backend)"; fi
        if [[ "$c_image" == *"remnawave/subscription-page"* ]]; then is_panel=true; debug_log "SCAN" "  -> Skip (subscription-page)"; fi
        if [[ "$c_image" == *"remnawave-telegram-sub-mini-app"* ]]; then is_panel=true; fi
        if [[ "$c_image" == *"certwarden-client"* ]]; then is_panel=true; fi
        if [[ "$c_image" == "nginx"* || "$c_image" == "postgres"* || "$c_image" == "redis"* ]]; then
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏–º—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç "remnawave" –ë–ï–ó "shop"/"bot"
            if [[ "$c_name" == *"remnawave"* && "$c_name" != *"shop"* && "$c_name" != *"bot"* ]]; then
                is_panel=true
                debug_log "SCAN" "  -> Skip (panel infra)"
            fi
        fi
        
        if [[ "$is_panel" == true ]]; then continue; fi

        # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–û–¢–ê –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        for key in "${KEYWORDS[@]}"; do
            if [[ "$c_image" == *"$key"* || "$c_name" == *"$key"* ]]; then
                debug_log "SCAN" "  -> MATCH! keyword=$key"
                FOUND_BOT="$c_name"
                local work_dir=$(docker inspect --format '{{ index .Config.Labels "com.docker.compose.project.working_dir" }}' "$c_name")
                debug_log "SCAN" "  -> working_dir=$work_dir"
                if [[ -n "$work_dir" && -d "$work_dir" ]]; then FOUND_PATH="$work_dir"; fi
                break 2
            fi
        done
    done
    
    debug_log "SCAN" "After container scan: FOUND_BOT=$FOUND_BOT, FOUND_PATH=$FOUND_PATH"

    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã ‚Äî –∏—â–µ–º –ø–æ —Ñ–∞–π–ª–∞–º docker-compose
    if [[ -z "$FOUND_PATH" ]]; then
        debug_log "SCAN" "No containers found, searching compose files..."
        local search_dirs=("/opt" "/home" "/root")
        local compose_files=$(find "${search_dirs[@]}" -maxdepth 4 -name "docker-compose.yml" -o -name "compose.yaml" 2> "$SILENT_LOG")
        for file in $compose_files; do
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º compose —Ñ–∞–π–ª—ã –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            if grep -q "remnawave/backend" "$file"; then continue; fi
            if grep -q "remnawave/subscription-page" "$file"; then continue; fi
            
            # –ò—â–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –ë–û–¢–ê
            if grep -qE "image:.*($(IFS="|"; echo "${KEYWORDS[*]}"))" "$file" || grep -qE "container_name:.*($(IFS="|"; echo "${KEYWORDS[*]}"))" "$file"; then
                FOUND_PATH=$(dirname "$file")
                # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ container_name
                FOUND_BOT=$(grep -E "container_name:" "$file" | grep -E "($(IFS="|"; echo "${KEYWORDS[*]}"))" | head -1 | awk '{print $2}' | tr -d '"' | tr -d "'")
                
                # –ï—Å–ª–∏ container_name –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º docker compose –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–º–µ–Ω–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
                if [[ -z "$FOUND_BOT" && -d "$FOUND_PATH" ]]; then
                    cd "$FOUND_PATH" 2> "$SILENT_LOG"
                    # –ò—â–µ–º service –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–∞—à image
                    for key in "${KEYWORDS[@]}"; do
                        local services=$(grep -B 2 "image:.*$key" "$file" | grep "^[a-z]" | head -1 | awk '{print $1}' | tr -d ':')
                        if [[ -n "$services" ]]; then
                            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ –∏–º—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —á–µ—Ä–µ–∑ docker compose
                            FOUND_BOT=$(docker compose ps -a --format '{{.Name}}' "$services" 2> "$SILENT_LOG" | head -1)
                            [[ -n "$FOUND_BOT" ]] && break
                        fi
                    done
                    cd - > "$SILENT_LOG"
                fi
                break
            fi
        done
    fi

    # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –ë–î
    if [[ -n "$FOUND_PATH" ]]; then
        if cd "$FOUND_PATH" 2> "$SILENT_LOG"; then
            local db_services=("db" "postgres" "database" "postgresql")
            for svc in "${db_services[@]}"; do
                local db_c=$(docker compose ps -a --format '{{.Name}}' "$svc" 2> "$SILENT_LOG")
                # –ò—Å–∫–ª—é—á–∞–µ–º –ë–î –ø–∞–Ω–µ–ª–∏
                if [[ -n "$db_c" && "$db_c" != "remnawave-db" && "$db_c" != *"remnawave_"* ]]; then 
                    FOUND_DB="$db_c"
                    break
                fi
            done
            cd - > "$SILENT_LOG"
        fi
    fi
}

# --- –§–£–ù–ö–¶–ò–ò –í–ï–†–°–ò–ò –ò –ü–û–ò–°–ö–ê ---

get_raw_bot_version() {
    if [[ -n "$BOT_CONTAINER_NAME" ]] && docker container inspect -f '{{.State.Running}}' "$BOT_CONTAINER_NAME" > /dev/null 2> "$SILENT_LOG"; then
        local full_image=$(docker inspect -f '{{.Config.Image}}' "$BOT_CONTAINER_NAME")
        local ver="${full_image##*:}"
        echo "${ver:-Unknown}"
    else
        echo ""
    fi
}

get_bot_version_display() {
    local ver=$(get_raw_bot_version)
    if [[ -n "$ver" ]]; then echo "$ver"; else echo "N/A"; fi
}

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –±–æ—Ç–∞
get_container_status() {
    if [[ -z "$BOT_CONTAINER_NAME" ]]; then
        echo "N/A"
        return
    fi
    
    local status
    status=$(docker inspect -f '{{.State.Status}}' "$BOT_CONTAINER_NAME" 2> "$SILENT_LOG")
    
    case "$status" in
        "running") echo "Online" ;;
        "exited"|"dead") echo "Offline" ;;
        "paused") echo "Paused" ;;
        "restarting") echo "Restarting" ;;
        *) echo "N/A" ;;
    esac
}

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ DB volume
get_db_volume_name() {
    debug_log "DB" "=== get_db_volume_name ==="
    debug_log "DB" "DB_CONTAINER_NAME=$DB_CONTAINER_NAME"
    
    if [[ -z "$DB_CONTAINER_NAME" ]]; then
        debug_log "DB" "ERROR: DB_CONTAINER_NAME is empty"
        echo ""
        return 1
    fi
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è volume –∏–∑ docker inspect
    debug_log "DB" "Trying docker inspect..."
    local volume=$(docker inspect -f '{{range .Mounts}}{{if eq .Type "volume"}}{{.Name}}{{end}}{{end}}' "$DB_CONTAINER_NAME" 2> "$SILENT_LOG")
    
    if [[ -n "$volume" ]]; then
        debug_log "DB" "Volume found via docker inspect: $volume"
        echo "$volume"
        return 0
    fi
    debug_log "DB" "No volume from docker inspect, trying compose fallback"
    
    # Fallback: –ø—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–∑ docker-compose.yml
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
        local compose_file=""
        [[ -f "$BOT_PATH/compose.yaml" ]] && compose_file="$BOT_PATH/compose.yaml"
        [[ -f "$BOT_PATH/docker-compose.yml" ]] && compose_file="$BOT_PATH/docker-compose.yml"
        debug_log "DB" "Compose file: $compose_file"
        
        if [[ -n "$compose_file" ]]; then
            # –ò—â–µ–º volume –≤ —Å–µ–∫—Ü–∏–∏ volumes –ë–î (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±–æ–∏—Ö –ø—É—Ç–µ–π)
            # –ù–æ–≤–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: /var/lib/postgresql/data
            # –°—Ç–∞—Ä—ã–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏: /var/lib/postgresql
            local vol=$(grep -A 10 "^\s*$DB_SERVICE_NAME:" "$compose_file" | grep -E "volumes:" -A 5 | grep -oE "[a-zA-Z0-9_-]+:/var/lib/postgresql(/data)?" | cut -d':' -f1 | head -1)
            debug_log "DB" "Parsed volume name from compose: '$vol'"
            if [[ -n "$vol" ]]; then
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ç–∞–∫–æ–π volume
                if docker volume inspect "$vol" > /dev/null 2> "$SILENT_LOG"; then
                    debug_log "DB" "Volume exists: $vol"
                    echo "$vol"
                    return 0
                else
                    debug_log "DB" "Volume '$vol' does not exist in docker"
                fi
            fi
        fi
    fi
    
    # –ï—Å–ª–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
    debug_log "DB" "No volume found, returning empty"
    echo ""
    return 1
}

# –ß—Ç–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ .env —Ñ–∞–π–ª–∞ –±–æ—Ç–∞
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: read_bot_env "POSTGRES_USER" ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ
read_bot_env() {
    local var_name="$1"
    local env_file=""
    
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
        [[ -f "$BOT_PATH/.env" ]] && env_file="$BOT_PATH/.env"
    fi
    
    if [[ -z "$env_file" ]]; then
        debug_log "DB" "read_bot_env: no .env file found for '$var_name'"
        echo ""
        return 1
    fi
    
    # –ß–∏—Ç–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏–∑ .env (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤ KEY=value –∏ KEY="value")
    local value=$(grep -E "^${var_name}=" "$env_file" 2>/dev/null | head -1 | cut -d'=' -f2- | sed -e 's/^"//' -e 's/"$//' -e "s/^'//" -e "s/'$//")
    debug_log "DB" "read_bot_env: $var_name='$value' from $env_file"
    echo "$value"
}

# –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ë–î –∏–∑ .env –±–æ—Ç–∞ –∏–ª–∏ fallback –Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É
get_db_user() {
    local env_user=$(read_bot_env "POSTGRES_USER")
    if [[ -n "$env_user" ]]; then
        debug_log "DB" "get_db_user: using env POSTGRES_USER=$env_user"
        echo "$env_user"
    else
        debug_log "DB" "get_db_user: using global DB_USER=$DB_USER"
        echo "$DB_USER"
    fi
}

# –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏–∑ .env –±–æ—Ç–∞ –∏–ª–∏ fallback –Ω–∞ postgres
get_db_name() {
    local env_db=$(read_bot_env "POSTGRES_DB")
    if [[ -n "$env_db" ]]; then
        debug_log "DB" "get_db_name: using env POSTGRES_DB=$env_db"
        echo "$env_db"
    else
        debug_log "DB" "get_db_name: using default 'postgres'"
        echo "postgres"
    fi
}

# --- –§–£–ù–ö–¶–ò–Ø –û–ë–ù–û–í–õ–ï–ù–ò–Ø –ë–û–¢–ê ---

# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (rwp_shop-3.23.0-amd64.tar ‚Üí 3.23.0)
extract_version_from_filename() {
    local filename="$1"
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤:
    # - rwp_shop-3.23.0-amd64.tar (–Ω–æ–≤—ã–π)
    # - rwp_shop-3.23.0.tar
    # - private-remnawave-telegram-shop-bot-3.21.2-amd64.tar (—Å—Ç–∞—Ä—ã–π)
    # - telegram-shop-2.0.0.tar
    echo "$filename" | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' | head -1
}

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–π (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0 –µ—Å–ª–∏ $1 > $2)
version_gt() {
    local v1="$1" v2="$2"
    # –†–∞–∑–±–∏–≤–∞–µ–º –≤–µ—Ä—Å–∏–∏ –Ω–∞ —á–∞—Å—Ç–∏
    local v1_major v1_minor v1_patch v2_major v2_minor v2_patch
    IFS='.' read -r v1_major v1_minor v1_patch <<< "$v1"
    IFS='.' read -r v2_major v2_minor v2_patch <<< "$v2"
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —á–∏—Å–ª–∞–º (—É–±–∏—Ä–∞–µ–º –≤–µ–¥—É—â–∏–µ –Ω—É–ª–∏)
    v1_major=$((10#${v1_major:-0})); v1_minor=$((10#${v1_minor:-0})); v1_patch=$((10#${v1_patch:-0}))
    v2_major=$((10#${v2_major:-0})); v2_minor=$((10#${v2_minor:-0})); v2_patch=$((10#${v2_patch:-0}))
    
    if [[ $v1_major -gt $v2_major ]]; then return 0; fi
    if [[ $v1_major -lt $v2_major ]]; then return 1; fi
    if [[ $v1_minor -gt $v2_minor ]]; then return 0; fi
    if [[ $v1_minor -lt $v2_minor ]]; then return 1; fi
    if [[ $v1_patch -gt $v2_patch ]]; then return 0; fi
    return 1
}

# –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –æ–±—Ä–∞–∑–∞ –±–æ—Ç–∞ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–∞–ø–∫–µ (–±–µ–∑ —Ä–µ–∫—É—Ä—Å–∏–∏)
# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è: –Ω–æ–≤—ã–µ –∏ —Å—Ç–∞—Ä—ã–µ
find_bot_image_files() {
    local search_path="$1"
    # –ò—â–µ–º .tar —Ñ–∞–π–ª—ã —Å–æ –≤—Å–µ–º–∏ –≤–æ–∑–º–æ–∂–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏:
    # - rwp_shop-*.tar (–Ω–æ–≤—ã–π –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π)
    # - private-remnawave-telegram-shop-bot-*.tar (—Å—Ç–∞—Ä—ã–π)
    # - telegram-shop-*.tar (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π)
    find "$search_path" -maxdepth 1 -type f \( \
        -name "rwp_shop*.tar" -o \
        -name "private-remnawave-telegram-shop-bot*.tar" -o \
        -name "telegram-shop*.tar" \
    \) 2> "$SILENT_LOG"
}

# –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –æ–±—Ä–∞–∑–∞ –≤–æ –≤—Å–µ—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –ø—É—Ç—è—Ö + BOT_PATH
# –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ –≤–µ—Ä—Å–∏–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
find_all_bot_image_files() {
    debug_log "SCAN" "=== find_all_bot_image_files() start ==="
    local search_paths=()
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—É—Ç–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
    # 1. –ü—É—Ç—å –∫ –±–æ—Ç—É (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω)
    [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]] && search_paths+=("$BOT_PATH")
    
    # 2. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—É—Ç–∏
    [[ -d "/opt" ]] && search_paths+=("/opt")
    [[ -d "/root" ]] && search_paths+=("/root")
    
    # 3. –ü—É—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–µ—Å–ª–∏ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç BOT_PATH)
    if [[ -d "$DEFAULT_BOT_PATH" && "$DEFAULT_BOT_PATH" != "$BOT_PATH" ]]; then
        search_paths+=("$DEFAULT_BOT_PATH")
    fi
    
    debug_log "SCAN" "Search paths: ${search_paths[*]}"
    
    local all_files=""
    local seen_files=()
    
    for search_path in "${search_paths[@]}"; do
        debug_log "SCAN" "Searching in: $search_path (maxdepth=3)"
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ (maxdepth 3 –¥–ª—è —Ä–∞–∑—É–º–Ω–æ–π –≥–ª—É–±–∏–Ω—ã)
        while IFS= read -r file; do
            [[ -z "$file" ]] && continue
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã (–ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞)
            local fname=$(basename "$file")
            local is_dup=false
            for seen in "${seen_files[@]}"; do
                [[ "$seen" == "$fname" ]] && is_dup=true && break
            done
            
            if [[ "$is_dup" == "false" ]]; then
                debug_log "SCAN" "  Found: $file"
                seen_files+=("$fname")
                all_files+="$file"$'\n'
            else
                debug_log "SCAN" "  Duplicate skipped: $fname"
            fi
        done < <(find "$search_path" -maxdepth 3 -type f \( \
            -name "rwp_shop*.tar" -o \
            -name "private-remnawave-telegram-shop-bot*.tar" -o \
            -name "telegram-shop*.tar" \
        \) 2> "$SILENT_LOG")
    done
    
    # –£–¥–∞–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
    all_files="${all_files%$'\n'}"
    
    if [[ -z "$all_files" ]]; then
        debug_log "SCAN" "No image files found"
        echo ""
        return 1
    fi
    
    debug_log "SCAN" "Total unique files found: $(echo "$all_files" | wc -l)"
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤–µ—Ä—Å–∏–∏ (–∏–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Ä—Å–∏—é, —Å–æ—Ä—Ç–∏—Ä—É–µ–º, –≤—ã–≤–æ–¥–∏–º)
    # –ù–æ–≤—ã–µ –≤–µ—Ä—Å–∏–∏ –ø–µ—Ä–≤—ã–º–∏ (sort -Vr)
    echo "$all_files" | while IFS= read -r file; do
        local version=$(extract_version_from_filename "$(basename "$file")")
        echo "$version|$file"
    done | sort -t'|' -k1 -Vr | cut -d'|' -f2
}

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ (—Å–∞–º–æ–≥–æ –Ω–æ–≤–æ–≥–æ) —Ñ–∞–π–ª–∞ –æ–±—Ä–∞–∑–∞
get_latest_bot_image_file() {
    local search_path="$1"
    local files=$(find_bot_image_files "$search_path")
    
    if [[ -z "$files" ]]; then
        echo ""
        return 1
    fi
    
    local latest_file=""
    local latest_version="0.0.0"
    
    while IFS= read -r file; do
        local version=$(extract_version_from_filename "$(basename "$file")")
        if [[ -n "$version" ]] && version_gt "$version" "$latest_version"; then
            latest_version="$version"
            latest_file="$file"
        fi
    done <<< "$files"
    
    echo "$latest_file"
}

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–º–µ–Ω–∏ image –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ tar —Ñ–∞–π–ª–∞
get_image_name_from_tar() {
    local tar_file="$1"
    # –ü–æ—Å–ª–µ docker load –≤—ã–≤–æ–¥–∏—Ç —á—Ç–æ-—Ç–æ —Ç–∏–ø–∞ "Loaded image: rwp_shop:3.23.5"
    # –ù–æ –º—ã –º–æ–∂–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    local filename=$(basename "$tar_file")
    
    if [[ "$filename" == rwp_shop* ]]; then
        echo "rwp_shop"
    elif [[ "$filename" == private-remnawave-telegram-shop-bot* ]]; then
        echo "private-remnawave-telegram-shop-bot"
    elif [[ "$filename" == telegram-shop* ]]; then
        echo "telegram-shop"
    else
        echo "rwp_shop"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
    fi
}

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ image –≤–µ—Ä—Å–∏–∏ –≤ docker-compose —Ñ–∞–π–ª–µ
# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è image
update_compose_image_version() {
    local compose_file="$1"
    local new_version="$2"
    local new_image_name="$3"  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –∏–º—è –Ω–æ–≤–æ–≥–æ image
    
    debug_log "COMPOSE" "=== update_compose_image_version() ==="
    debug_log "COMPOSE" "  compose_file=$compose_file"
    debug_log "COMPOSE" "  new_version=$new_version"
    debug_log "COMPOSE" "  new_image_name=$new_image_name"
    
    if [[ ! -f "$compose_file" ]]; then
        debug_log "COMPOSE" "Compose file not found: $compose_file"
        print_message "ERROR" "Compose —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: $compose_file"
        return 1
    fi
    
    # –ï—Å–ª–∏ –Ω–æ–≤–æ–µ –∏–º—è image –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º rwp_shop (–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–µ)
    [[ -z "$new_image_name" ]] && new_image_name="rwp_shop"
    debug_log "COMPOSE" "Target image name: $new_image_name"
    
    # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∏–º—ë–Ω image –±–æ—Ç–∞
    local image_patterns=(
        "rwp_shop"
        "private-remnawave-telegram-shop-bot"
        "telegram-shop"
        "shopbot"
    )
    
    local found=false
    for pattern in "${image_patterns[@]}"; do
        debug_log "COMPOSE" "Checking for pattern: $pattern"
        if grep -qE "image:\s*['\"]?${pattern}:" "$compose_file"; then
            debug_log "COMPOSE" "Pattern matched: $pattern"
            # –ó–∞–º–µ–Ω—è–µ–º –Ω–∞ –Ω–æ–≤–æ–µ –∏–º—è –∏ –≤–µ—Ä—Å–∏—é
            sed -i -E "s|(image:\s*['\"]?)${pattern}:[0-9]+\.[0-9]+\.[0-9]+|\1${new_image_name}:${new_version}|g" "$compose_file"
            found=true
            debug_log "COMPOSE" "Sed replacement done: ${pattern} -> ${new_image_name}:${new_version}"
            print_message "SUCCESS" "Image –æ–±–Ω–æ–≤–ª—ë–Ω: ${pattern} ‚Üí ${new_image_name}:${new_version}"
            break
        fi
    done
    
    if [[ "$found" == "false" ]]; then
        debug_log "COMPOSE" "No matching image pattern found in compose file"
        print_message "ERROR" "–ù–µ –Ω–∞–π–¥–µ–Ω image –±–æ—Ç–∞ –≤ compose —Ñ–∞–π–ª–µ"
        print_message "INFO" "–ò—Å–∫–∞–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: ${image_patterns[*]}"
        return 1
    fi
    
    debug_log "COMPOSE" "update_compose_image_version() completed successfully"
    return 0
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –ë–î
check_db_health() {
    local db_container="$1"
    local max_attempts="${2:-30}"
    local attempt=1
    
    debug_log "HEALTH" "check_db_health($db_container, max=$max_attempts)"
    
    while [[ $attempt -le $max_attempts ]]; do
        local health=$(docker inspect -f '{{.State.Health.Status}}' "$db_container" 2> "$SILENT_LOG")
        debug_log "HEALTH" "  attempt $attempt: health=$health"
        
        if [[ "$health" == "healthy" ]]; then
            debug_log "HEALTH" "DB healthy via docker healthcheck"
            return 0
        fi
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ pg_isready
        if docker exec "$db_container" pg_isready -U "$DB_USER" > "$SILENT_LOG" 2>&1; then
            debug_log "HEALTH" "DB healthy via pg_isready"
            return 0
        fi
        
        echo -ne "\r  –û–∂–∏–¥–∞–Ω–∏–µ –ë–î... ($attempt/$max_attempts)"
        sleep 1
        ((attempt++))
    done
    
    debug_log "HEALTH" "DB health check failed after $max_attempts attempts"
    echo ""
    return 1
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –±–æ—Ç–∞ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç
check_bot_health() {
    local bot_container="$1"
    local max_attempts="${2:-20}"
    local attempt=1
    
    debug_log "HEALTH" "check_bot_health($bot_container, max=$max_attempts)"
    
    while [[ $attempt -le $max_attempts ]]; do
        local status=$(docker inspect -f '{{.State.Status}}' "$bot_container" 2> "$SILENT_LOG")
        local running=$(docker inspect -f '{{.State.Running}}' "$bot_container" 2> "$SILENT_LOG")
        debug_log "HEALTH" "  attempt $attempt: status=$status, running=$running"
        
        if [[ "$status" == "running" && "$running" == "true" ]]; then
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–µ —Ä–µ—Å—Ç–∞—Ä—Ç—É–µ—Ç
            sleep 2
            local status2=$(docker inspect -f '{{.State.Status}}' "$bot_container" 2> "$SILENT_LOG")
            debug_log "HEALTH" "  stability check: status2=$status2"
            if [[ "$status2" == "running" ]]; then
                debug_log "HEALTH" "Bot healthy and stable"
                return 0
            fi
        fi
        
        echo -ne "\r  –û–∂–∏–¥–∞–Ω–∏–µ –±–æ—Ç–∞... ($attempt/$max_attempts)"
        sleep 1
        ((attempt++))
    done
    
    debug_log "HEALTH" "Bot health check failed after $max_attempts attempts"
    echo ""
    return 1
}

# –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –±—ç–∫–∞–ø –ë–î –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ rollback
get_latest_db_backup() {
    local latest=$(find "$BACKUP_DIR" -maxdepth 1 -type f \( -name "lazarus_db_*.tar.gz" -o -name "lazarus_db_*.tar.gz.enc" \) -printf '%T@ %p\n' 2> "$SILENT_LOG" | sort -rn | head -1 | awk '{print $2}')
    echo "$latest"
}

# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–æ—Ç–∞
update_bot() {
    debug_log "UPDATE" "=== Starting update_bot() ==="
    clear_screen
    echo -e "${GREEN}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo -e "${GREEN}${BOLD}  –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–æ—Ç–∞${RESET}"
    echo -e "${GREEN}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo ""
    
    # === –≠–¢–ê–ü 1: –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–£–¢–ò –ö –ë–û–¢–£ ===
    debug_log "UPDATE" "[STAGE 1] Checking bot path..."
    local bot_path_ok=false
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–∏–π BOT_PATH
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" && ( -f "$BOT_PATH/docker-compose.yml" || -f "$BOT_PATH/compose.yaml" ) ]]; then
        bot_path_ok=true
        debug_log "UPDATE" "Bot path OK: $BOT_PATH"
    fi
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω ‚Äî –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏
    if [[ "$bot_path_ok" == "false" ]]; then
        debug_log "UPDATE" "Bot path not configured, starting search..."
        print_message "INFO" "–ü—É—Ç—å –∫ –±–æ—Ç—É –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫..."
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        if [[ -d "$DEFAULT_BOT_PATH" && ( -f "$DEFAULT_BOT_PATH/docker-compose.yml" || -f "$DEFAULT_BOT_PATH/compose.yaml" ) ]]; then
            debug_log "UPDATE" "Found bot at default path: $DEFAULT_BOT_PATH"
            print_message "SUCCESS" "–ù–∞–π–¥–µ–Ω –±–æ—Ç –≤ $DEFAULT_BOT_PATH"
            BOT_PATH="$DEFAULT_BOT_PATH"
            save_config
            bot_path_ok=true
        else
            debug_log "UPDATE" "Default path not found, running ensure_bot_path()..."
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–ø–æ–∏—Å–∫
            if ! ensure_bot_path; then
                debug_log "UPDATE" "ensure_bot_path() failed, prompting manual input"
                echo ""
                print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–∫—É –±–æ—Ç–∞!"
                echo ""
                echo -e "–û–∂–∏–¥–∞–µ–º—ã–µ –ø—É—Ç–∏ (–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏):"
                echo -e "  ${CYAN}/opt/private-remnawave-telegram-shop-bot/${RESET}"
                echo -e "  ${CYAN}/opt/remnawave-telegram-shop/${RESET}"
                echo ""
                echo -e "–û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:"
                echo -e "  ‚îú‚îÄ‚îÄ compose.yaml (–∏–ª–∏ docker-compose.yml)"
                echo -e "  ‚îú‚îÄ‚îÄ .env"
                echo -e "  ‚îî‚îÄ‚îÄ rwp_shop-X.Y.Z-amd64.tar"
                echo ""
                read -erp "–£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –≤—Ä—É—á–Ω—É—é (Enter - $DEFAULT_BOT_PATH): " manual_path
                manual_path="${manual_path:-$DEFAULT_BOT_PATH}"
                
                if [[ -d "$manual_path" ]]; then
                    debug_log "UPDATE" "Manual path accepted: $manual_path"
                    BOT_PATH="$manual_path"
                    save_config
                    bot_path_ok=true
                else
                    debug_log "UPDATE" "Manual path not found: $manual_path"
                    print_message "ERROR" "–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: $manual_path"
                    read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
                    return 1
                fi
            else
                debug_log "UPDATE" "ensure_bot_path() success, BOT_PATH=$BOT_PATH"
                bot_path_ok=true
            fi
        fi
    fi
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–∏
    debug_log "UPDATE" "Final path check: bot_path_ok=$bot_path_ok, BOT_PATH=$BOT_PATH"
    if [[ "$bot_path_ok" == "false" || -z "$BOT_PATH" || ! -d "$BOT_PATH" ]]; then
        debug_log "UPDATE" "Path validation failed, aborting"
        print_message "ERROR" "–ü—É—Ç—å –∫ –±–æ—Ç—É –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!"
        read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
        return 1
    fi
    
    # === –≠–¢–ê–ü 2: –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –¢–ï–ö–£–©–ï–ô –£–°–¢–ê–ù–û–í–ö–ï ===
    debug_log "UPDATE" "[STAGE 2] Getting current installation info..."
    local current_version=$(get_raw_bot_version)
    debug_log "UPDATE" "Current version raw: $current_version"
    if [[ -z "$current_version" || "$current_version" == "Unknown" ]]; then
        print_message "WARN" "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–µ–∫—É—â—É—é –≤–µ—Ä—Å–∏—é –±–æ—Ç–∞"
        current_version="0.0.0"
    fi
    
    local container_status=$(get_container_status)
    debug_log "UPDATE" "Container status: $container_status"
    
    echo -e "–ü—É—Ç—å –∫ –±–æ—Ç—É:     ${CYAN}$BOT_PATH${RESET}"
    echo -e "–¢–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è:  ${CYAN}$current_version${RESET}"
    echo -e "–°—Ç–∞—Ç—É—Å:          ${CYAN}$container_status${RESET}"
    echo ""
    
    # === –≠–¢–ê–ü 3: –ü–û–ò–°–ö –§–ê–ô–õ–û–í –û–ë–†–ê–ó–û–í ===
    debug_log "UPDATE" "[STAGE 3] Searching for image files..."
    print_message "INFO" "–ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –æ–±—Ä–∞–∑–∞ –≤ /opt/, /root/, $BOT_PATH..."
    local image_files=$(find_all_bot_image_files)
    debug_log "UPDATE" "Image files found: $(echo "$image_files" | wc -l) files"
    
    if [[ -z "$image_files" ]]; then
        debug_log "UPDATE" "No image files found, aborting"
        echo ""
        print_message "WARN" "–§–∞–π–ª—ã –æ–±—Ä–∞–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        echo ""
        echo -e "${BOLD}–ü—É—Ç–∏ –ø–æ–∏—Å–∫–∞:${RESET}"
        echo -e "  ${CYAN}/opt/${RESET} (—Å –ø–æ–¥–ø–∞–ø–∫–∞–º–∏)"
        echo -e "  ${CYAN}/root/${RESET} (—Å –ø–æ–¥–ø–∞–ø–∫–∞–º–∏)"
        [[ -n "$BOT_PATH" ]] && echo -e "  ${CYAN}$BOT_PATH/${RESET}"
        echo ""
        echo -e "${BOLD}–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤:${RESET}"
        echo -e "  ${CYAN}rwp_shop-X.Y.Z-amd64.tar${RESET}  (–Ω–æ–≤—ã–π, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π)"
        echo -e "  ${GRAY}private-remnawave-telegram-shop-bot-X.Y.Z-amd64.tar${RESET}  (—Å—Ç–∞—Ä—ã–π)"
        echo ""
        echo -e "–°–∫–∞—á–∞–π—Ç–µ —Ñ–∞–π–ª –∏–∑ –ø—Ä–∏–≤–∞—Ç–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞ –∏ –ø–æ–ª–æ–∂–∏—Ç–µ –≤:"
        echo -e "  ${BOLD}$BOT_PATH/${RESET}"
        echo ""
        read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
        return 1
    fi
    
    # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    local files_count=$(echo "$image_files" | wc -l)
    debug_log "UPDATE" "Files count: $files_count"
    print_message "SUCCESS" "–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: $files_count"
    
    # === –≠–¢–ê–ü 4: –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –ù–ê–ô–î–ï–ù–ù–´–• –§–ê–ô–õ–û–í ===
    debug_log "UPDATE" "[STAGE 4] Displaying found files..."
    echo ""
    echo -e "${BOLD}–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –æ–±—Ä–∞–∑–æ–≤ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏):${RESET}"
    local i=1
    local files_array=()
    while IFS= read -r file; do
        [[ -z "$file" ]] && continue
        local fname=$(basename "$file")
        local fdir=$(dirname "$file")
        local fversion=$(extract_version_from_filename "$fname")
        local fsize=$(du -h "$file" 2>/dev/null | cut -f1)
        local fimage=$(get_image_name_from_tar "$file")
        files_array+=("$file")
        debug_log "UPDATE" "  [$i] $fname (v$fversion, size=$fsize, image=$fimage)"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
        local type_label=""
        if [[ "$fname" == rwp_shop* ]]; then
            type_label="${GREEN}[–Ω–æ–≤—ã–π]${RESET}"
        elif [[ "$fname" == private-remnawave* ]]; then
            type_label="${GRAY}[—Å—Ç–∞—Ä—ã–π]${RESET}"
        fi
        
        # –ü–æ–¥—Å–≤–µ—Ç–∫–∞ –µ—Å–ª–∏ –≤–µ—Ä—Å–∏—è –Ω–æ–≤–µ–µ
        if version_gt "$fversion" "$current_version"; then
            echo -e " ${GREEN}$i. $fname${RESET}"
            echo -e "    v$fversion | $fsize | $type_label ${GREEN}‚Üê –û–ë–ù–û–í–õ–ï–ù–ò–ï${RESET}"
            echo -e "    ${GRAY}$fdir${RESET}"
        elif [[ "$fversion" == "$current_version" ]]; then
            echo -e " ${YELLOW}$i. $fname${RESET}"
            echo -e "    v$fversion | $fsize | $type_label ${YELLOW}(—Ç–µ–∫—É—â–∞—è)${RESET}"
            echo -e "    ${GRAY}$fdir${RESET}"
        else
            echo -e " ${GRAY}$i. $fname${RESET}"
            echo -e "    v$fversion | $fsize | $type_label"
            echo -e "    ${GRAY}$fdir${RESET}"
        fi
        ((i++))
    done <<< "$image_files"
    
    echo ""
    echo " 0. –ù–∞–∑–∞–¥"
    echo ""
    
    # === –≠–¢–ê–ü 5: –í–´–ë–û–† –§–ê–ô–õ–ê ===
    debug_log "UPDATE" "[STAGE 5] File selection..."
    # –ü–µ—Ä–≤—ã–π —Ñ–∞–π–ª –≤ —Å–ø–∏—Å–∫–µ = —Å–∞–º–∞—è –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è (–ø–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏)
    local latest_file="${files_array[0]}"
    local latest_version=$(extract_version_from_filename "$(basename "$latest_file")")
    debug_log "UPDATE" "Latest file: $(basename "$latest_file"), version: $latest_version"
    
    local choice=""
    if ! version_gt "$latest_version" "$current_version"; then
        debug_log "UPDATE" "Current version is latest ($current_version >= $latest_version)"
        print_message "INFO" "–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è –≤–µ—Ä—Å–∏—è ($current_version)"
        echo ""
        read -erp "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∏ (–∏–ª–∏ Enter - –Ω–∞–∑–∞–¥): " choice
        [[ -z "$choice" || "$choice" == "0" ]] && return 0
    else
        debug_log "UPDATE" "Update available: $current_version -> $latest_version"
        echo -e "${YELLOW}${BOLD}–î–æ—Å—Ç—É–ø–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: $current_version ‚Üí $latest_version${RESET}"
        echo ""
        read -erp "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª (Enter - –ø–æ—Å–ª–µ–¥–Ω–∏–π v$latest_version): " choice
        [[ -z "$choice" ]] && choice=1
    fi
    
    debug_log "UPDATE" "User choice: $choice"
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—ã–±–æ—Ä–∞
    if [[ "$choice" == "0" ]]; then return 0; fi
    if ! [[ "$choice" =~ ^[0-9]+$ ]] || [[ "$choice" -lt 1 ]] || [[ "$choice" -gt "${#files_array[@]}" ]]; then
        debug_log "UPDATE" "Invalid choice: $choice (valid: 1-${#files_array[@]})"
        print_message "ERROR" "–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä"
        sleep 1
        return 1
    fi
    
    local selected_file="${files_array[$((choice-1))]}"
    local selected_version=$(extract_version_from_filename "$(basename "$selected_file")")
    local selected_image_name=$(get_image_name_from_tar "$selected_file")
    debug_log "UPDATE" "Selected: file=$selected_file, version=$selected_version, image=$selected_image_name"
    
    # === –≠–¢–ê–ü 6: –ü–û–î–¢–í–ï–†–ñ–î–ï–ù–ò–ï ===
    debug_log "UPDATE" "[STAGE 6] User confirmation..."
    echo ""
    echo -e "${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo -e "${BOLD}–í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª:${RESET} $(basename "$selected_file")"
    echo -e "${BOLD}–í–µ—Ä—Å–∏—è:${RESET}      $selected_version"
    echo -e "${BOLD}Image:${RESET}       $selected_image_name"
    echo -e "${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo ""
    
    echo -e "${YELLOW}${BOLD}‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï ‚Äî –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ö –ü–†–û–ß–¢–ï–ù–ò–Æ:${RESET}"
    echo ""
    echo -e " ${GREEN}‚úì${RESET} –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –ø–æ–ª–Ω—ã–π –±—ç–∫–∞–ø (–ë–î + —Ñ–∞–π–ª—ã)"
    echo -e " ${GREEN}‚úì${RESET} –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –æ—Ç–¥–µ–ª—å–Ω—ã–π –±—ç–∫–∞–ø –ë–î"
    echo -e " ${GREEN}‚úì${RESET} Compose —Ñ–∞–π–ª –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª—ë–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"
    echo ""
    echo -e " ${YELLOW}!${RESET} –ë–æ—Ç –±—É–¥–µ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ –≤—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"
    echo -e " ${YELLOW}!${RESET} –ü—Ä–∏ –æ—à–∏–±–∫–µ –¥–æ—Å—Ç—É–ø–µ–Ω –æ—Ç–∫–∞—Ç –∏–∑ –±—ç–∫–∞–ø–∞"
    echo ""
    
    read -erp "–ù–∞—á–∞—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ? (y/N): " confirm
    if [[ "$confirm" != "y" && "$confirm" != "Y" ]]; then
        debug_log "UPDATE" "User cancelled update"
        print_message "INFO" "–û—Ç–º–µ–Ω–µ–Ω–æ"
        return 0
    fi
    
    # === –≠–¢–ê–ü 7: –°–û–ó–î–ê–ù–ò–ï –ë–≠–ö–ê–ü–û–í ===
    debug_log "UPDATE" "[STAGE 7] Creating pre-update backups..."
    echo ""
    echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –°–û–ó–î–ê–ù–ò–ï –ë–≠–ö–ê–ü–û–í ‚ïê‚ïê‚ïê${RESET}"
    log_message "INFO" "Starting bot update: $current_version -> $selected_version"
    
    # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –±—ç–∫–∞–ø–æ–≤
    local update_start_time=$(date +%s)
    
    debug_log "UPDATE" "Creating full backup..."
    print_message "INFO" "[1/7] –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –±—ç–∫–∞–ø–∞..."
    create_backup "full"
    local backup_result=$?
    debug_log "UPDATE" "Full backup result: $backup_result"
    
    if [[ $backup_result -ne 0 ]]; then
        debug_log "UPDATE" "Full backup FAILED, aborting update"
        print_message "ERROR" "–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞! –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ."
        log_message "ERROR" "Bot update aborted: full backup failed"
        read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
        return 1
    fi
    print_message "SUCCESS" "–ü–æ–ª–Ω—ã–π –±—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω"
    
    debug_log "UPDATE" "Creating DB backup..."
    print_message "INFO" "[2/7] –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –ë–î..."
    create_backup "db_only"
    local db_backup_result=$?
    debug_log "UPDATE" "DB backup result: $db_backup_result"
    
    if [[ $db_backup_result -ne 0 ]]; then
        print_message "WARN" "–ë—ç–∫–∞–ø –ë–î –Ω–µ —Å–æ–∑–¥–∞–Ω (–ø–æ–ª–Ω—ã–π –±—ç–∫–∞–ø –µ—Å—Ç—å)"
    else
        print_message "SUCCESS" "–ë—ç–∫–∞–ø –ë–î —Å–æ–∑–¥–∞–Ω"
    fi
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –±—ç–∫–∞–ø—É –ë–î –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ rollback
    local rollback_backup=$(get_latest_db_backup)
    debug_log "UPDATE" "Rollback backup: $rollback_backup"
    
    # === –≠–¢–ê–ü 8: –ó–ê–ì–†–£–ó–ö–ê DOCKER IMAGE ===
    debug_log "UPDATE" "[STAGE 8] Loading Docker image..."
    echo ""
    echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –ó–ê–ì–†–£–ó–ö–ê IMAGE ‚ïê‚ïê‚ïê${RESET}"
    print_message "INFO" "[3/7] –ó–∞–≥—Ä—É–∑–∫–∞ Docker image..."
    debug_log "DOCKER" "Running: docker load -i $selected_file"
    
    local load_output
    load_output=$(docker load -i "$selected_file" 2>&1)
    local load_result=$?
    debug_log "DOCKER" "docker load result: $load_result"
    debug_log "DOCKER" "docker load output: $load_output"
    
    if [[ $load_result -ne 0 ]]; then
        debug_log "DOCKER" "docker load FAILED"
        print_message "ERROR" "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ image!"
        echo "$load_output"
        log_message "ERROR" "Bot update failed: docker load error"
        echo ""
        print_message "INFO" "–ë—ç–∫–∞–ø—ã —Å–æ–∑–¥–∞–Ω—ã. –î–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ—Ç–µ—Ä—è–Ω—ã."
        read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
        return 1
    fi
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ –∏–º—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ image
    local loaded_image=$(echo "$load_output" | grep -oE "Loaded image: [^ ]+" | cut -d' ' -f3)
    debug_log "DOCKER" "Loaded image from output: $loaded_image"
    if [[ -n "$loaded_image" ]]; then
        print_message "SUCCESS" "Image –∑–∞–≥—Ä—É–∂–µ–Ω: $loaded_image"
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è image –±–µ–∑ –≤–µ—Ä—Å–∏–∏
        selected_image_name="${loaded_image%%:*}"
        debug_log "DOCKER" "Image name extracted: $selected_image_name"
    else
        print_message "SUCCESS" "Image –∑–∞–≥—Ä—É–∂–µ–Ω"
        echo "$load_output" | grep -i "loaded" | head -1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ image –ø–æ—è–≤–∏–ª—Å—è
    debug_log "DOCKER" "Verifying image in docker images..."
    if ! docker images | grep -q "$selected_image_name.*$selected_version"; then
        debug_log "DOCKER" "Image not found in list, showing available:"
        print_message "WARN" "Image –∑–∞–≥—Ä—É–∂–µ–Ω, –Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–ø–∏—Å–∫–µ"
        docker images | grep -E "(rwp_shop|telegram-shop|private-remnawave)" | head -5
    else
        debug_log "DOCKER" "Image verified in docker images list"
    fi
    
    # === –≠–¢–ê–ü 9: –û–ë–ù–û–í–õ–ï–ù–ò–ï COMPOSE –§–ê–ô–õ–ê ===
    debug_log "UPDATE" "[STAGE 9] Updating compose file..."
    echo ""
    echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –û–ë–ù–û–í–õ–ï–ù–ò–ï –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò ‚ïê‚ïê‚ïê${RESET}"
    
    local compose_file=""
    [[ -f "$BOT_PATH/compose.yaml" ]] && compose_file="$BOT_PATH/compose.yaml"
    [[ -f "$BOT_PATH/docker-compose.yml" ]] && compose_file="$BOT_PATH/docker-compose.yml"
    debug_log "COMPOSE" "Compose file: $compose_file"
    
    if [[ -z "$compose_file" ]]; then
        debug_log "COMPOSE" "No compose file found in $BOT_PATH"
        print_message "ERROR" "Compose —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!"
        log_message "ERROR" "Bot update failed: compose file not found"
        read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
        return 1
    fi
    
    print_message "INFO" "[4/7] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ compose —Ñ–∞–π–ª–∞..."
    
    # –°–æ–∑–¥–∞—ë–º –±—ç–∫–∞–ø compose —Ñ–∞–π–ª–∞
    debug_log "COMPOSE" "Creating backup: ${compose_file}.pre-update.bak"
    cp "$compose_file" "${compose_file}.pre-update.bak"
    
    debug_log "COMPOSE" "Calling update_compose_image_version($compose_file, $selected_version, $selected_image_name)"
    if ! update_compose_image_version "$compose_file" "$selected_version" "$selected_image_name"; then
        debug_log "COMPOSE" "update_compose_image_version FAILED, restoring backup"
        print_message "ERROR" "–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è compose!"
        mv "${compose_file}.pre-update.bak" "$compose_file"
        log_message "ERROR" "Bot update failed: compose update error"
        echo ""
        print_message "INFO" "Compose —Ñ–∞–π–ª –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑ –±—ç–∫–∞–ø–∞."
        read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
        return 1
    fi
    
    # === –≠–¢–ê–ü 10: –û–°–¢–ê–ù–û–í–ö–ê –ö–û–ù–¢–ï–ô–ù–ï–†–û–í ===
    debug_log "UPDATE" "[STAGE 10] Stopping containers..."
    echo ""
    echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –ü–ï–†–ï–ó–ê–ü–£–°–ö –ö–û–ù–¢–ï–ô–ù–ï–†–û–í ‚ïê‚ïê‚ïê${RESET}"
    print_message "INFO" "[5/7] –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤..."
    
    cd "$BOT_PATH"
    debug_log "CONTAINER" "Running: docker compose down in $BOT_PATH"
    docker compose down 2> "$SILENT_LOG"
    local down_result=$?
    debug_log "CONTAINER" "docker compose down result: $down_result"
    sleep 2
    
    # === –≠–¢–ê–ü 11: –ó–ê–ü–£–°–ö –ö–û–ù–¢–ï–ô–ù–ï–†–û–í ===
    debug_log "UPDATE" "[STAGE 11] Starting containers..."
    print_message "INFO" "[6/7] –ó–∞–ø—É—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤..."
    debug_log "CONTAINER" "Running: docker compose up -d"
    docker compose up -d 2> "$SILENT_LOG"
    local up_result=$?
    debug_log "CONTAINER" "docker compose up result: $up_result"
    
    # === –≠–¢–ê–ü 12: –ü–†–û–í–ï–†–ö–ê –ó–î–û–†–û–í–¨–Ø ===
    debug_log "UPDATE" "[STAGE 12] Health checks..."
    print_message "INFO" "[7/7] –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏..."
    echo ""
    
    # –ñ–¥—ë–º –ë–î
    if [[ -n "$DB_CONTAINER_NAME" ]]; then
        debug_log "HEALTH" "Checking DB health for: $DB_CONTAINER_NAME"
        echo -n "  –ü—Ä–æ–≤–µ—Ä–∫–∞ –ë–î..."
        if check_db_health "$DB_CONTAINER_NAME" 30; then
            debug_log "HEALTH" "DB health check: OK"
            echo -e " ${GREEN}OK${RESET}"
        else
            debug_log "HEALTH" "DB health check: WARN (may still be initializing)"
            echo -e " ${YELLOW}WARN${RESET}"
            print_message "WARN" "–ë–î –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç, –Ω–æ –º–æ–∂–µ—Ç –µ—â—ë –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è"
        fi
    fi
    
    # –ñ–¥—ë–º –±–æ—Ç–∞
    if [[ -n "$BOT_CONTAINER_NAME" ]]; then
        debug_log "HEALTH" "Checking bot health for: $BOT_CONTAINER_NAME"
        echo -n "  –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–æ—Ç–∞..."
        if check_bot_health "$BOT_CONTAINER_NAME" 20; then
            debug_log "HEALTH" "Bot health check: OK"
            echo -e " ${GREEN}OK${RESET}"
        else
            debug_log "HEALTH" "Bot health check: FAIL"
            echo -e " ${RED}FAIL${RESET}"
        fi
    fi
    
    sleep 2
    
    # === –≠–¢–ê–ü 13: –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê ===
    debug_log "UPDATE" "[STAGE 13] Final verification..."
    local new_version=$(get_raw_bot_version)
    local new_status=$(get_container_status)
    debug_log "UPDATE" "New version: $new_version, status: $new_status"
    
    echo ""
    echo -e "${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    
    if [[ "$new_status" == "Online" ]]; then
        if [[ "$new_version" == "$selected_version" ]]; then
            debug_log "UPDATE" "=== Update SUCCESS: $current_version -> $new_version ==="
            echo -e "${GREEN}${BOLD}‚úì –û–ë–ù–û–í–õ–ï–ù–ò–ï –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û${RESET}"
            echo ""
            echo -e "  –í–µ—Ä—Å–∏—è: ${CYAN}$current_version${RESET} ‚Üí ${GREEN}$new_version${RESET}"
            echo -e "  –°—Ç–∞—Ç—É—Å: ${GREEN}$new_status${RESET}"
            log_message "SUCCESS" "Bot updated successfully: $current_version -> $new_version"
            
            # –£–¥–∞–ª—è–µ–º –±—ç–∫–∞–ø compose —Ñ–∞–π–ª–∞
            debug_log "UPDATE" "Removing compose backup file"
            rm -f "${compose_file}.pre-update.bak"
            
            echo ""
            read -erp "–£–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª –æ–±—Ä–∞–∑–∞ $(basename "$selected_file")? (y/N): " del_confirm
            if [[ "$del_confirm" == "y" || "$del_confirm" == "Y" ]]; then
                debug_log "UPDATE" "Deleting image file: $selected_file"
                rm -f "$selected_file"
                print_message "SUCCESS" "–§–∞–π–ª —É–¥–∞–ª—ë–Ω"
            fi
        else
            debug_log "UPDATE" "=== Update WARN: version mismatch (expected=$selected_version, got=$new_version) ==="
            echo -e "${YELLOW}${BOLD}‚ö† –û–ë–ù–û–í–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –° –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï–ú${RESET}"
            echo ""
            echo -e "  –û–∂–∏–¥–∞–ª–∞—Å—å –≤–µ—Ä—Å–∏—è: ${CYAN}$selected_version${RESET}"
            echo -e "  –¢–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è:   ${YELLOW}$new_version${RESET}"
            echo -e "  –°—Ç–∞—Ç—É—Å:           ${GREEN}$new_status${RESET}"
            echo ""
            print_message "INFO" "–ë–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –≤–µ—Ä—Å–∏—è –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è"
            log_message "WARN" "Bot update: version mismatch (expected=$selected_version, got=$new_version)"
        fi
    else
        debug_log "UPDATE" "=== Update FAILED: container not running (status=$new_status) ==="
        echo -e "${RED}${BOLD}‚úó –û–ë–ù–û–í–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –° –û–®–ò–ë–ö–û–ô${RESET}"
        echo ""
        echo -e "  –°—Ç–∞—Ç—É—Å: ${RED}$new_status${RESET}"
        echo ""
        log_message "ERROR" "Bot update failed: container not running after update"
        
        echo -e "${YELLOW}–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:${RESET}"
        echo "  docker compose ps"
        echo "  docker compose logs -f bot"
        echo ""
        
        echo -e "${YELLOW}–î–ª—è –æ—Ç–∫–∞—Ç–∞:${RESET}"
        if [[ -n "$rollback_backup" ]]; then
            echo "  1. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏–∑ –±—ç–∫–∞–ø–∞ (–º–µ–Ω—é 3)"
            echo "  2. –ò–ª–∏ –≤—Ä—É—á–Ω—É—é: docker compose down && mv ${compose_file}.pre-update.bak $compose_file && docker compose up -d"
        fi
        echo ""
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏
        echo -e "${GRAY}–ü–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏ –±–æ—Ç–∞:${RESET}"
        docker compose logs --tail 10 bot 2> "$SILENT_LOG" | tail -5
    fi
    
    echo -e "${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo ""
    read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
    return 0
}

detect_bot_installation() {
    debug_log "SCAN" "=== detect_bot_installation ==="
    print_message "INFO" "–ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞..."
    scan_system_for_bot 
    if [[ -n "$FOUND_PATH" ]]; then
        debug_log "SCAN" "Found installation: PATH=$FOUND_PATH, BOT=$FOUND_BOT, DB=$FOUND_DB"
        echo ""; print_message "SUCCESS" "–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∞!"
        echo -e "   –ü—É—Ç—å:      ${BOLD}$FOUND_PATH${RESET}"
        [[ -n "$FOUND_BOT" ]] && echo -e "   –ë–æ—Ç:       ${BOLD}$FOUND_BOT${RESET}"
        [[ -n "$FOUND_DB" ]]  && echo -e "   –ë–î:        ${BOLD}$FOUND_DB${RESET}"
        echo ""
        read -erp "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏? (Y/n): " confirm
        if [[ -z "$confirm" || "$confirm" =~ ^[Yy]$ ]]; then
            debug_log "SCAN" "User confirmed, applying settings"
            BOT_PATH="$FOUND_PATH"
            if [[ -n "$FOUND_BOT" ]]; then BOT_CONTAINER_NAME="$FOUND_BOT"; fi
            if [[ -n "$FOUND_DB" ]]; then DB_CONTAINER_NAME="$FOUND_DB"; fi
            save_config; print_message "SUCCESS" "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã."; return 0
        else
            debug_log "SCAN" "User declined auto-detected settings"
        fi
    else
        debug_log "SCAN" "No installation found by auto-detection"
    fi
    print_message "WARN" "–ê–≤—Ç–æ-–ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞. –í–≤–µ–¥–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤—Ä—É—á–Ω—É—é –≤ –ù–∞—Å—Ç—Ä–æ–π–∫–∞—Ö."
    return 1
}

# --- –ü–†–û–í–ï–†–ö–ê –ù–ï–°–û–û–¢–í–ï–¢–°–¢–í–ò–ô ---

check_config_mismatch() {
    debug_log "CONFIG" "=== check_config_mismatch ==="
    debug_log "CONFIG" "BOT_CONTAINER_NAME=$BOT_CONTAINER_NAME, IGNORE_MISMATCH=$IGNORE_MISMATCH"
    if [[ -n "$BOT_CONTAINER_NAME" && "$IGNORE_MISMATCH" != "true" ]]; then
        debug_log "CONFIG" "Checking if container exists..."
        if ! docker inspect "$BOT_CONTAINER_NAME" > /dev/null 2> "$SILENT_LOG"; then
            debug_log "CONFIG" "Container '$BOT_CONTAINER_NAME' NOT found, scanning for alternatives"
            scan_system_for_bot
            if [[ -n "$FOUND_BOT" && "$FOUND_BOT" != "$BOT_CONTAINER_NAME" ]]; then
                debug_log "CONFIG" "Found alternative: $FOUND_BOT (was: $BOT_CONTAINER_NAME)"
                echo ""; print_message "WARN" "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä '$BOT_CONTAINER_NAME' –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–æ –Ω–∞–π–¥–µ–Ω '$FOUND_BOT'."
                echo -e " ${GREEN}–ü—Ä–µ–¥–ª–∞–≥–∞—é –æ–±–Ω–æ–≤–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.${RESET}"
                read -erp "–û–±–Ω–æ–≤–∏—Ç—å? (Y/n): " upd
                if [[ -z "$upd" || "$upd" =~ ^[Yy]$ ]]; then
                    debug_log "CONFIG" "User confirmed update to new container"
                    BOT_CONTAINER_NAME="$FOUND_BOT"
                    [[ -n "$FOUND_DB" ]] && DB_CONTAINER_NAME="$FOUND_DB"
                    [[ -n "$FOUND_PATH" ]] && BOT_PATH="$FOUND_PATH"
                    save_config; print_message "SUCCESS" "–û–±–Ω–æ–≤–ª–µ–Ω–æ."; sleep 1
                else
                    debug_log "CONFIG" "User declined, setting IGNORE_MISMATCH=true"
                    IGNORE_MISMATCH="true"; save_config
                fi
            fi
        else
            debug_log "CONFIG" "Container '$BOT_CONTAINER_NAME' exists"
        fi
    fi
}

ensure_bot_path() {
    debug_log "CONFIG" "=== ensure_bot_path ==="
    debug_log "CONFIG" "Current: BOT_PATH=$BOT_PATH, BOT=$BOT_CONTAINER_NAME, DB=$DB_CONTAINER_NAME"
    
    if [[ -z "$BOT_CONTAINER_NAME" || -z "$DB_CONTAINER_NAME" ]]; then
        debug_log "CONFIG" "Container names empty, starting detection"
        echo ""; print_message "WARN" "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –ø—É—Å—Ç—ã."
        detect_bot_installation; load_or_create_config 
    fi

    local path_valid=false
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" && ( -f "$BOT_PATH/docker-compose.yml" || -f "$BOT_PATH/compose.yaml" ) ]]; then path_valid=true; fi
    debug_log "CONFIG" "path_valid=$path_valid (BOT_PATH=$BOT_PATH)"
    
    local container_valid=false
    if [[ -n "$BOT_CONTAINER_NAME" ]] && docker inspect "$BOT_CONTAINER_NAME" > /dev/null 2> "$SILENT_LOG"; then container_valid=true; fi
    debug_log "CONFIG" "container_valid=$container_valid (BOT_CONTAINER=$BOT_CONTAINER_NAME)"
    
    local db_valid=false
    if [[ -n "$DB_CONTAINER_NAME" ]] && docker inspect "$DB_CONTAINER_NAME" > /dev/null 2> "$SILENT_LOG"; then db_valid=true; fi
    debug_log "CONFIG" "db_valid=$db_valid (DB_CONTAINER=$DB_CONTAINER_NAME)"

    if [[ "$path_valid" == "false" || "$container_valid" == "false" || "$db_valid" == "false" ]]; then
        debug_log "CONFIG" "Some validations failed, attempting auto-detection"
        if [[ "$path_valid" == "false" ]]; then
            detect_bot_installation; load_or_create_config
            if [[ -n "$BOT_PATH" ]]; then path_valid=true; fi
            if [[ -n "$BOT_CONTAINER_NAME" ]]; then container_valid=true; fi
            if [[ -n "$DB_CONTAINER_NAME" ]]; then db_valid=true; fi
            debug_log "CONFIG" "After detection: path=$path_valid, container=$container_valid, db=$db_valid"
        fi

        if [[ -z "$BOT_PATH" || ! -d "$BOT_PATH" ]]; then
            debug_log "CONFIG" "BOT_PATH still invalid, prompting user"
            echo ""; print_message "ACTION" "–£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ –±–æ—Ç–∞ –≤—Ä—É—á–Ω—É—é."
            read -erp "–ü—É—Ç—å (Enter –¥–ª—è '$DEFAULT_BOT_PATH'): " input_path
            BOT_PATH="${input_path:-$DEFAULT_BOT_PATH}"
            debug_log "CONFIG" "User entered BOT_PATH=$BOT_PATH"
            if [[ ! -d "$BOT_PATH" ]]; then 
                debug_log "CONFIG" "ERROR: Path does not exist"
                print_message "ERROR" "–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!"; return 1
            fi
            save_config
        fi

        if [[ -z "$BOT_CONTAINER_NAME" ]] || ! docker inspect "$BOT_CONTAINER_NAME" > /dev/null 2> "$SILENT_LOG"; then
            debug_log "CONFIG" "BOT_CONTAINER_NAME invalid, prompting user"
            echo ""; print_message "WARN" "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –±–æ—Ç–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω."
            print_message "ACTION" "–í–≤–µ–¥–∏—Ç–µ –∏–º—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –±–æ—Ç–∞ (–∫–∞–∫ –≤ 'docker ps')."
            read -erp "–ò–º—è (Enter –¥–ª—è '$DEFAULT_BOT_CONTAINER'): " input_name
            BOT_CONTAINER_NAME="${input_name:-$DEFAULT_BOT_CONTAINER}"
            debug_log "CONFIG" "User entered BOT_CONTAINER_NAME=$BOT_CONTAINER_NAME"
            save_config
        fi

        if [[ -z "$DB_CONTAINER_NAME" ]] || ! docker inspect "$DB_CONTAINER_NAME" > /dev/null 2> "$SILENT_LOG"; then
            debug_log "CONFIG" "DB_CONTAINER_NAME invalid, prompting user"
            echo ""; print_message "WARN" "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–∞–∑—ã –î–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω."
            print_message "ACTION" "–í–≤–µ–¥–∏—Ç–µ –∏–º—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –ë–î."
            read -erp "–ò–º—è –ë–î (Enter –¥–ª—è '$DEFAULT_DB_CONTAINER'): " input_db
            DB_CONTAINER_NAME="${input_db:-$DEFAULT_DB_CONTAINER}"
            debug_log "CONFIG" "User entered DB_CONTAINER_NAME=$DB_CONTAINER_NAME"
            save_config
        fi
    fi
    debug_log "CONFIG" "=== ensure_bot_path completed ==="
    return 0
}

save_config() {
    debug_log "CONFIG" "=== save_config ==="
    debug_log "CONFIG" "Creating config dir: $INSTALL_DIR"
    mkdir -p "$INSTALL_DIR"
    debug_log "CONFIG" "Writing config to: $CONFIG_FILE"
    cat > "$CONFIG_FILE" <<EOF
BOT_TOKEN="$BOT_TOKEN"
CHAT_ID="$CHAT_ID"
TG_MESSAGE_THREAD_ID="$TG_MESSAGE_THREAD_ID"
BOT_PATH="$BOT_PATH"
DB_USER="$DB_USER"
SCHEDULE_FULL="$SCHEDULE_FULL"
SCHEDULE_DB="$SCHEDULE_DB"
SCHEDULE_FILES="$SCHEDULE_FILES"
MAX_BACKUPS_COUNT="$MAX_BACKUPS_COUNT"
BOT_CONTAINER_NAME="$BOT_CONTAINER_NAME"
DB_CONTAINER_NAME="$DB_CONTAINER_NAME"
IGNORE_MISMATCH="$IGNORE_MISMATCH"
EXCLUDE_DIRS="$EXCLUDE_DIRS"
MAX_FILE_SIZE_MB="$MAX_FILE_SIZE_MB"
REMOTE_STORAGE_TYPE="$REMOTE_STORAGE_TYPE"
REMOTE_STORAGE_URL="$REMOTE_STORAGE_URL"
REMOTE_STORAGE_USER="$REMOTE_STORAGE_USER"
REMOTE_STORAGE_PASS="$REMOTE_STORAGE_PASS"
BACKUP_PASSWORD="$BACKUP_PASSWORD"
SEND_TO_TELEGRAM="$SEND_TO_TELEGRAM"
TG_SEND_FILE="$TG_SEND_FILE"
SEND_TO_REMOTE="$SEND_TO_REMOTE"
DELETE_MODE="$DELETE_MODE"
RETENTION_DAYS="$RETENTION_DAYS"
MAX_BACKUP_SIZE_MB="$MAX_BACKUP_SIZE_MB"
EOF
    chmod 600 "$CONFIG_FILE"
    debug_log "CONFIG" "Config saved, chmod 600 applied"
    debug_log "CONFIG" "BOT_PATH=$BOT_PATH"
    debug_log "CONFIG" "BOT_CONTAINER=$BOT_CONTAINER_NAME, DB_CONTAINER=$DB_CONTAINER_NAME"
    debug_log "CONFIG" "REMOTE_STORAGE_TYPE=$REMOTE_STORAGE_TYPE"
    debug_log "CONFIG" "DELETE_MODE=$DELETE_MODE, MAX_BACKUPS=$MAX_BACKUPS_COUNT, RETENTION=$RETENTION_DAYS days"
    debug_log "CONFIG" "MAX_BACKUP_SIZE_MB=$MAX_BACKUP_SIZE_MB"
}

load_or_create_config() {
    debug_log "CONFIG" "=== load_or_create_config ==="
    debug_log "CONFIG" "Config file: $CONFIG_FILE"
    if [[ -f "$CONFIG_FILE" ]]; then 
        debug_log "CONFIG" "Config exists, sourcing..."
        source "$CONFIG_FILE"
        debug_log "CONFIG" "Config loaded successfully"
    else
        debug_log "CONFIG" "Config file not found, using defaults"
    fi
    if [[ -z "$MAX_BACKUPS_COUNT" ]]; then MAX_BACKUPS_COUNT=100; fi
    if [[ -z "$IGNORE_MISMATCH" ]]; then IGNORE_MISMATCH="false"; fi
    if [[ -z "$MAX_FILE_SIZE_MB" ]]; then MAX_FILE_SIZE_MB="1"; fi
    if [[ -z "$REMOTE_STORAGE_TYPE" ]]; then REMOTE_STORAGE_TYPE="off"; fi
    if [[ -z "$SEND_TO_TELEGRAM" ]]; then SEND_TO_TELEGRAM="true"; fi
    if [[ -z "$TG_SEND_FILE" ]]; then TG_SEND_FILE="true"; fi
    if [[ -z "$SEND_TO_REMOTE" ]]; then SEND_TO_REMOTE="true"; fi
    if [[ -z "$DELETE_MODE" ]]; then DELETE_MODE="time"; fi
    if [[ -z "$RETENTION_DAYS" ]]; then RETENTION_DAYS="7"; fi
    if [[ -z "$MAX_BACKUP_SIZE_MB" ]]; then MAX_BACKUP_SIZE_MB="0"; fi
    debug_log "CONFIG" "Defaults applied: MAX_BACKUPS=$MAX_BACKUPS_COUNT, DELETE_MODE=$DELETE_MODE"
    debug_log "CONFIG" "Creating backup dir: $BACKUP_DIR"
    mkdir -p "$BACKUP_DIR"

    local updated=false
    if [[ -z "$BOT_TOKEN" || -z "$CHAT_ID" ]]; then
        debug_log "CONFIG" "Telegram settings missing, prompting user"
        echo ""; print_message "WARN" "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ Telegram –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
        [[ -z "$BOT_TOKEN" ]] && read -erp " –í–≤–µ–¥–∏—Ç–µ Bot Token: " BOT_TOKEN
        [[ -z "$CHAT_ID" ]] && read -erp " –í–≤–µ–¥–∏—Ç–µ Chat ID: " CHAT_ID
        [[ -z "$TG_MESSAGE_THREAD_ID" ]] && read -erp " –í–≤–µ–¥–∏—Ç–µ ID —Ç–æ–ø–∏–∫–∞ (–∏–ª–∏ Enter): " TG_MESSAGE_THREAD_ID
        updated=true
        debug_log "CONFIG" "Telegram settings received from user"
    fi
    
    if [[ -z "$BOT_PATH" || -z "$BOT_CONTAINER_NAME" || -z "$DB_CONTAINER_NAME" ]]; then 
        debug_log "CONFIG" "Bot installation not configured, starting detection"
        detect_bot_installation
    fi
    
    if $updated; then 
        debug_log "CONFIG" "Config updated, saving..."
        save_config
    fi
    debug_log "CONFIG" "=== load_or_create_config completed ==="
}

send_telegram_document() {
    local file_path="$1"; local caption="$2"
    debug_log "TG" "=== send_telegram_document ==="
    debug_log "TG" "File: $file_path"
    debug_log "TG" "SEND_TO_TELEGRAM=$SEND_TO_TELEGRAM, TG_SEND_FILE=$TG_SEND_FILE"
    [[ -z "$BOT_TOKEN" || -z "$CHAT_ID" ]] && { debug_log "TG" "Missing BOT_TOKEN or CHAT_ID"; return 1; }
    
    # –ï—Å–ª–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–ª—é—á–µ–Ω—ã
    if [[ "$SEND_TO_TELEGRAM" != "true" ]]; then
        print_message "INFO" "–£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è Telegram –æ—Ç–∫–ª—é—á–µ–Ω—ã."
        debug_log "TG" "Notifications disabled, skipping"
        return 0
    fi
    
    # –ï—Å–ª–∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
    if [[ "$TG_SEND_FILE" != "true" ]]; then
        print_message "INFO" "–û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ TG –æ—Ç–∫–ª—é—á–µ–Ω–∞, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ..."
        debug_log "TG" "File sending disabled, sending text only"
        local filename=$(basename "$file_path")
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –¥–ª—è MarkdownV2
        local escaped_filename=$(escape_markdown_v2 "$filename")
        local escaped_caption=$(escape_markdown_v2 "$caption")
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ (—É–∂–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ)
        local notify_text="üì¶ *–ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω*

${escaped_caption}

üìÅ –§–∞–π–ª: \`${escaped_filename}\`
üí° _–û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ Telegram –æ—Ç–∫–ª—é—á–µ–Ω–∞_"
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞–ø—Ä—è–º—É—é (—Ç–µ–∫—Å—Ç —É–∂–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω)
        local thread_param=""
        [[ -n "$TG_MESSAGE_THREAD_ID" ]] && thread_param="-d message_thread_id=$TG_MESSAGE_THREAD_ID"
        
        local http_code
        http_code=$(curl $CURL_SILENT -o "$SILENT_LOG" -w "%{http_code}" -X POST "https://api.telegram.org/bot$BOT_TOKEN/sendMessage" \
            -d chat_id="$CHAT_ID" \
            -d parse_mode="MarkdownV2" \
            --data-urlencode text="$notify_text" \
            $thread_param 2> "$SILENT_LOG")
        debug_log "TG" "Text-only notification HTTP code: $http_code"
        
        if [[ "$http_code" == "200" ]]; then
            print_message "SUCCESS" "–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram."
            return 0
        else
            print_message "WARN" "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ (HTTP: $http_code)"
            log_message "WARN" "Telegram notification failed, HTTP code: $http_code"
            return 1
        fi
    fi
    
    print_message "INFO" "–û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram..."
    local file_size_bytes=$(stat -c%s "$file_path" 2> "$SILENT_LOG" || echo 0)
    debug_log "TG" "File size: $file_size_bytes bytes ($(numfmt --to=iec $file_size_bytes 2>/dev/null || echo "$file_size_bytes"))"
    
    local form_params=(-F chat_id="$CHAT_ID" -F document=@"$file_path" -F parse_mode="MarkdownV2" -F caption="$(escape_markdown_v2 "$caption")")
    [[ -n "$TG_MESSAGE_THREAD_ID" ]] && form_params+=(-F message_thread_id="$TG_MESSAGE_THREAD_ID")
    debug_log "TG" "Sending to: https://api.telegram.org/bot<TOKEN>/sendDocument"
    debug_log "TG" "Chat ID: $CHAT_ID, Thread ID: ${TG_MESSAGE_THREAD_ID:-none}"
    
    local http_code=$(curl $CURL_SILENT -o "$SILENT_LOG" -w "%{http_code}" -X POST "https://api.telegram.org/bot$BOT_TOKEN/sendDocument" "${form_params[@]}")
    debug_log "TG" "HTTP response code: $http_code"
    
    if [[ "$http_code" == "200" ]]; then
        print_message "SUCCESS" "–£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram."
    else
        local file_size=$(stat -c%s "$file_path" 2> "$SILENT_LOG" || echo 0)
        debug_log "TG" "Send FAILED! File size: $file_size"
        
        if [[ $file_size -ge 52428800 ]]; then
            print_message "ERROR" "–§–∞–π–ª >50MB. Telegram API –æ—Ç–∫–ª–æ–Ω–∏–ª –æ—Ç–ø—Ä–∞–≤–∫—É."
            debug_log "TG" "File exceeds 50MB limit"
            local escaped_fname=$(escape_markdown_v2 "$(basename "$file_path")")
            local error_msg="‚ö†Ô∏è *–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –±—ç–∫–∞–ø–∞*

–§–∞–π–ª –∑–∞–Ω–∏–º–∞–µ—Ç –±–æ–ª—å—à–µ 50 –ú–ë\. Telegram Bot API –Ω–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å —Ç–∞–∫–∏–µ —Ñ–∞–π–ª—ã –Ω–∞–ø—Ä—è–º—É—é\.

üìÇ *–ë—ç–∫–∞–ø —Å–æ—Ö—Ä–∞–Ω–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ:*
\`${escaped_fname}\`"
            
            local thread_param=""
            [[ -n "$TG_MESSAGE_THREAD_ID" ]] && thread_param="-d message_thread_id=$TG_MESSAGE_THREAD_ID"

            curl $CURL_SILENT -X POST "https://api.telegram.org/bot$BOT_TOKEN/sendMessage" \
                -d chat_id="$CHAT_ID" \
                --data-urlencode text="$error_msg" \
                -d parse_mode="MarkdownV2" \
                $thread_param > "$SILENT_LOG"
        else
            print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ Telegram (HTTP –∫–æ–¥: $http_code)."
        fi
    fi
}

send_telegram_text() {
    # send simple text message to configured chat (expects already escaped MarkdownV2 text)
    local text="$1"
    [[ -z "$BOT_TOKEN" || -z "$CHAT_ID" ]] && return 1
    [[ "$SEND_TO_TELEGRAM" != "true" ]] && return 0
    local thread_param=""
    [[ -n "$TG_MESSAGE_THREAD_ID" ]] && thread_param="-d message_thread_id=$TG_MESSAGE_THREAD_ID"
    curl $CURL_SILENT -X POST "https://api.telegram.org/bot$BOT_TOKEN/sendMessage" \
        -d chat_id="$CHAT_ID" \
        --data-urlencode text="$text" \
        -d parse_mode="MarkdownV2" $thread_param > "$SILENT_LOG" 2>&1
}

test_telegram_connection() {
    print_message "INFO" "–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤—è–∑–∏ —Å Telegram API..."
    local res=$(curl $CURL_SILENT "https://api.telegram.org/bot$BOT_TOKEN/getMe")
    if [[ "$res" == *'"ok":true'* ]]; then
        local bot_user=$(echo "$res" | grep -o '"username":"[^"]*"' | cut -d'"' -f4)
        print_message "SUCCESS" "–£—Å–ø–µ—Ö! –ë–æ—Ç: @$bot_user"
    else
        print_message "ERROR" "–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω."
    fi
    read -erp "Enter..." dummy
}

validate_remote_connection() {
    local type="$1"; local url="$2"; local user="$3"; local pass="$4"
    
    debug_log "REMOTE" "=== validate_remote_connection($type) ==="
    debug_log "REMOTE" "URL: $url"
    debug_log "REMOTE" "User: ${user:-<empty>}"
    
    print_message "INFO" "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è ($type)..."
    
    local base_url="${url%/}"
    
    if [[ "$type" == "ftp" ]]; then
        debug_log "REMOTE" "Testing FTP connection..."
        # FTP: –ø—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏—Å—Ç–∏–Ω–≥ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        local curl_cmd=(curl $CURL_SILENT -m 15 --ftp-pasv --list-only)
        [[ -n "$user" ]] && curl_cmd+=(--user "$user:$pass")
        
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ FTPS (implicit –∏ explicit)
        if [[ "$base_url" == ftps://* ]]; then
            debug_log "REMOTE" "Using FTPS (implicit TLS)"
            curl_cmd+=(--ssl-reqd --insecure)
        elif [[ "$base_url" == ftp://* ]]; then
            debug_log "REMOTE" "Using FTP with optional TLS"
            # –ü–æ–ø—Ä–æ–±—É–µ–º explicit TLS –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            curl_cmd+=(--ssl --insecure)
        fi
        
        debug_log "REMOTE" "Running: ${curl_cmd[*]} $base_url/"
        if "${curl_cmd[@]}" "$base_url/" > "$SILENT_LOG" 2>&1; then 
            debug_log "REMOTE" "FTP connection SUCCESS"
            return 0
        else 
            debug_log "REMOTE" "FTP with TLS failed, trying without TLS..."
            # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –±–µ–∑ TLS –¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ FTP
            if [[ "$base_url" == ftp://* ]]; then
                curl_cmd=(curl $CURL_SILENT -m 15 --ftp-pasv --list-only)
                [[ -n "$user" ]] && curl_cmd+=(--user "$user:$pass")
                if "${curl_cmd[@]}" "$base_url/" > "$SILENT_LOG" 2>&1; then
                    debug_log "REMOTE" "FTP without TLS SUCCESS"
                    return 0
                fi
            fi
            debug_log "REMOTE" "FTP connection FAILED"
            return 1
        fi
        
    elif [[ "$type" == "webdav" ]]; then
        debug_log "REMOTE" "Testing WebDAV connection..."
        # WebDAV: PROPFIND —Å Depth: 0
        local curl_cmd=(curl $CURL_SILENT -m 15 -L)
        [[ -n "$user" ]] && curl_cmd+=(--user "$user:$pass")
        
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å–∞–º–æ–ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã—Ö —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤
        [[ "$base_url" == https://* ]] && curl_cmd+=(--insecure)
        
        local http_code
        debug_log "REMOTE" "Sending PROPFIND request..."
        http_code=$("${curl_cmd[@]}" -o "$SILENT_LOG" -w "%{http_code}" -X PROPFIND -H "Depth: 0" "$base_url/" 2> "$SILENT_LOG")
        debug_log "REMOTE" "PROPFIND HTTP code: $http_code"
        
        # 207 Multi-Status ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç WebDAV
        # 200 OK ‚Äî –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–µ—Ä–≤–µ—Ä—ã –æ—Ç–≤–µ—á–∞—é—Ç —Ç–∞–∫
        # 301/302 ‚Äî —Ä–µ–¥–∏—Ä–µ–∫—Ç (curl -L –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç)
        if [[ "$http_code" =~ ^(200|207)$ ]]; then 
            debug_log "REMOTE" "WebDAV connection SUCCESS"
            return 0
        else 
            debug_log "REMOTE" "PROPFIND failed, trying GET fallback..."
            # Fallback: –ø–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π GET
            http_code=$("${curl_cmd[@]}" -o "$SILENT_LOG" -w "%{http_code}" "$base_url/" 2> "$SILENT_LOG")
            debug_log "REMOTE" "GET HTTP code: $http_code"
            if [[ "$http_code" =~ ^(200|207|401)$ ]]; then
                # 401 –æ–∑–Ω–∞—á–∞–µ—Ç —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –æ—Ç–≤–µ—á–∞–µ—Ç, –Ω–æ –Ω—É–∂–Ω–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
                debug_log "REMOTE" "WebDAV connection SUCCESS (via GET)"
                return 0
            fi
            debug_log "REMOTE" "WebDAV connection FAILED"
            return 1
        fi
        
    elif [[ "$type" == "rclone" ]]; then
        debug_log "REMOTE" "Testing rclone connection..."
        if ! command -v rclone > "$SILENT_LOG" 2>&1; then
            debug_log "REMOTE" "rclone not installed!"
            print_message "ERROR" "Rclone –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!"
            return 1
        fi
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å remote
        local remote_name="${url%%:*}"
        debug_log "REMOTE" "Remote name: $remote_name"
        if rclone listremotes 2> "$SILENT_LOG" | grep -q "^${remote_name}:$"; then
            debug_log "REMOTE" "Remote exists, testing lsd..."
            # Remote —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
            if rclone lsd "$url" > "$SILENT_LOG" 2>&1; then 
                debug_log "REMOTE" "Rclone connection SUCCESS"
                return 0
            fi
        else
            debug_log "REMOTE" "Remote '$remote_name' not found in rclone config"
        fi
        debug_log "REMOTE" "Rclone connection FAILED"
        return 1
    fi
    
    debug_log "REMOTE" "Unknown storage type: $type"
    return 1
}

upload_to_remote() {
    if [[ "$SEND_TO_REMOTE" != "true" ]]; then 
        debug_log "REMOTE" "Remote upload disabled (SEND_TO_REMOTE=$SEND_TO_REMOTE)"
        return 0
    fi
    local file_path="$1"
    local filename=$(basename "$file_path")
    local file_size=$(stat -c%s "$file_path" 2> "$SILENT_LOG" || echo "0")
    REMOTE_UPLOAD_STATUS_TEXT="" 
    
    debug_log "REMOTE" "=== upload_to_remote ==="
    debug_log "REMOTE" "File: $file_path"
    debug_log "REMOTE" "Size: $file_size bytes"
    debug_log "REMOTE" "Type: $REMOTE_STORAGE_TYPE"
    debug_log "REMOTE" "URL: $REMOTE_STORAGE_URL"

    if [[ "$REMOTE_STORAGE_TYPE" == "off" || -z "$REMOTE_STORAGE_URL" ]]; then 
        debug_log "REMOTE" "Remote storage disabled or URL empty"
        return 0
    fi
    
    if [[ ! -f "$file_path" ]]; then
        print_message "ERROR" "–§–∞–π–ª –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: $file_path" >&2
        log_message "ERROR" "Upload failed: file not found $file_path"
        debug_log "REMOTE" "ERROR: File not found!"
        return 1
    fi

    print_message "INFO" "–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ $REMOTE_STORAGE_TYPE ($(numfmt --to=iec $file_size 2> "$SILENT_LOG" || echo "${file_size}B"))..." >&2

    # === RCLONE ===
    if [[ "$REMOTE_STORAGE_TYPE" == "rclone" ]]; then
        debug_log "REMOTE" "Using rclone..."
        if ! command -v rclone > "$SILENT_LOG" 2>&1; then
            print_message "ERROR" "Rclone –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!"
            REMOTE_UPLOAD_STATUS_TEXT=$'\n‚òÅÔ∏è Rclone: –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'
            return 1
        fi
        local dest="${REMOTE_STORAGE_URL%/}"
        local rclone_opts=(--progress --retries 3 --low-level-retries 10)
        [[ "$IS_INTERACTIVE" != "true" ]] && rclone_opts=(--quiet --retries 3 --low-level-retries 10)
        debug_log "REMOTE" "Running: rclone copy $file_path $dest ${rclone_opts[*]}"
        
        if rclone copy "$file_path" "$dest" "${rclone_opts[@]}" 2>&1; then
            print_message "SUCCESS" "–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω (rclone)." >&2
            debug_log "REMOTE" "Rclone upload SUCCESS"
            REMOTE_UPLOAD_STATUS_TEXT=$'\n‚òÅÔ∏è Rclone: OK'
            log_message "SUCCESS" "Uploaded $filename to rclone:$dest"
            return 0
        else
            print_message "ERROR" "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ rclone." >&2
            REMOTE_UPLOAD_STATUS_TEXT=$'\n‚òÅÔ∏è Rclone: –û—à–∏–±–∫–∞'
            log_message "ERROR" "Failed upload $filename to rclone:$dest"
            return 1
        fi
    fi

    # === FTP / WEBDAV ===
    local upload_url="${REMOTE_STORAGE_URL%/}/$filename"
    local max_retries=3
    local retry_delay=5
    local attempt=1
    local http_code=""
    local upload_success=false
    
    # –†–∞—Å—á—ë—Ç —Ç–∞–π–º–∞—É—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞ (–º–∏–Ω–∏–º—É–º 120 —Å–µ–∫, +60 —Å–µ–∫ –Ω–∞ –∫–∞–∂–¥—ã–µ 50MB)
    local timeout=$((120 + (file_size / 50000000) * 60))
    [[ $timeout -gt 1800 ]] && timeout=1800  # –ú–∞–∫—Å–∏–º—É–º 30 –º–∏–Ω—É—Ç
    debug_log "UPLOAD" "Upload URL: $upload_url"
    debug_log "UPLOAD" "Timeout: ${timeout}s, Max retries: $max_retries"
    
    while [[ $attempt -le $max_retries ]]; do
        debug_log "UPLOAD" "Attempt $attempt/$max_retries"
        [[ $attempt -gt 1 ]] && print_message "INFO" "–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ $attempt/$max_retries..." >&2
        
        # –ë–∞–∑–æ–≤—ã–µ –æ–ø—Ü–∏–∏ curl
        local curl_opts=(-o "$SILENT_LOG" -w "%{http_code}" -m "$timeout" -T "$file_path")
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –∏–ª–∏ —Ç–∏—Ö–∏–π —Ä–µ–∂–∏–º
        if [[ "$IS_INTERACTIVE" == "true" ]]; then
            curl_opts+=(-#)
        else
            curl_opts+=(-s)
        fi
        
        # –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
        [[ -n "$REMOTE_STORAGE_USER" ]] && curl_opts+=(--user "$REMOTE_STORAGE_USER:$REMOTE_STORAGE_PASS")
        
        if [[ "$REMOTE_STORAGE_TYPE" == "ftp" ]]; then
            # FTP —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –æ–ø—Ü–∏–∏
            curl_opts+=(--ftp-pasv)              # Passive mode (—Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞ NAT)
            curl_opts+=(--ftp-create-dirs)       # –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            debug_log "UPLOAD" "FTP mode: passive, create-dirs"
            
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ FTPS
            if [[ "$upload_url" == ftps://* ]]; then
                curl_opts+=(--ssl-reqd --insecure)
                debug_log "UPLOAD" "FTPS: SSL required"
            elif [[ "$upload_url" == ftp://* ]]; then
                curl_opts+=(--ssl --insecure)    # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å TLS –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
                debug_log "UPLOAD" "FTP: Try TLS if available"
            fi
            
            curl_opts+=("$upload_url")
            debug_log "UPLOAD" "Executing FTP upload..."
            http_code=$(curl "${curl_opts[@]}" 2> "$SILENT_LOG") || http_code="000"
            debug_log "UPLOAD" "FTP response code: $http_code"
            
            # FTP –∫–æ–¥—ã —É—Å–ø–µ—Ö–∞: 226 (Transfer complete), 250 (Requested file action okay)
            if [[ "$http_code" =~ ^(226|250|200)$ ]]; then
                upload_success=true
                debug_log "UPLOAD" "FTP upload SUCCESS"
                break
            fi
            
        elif [[ "$REMOTE_STORAGE_TYPE" == "webdav" ]]; then
            # WebDAV —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –æ–ø—Ü–∏–∏
            curl_opts+=(-L)                      # –°–ª–µ–¥–æ–≤–∞—Ç—å —Ä–µ–¥–∏—Ä–µ–∫—Ç–∞–º
            curl_opts+=(--retry 2)               # –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π retry curl
            curl_opts+=(--retry-delay 3)
            debug_log "UPLOAD" "WebDAV mode: follow redirects, retry 2"
            
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ HTTPS —Å —Å–∞–º–æ–ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–º–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞–º–∏
            if [[ "$upload_url" == https://* ]]; then
                curl_opts+=(--insecure)
                debug_log "UPLOAD" "WebDAV: HTTPS with insecure"
            fi
            
            curl_opts+=("$upload_url")
            debug_log "UPLOAD" "Executing WebDAV upload..."
            http_code=$(curl "${curl_opts[@]}" 2> "$SILENT_LOG") || http_code="000"
            debug_log "UPLOAD" "WebDAV response code: $http_code"
            
            # WebDAV –∫–æ–¥—ã —É—Å–ø–µ—Ö–∞: 200 OK, 201 Created, 204 No Content
            if [[ "$http_code" =~ ^(200|201|204)$ ]]; then
                upload_success=true
                debug_log "UPLOAD" "WebDAV upload SUCCESS"
                break
            fi
        fi
        
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–µ—É–¥–∞—á–Ω—É—é –ø–æ–ø—ã—Ç–∫—É
        debug_log "UPLOAD" "Attempt $attempt FAILED with HTTP $http_code"
        log_message "WARN" "Upload attempt $attempt failed: HTTP $http_code for $upload_url"
        
        ((attempt++))
        [[ $attempt -le $max_retries ]] && sleep $retry_delay
    done
    
    if [[ "$upload_success" == true ]]; then
        print_message "SUCCESS" "–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ." >&2
        if [[ "$REMOTE_STORAGE_TYPE" == "ftp" ]]; then 
            REMOTE_UPLOAD_STATUS_TEXT=$'\n‚òÅÔ∏è FTP: OK'
        else 
            REMOTE_UPLOAD_STATUS_TEXT=$'\n‚òÅÔ∏è WebDAV: OK'
        fi
        log_message "SUCCESS" "Uploaded $filename to $REMOTE_STORAGE_TYPE ($upload_url) HTTP=$http_code"
        return 0
    else
        print_message "ERROR" "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Å–ª–µ $max_retries –ø–æ–ø—ã—Ç–æ–∫ (–ö–æ–¥: $http_code)" >&2
        if [[ "$REMOTE_STORAGE_TYPE" == "ftp" ]]; then 
            REMOTE_UPLOAD_STATUS_TEXT=$'\n‚òÅÔ∏è FTP: –û—à–∏–±–∫–∞'
        else 
            REMOTE_UPLOAD_STATUS_TEXT=$'\n‚òÅÔ∏è WebDAV: –û—à–∏–±–∫–∞'
        fi
        log_message "ERROR" "Failed upload $filename to $REMOTE_STORAGE_TYPE after $max_retries attempts. Last HTTP=$http_code"
        return 1
    fi
}

configure_remote_storage() {
    while true; do
        clear_screen
        echo -e "${GREEN}${BOLD}–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É–¥–∞–ª—ë–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞${RESET}"
        echo ""
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å
        if [[ "$REMOTE_STORAGE_TYPE" != "off" && -n "$REMOTE_STORAGE_URL" ]]; then
            echo -e "–¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:"
            echo -e "  –¢–∏–ø: ${YELLOW}${REMOTE_STORAGE_TYPE^^}${RESET}"
            echo -e "  URL: ${CYAN}${REMOTE_STORAGE_URL}${RESET}"
            [[ -n "$REMOTE_STORAGE_USER" ]] && echo -e "  –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: ${GRAY}${REMOTE_STORAGE_USER}${RESET}"
            echo ""
        fi
        
        echo " 1. FTP / FTPS"
        echo " 2. WebDAV (–Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫, Nextcloud, –∏ –¥—Ä.)"
        echo " 3. Rclone (Google Drive, S3, Dropbox, –∏ –¥—Ä.)"
        echo ""
        echo -e " ${RED}0. –û—Ç–∫–ª—é—á–∏—Ç—å${RESET}"
        echo ""
        read -erp "–í—ã–±–æ—Ä (Enter - –ù–∞–∑–∞–¥): " r_type
        [[ -z "$r_type" ]] && return
        
        local new_type="off"
        local input_url="" input_user="" input_pass="" input_folder=""
        local base_url=""
        
        case $r_type in
            1) new_type="ftp" ;;
            2) new_type="webdav" ;;
            3) new_type="rclone" ;;
            0) 
                REMOTE_STORAGE_TYPE="off"
                REMOTE_STORAGE_URL=""
                REMOTE_STORAGE_USER=""
                REMOTE_STORAGE_PASS=""
                save_config
                print_message "SUCCESS" "–£–¥–∞–ª—ë–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ."
                sleep 1
                return 
                ;;
            *) continue ;;
        esac

        echo ""
        
        if [[ "$new_type" == "ftp" ]]; then
            echo -e "${CYAN}${BOLD}–ù–∞—Å—Ç—Ä–æ–π–∫–∞ FTP/FTPS${RESET}"
            echo ""
            echo -e "${GRAY}–®–∞–≥ 1/3: –ê–¥—Ä–µ—Å —Å–µ—Ä–≤–µ—Ä–∞${RESET}"
            echo ""
            echo "–ü—Ä–∏–º–µ—Ä—ã:"
            echo -e "  ${GRAY}ftp://backup.example.com${RESET}"
            echo -e "  ${GRAY}ftps://secure.example.com:990${RESET}"
            echo ""
            read -erp "–ê–¥—Ä–µ—Å —Å–µ—Ä–≤–µ—Ä–∞ (Enter - –Ω–∞–∑–∞–¥): " base_url
            [[ -z "$base_url" ]] && continue
            
            # –£–±–∏—Ä–∞–µ–º trailing slash
            base_url="${base_url%/}"
            
            echo ""
            echo -e "${GRAY}–®–∞–≥ 2/3: –ü–∞–ø–∫–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ${RESET}"
            echo ""
            echo "–ü—Ä–∏–º–µ—Ä—ã:"
            echo -e "  ${GRAY}backups${RESET}           ‚Üí ${CYAN}${base_url}/backups${RESET}"
            echo -e "  ${GRAY}backup/lazarus${RESET}    ‚Üí ${CYAN}${base_url}/backup/lazarus${RESET}"
            echo -e "  ${GRAY}(–ø—É—Å—Ç–æ)${RESET}           ‚Üí ${CYAN}${base_url}${RESET} (–∫–æ—Ä–µ–Ω—å)"
            echo ""
            read -erp "–ü–∞–ø–∫–∞: " input_folder
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π URL
            if [[ -n "$input_folder" ]]; then
                input_folder="${input_folder#/}"  # –£–±–∏—Ä–∞–µ–º leading slash
                input_folder="${input_folder%/}"  # –£–±–∏—Ä–∞–µ–º trailing slash
                input_url="${base_url}/${input_folder}"
            else
                input_url="$base_url"
            fi
            
            echo ""
            echo -e "–ò—Ç–æ–≥–æ–≤—ã–π –ø—É—Ç—å: ${CYAN}${input_url}${RESET}"
            echo ""
            echo -e "${GRAY}–®–∞–≥ 3/3: –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è${RESET}"
            read -erp "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: " input_user
            read -s -erp "–ü–∞—Ä–æ–ª—å: " input_pass
            echo ""
            
        elif [[ "$new_type" == "webdav" ]]; then
            echo -e "${CYAN}${BOLD}–ù–∞—Å—Ç—Ä–æ–π–∫–∞ WebDAV${RESET}"
            echo ""
            echo -e "${GRAY}–®–∞–≥ 1/3: –ê–¥—Ä–µ—Å —Å–µ—Ä–≤–µ—Ä–∞${RESET}"
            echo ""
            echo "–ü—Ä–∏–º–µ—Ä—ã –±–∞–∑–æ–≤—ã—Ö –∞–¥—Ä–µ—Å–æ–≤:"
            echo -e "  ${GRAY}https://webdav.yandex.ru${RESET}                    (–Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫)"
            echo -e "  ${GRAY}https://cloud.example.com/remote.php/dav/files/user${RESET} (Nextcloud)"
            echo ""
            read -erp "–ê–¥—Ä–µ—Å —Å–µ—Ä–≤–µ—Ä–∞ (Enter - –Ω–∞–∑–∞–¥): " base_url
            [[ -z "$base_url" ]] && continue
            
            # –£–±–∏—Ä–∞–µ–º trailing slash
            base_url="${base_url%/}"
            
            echo ""
            echo -e "${GRAY}–®–∞–≥ 2/3: –ü–∞–ø–∫–∞ –¥–ª—è –±—ç–∫–∞–ø–æ–≤${RESET}"
            echo ""
            echo "–ü—Ä–∏–º–µ—Ä—ã:"
            echo -e "  ${GRAY}backups${RESET}           ‚Üí ${CYAN}${base_url}/backups${RESET}"
            echo -e "  ${GRAY}Backup/Lazarus${RESET}    ‚Üí ${CYAN}${base_url}/Backup/Lazarus${RESET}"
            echo -e "  ${GRAY}(–ø—É—Å—Ç–æ)${RESET}           ‚Üí ${CYAN}${base_url}${RESET} (–∫–æ—Ä–µ–Ω—å)"
            echo ""
            read -erp "–ü–∞–ø–∫–∞: " input_folder
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π URL
            if [[ -n "$input_folder" ]]; then
                input_folder="${input_folder#/}"
                input_folder="${input_folder%/}"
                input_url="${base_url}/${input_folder}"
            else
                input_url="$base_url"
            fi
            
            echo ""
            echo -e "–ò—Ç–æ–≥–æ–≤—ã–π –ø—É—Ç—å: ${CYAN}${input_url}${RESET}"
            echo ""
            echo -e "${GRAY}–®–∞–≥ 3/3: –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è${RESET}"
            read -erp "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: " input_user
            read -s -erp "–ü–∞—Ä–æ–ª—å (–∏–ª–∏ —Ç–æ–∫–µ–Ω –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è): " input_pass
            echo ""
            
        elif [[ "$new_type" == "rclone" ]]; then
            echo -e "${CYAN}${BOLD}–ù–∞—Å—Ç—Ä–æ–π–∫–∞ Rclone${RESET}"
            echo ""
            if ! command -v rclone > "$SILENT_LOG" 2>&1; then
                print_message "ERROR" "Rclone –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!"
                echo -e "–£—Å—Ç–∞–Ω–æ–≤–∫–∞: ${GRAY}curl https://rclone.org/install.sh | sudo bash${RESET}"
                read -erp "Enter..." dummy
                continue
            fi
            
            echo -e "${GRAY}–®–∞–≥ 1/2: –í—ã–±–æ—Ä remote${RESET}"
            echo ""
            echo "–î–æ—Å—Ç—É–ø–Ω—ã–µ remotes:"
            local remotes=$(rclone listremotes 2> "$SILENT_LOG")
            if [[ -z "$remotes" ]]; then
                print_message "WARN" "–ù–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö remotes!"
                echo -e "–ù–∞—Å—Ç—Ä–æ–π—Ç–µ —á–µ—Ä–µ–∑: ${GRAY}rclone config${RESET}"
                read -erp "Enter..." dummy
                continue
            fi
            echo "$remotes" | sed 's/^/  /'
            echo ""
            read -erp "–ò–º—è remote (–±–µ–∑ –¥–≤–æ–µ—Ç–æ—á–∏—è, Enter - –Ω–∞–∑–∞–¥): " base_url
            [[ -z "$base_url" ]] && continue
            
            # –£–±–∏—Ä–∞–µ–º –¥–≤–æ–µ—Ç–æ—á–∏–µ –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –µ–≥–æ –¥–æ–±–∞–≤–∏–ª
            base_url="${base_url%:}"
            
            echo ""
            echo -e "${GRAY}–®–∞–≥ 2/2: –ü–∞–ø–∫–∞ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ${RESET}"
            echo ""
            echo "–ü—Ä–∏–º–µ—Ä—ã:"
            echo -e "  ${GRAY}backups${RESET}           ‚Üí ${CYAN}${base_url}:backups${RESET}"
            echo -e "  ${GRAY}Backup/Server1${RESET}    ‚Üí ${CYAN}${base_url}:Backup/Server1${RESET}"
            echo -e "  ${GRAY}(–ø—É—Å—Ç–æ)${RESET}           ‚Üí ${CYAN}${base_url}:${RESET} (–∫–æ—Ä–µ–Ω—å)"
            echo ""
            read -erp "–ü–∞–ø–∫–∞: " input_folder
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –ø—É—Ç—å –¥–ª—è rclone
            if [[ -n "$input_folder" ]]; then
                input_folder="${input_folder#/}"
                input_folder="${input_folder%/}"
                input_url="${base_url}:${input_folder}"
            else
                input_url="${base_url}:"
            fi
            
            echo ""
            echo -e "–ò—Ç–æ–≥–æ–≤—ã–π –ø—É—Ç—å: ${CYAN}${input_url}${RESET}"
            input_user=""
            input_pass=""
        fi

        echo ""
        print_message "INFO" "–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è..."
        
        if validate_remote_connection "$new_type" "$input_url" "$input_user" "$input_pass"; then
            print_message "SUCCESS" "–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ!"
            REMOTE_STORAGE_TYPE="$new_type"
            REMOTE_STORAGE_URL="$input_url"
            REMOTE_STORAGE_USER="$input_user"
            REMOTE_STORAGE_PASS="$input_pass"
            save_config
            print_message "SUCCESS" "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã."
            sleep 1.5
            return
        else
            print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É!"
            echo ""
            read -erp "–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –æ—à–∏–±–∫—É? (y/N): " force_save
            if [[ "$force_save" =~ ^[Yy]$ ]]; then
                REMOTE_STORAGE_TYPE="$new_type"
                REMOTE_STORAGE_URL="$input_url"
                REMOTE_STORAGE_USER="$input_user"
                REMOTE_STORAGE_PASS="$input_pass"
                save_config
                print_message "WARN" "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã (—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ)."
                sleep 1.5
                return
            else
                print_message "INFO" "–û—Ç–º–µ–Ω–µ–Ω–æ. –í–æ–∑–≤—Ä–∞—Ç –∫ –≤—ã–±–æ—Ä—É —Ç–∏–ø–∞..."
                sleep 1
            fi
        fi
    done
}

# --- –†–û–¢–ê–¶–ò–Ø (–£–î–ê–õ–ï–ù–ò–ï –õ–ò–®–ù–ò–•) ---

rotate_backups_by_count() {
    local PREFIX="$1"
    local LABEL="$2"
    local PERFORM_DELETE="$3" 
    
    debug_log "ROTATION" "=== rotate_backups_by_count($PREFIX, $LABEL, delete=$PERFORM_DELETE) ==="
    debug_log "ROTATION" "MAX_BACKUPS_COUNT=$MAX_BACKUPS_COUNT"
    
    # –°–¢–†–û–ì–ò–ô –ü–û–ò–°–ö (–¢–æ–ª—å–∫–æ –∞—Ä—Ö–∏–≤—ã), —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (—Å—Ç–∞—Ä—ã–µ –≤ –Ω–∞—á–∞–ª–µ)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º ls -1tr –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ while read –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏–º–µ–Ω —Å –ø—Ä–æ–±–µ–ª–∞–º–∏
    local files=()
    while IFS= read -r f; do
        files+=("$f")
    done < <(ls -1tr "$BACKUP_DIR"/${PREFIX}_*.tar.gz "$BACKUP_DIR"/${PREFIX}_*.tar.gz.enc 2> "$SILENT_LOG")
    
    local count=${#files[@]}
    local diff=$((count - MAX_BACKUPS_COUNT))
    debug_log "ROTATION" "Found $count files, limit=$MAX_BACKUPS_COUNT, to_delete=$diff"
    
    if [[ $diff -gt 0 ]]; then
        if [[ "$PERFORM_DELETE" == "true" ]]; then
            if [[ "$DRY_RUN" == "true" ]]; then
                debug_log "ROTATION" "[DRY-RUN] Would delete $diff files"
                echo -e "${YELLOW}[DRY-RUN] –ö–∞—Ç–µ–≥–æ—Ä–∏—è '$LABEL': –±—ã–ª–æ –±—ã —É–¥–∞–ª–µ–Ω–æ $diff —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ (–ª–∏–º–∏—Ç $MAX_BACKUPS_COUNT).${RESET}"
                log_message "INFO" "[DRY_RUN] Would delete $diff files (count-based rotation, prefix=$PREFIX, limit=$MAX_BACKUPS_COUNT)"
                echo "$diff"
                return 0
            fi
            echo -e "${YELLOW}–û—á–∏—Å—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '$LABEL' (—É–¥–∞–ª–µ–Ω–∏–µ $diff —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤):${RESET}"
            for (( i=0; i<diff; i++ )); do
                local file_to_del="${files[$i]}"
                if [[ -f "$file_to_del" ]]; then
                    debug_log "ROTATION" "Deleting: $file_to_del"
                    rm -f "$file_to_del"
                    rm -f "$file_to_del.version"
                    echo "  üóë –£–¥–∞–ª–µ–Ω: $(basename "$file_to_del")"
                    log_message "INFO" "Deleted $file_to_del (count-based rotation, prefix=$PREFIX)"
                fi
            done
            debug_log "ROTATION" "Deleted $diff files"
            echo "$diff"
            return 0
        else
            echo -e " $LABEL: –ù–∞–π–¥–µ–Ω–æ $count (–õ–∏–º–∏—Ç $MAX_BACKUPS_COUNT) -> ${RED}–ö–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ: $diff —à—Ç.${RESET}"
            echo "$diff"
        fi
    else
        debug_log "ROTATION" "No files to delete (count=$count <= limit=$MAX_BACKUPS_COUNT)"
        if [[ "$PERFORM_DELETE" != "true" ]]; then
            echo -e " $LABEL: –ù–∞–π–¥–µ–Ω–æ $count (–õ–∏–º–∏—Ç $MAX_BACKUPS_COUNT) -> ${GREEN}OK${RESET}"
        fi
        echo "0"
        return 0
    fi
}

rotate_backups_by_age() {
    local PREFIX="$1"
    local LABEL="$2"
    local DAYS="$3"
    local PERFORM_DELETE="$4"

    debug_log "ROTATION" "=== rotate_backups_by_age($PREFIX, $LABEL, days=$DAYS, delete=$PERFORM_DELETE) ==="

    # –ò—â–µ–º —Ç–æ–ª—å–∫–æ –∞—Ä—Ö–∏–≤—ã (–≤–∫–ª—é—á–∞—è .enc)
    local pattern1="$BACKUP_DIR/${PREFIX}_*.tar.gz"
    local pattern2="$BACKUP_DIR/${PREFIX}_*.tar.gz.enc"

    # –ù–∞–π–¥—ë–º —Ñ–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ DAYS –¥–Ω–µ–π
    local files=()
    # find -mtime +N –æ–∑–Ω–∞—á–∞–µ—Ç "—Å—Ç—Ä–æ–≥–æ –±–æ–ª—å—à–µ N –¥–Ω–µ–π". –ß—Ç–æ–±—ã RETENTION_DAYS=N –æ–∑–Ω–∞—á–∞–ª
    # "—É–¥–∞–ª—è—Ç—å —Ñ–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π", –∏—Å–ø–æ–ª—å–∑—É–µ–º -mtime +$((N-1)). –î–ª—è N==0 ‚Äî –±—É–¥–µ–º
    # —É–¥–∞–ª—è—Ç—å –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ñ–∞–π–ª—ã.
    # –°–æ–±–∏—Ä–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã find –±–µ–∑ eval
    local find_args=("$BACKUP_DIR" -maxdepth 1 \( -name "${PREFIX}_*.tar.gz" -o -name "${PREFIX}_*.tar.gz.enc" \) -type f)
    if [[ "$DAYS" -le 0 ]]; then
        # –ï—Å–ª–∏ 0 –∏–ª–∏ –º–µ–Ω—å—à–µ - –Ω–µ —É–¥–∞–ª—è–µ–º –Ω–∏—á–µ–≥–æ (–∑–∞—â–∏—Ç–∞ –æ—Ç –ø–æ–ª–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏)
        debug_log "ROTATION" "Days <= 0, skipping rotation"
        return 0
    else
        local nd=$((DAYS - 1))
        find_args+=( -mtime +"$nd" )
        debug_log "ROTATION" "Find mtime: +$nd (files older than $DAYS days)"
    fi
    find_args+=( -print0 )
    while IFS= read -r -d $'\0' f; do files+=("$f"); done < <(find "${find_args[@]}" 2> "$SILENT_LOG")

    local count=${#files[@]}
    debug_log "ROTATION" "Found $count files older than $DAYS days"

    if [[ $count -gt 0 ]]; then
        if [[ "$PERFORM_DELETE" == "true" ]]; then
            if [[ "$DRY_RUN" == "true" ]]; then
                debug_log "ROTATION" "[DRY-RUN] Would delete $count files"
                echo -e "${YELLOW}[DRY-RUN] –ö–∞—Ç–µ–≥–æ—Ä–∏—è '$LABEL': –±—ã–ª–æ –±—ã —É–¥–∞–ª–µ–Ω–æ $count —Ñ–∞–π–ª–æ–≤ —Å—Ç–∞—Ä—à–µ $DAYS –¥–Ω–µ–π.${RESET}"
                log_message "INFO" "[DRY_RUN] Would delete $count files (age-based rotation, prefix=$PREFIX, days=$DAYS)"
                echo "$count"
                return 0
            fi
            echo -e "${YELLOW}–û—á–∏—Å—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '$LABEL' (—É–¥–∞–ª–µ–Ω–∏–µ $count —Ñ–∞–π–ª–æ–≤ —Å—Ç–∞—Ä—à–µ $DAYS –¥–Ω–µ–π):${RESET}"
            for f in "${files[@]}"; do
                if [[ -f "$f" ]]; then
                    debug_log "ROTATION" "Deleting: $f"
                    rm -f "$f"
                    rm -f "$f.version"
                    echo "  üóë –£–¥–∞–ª–µ–Ω: $(basename "$f")"
                    log_message "INFO" "Deleted $f (age-based rotation, prefix=$PREFIX, days=$DAYS)"
                fi
            done
            debug_log "ROTATION" "Deleted $count files"
            echo "$count"
            return 0
        else
            echo -e " $LABEL: –ù–∞–π–¥–µ–Ω–æ $count —Ñ–∞–π–ª–æ–≤ —Å—Ç–∞—Ä—à–µ $DAYS –¥–Ω–µ–π -> ${RED}–ö–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ: $count —à—Ç.${RESET}"
            echo "$count"
        fi
    else
        debug_log "ROTATION" "No files to delete"
        if [[ "$PERFORM_DELETE" != "true" ]]; then
            echo -e " $LABEL: –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ —Å—Ç–∞—Ä—à–µ $DAYS –¥–Ω–µ–π -> ${GREEN}OK${RESET}"
        fi
        echo "0"
        return 0
    fi
}

# –†–æ—Ç–∞—Ü–∏—è –ø–æ —Ä–∞–∑–º–µ—Ä—É - —É–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã –ø–æ–∫–∞ –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä –Ω–µ —Å—Ç–∞–Ω–µ—Ç <= –ª–∏–º–∏—Ç–∞
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: rotate_backups_by_size "true" –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è, –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ - —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫–∞
rotate_backups_by_size() {
    local PERFORM_DELETE="$1"
    
    debug_log "SIZE" "=== rotate_backups_by_size(delete=$PERFORM_DELETE) ==="
    
    # –ï—Å–ª–∏ –ª–∏–º–∏—Ç 0 –∏–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω - –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
    if [[ -z "$MAX_BACKUP_SIZE_MB" || "$MAX_BACKUP_SIZE_MB" == "0" ]]; then
        debug_log "SIZE" "Size limit disabled (MAX_BACKUP_SIZE_MB=$MAX_BACKUP_SIZE_MB)"
        return 0
    fi
    
    local limit_mb="$MAX_BACKUP_SIZE_MB"
    local limit_bytes=$((limit_mb * 1024 * 1024))
    debug_log "SIZE" "Limit: $limit_mb MB ($limit_bytes bytes)"
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ä–∞–∑–º–µ—Ä –ø–∞–ø–∫–∏ –±—ç–∫–∞–ø–æ–≤ –≤ –±–∞–π—Ç–∞—Ö
    local current_size_bytes=$(du -sb "$BACKUP_DIR" 2> "$SILENT_LOG" | awk '{print $1}')
    local current_size_mb=$((current_size_bytes / 1024 / 1024))
    debug_log "SIZE" "Current size: $current_size_mb MB ($current_size_bytes bytes)"
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    local limit_display=""
    local current_display=""
    if [[ $limit_mb -ge 1024 ]]; then
        limit_display="$(echo "scale=1; $limit_mb / 1024" | bc) GB"
    else
        limit_display="$limit_mb MB"
    fi
    if [[ $current_size_mb -ge 1024 ]]; then
        current_display="$(echo "scale=1; $current_size_mb / 1024" | bc) GB"
    else
        current_display="$current_size_mb MB"
    fi
    
    debug_log "SIZE" "Current: $current_size_bytes bytes ($current_display), Limit: $limit_bytes bytes ($limit_display)"
    
    # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ª–∏–º–∏—Ç–∞ - –≤—Å—ë –æ–∫
    if [[ $current_size_bytes -le $limit_bytes ]]; then
        if [[ "$PERFORM_DELETE" != "true" ]]; then
            echo -e " –†–∞–∑–º–µ—Ä –±—ç–∫–∞–ø–æ–≤: ${GREEN}$current_display${RESET} / $limit_display -> ${GREEN}OK${RESET}"
        fi
        return 0
    fi
    
    # –ù—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª—ã
    local excess_mb=$((current_size_mb - limit_mb))
    local excess_display=""
    if [[ $excess_mb -ge 1024 ]]; then
        excess_display="$(echo "scale=1; $excess_mb / 1024" | bc) GB"
    else
        excess_display="$excess_mb MB"
    fi
    debug_log "SIZE" "Excess: $excess_mb MB ($excess_display)"
    
    if [[ "$PERFORM_DELETE" != "true" ]]; then
        echo -e " –†–∞–∑–º–µ—Ä –±—ç–∫–∞–ø–æ–≤: ${RED}$current_display${RESET} / $limit_display -> ${RED}–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ: $excess_display${RESET}"
        return 0
    fi
    
    # –†–µ–∂–∏–º —É–¥–∞–ª–µ–Ω–∏—è
    if [[ "$DRY_RUN" == "true" ]]; then
        debug_log "SIZE" "[DRY-RUN] Would delete files to free $excess_display"
        echo -e "${YELLOW}[DRY-RUN] –ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞ –Ω–∞ $excess_display. –°—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã –±—ã–ª–∏ –±—ã —É–¥–∞–ª–µ–Ω—ã.${RESET}"
        log_message "INFO" "[DRY_RUN] Size rotation: current=$current_display, limit=$limit_display, excess=$excess_display"
        return 0
    fi
    
    debug_log "SIZE" "Starting deletion loop..."
    echo -e "${YELLOW}–û—á–∏—Å—Ç–∫–∞ –ø–æ –ª–∏–º–∏—Ç—É —Ä–∞–∑–º–µ—Ä–∞ (—Ç–µ–∫—É—â–∏–π: $current_display, –ª–∏–º–∏—Ç: $limit_display):${RESET}"
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –±—ç–∫–∞–ø–æ–≤ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (—Å—Ç–∞—Ä—ã–µ –ø–µ—Ä–≤—ã–º–∏)
    local files=()
    while IFS= read -r -d $'\0' f; do 
        files+=("$f")
    done < <(find "$BACKUP_DIR" -maxdepth 1 -type f \( -name "lazarus_*.tar.gz" -o -name "lazarus_*.tar.gz.enc" \) -printf '%T@ %p\0' 2> "$SILENT_LOG" | sort -zn | cut -z -d' ' -f2-)
    
    debug_log "SIZE" "Found ${#files[@]} backup files to process"
    
    local deleted_count=0
    local deleted_size=0
    
    for file in "${files[@]}"; do
        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ä–∞–∑–º–µ—Ä
        current_size_bytes=$(du -sb "$BACKUP_DIR" 2> "$SILENT_LOG" | awk '{print $1}')
        debug_log "SIZE" "Current: $current_size_bytes bytes, limit: $limit_bytes bytes"
        
        if [[ $current_size_bytes -le $limit_bytes ]]; then
            debug_log "SIZE" "Size now within limit, stopping"
            break
        fi
        
        if [[ -f "$file" ]]; then
            local file_size=$(stat -c%s "$file" 2> "$SILENT_LOG" || echo 0)
            debug_log "SIZE" "Deleting: $file (size=$file_size bytes)"
            rm -f "$file"
            rm -f "$file.version"
            echo "  üóë –£–¥–∞–ª–µ–Ω: $(basename "$file")"
            log_message "INFO" "Deleted $file (size-based rotation)"
            ((deleted_count++))
            ((deleted_size += file_size))
        fi
    done
    
    local deleted_display=""
    local deleted_mb=$((deleted_size / 1024 / 1024))
    if [[ $deleted_mb -ge 1024 ]]; then
        deleted_display="$(echo "scale=1; $deleted_mb / 1024" | bc) GB"
    else
        deleted_display="$deleted_mb MB"
    fi
    
    if [[ $deleted_count -gt 0 ]]; then
        print_message "SUCCESS" "–£–¥–∞–ª–µ–Ω–æ $deleted_count —Ñ–∞–π–ª–æ–≤ ($deleted_display)"
        log_message "SUCCESS" "Size-based rotation: deleted $deleted_count files ($deleted_display)"
    fi
    
    return 0
}

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
format_size_mb() {
    local size_mb="$1"
    if [[ -z "$size_mb" || "$size_mb" == "0" ]]; then
        echo "–ë–µ–∑ –ª–∏–º–∏—Ç–∞"
    elif [[ $size_mb -ge 1024 ]]; then
        echo "$(echo "scale=1; $size_mb / 1024" | bc) GB"
    else
        echo "$size_mb MB"
    fi
}

uninstall_script() {
    if [[ "$EUID" -ne 0 ]]; then
        print_message "ERROR" "Uninstall requires root (sudo)."
        return 1
    fi
    echo ""
    print_message "WARN" "–£–¥–∞–ª–µ–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞ –∏ –¥–∞–Ω–Ω—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–æ.";
    read -erp "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/N): " ans
    if [[ ! "$ans" =~ ^[Yy]$ ]]; then print_message "INFO" "–û—Ç–º–µ–Ω–µ–Ω–æ."; return 0; fi

    # remove symlink
    if [[ -L "$SYMLINK_PATH" ]]; then
        rm -f "$SYMLINK_PATH" && log_message "INFO" "Removed symlink $SYMLINK_PATH"
    fi
    # remove installed script
    if [[ -f "$INSTALL_DIR/$SCRIPT_NAME" ]]; then
        rm -f "$INSTALL_DIR/$SCRIPT_NAME" && log_message "INFO" "Removed $INSTALL_DIR/$SCRIPT_NAME"
    fi
    # remove config and backups (ask)
    if [[ -d "$INSTALL_DIR" ]]; then
        read -erp "–£–¥–∞–ª–∏—Ç—å –ø–∞–ø–∫—É $INSTALL_DIR –∏ –≤—Å–µ –±—ç–∫–∞–ø—ã? (y/N): " r2
        if [[ "$r2" =~ ^[Yy]$ ]]; then
            rm -rf "$INSTALL_DIR" && log_message "INFO" "Removed $INSTALL_DIR"
        else
            log_message "INFO" "Preserved $INSTALL_DIR"
        fi
    fi
    # try to remove cron entries
    crontab -l 2> "$SILENT_LOG" | grep -v "# LAZARUS-JOB-" | crontab - 2> "$SILENT_LOG" || true
    log_message "INFO" "Attempted to remove cron entries for lazarus"
    print_message "SUCCESS" "Uninstall finished."
}

# --- –ü–†–û–í–ï–†–ö–ê CRON –ó–ê–î–ê–ß ---

# –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ cron-–∑–∞–¥–∞—á –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å
get_cron_status() {
    local JOB_TYPE="$1"  # full, db, files
    local JOB_ID="# LAZARUS-JOB-${JOB_TYPE^^}"
    
    local cron_line=$(crontab -l 2> "$SILENT_LOG" | grep "$JOB_ID")
    
    if [[ -z "$cron_line" ]]; then
        echo "–í—ã–∫–ª"
        return
    fi
    
    # –ü–∞—Ä—Å–∏–º cron-—Å—Ç—Ä–æ–∫—É –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
    local minute=$(echo "$cron_line" | awk '{print $1}')
    local hour=$(echo "$cron_line" | awk '{print $2}')
    local day_month=$(echo "$cron_line" | awk '{print $3}')
    local month=$(echo "$cron_line" | awk '{print $4}')
    local day_week=$(echo "$cron_line" | awk '{print $5}')
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
    if [[ "$minute" == "0" && "$hour" == "*" ]]; then
        echo "–ï–∂–µ—á–∞—Å–Ω–æ"
    elif [[ "$minute" =~ ^\*/([0-9]+)$ ]]; then
        echo "–ö–∞–∂–¥—ã–µ ${BASH_REMATCH[1]} –º–∏–Ω"
    elif [[ "$minute" == "0" && "$hour" == "4" && "$day_week" == "1" ]]; then
        echo "–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ"
    elif [[ "$minute" == "0" && "$hour" =~ ^[0-9]+$ && "$day_month" == "*" ]]; then
        printf "–ï–∂–µ–¥–Ω–µ–≤–Ω–æ %02d:00" "$hour"
    elif [[ "$hour" =~ ^[0-9]+$ && "$minute" =~ ^[0-9]+$ ]]; then
        printf "–ï–∂–µ–¥–Ω–µ–≤–Ω–æ %02d:%02d" "$hour" "$minute"
    else
        echo "–ê–∫—Ç–∏–≤–Ω–æ"
    fi
}

# –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∫—Ä–∏–ø—Ç–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º cron
sync_cron_with_config() {
    local CRON_FULL=$(get_cron_status "full")
    local CRON_DB=$(get_cron_status "db")
    local CRON_FILES=$(get_cron_status "files")
    
    local needs_save=false
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –µ—Å–ª–∏ –æ–Ω–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ cron
    if [[ "$SCHEDULE_FULL" != "$CRON_FULL" ]]; then
        SCHEDULE_FULL="$CRON_FULL"
        needs_save=true
    fi
    if [[ "$SCHEDULE_DB" != "$CRON_DB" ]]; then
        SCHEDULE_DB="$CRON_DB"
        needs_save=true
    fi
    if [[ "$SCHEDULE_FILES" != "$CRON_FILES" ]]; then
        SCHEDULE_FILES="$CRON_FILES"
        needs_save=true
    fi
    
    if [[ "$needs_save" == "true" ]]; then
        save_config
    fi
}

# –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ–∂–¥—É –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∏ cron, –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∏—Å–ø—Ä–∞–≤–∏—Ç—å
check_cron_mismatch() {
    [[ "$IS_INTERACTIVE" != "true" ]] && return 0
    
    local CRON_FULL=$(get_cron_status "full")
    local CRON_DB=$(get_cron_status "db")
    local CRON_FILES=$(get_cron_status "files")
    
    local mismatches=()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º: –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –≤–∫–ª—é—á–µ–Ω–æ, –Ω–æ –≤ cron –Ω–µ—Ç
    if [[ "$SCHEDULE_FULL" != "–í—ã–∫–ª" && "$CRON_FULL" == "–í—ã–∫–ª" ]]; then
        mismatches+=("Full: –Ω–∞—Å—Ç—Ä–æ–π–∫–∞='$SCHEDULE_FULL', cron=–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    fi
    if [[ "$SCHEDULE_DB" != "–í—ã–∫–ª" && "$CRON_DB" == "–í—ã–∫–ª" ]]; then
        mismatches+=("DB: –Ω–∞—Å—Ç—Ä–æ–π–∫–∞='$SCHEDULE_DB', cron=–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    fi
    if [[ "$SCHEDULE_FILES" != "–í—ã–∫–ª" && "$CRON_FILES" == "–í—ã–∫–ª" ]]; then
        mismatches+=("Files: –Ω–∞—Å—Ç—Ä–æ–π–∫–∞='$SCHEDULE_FILES', cron=–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    fi
    
    if [[ ${#mismatches[@]} -eq 0 ]]; then
        return 0
    fi
    
    clear_screen
    echo -e "${YELLOW}${BOLD}‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏ cron-–∑–∞–¥–∞—á${RESET}"
    echo ""
    echo "–í –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö —Å–∫—Ä–∏–ø—Ç–∞ —É–∫–∞–∑–∞–Ω—ã –∑–∞–¥–∞—á–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫–∞–ø–∞,"
    echo "–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ cron-–∑–∞–¥–∞—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Å–∏—Å—Ç–µ–º–µ."
    echo ""
    echo -e "${CYAN}–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è:${RESET}"
    for m in "${mismatches[@]}"; do
        echo -e " ‚Ä¢ $m"
    done
    echo ""
    echo "–í–æ–∑–º–æ–∂–Ω–æ, cron-–∑–∞–¥–∞—á–∏ –±—ã–ª–∏ —É–¥–∞–ª–µ–Ω—ã –≤—Ä—É—á–Ω—É—é."
    echo ""
    echo " 1. –°–æ–∑–¥–∞—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ cron-–∑–∞–¥–∞—á–∏ (–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å)"
    echo " 2. –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å cron (—Å–±—Ä–æ—Å–∏—Ç—å –≤ '–í—ã–∫–ª')"
    echo " 0. –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å (–æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å)"
    echo ""
    read -erp "–í–∞—à –≤—ã–±–æ—Ä: " choice
    
    case $choice in
        1)
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º cron-–∑–∞–¥–∞—á–∏ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
            if [[ "$SCHEDULE_FULL" != "–í—ã–∫–ª" && "$CRON_FULL" == "–í—ã–∫–ª" ]]; then
                recreate_cron_from_schedule "full" "$SCHEDULE_FULL"
            fi
            if [[ "$SCHEDULE_DB" != "–í—ã–∫–ª" && "$CRON_DB" == "–í—ã–∫–ª" ]]; then
                recreate_cron_from_schedule "db" "$SCHEDULE_DB"
            fi
            if [[ "$SCHEDULE_FILES" != "–í—ã–∫–ª" && "$CRON_FILES" == "–í—ã–∫–ª" ]]; then
                recreate_cron_from_schedule "files" "$SCHEDULE_FILES"
            fi
            print_message "SUCCESS" "Cron-–∑–∞–¥–∞—á–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã."
            sleep 1
            ;;
        2)
            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º cron
            sync_cron_with_config
            print_message "SUCCESS" "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å cron."
            sleep 1
            ;;
        *)
            print_message "INFO" "–ü—Ä–æ–ø—É—â–µ–Ω–æ."
            sleep 0.5
            ;;
    esac
}

# –í–æ—Å—Å–æ–∑–¥–∞—ë—Ç cron-–∑–∞–¥–∞—á—É –∏–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
recreate_cron_from_schedule() {
    local TASK_TYPE="$1"
    local SCHEDULE="$2"
    
    local JOB_CMD="$SYMLINK_PATH backup_$TASK_TYPE"
    [[ "$TASK_TYPE" == "db" ]] && JOB_CMD="$SYMLINK_PATH backup_db"
    [[ "$TASK_TYPE" == "files" ]] && JOB_CMD="$SYMLINK_PATH backup_files"
    [[ "$TASK_TYPE" == "full" ]] && JOB_CMD="$SYMLINK_PATH backup_full"
    
    local JOB_ID="# LAZARUS-JOB-${TASK_TYPE^^}"
    local NEW_CRON_LINE=""
    
    # –ü–∞—Ä—Å–∏–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∏ —Å–æ–∑–¥–∞—ë–º cron-—Å—Ç—Ä–æ–∫—É
    case "$SCHEDULE" in
        "–ï–∂–µ—á–∞—Å–Ω–æ")
            NEW_CRON_LINE="0 * * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"
            ;;
        "–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ")
            NEW_CRON_LINE="0 4 * * 1 $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"
            ;;
        –ï–∂–µ–¥–Ω–µ–≤–Ω–æ\ *)
            # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è –∏–∑ "–ï–∂–µ–¥–Ω–µ–≤–Ω–æ HH:MM" –∏–ª–∏ "–ï–∂–µ–¥–Ω–µ–≤–Ω–æ HH:00"
            local time_part="${SCHEDULE#–ï–∂–µ–¥–Ω–µ–≤–Ω–æ }"
            local hour="${time_part%%:*}"
            local minute="${time_part##*:}"
            hour=$((10#$hour))  # –£–±–∏—Ä–∞–µ–º –≤–µ–¥—É—â–∏–π –Ω–æ–ª—å
            minute=$((10#$minute))
            NEW_CRON_LINE="$minute $hour * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"
            ;;
        –ö–∞–∂–¥—ã–µ\ *\ –º–∏–Ω)
            local interval="${SCHEDULE#–ö–∞–∂–¥—ã–µ }"
            interval="${interval% –º–∏–Ω}"
            NEW_CRON_LINE="*/$interval * * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"
            ;;
        *)
            # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            print_message "WARN" "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ: $SCHEDULE"
            return 1
            ;;
    esac
    
    if [[ -n "$NEW_CRON_LINE" ]]; then
        local CURRENT_CRON=$(crontab -l 2> "$SILENT_LOG" | grep -v "$JOB_ID")
        echo -e "$CURRENT_CRON\n$NEW_CRON_LINE" | crontab -
        log_message "INFO" "Recreated cron job for $TASK_TYPE: $SCHEDULE"
    fi
}

# --- –ë–≠–ö–ê–ü ---

create_backup() {
    local TYPE="$1"
    debug_log "BACKUP" "=== Starting backup: type=$TYPE ==="
    debug_log "BACKUP" "BOT_PATH=$BOT_PATH"
    debug_log "BACKUP" "BOT_CONTAINER=$BOT_CONTAINER_NAME, DB_CONTAINER=$DB_CONTAINER_NAME"
    debug_log "BACKUP" "IS_INTERACTIVE=$IS_INTERACTIVE"
    
    # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –æ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ (—Ç–æ–ª—å–∫–æ –≤ non-interactive —Ä–µ–∂–∏–º–µ)
    local LOCK_ACQUIRED="false"
    if [[ "$IS_INTERACTIVE" == "false" ]]; then
        debug_log "LOCK" "Attempting to acquire lock..."
        if ! acquire_lock; then
            local owner_pid=$(check_lock_owner)
            debug_log "LOCK" "Lock failed! Owner PID: $owner_pid"
            log_message "WARN" "Backup skipped: another instance is running (PID: $owner_pid)"
            print_message "WARN" "–î—Ä—É–≥–æ–π –ø—Ä–æ—Ü–µ—Å—Å –±—ç–∫–∞–ø–∞ —É–∂–µ –∑–∞–ø—É—â–µ–Ω (PID: $owner_pid)"
            return 1
        fi
        debug_log "LOCK" "Lock acquired successfully"
        LOCK_ACQUIRED="true"
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ (–º–∏–Ω–∏–º—É–º 1GB)
    local MIN_SPACE_MB=1024
    local free_space_kb=$(df -P "$BACKUP_DIR" 2> "$SILENT_LOG" | tail -1 | awk '{print $4}')
    local free_space_mb=$((free_space_kb / 1024))
    local free_space_human=$(df -h "$BACKUP_DIR" 2> "$SILENT_LOG" | tail -1 | awk '{print $4}')
    debug_log "DISK" "Free space: ${free_space_mb}MB (${free_space_human}), required: ${MIN_SPACE_MB}MB"
    
    if [[ $free_space_mb -lt $MIN_SPACE_MB ]]; then
        print_message "ERROR" "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ! –°–≤–æ–±–æ–¥–Ω–æ: ${free_space_human} (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 1GB)"
        log_message "ERROR" "Backup aborted: insufficient disk space (free=${free_space_human}, required=1GB)"
        if [[ "$IS_INTERACTIVE" == "true" ]]; then
            echo ""
            echo -e "${YELLOW}–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:${RESET}"
            echo " ‚Ä¢ –£–¥–∞–ª–∏—Ç–µ —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã (–º–µ–Ω—é 5)"
            echo " ‚Ä¢ –û—Å–≤–æ–±–æ–¥–∏—Ç–µ –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ"
            echo ""
            read -erp "–í—Å—ë —Ä–∞–≤–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/N): " force_continue
            if [[ ! "$force_continue" =~ ^[Yy]$ ]]; then
                return 1
            fi
            print_message "WARN" "–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –Ω–∞ —Å–≤–æ–π —Ä–∏—Å–∫..."
        else
            # –í non-interactive —Ä–µ–∂–∏–º–µ (cron) –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∏ –ø—Ä–µ—Ä—ã–≤–∞–µ–º
            send_telegram_notification "–ë—ç–∫–∞–ø –ø—Ä–µ—Ä–≤–∞–Ω: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ (${free_space_human})"
            [[ "$LOCK_ACQUIRED" == "true" ]] && release_lock
            return 1
        fi
    fi
    
    # Health-check –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –ø–µ—Ä–µ–¥ –±—ç–∫–∞–ø–æ–º
    if [[ "$TYPE" == "full" || "$TYPE" == "db_only" ]]; then
        debug_log "HEALTH" "Checking DB container health..."
        if [[ -n "$DB_CONTAINER_NAME" ]]; then
            local db_running=$(docker container inspect -f '{{.State.Running}}' "$DB_CONTAINER_NAME" 2> "$SILENT_LOG")
            debug_log "HEALTH" "Container $DB_CONTAINER_NAME running=$db_running"
            if [[ "$db_running" != "true" ]]; then
                print_message "ERROR" "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–î ($DB_CONTAINER_NAME) –Ω–µ –∑–∞–ø—É—â–µ–Ω!"
                log_message "ERROR" "Backup aborted: DB container not running ($DB_CONTAINER_NAME)"
                if [[ "$IS_INTERACTIVE" != "true" ]]; then
                    send_telegram_notification "–ë—ç–∫–∞–ø –ø—Ä–µ—Ä–≤–∞–Ω: –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–î –Ω–µ –∑–∞–ø—É—â–µ–Ω ($DB_CONTAINER_NAME)"
                fi
                [[ "$LOCK_ACQUIRED" == "true" ]] && release_lock
                return 1
            fi
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º health status –µ—Å–ª–∏ –µ—Å—Ç—å
            local db_health=$(docker container inspect -f '{{.State.Health.Status}}' "$DB_CONTAINER_NAME" 2> "$SILENT_LOG")
            debug_log "HEALTH" "Container health status: $db_health"
            if [[ "$db_health" == "unhealthy" ]]; then
                print_message "WARN" "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–î –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ 'unhealthy'!"
                log_message "WARN" "DB container health status: unhealthy ($DB_CONTAINER_NAME)"
                if [[ "$IS_INTERACTIVE" == "true" ]]; then
                    read -erp "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ? (y/N): " cont_unhealthy
                    if [[ ! "$cont_unhealthy" =~ ^[Yy]$ ]]; then
                        return 1
                    fi
                fi
                # –í cron-—Ä–µ–∂–∏–º–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º, –Ω–æ –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
            fi
        fi
    fi
    
    if [[ -z "$BACKUP_PASSWORD" && "$IS_INTERACTIVE" == "true" ]]; then
        clear_screen
        echo -e "${RED}${BOLD}‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ü–∞—Ä–æ–ª—å —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!${RESET}"
        echo "–§–∞–π–ª –±—ç–∫–∞–ø–∞ –Ω–µ –±—É–¥–µ—Ç –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω. –î–∞–Ω–Ω—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã —Ç—Ä–µ—Ç—å–∏–º –ª–∏—Ü–∞–º."
        echo ""
        echo " 1. –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –±–µ–∑ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è"
        echo " 2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–∞—Ä–æ–ª—å —Å–µ–π—á–∞—Å"
        echo " 0. –û—Ç–º–µ–Ω–∞"
        echo ""
        read -erp "–í–∞—à –≤—ã–±–æ—Ä: " enc_choice
        case $enc_choice in
            1) ;; 
            2) read -s -erp "–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è: " np
               echo ""; if [[ -n "$np" ]]; then BACKUP_PASSWORD="$np"; save_config; print_message "SUCCESS" "–ü–∞—Ä–æ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω."; else print_message "ERROR" "–ü—É—Å—Ç–æ–π –ø–∞—Ä–æ–ª—å. –û—Ç–º–µ–Ω–∞."; return; fi ;;
            *) print_message "INFO" "–ë—ç–∫–∞–ø –æ—Ç–º–µ–Ω–µ–Ω."; return ;;
        esac
    fi

    local TIMESTAMP=$(date +%Y-%m-%d"_"%H_%M_%S)
    local FILE_DB="db_${TIMESTAMP}.sql.gz"
    local FILE_DIR="dir_${TIMESTAMP}.tar.gz"
    local FILE_VERSION="bot_version.txt"
    local FILE_FINAL=""
    local HAS_ERROR=0
    local SKIP_INFO=""
    local SKIP_FILE="$BACKUP_DIR/skipped_files.txt"

    if [[ "$TYPE" != "db_only" ]]; then if ! ensure_bot_path; then return; fi; fi
    if [[ "$TYPE" == "db_only" || "$TYPE" == "full" ]]; then
        if [[ -z "$DB_CONTAINER_NAME" ]]; then ensure_bot_path; fi
    fi

    local CURRENT_VER=$(get_raw_bot_version)
    echo "${CURRENT_VER:-Unknown}" > "$BACKUP_DIR/$FILE_VERSION"
    debug_log "BACKUP" "Bot version saved: ${CURRENT_VER:-Unknown}"

    if [[ "$TYPE" == "full" || "$TYPE" == "db_only" ]]; then
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ë–î –∏–∑ .env –±–æ—Ç–∞ (—Å–æ–≥–ª–∞—Å–Ω–æ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏)
        local ACTUAL_DB_USER=$(get_db_user)
        local ACTUAL_DB_NAME=$(get_db_name)
        debug_log "DB" "DB params: user=$ACTUAL_DB_USER, db=$ACTUAL_DB_NAME"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –ë–î —á–µ—Ä–µ–∑ pg_isready (—Å–æ–≥–ª–∞—Å–Ω–æ healthcheck –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏)
        print_message "INFO" "–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ë–î..."
        debug_log "DB" "Running: docker exec $DB_CONTAINER_NAME pg_isready -U $ACTUAL_DB_USER -d $ACTUAL_DB_NAME"
        if ! docker exec "$DB_CONTAINER_NAME" pg_isready -U "$ACTUAL_DB_USER" -d "$ACTUAL_DB_NAME" > "$SILENT_LOG" 2>&1; then
            print_message "ERROR" "–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –≥–æ—Ç–æ–≤–∞! (pg_isready failed)"
            log_message "ERROR" "Backup aborted: pg_isready failed for $DB_CONTAINER_NAME"
            if [[ "$IS_INTERACTIVE" != "true" ]]; then
                send_telegram_notification "–ë—ç–∫–∞–ø –ø—Ä–µ—Ä–≤–∞–Ω: –ë–î –Ω–µ –≥–æ—Ç–æ–≤–∞ ($DB_CONTAINER_NAME)"
            fi
            [[ "$LOCK_ACQUIRED" == "true" ]] && release_lock
            return 1
        fi
        debug_log "DB" "pg_isready: OK"
        
        print_message "INFO" "–î–∞–º–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö ($DB_CONTAINER_NAME, user=$ACTUAL_DB_USER, db=$ACTUAL_DB_NAME)..."
        debug_log "DB" "Running: docker exec $DB_CONTAINER_NAME pg_dump -U $ACTUAL_DB_USER $ACTUAL_DB_NAME | gzip -9 > $BACKUP_DIR/$FILE_DB"
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º pg_dump –≤–º–µ—Å—Ç–æ pg_dumpall (—Å–æ–≥–ª–∞—Å–Ω–æ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏)
        # pg_dump –±—ã—Å—Ç—Ä–µ–µ –∏ –ø—Ä–æ—â–µ –¥–ª—è –æ–¥–Ω–æ–π –ë–î
        if ! docker exec "$DB_CONTAINER_NAME" pg_dump -U "$ACTUAL_DB_USER" "$ACTUAL_DB_NAME" 2> "$SILENT_LOG" | gzip -9 > "$BACKUP_DIR/$FILE_DB"; then
            print_message "ERROR" "–û—à–∏–±–∫–∞ –¥–∞–º–ø–∞ –ë–î."
            debug_log "DB" "pg_dump FAILED"
            HAS_ERROR=1
        else
            local db_size=$(du -h "$BACKUP_DIR/$FILE_DB" 2>/dev/null | cut -f1)
            debug_log "DB" "pg_dump SUCCESS, file size: $db_size"
        fi
    fi

    if [[ $HAS_ERROR -eq 1 ]]; then 
        rm -f "$BACKUP_DIR/$FILE_DB" "$BACKUP_DIR/$FILE_VERSION"
        [[ "$LOCK_ACQUIRED" == "true" ]] && release_lock
        return 1
    fi

    IFS=' ' read -r -a EXCLUDE_ARRAY <<< "$EXCLUDE_DIRS"
    EXCLUDE_FLAGS=()
    for ex in "${EXCLUDE_ARRAY[@]}"; do if [[ -n "$ex" ]]; then EXCLUDE_FLAGS+=(--exclude="$ex"); fi; done
    # –ò—Å–∫–ª—é—á–∞–µ–º —Å–æ–≥–ª–∞—Å–Ω–æ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:
    # - *.log —Ñ–∞–π–ª—ã
    # - .git –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
    # - Docker –æ–±—Ä–∞–∑—ã (*.tar —Ñ–∞–π–ª—ã)
    # - logs/ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (access-–ª–æ–≥–∏ –∏–∑ ACCESS_LOG_PATH)
    # - backups/ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (–ª–æ–∫–∞–ª—å–Ω—ã–µ –±—ç–∫–∞–ø—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
    EXCLUDE_FLAGS+=(--exclude="*.log" --exclude=".git" --exclude="logs" --exclude="backups")
    EXCLUDE_FLAGS+=(--exclude="private-remnawave-*.tar" --exclude="rwp_shop*.tar" --exclude="telegram-shop*.tar")
    debug_log "TAR" "Exclude flags: ${EXCLUDE_FLAGS[*]}"

    if [[ "$TYPE" != "db_only" ]]; then
        : > "$SKIP_FILE"
        local BOT_DIRNAME=$(basename "$BOT_PATH")
        debug_log "TAR" "BOT_DIRNAME=$BOT_DIRNAME, MAX_FILE_SIZE_MB=$MAX_FILE_SIZE_MB"
        local FIND_CMD="find ."
        for ex in "${EXCLUDE_ARRAY[@]}"; do if [[ -n "$ex" ]]; then FIND_CMD+=" -path './$ex' -prune -o"; fi; done
        FIND_CMD+=" -type f -size +${MAX_FILE_SIZE_MB}M -print"
        debug_log "TAR" "Find command: $FIND_CMD"
        cd "$BOT_PATH"; eval "$FIND_CMD" | while read -r f; do
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ./path/file –≤ BOT_DIRNAME/path/file –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã --exclude-from
            echo "${BOT_DIRNAME}${f#.}"
        done > "$SKIP_FILE"
        local SKIP_COUNT=$(wc -l < "$SKIP_FILE")
        debug_log "TAR" "Large files to skip: $SKIP_COUNT"
        if [[ "$SKIP_COUNT" -gt 0 ]]; then
            local SKIP_SIZE=$(cd "$BOT_PATH" && eval "$FIND_CMD" | tr '\n' '\0' | du -ch --files0-from=- 2>/dev/null | tail -1 | cut -f1)
            print_message "WARN" "–ü—Ä–æ–ø—É—â–µ–Ω–æ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ (>${MAX_FILE_SIZE_MB}MB): $SKIP_COUNT (–æ–±—â–∏–π –≤–µ—Å: $SKIP_SIZE)"
            debug_log "TAR" "Skipped files content:"
            if [[ "$DEBUG_MODE" == true ]]; then cat "$SKIP_FILE"; fi
            EXCLUDE_FLAGS+=(--exclude-from="$SKIP_FILE")
            SKIP_INFO=$'\n‚ö†Ô∏è Skip: '"$SKIP_COUNT"$' (>'"$MAX_FILE_SIZE_MB"$'MB)'
        fi
    fi

    if [[ "$TYPE" == "db_only" ]]; then
        FILE_FINAL="lazarus_db_${TIMESTAMP}.tar.gz"
        debug_log "TAR" "Creating DB archive: $FILE_FINAL"
        tar -czf "$BACKUP_DIR/$FILE_FINAL" -C "$BACKUP_DIR" "$FILE_VERSION" "$FILE_DB"
        rm -f "$BACKUP_DIR/$FILE_DB"
    elif [[ "$TYPE" == "files_only" ]]; then
        FILE_FINAL="lazarus_files_${TIMESTAMP}.tar.gz"
        local FILE_DIR="bot_files_${TIMESTAMP}.tar.gz"
        print_message "INFO" "–ê—Ä—Ö–∏–≤–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)..."
        debug_log "TAR" "Creating files archive: $FILE_FINAL"
        debug_log "TAR" "Running: tar -czf $BACKUP_DIR/$FILE_DIR ${EXCLUDE_FLAGS[*]} -C $(dirname "$BOT_PATH") $(basename "$BOT_PATH")"
        # –°–Ω–∞—á–∞–ª–∞ –∞—Ä—Ö–∏–≤–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –±–æ—Ç–∞ —Å –∏—Å–∫–ª—é—á–µ–Ω–∏—è–º–∏
        tar -czf "$BACKUP_DIR/$FILE_DIR" "${EXCLUDE_FLAGS[@]}" -C "$(dirname "$BOT_PATH")" "$(basename "$BOT_PATH")"
        # –ó–∞—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å –≤–µ—Ä—Å–∏–µ–π
        tar -czf "$BACKUP_DIR/$FILE_FINAL" -C "$BACKUP_DIR" "$FILE_VERSION" "$FILE_DIR"
        rm -f "$BACKUP_DIR/$FILE_DIR"
    else 
        FILE_FINAL="lazarus_full_${TIMESTAMP}.tar.gz"
        print_message "INFO" "–ê—Ä—Ö–∏–≤–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)..."
        debug_log "TAR" "Creating full archive: $FILE_FINAL"
        tar -czf "$BACKUP_DIR/$FILE_DIR" "${EXCLUDE_FLAGS[@]}" -C "$(dirname "$BOT_PATH")" "$(basename "$BOT_PATH")"
        tar -czf "$BACKUP_DIR/$FILE_FINAL" -C "$BACKUP_DIR" "$FILE_VERSION" "$FILE_DB" "$FILE_DIR"
        rm -f "$BACKUP_DIR/$FILE_DB" "$BACKUP_DIR/$FILE_DIR"
    fi

    rm -f "$SKIP_FILE"

    local ENC_STATUS="üîì Unencrypted"
    if [[ -z "$BACKUP_PASSWORD" && "$IS_INTERACTIVE" == "false" ]]; then ENC_STATUS="‚ö†Ô∏è NO PASSWORD"; fi

    if [[ -n "$BACKUP_PASSWORD" ]]; then
        print_message "INFO" "–®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)..."
        # Pass password via env var to avoid process listing leak
        # AES-256-CBC + PBKDF2 with 100k iterations for brute-force protection
        export LAZARUS_ENC_PASS="$BACKUP_PASSWORD"
        openssl enc -aes-256-cbc -salt -pbkdf2 -iter 100000 -in "$BACKUP_DIR/$FILE_FINAL" -out "$BACKUP_DIR/${FILE_FINAL}.enc" -pass env:LAZARUS_ENC_PASS
        local enc_res=$?
        unset LAZARUS_ENC_PASS
        
        if [[ $enc_res -eq 0 ]]; then
            rm "$BACKUP_DIR/$FILE_FINAL"
            FILE_FINAL="${FILE_FINAL}.enc"
            ENC_STATUS="üîí Encrypted"
            print_message "SUCCESS" "–ê—Ä—Ö–∏–≤ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω."
            debug_log "ENC" "Encryption successful: $FILE_FINAL"
        else
            print_message "ERROR" "–û—à–∏–±–∫–∞ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è! –û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–µ–∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."
            debug_log "ENC" "Encryption FAILED!"
        fi
    fi

    local FINAL_VERSION_FILE="$BACKUP_DIR/$FILE_FINAL.version"
    cp "$BACKUP_DIR/$FILE_VERSION" "$FINAL_VERSION_FILE"
    rm -f "$BACKUP_DIR/$FILE_VERSION"
    debug_log "BACKUP" "Version file: $FINAL_VERSION_FILE"
    
    # --- VERIFY ARCHIVE ---
    print_message "INFO" "–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –∞—Ä—Ö–∏–≤–∞..."
    debug_log "VERIFY" "Verifying archive integrity..."
    local VERIFY_OK="false"
    if [[ "$FILE_FINAL" == *".enc" ]]; then
        # For encrypted files, we can't easily verify without decrypting. 
        # We assume openssl exit code 0 was enough, or we could decrypt to /dev/null
        debug_log "VERIFY" "Running: openssl enc -d ... | gzip -t"
        export LAZARUS_VERIFY_PASS="$BACKUP_PASSWORD"
        if openssl enc -d -aes-256-cbc -pbkdf2 -iter 100000 -in "$BACKUP_DIR/$FILE_FINAL" -pass env:LAZARUS_VERIFY_PASS | gzip -t 2> "$SILENT_LOG"; then
             VERIFY_OK="true"
        fi
        unset LAZARUS_VERIFY_PASS
    else
        debug_log "VERIFY" "Running: gzip -t $BACKUP_DIR/$FILE_FINAL"
        if gzip -t "$BACKUP_DIR/$FILE_FINAL" 2> "$SILENT_LOG"; then
             VERIFY_OK="true"
        fi
    fi
    debug_log "VERIFY" "Result: $VERIFY_OK"

    if [[ "$VERIFY_OK" == "true" ]]; then
        print_message "SUCCESS" "–ê—Ä—Ö–∏–≤ –≤–∞–ª–∏–¥–µ–Ω."
    else
        print_message "ERROR" "–ê—Ä—Ö–∏–≤ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω! (Verification failed)"
        # We do not delete it, just warn
    fi

    local SIZE=$(du -h "$BACKUP_DIR/$FILE_FINAL" | awk '{print $1}')
    print_message "SUCCESS" "–ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: $FILE_FINAL ($SIZE)"
    log_message "SUCCESS" "Backup created: $FILE_FINAL (type=$TYPE, size=$SIZE, enc_status=$ENC_STATUS, verify=$VERIFY_OK)"
    debug_log "BACKUP" "Final file: $FILE_FINAL, size: $SIZE"

    debug_log "UPLOAD" "Starting remote upload..."
    upload_to_remote "$BACKUP_DIR/$FILE_FINAL"
    debug_log "UPLOAD" "Remote upload complete"
    
    local DISPLAY_DATE=$(date "+%d.%m.%Y %H:%M:%S")
    local HASHTAG=""; local TYPE_NAME=""; local ROTATION_KEY=""
    
    case "$TYPE" in
        "full") HASHTAG="üíæ #full_backup"; TYPE_NAME="üì¶ –ü–æ–ª–Ω—ã–π –±—ç–∫–∞–ø"; ROTATION_KEY="–ü–æ–ª–Ω—ã–µ –±—ç–∫–∞–ø—ã" ;;
        "db_only") HASHTAG="üíæ #db_only"; TYPE_NAME="üóÑ –î–∞–º–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"; ROTATION_KEY="–ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö" ;;
        "files_only") HASHTAG="üíæ #files_only"; TYPE_NAME="üìÇ –§–∞–π–ª—ã –±–æ—Ç–∞"; ROTATION_KEY="–ê—Ä—Ö–∏–≤—ã —Ñ–∞–π–ª–æ–≤" ;;
    esac

    local VER_MSG=""; [[ -n "$CURRENT_VER" ]] && VER_MSG=" | üè∑ v${CURRENT_VER}"
    local CAPTION="${HASHTAG}
üìÖ ${DISPLAY_DATE}
${TYPE_NAME}
üìè ${SIZE}${VER_MSG}
${ENC_STATUS}${REMOTE_UPLOAD_STATUS_TEXT}${SKIP_INFO}"
    
    send_telegram_document "$BACKUP_DIR/$FILE_FINAL" "$CAPTION"

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–æ—Ç–∞—Ü–∏—è –±—ç–∫–∞–ø–æ–≤ –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è (–ø–æ–¥–∞–≤–ª—è–µ–º –≤—ã–≤–æ–¥ —Å—á—ë—Ç—á–∏–∫–æ–≤)
    local ROTATION_PREFIX="lazarus_$TYPE"
    if [[ "$TYPE" == "db_only" ]]; then ROTATION_PREFIX="lazarus_db"; fi
    if [[ "$TYPE" == "files_only" ]]; then ROTATION_PREFIX="lazarus_files"; fi

    # –†–æ—Ç–∞—Ü–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–∫ DELETE_MODE
    if [[ "$DELETE_MODE" == "count" ]]; then
        rotate_backups_by_count "$ROTATION_PREFIX" "$ROTATION_KEY" "true" > /dev/null
    else
        rotate_backups_by_age "$ROTATION_PREFIX" "$ROTATION_KEY" "$RETENTION_DAYS" "true" > /dev/null
    fi
    
    # –†–æ—Ç–∞—Ü–∏—è –ø–æ —Ä–∞–∑–º–µ—Ä—É (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –ª–∏–º–∏—Ç)
    rotate_backups_by_size "true" > /dev/null
    
    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
    [[ "$LOCK_ACQUIRED" == "true" ]] && release_lock
    
    return 0
}

# --- –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï ---

select_backup_file() {
    local FILTER_PREFIX="$1"; local TITLE="$2"
    local show_limit=5; local show_filenames=false

    while true; do
        local files_raw=("$BACKUP_DIR/${FILTER_PREFIX}_"*.tar.gz*)
        local valid_files=()
        for f in "${files_raw[@]}"; do
            if [[ ! -e "$f" ]]; then continue; fi 
            if [[ "$f" == *".version" ]]; then continue; fi
            if [[ ! "$f" =~ \.tar\.gz(\.enc)?$ ]]; then continue; fi
            valid_files+=("$f")
        done
        
        local total_count=${#valid_files[@]}
        
        if [[ "$total_count" -eq 0 ]]; then
            print_message "WARN" "–§–∞–π–ª–æ–≤ —Ç–∏–ø–∞ '${TITLE}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."; read -erp "Enter..." dummy; return 1
        fi
        
        IFS=$'\n' sorted_backups=($(sort -r <<<"${valid_files[*]}"))
        unset IFS
        
        local CURRENT_VER=$(get_raw_bot_version)

        clear_screen; echo -e "${GREEN}–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ: ${BOLD}${TITLE}${RESET}"
        echo -e "–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: ${CYAN}${total_count}${RESET}"; echo ""

        local loop_limit=$show_limit
        if [[ $loop_limit -gt $total_count ]]; then loop_limit=$total_count; fi

        for (( i=0; i<loop_limit; i++ )); do
            local file="${sorted_backups[$i]}"
            local filename=$(basename "$file")
            
            local CACHE_FILE="${file}.version"
            local B_VER=""
            if [[ -f "$CACHE_FILE" ]]; then B_VER=$(cat "$CACHE_FILE")
            else
                if [[ "$file" != *".enc" ]]; then
                    B_VER=$(tar -xzf "$file" -O bot_version.txt 2> "$SILENT_LOG")
                fi
                if [[ -n "$B_VER" ]]; then echo "$B_VER" > "$CACHE_FILE"; else echo "?" > "$CACHE_FILE"; B_VER="?"; fi
            fi
            
            local ENC_MARK=""; [[ "$file" == *".enc" ]] && ENC_MARK="${RED}[ENC]${RESET} "
            
            local VER_STR=""
            if [[ "$B_VER" == "Unknown" || "$B_VER" == "" ]]; then VER_STR="${GRAY}[–ù/–î]${RESET}"
            elif [[ "$B_VER" == "?" ]]; then VER_STR="${GRAY}[Legacy]${RESET}"
            elif [[ -z "$CURRENT_VER" ]]; then VER_STR="${GRAY}[v$B_VER]${RESET}"
            elif [[ "$B_VER" == "$CURRENT_VER" ]]; then VER_STR="${GREEN}[v$B_VER]${RESET}"
            else VER_STR="${RED}[v$B_VER]${RESET}"; fi

            if [[ "$show_filenames" == "true" ]]; then
                printf " %2d. %s%s %s\n" "$((i+1))" "$ENC_MARK" "$filename" "$VER_STR"
            else
                if [[ $filename =~ _([0-9]{4}-[0-9]{2}-[0-9]{2})_([0-9]{2})_([0-9]{2}) ]]; then
                    local date_part="${BASH_REMATCH[1]}"
                    local time_part="${BASH_REMATCH[2]}:${BASH_REMATCH[3]}"
                    local d_d=${date_part:8:2}; local d_m=${date_part:5:2}
                    local pretty_date="$d_d.$d_m $time_part"
                    local fsize=$(du -h "$file" | awk '{print $1}')
                    printf " %2d. %s | %5s | %s%s\n" "$((i+1))" "${BOLD}$pretty_date${RESET}" "$fsize" "$ENC_MARK" "$VER_STR"
                else
                    printf " %2d. %s %s\n" "$((i+1))" "$filename" "$VER_STR"
                fi
            fi
        done

        echo ""
        if [[ $total_count -gt 5 ]]; then
            if [[ $loop_limit -lt $total_count ]]; then
                 echo -e " ${MAGENTA}888. –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ ($total_count —à—Ç)${RESET}"
            else
                 echo -e " ${MAGENTA}888. –°–≤–µ—Ä–Ω—É—Ç—å —Å–ø–∏—Å–æ–∫ (–ø–æ–∫–∞–∑–∞—Ç—å 5)${RESET}"
            fi
        fi

        if [[ "$show_filenames" == "false" ]]; then
            echo -e " 999. –ü–æ–∫–∞–∑–∞—Ç—å –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤"; 
        else
            echo -e " 999. –ü–æ–∫–∞–∑–∞—Ç—å –¥–∞—Ç—É –∏ —Ä–∞–∑–º–µ—Ä"; 
        fi
        echo " 0. –ù–∞–∑–∞–¥"; echo ""
        read -erp "–ù–æ–º–µ—Ä —Ñ–∞–π–ª–∞ –∏–ª–∏ –∫–æ–º–∞–Ω–¥–∞ (Enter - –ù–∞–∑–∞–¥): " choice
        
        if [[ -z "$choice" || "$choice" == "0" ]]; then return 1
        elif [[ "$choice" == "888" ]]; then 
            if [[ $loop_limit -lt $total_count ]]; then loop_limit=$total_count; else loop_limit=5; fi
            show_limit=$loop_limit
            continue
        elif [[ "$choice" == "999" ]]; then 
            if [[ "$show_filenames" == "false" ]]; then show_filenames=true; else show_filenames=false; fi
            continue
        elif [[ "$choice" =~ ^[0-9]+$ && "$choice" -ge 1 && "$choice" -le "$total_count" ]]; then SELECTED_FILE="${sorted_backups[$((choice-1))]}"; return 0
        else print_message "ERROR" "–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä."; sleep 1; fi
    done
}

execute_restore() {
    local MODE="$1"; local FILE="$2"
    debug_log "RESTORE" "=== execute_restore ==="
    debug_log "RESTORE" "Mode: $MODE, File: $FILE"
    echo ""; print_message "WARN" "–í–ù–ò–ú–ê–ù–ò–ï: –¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω—ã!"
    read -erp "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/n): " confirm; [[ "$confirm" != "y" ]] && return

    local TMP_DIR="$BACKUP_DIR/restore_tmp_$$"
    mkdir -p "$TMP_DIR"
    debug_log "RESTORE" "Temp dir: $TMP_DIR"
    
    local WORK_FILE="$FILE"
    if [[ "$FILE" == *".enc" ]]; then
        print_message "INFO" "–§–∞–π–ª –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω. –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–∞—Ä–æ–ª—å."
        debug_log "RESTORE" "File is encrypted, requesting password..."
        read -s -erp "–ü–∞—Ä–æ–ª—å: " decrypt_pass; echo ""
        local DECRYPTED_FILE="$TMP_DIR/decrypted.tar.gz"
        
        debug_log "RESTORE" "Decrypting to: $DECRYPTED_FILE"
        export LAZARUS_DEC_PASS="$decrypt_pass"
        openssl enc -d -aes-256-cbc -pbkdf2 -iter 100000 -in "$FILE" -out "$DECRYPTED_FILE" -pass env:LAZARUS_DEC_PASS 2> "$SILENT_LOG"
        local dec_res=$?
        unset LAZARUS_DEC_PASS
        debug_log "RESTORE" "Decryption result: $dec_res"

        if [[ $dec_res -ne 0 ]]; then print_message "ERROR" "–ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª!"; rm -rf "$TMP_DIR"; return; fi
        print_message "SUCCESS" "–ü–∞—Ä–æ–ª—å –ø—Ä–∏–Ω—è—Ç."
        WORK_FILE="$DECRYPTED_FILE"
    fi

    print_message "INFO" "–†–∞—Å–ø–∞–∫–æ–≤–∫–∞..."
    debug_log "RESTORE" "Extracting: tar -xzf $WORK_FILE -C $TMP_DIR"
    tar -xzf "$WORK_FILE" -C "$TMP_DIR"
    debug_log "RESTORE" "Contents: $(ls -la "$TMP_DIR")"

    local DB_DUMP=$(find "$TMP_DIR" -name "db_*.sql.gz" | head -1)
    local DIR_ARC=$(find "$TMP_DIR" -name "dir_*.tar.gz" | head -1)
    debug_log "RESTORE" "DB_DUMP: $DB_DUMP"
    debug_log "RESTORE" "DIR_ARC: $DIR_ARC"

    if [[ "$MODE" == "full" && -n "$DIR_ARC" ]]; then
        if ! ensure_bot_path; then rm -rf "$TMP_DIR"; return; fi
        print_message "INFO" "–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤..."
        debug_log "RESTORE" "Stopping containers in $BOT_PATH"
        cd "$BOT_PATH" && docker compose down 2> "$SILENT_LOG"
        print_message "INFO" "–û—á–∏—Å—Ç–∫–∞ –ø–∞–ø–∫–∏..."
        debug_log "RESTORE" "Cleaning $BOT_PATH/*"
        rm -rf "$BOT_PATH"/*
        print_message "INFO" "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤..."
        debug_log "RESTORE" "Extracting: tar -xzf $DIR_ARC -C $(dirname "$BOT_PATH")"
        tar -xzf "$DIR_ARC" -C "$(dirname "$BOT_PATH")"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è volume –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        local volume_name=$(get_db_volume_name)
        debug_log "RESTORE" "DB Volume: $volume_name"
        if [[ -n "$volume_name" ]]; then
            print_message "INFO" "–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ volume: $volume_name"
            debug_log "RESTORE" "Running: docker volume rm $volume_name"
            docker volume rm "$volume_name" 2> "$SILENT_LOG" || true
        else
            print_message "WARN" "Volume –ë–î –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —É–¥–∞–ª–µ–Ω–∏–µ."
        fi
        
        print_message "INFO" "–ó–∞–ø—É—Å–∫ –ë–î..."
        debug_log "RESTORE" "Running: docker compose up -d $DB_SERVICE_NAME"
        docker compose up -d "$DB_SERVICE_NAME"
        sleep 5
    fi

    if [[ -n "$DB_DUMP" ]]; then
        print_message "INFO" "–ò–º–ø–æ—Ä—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö..."
        if ! ensure_bot_path; then rm -rf "$TMP_DIR"; return; fi
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ë–î –∏–∑ .env –±–æ—Ç–∞
        local ACTUAL_DB_USER=$(get_db_user)
        local ACTUAL_DB_NAME=$(get_db_name)
        debug_log "RESTORE" "DB params: user=$ACTUAL_DB_USER, db=$ACTUAL_DB_NAME"
        
        # –°–æ–≥–ª–∞—Å–Ω–æ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: –æ—á–∏—â–∞–µ–º —Å—Ö–µ–º—É –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º
        # https://docs.remnawave.shop/ru/private/backup/
        print_message "INFO" "–û—á–∏—Å—Ç–∫–∞ —Å—Ö–µ–º—ã –ë–î (DROP SCHEMA public CASCADE)..."
        debug_log "RESTORE" "Running: docker exec $DB_CONTAINER_NAME psql -U $ACTUAL_DB_USER -c 'DROP SCHEMA...'"
        docker exec -i "$DB_CONTAINER_NAME" psql -U "$ACTUAL_DB_USER" -c "DROP SCHEMA public CASCADE; CREATE SCHEMA public;" > "$SILENT_LOG" 2>&1
        
        print_message "INFO" "–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö (user=$ACTUAL_DB_USER, db=$ACTUAL_DB_NAME)..."
        debug_log "RESTORE" "Running: zcat $DB_DUMP | docker exec $DB_CONTAINER_NAME psql -U $ACTUAL_DB_USER $ACTUAL_DB_NAME"
        zcat "$DB_DUMP" | docker exec -i "$DB_CONTAINER_NAME" psql -U "$ACTUAL_DB_USER" "$ACTUAL_DB_NAME" > "$SILENT_LOG" 2>&1
        debug_log "RESTORE" "DB import complete"
    fi

    if [[ "$MODE" == "full" ]]; then
        print_message "INFO" "–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤..."
        debug_log "RESTORE" "Running: docker compose up -d"
        cd "$BOT_PATH" && docker compose up -d
    fi

    rm -rf "$TMP_DIR"
    debug_log "RESTORE" "Temp dir cleaned up"
    print_message "SUCCESS" "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ."
    log_message "SUCCESS" "Restore completed (mode=$MODE, file=$FILE)"
    read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
}

# --- –ú–ï–ù–Æ–®–ö–ò ---

menu_manual_backup() {
    while true; do
        clear_screen; echo -e "${GREEN}–°–æ–∑–¥–∞–Ω–∏–µ —Ä—É—á–Ω–æ–≥–æ –±—ç–∫–∞–ø–∞${RESET}"
        echo " 1. –ü–æ–ª–Ω—ã–π –±—ç–∫–∞–ø (–ë–î + –§–∞–π–ª—ã)"
        echo " 2. –¢–æ–ª—å–∫–æ –ë–î"
        echo " 3. –¢–æ–ª—å–∫–æ –§–∞–π–ª—ã"
        echo " 0. –ù–∞–∑–∞–¥"
        echo ""
        read -erp "–í–∞—à –≤—ã–±–æ—Ä (Enter - –ù–∞–∑–∞–¥): " m_choice
        [[ -z "$m_choice" ]] && return
        case $m_choice in
            1) create_backup "full"; read -erp "Enter..." dummy; return ;;
            2) create_backup "db_only"; read -erp "Enter..." dummy; return ;;
            3) create_backup "files_only"; read -erp "Enter..." dummy; return ;;
            0) return ;;
        esac
    done
}

menu_restore() {
    while true; do
        # –°–¢–†–û–ì–ê–Ø –õ–û–ì–ò–ö–ê –ü–û–î–°–ß–ï–¢–ê
        local n_full=$(find "$BACKUP_DIR" -type f \( -name "lazarus_full_*.tar.gz" -o -name "lazarus_full_*.tar.gz.enc" \) 2> "$SILENT_LOG" | wc -l)
        local n_db=$(find "$BACKUP_DIR" -type f \( -name "lazarus_db_*.tar.gz" -o -name "lazarus_db_*.tar.gz.enc" \) 2> "$SILENT_LOG" | wc -l)
        local n_files=$(find "$BACKUP_DIR" -type f \( -name "lazarus_files_*.tar.gz" -o -name "lazarus_files_*.tar.gz.enc" \) 2> "$SILENT_LOG" | wc -l)

        local c_f="$CYAN"; [[ "$n_full" == "0" ]] && c_f="$GRAY"
        local c_d="$CYAN"; [[ "$n_db" == "0" ]] && c_d="$GRAY"
        local c_fl="$CYAN"; [[ "$n_files" == "0" ]] && c_fl="$GRAY"

        clear_screen; echo -e "${GREEN}–ú–µ–Ω—é –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è${RESET}"
        echo -e " 1. –ü–æ–ª–Ω—ã–π –±—ç–∫–∞–ø      ${c_f}[${n_full} —à—Ç]${RESET}"
        echo -e " 2. –¢–æ–ª—å–∫–æ –ë–î         ${c_d}[${n_db} —à—Ç]${RESET}"
        echo -e " 3. –¢–æ–ª—å–∫–æ –§–∞–π–ª—ã      ${c_fl}[${n_files} —à—Ç]${RESET}"
        echo " 0. –ù–∞–∑–∞–¥"
        echo ""
        read -erp "–í—ã–±–æ—Ä (Enter - –ù–∞–∑–∞–¥): " r_choice
        [[ -z "$r_choice" ]] && return

        local SELECTED_FILE=""
        case $r_choice in
            1) if select_backup_file "lazarus_full" "–ü–æ–ª–Ω—ã–µ –±—ç–∫–∞–ø—ã"; then execute_restore "full" "$SELECTED_FILE"; fi ;;
            2) if select_backup_file "lazarus_db" "–ë—ç–∫–∞–ø—ã –ë–î"; then execute_restore "db_only" "$SELECTED_FILE"; fi ;;
            3) if select_backup_file "lazarus_files" "–ë—ç–∫–∞–ø—ã –§–∞–π–ª–æ–≤"; then 
                   echo ""; print_message "WARN" "–ë—É–¥—É—Ç –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω—ã —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ –±–æ—Ç–∞!"
                   read -erp "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/n): " cf
                   if [[ "$cf" == "y" ]]; then 
                       if ensure_bot_path; then tar -xzf "$SELECTED_FILE" -C "$(dirname "$BOT_PATH")"; print_message "SUCCESS" "–§–∞–π–ª—ã —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω—ã."; read -erp "Enter..." dummy; fi
                   fi
               fi ;;
            0) return ;;
        esac
    done
}

setup_cron_task() {
    local TASK_TYPE="$1"; local JOB_CMD=""; local JOB_ID=""
    if [[ "$TASK_TYPE" == "db" ]]; then JOB_CMD="$SYMLINK_PATH backup_db"; JOB_ID="# LAZARUS-JOB-DB"
    elif [[ "$TASK_TYPE" == "files" ]]; then if ! ensure_bot_path; then return; fi; JOB_CMD="$SYMLINK_PATH backup_files"; JOB_ID="# LAZARUS-JOB-FILES"
    elif [[ "$TASK_TYPE" == "full" ]]; then if ! ensure_bot_path; then return; fi; JOB_CMD="$SYMLINK_PATH backup_full"; JOB_ID="# LAZARUS-JOB-FULL"; fi

    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å
    local CURRENT_STATUS=$(get_cron_status "$TASK_TYPE")
    local STATUS_COLOR="$GRAY"; [[ "$CURRENT_STATUS" != "–í—ã–∫–ª" ]] && STATUS_COLOR="$YELLOW"
    
    # –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∏–ø–∞
    local TYPE_NAME=""
    case "$TASK_TYPE" in
        "full") TYPE_NAME="–ü–æ–ª–Ω—ã–π –±—ç–∫–∞–ø" ;;
        "db") TYPE_NAME="–¢–æ–ª—å–∫–æ –ë–î" ;;
        "files") TYPE_NAME="–¢–æ–ª—å–∫–æ –§–∞–π–ª—ã" ;;
    esac

    clear_screen
    echo -e "${GREEN}${BOLD}–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: ${TYPE_NAME}${RESET}"
    echo -e "–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å: [${STATUS_COLOR}${CURRENT_STATUS}${RESET}]"
    echo ""
    echo -e " 1. –ï–∂–µ—á–∞—Å–Ω–æ          ${GRAY}[–≤ :00]${RESET}"
    echo -e " 2. –ï–∂–µ–¥–Ω–µ–≤–Ω–æ         ${GRAY}[–≤ 04:00]${RESET}"
    echo -e " 3. –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ       ${GRAY}[–ü–Ω –≤ 04:00]${RESET}"
    echo -e " 4. –°–≤–æ—ë –≤—Ä–µ–º—è        ${GRAY}[–ß–ß:–ú–ú]${RESET}"
    echo -e " 5. –ö–∞–∂–¥—ã–µ N –º–∏–Ω—É—Ç    ${GRAY}[1-59]${RESET}"
    echo ""
    if [[ "$CURRENT_STATUS" != "–í—ã–∫–ª" ]]; then
        echo -e " ${RED}0. –û—Ç–∫–ª—é—á–∏—Ç—å${RESET}"
    else
        echo " 0. –ù–∞–∑–∞–¥"
    fi
    echo ""
    read -erp "–í—ã–±–æ—Ä (Enter - –ù–∞–∑–∞–¥): " c
    [[ -z "$c" ]] && return
    
    local NEW_CRON_LINES=""; local DISPLAY_TIME=""

    case $c in
        1) NEW_CRON_LINES="0 * * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"; DISPLAY_TIME="–ï–∂–µ—á–∞—Å–Ω–æ" ;;
        2) NEW_CRON_LINES="0 4 * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"; DISPLAY_TIME="–ï–∂–µ–¥–Ω–µ–≤–Ω–æ 04:00" ;;
        3) NEW_CRON_LINES="0 4 * * 1 $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"; DISPLAY_TIME="–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ" ;;
        4) 
           echo ""
           echo "–í–≤–µ–¥–∏—Ç–µ –≤—Ä–µ–º—è (–ß–ß:–ú–ú), –º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª:"
           echo -e "${GRAY}–ü—Ä–∏–º–µ—Ä: 09:00 18:30${RESET}"
           read -erp "> " times_input
           if [[ -z "$times_input" ]]; then print_message "ERROR" "–í—Ä–µ–º—è –Ω–µ –≤–≤–µ–¥–µ–Ω–æ!"; sleep 1; return; fi
           for t in $times_input; do 
               if [[ "$t" =~ ^([0-9]{1,2}):([0-9]{1,2})$ ]]; then 
                   h=$((10#${BASH_REMATCH[1]})); m=$((10#${BASH_REMATCH[2]}))
                   NEW_CRON_LINES+="$m $h * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"$'\n'
               fi
           done
           DISPLAY_TIME="–°–≤–æ–µ: $times_input" ;;
        5) 
           echo ""
           echo "–í–≤–µ–¥–∏—Ç–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª –≤ –º–∏–Ω—É—Ç–∞—Ö (1-59):"
           read -erp "> " interval
           if [[ "$interval" =~ ^[0-9]+$ ]] && [ "$interval" -gt 0 ] && [ "$interval" -lt 60 ]; then
               NEW_CRON_LINES="*/$interval * * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"
               DISPLAY_TIME="–ö–∞–∂–¥—ã–µ $interval –º–∏–Ω"
           else print_message "ERROR" "–í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ 59."; sleep 1; return; fi ;;
        0) 
           if [[ "$CURRENT_STATUS" != "–í—ã–∫–ª" ]]; then
               DISPLAY_TIME="–í—ã–∫–ª"
           else
               return
           fi ;;
        *) return ;;
    esac

    local CURRENT_CRON=$(crontab -l 2> "$SILENT_LOG" | grep -v "$JOB_ID")
    if [[ "$DISPLAY_TIME" != "–í—ã–∫–ª" && -n "$NEW_CRON_LINES" ]]; then echo -e "$CURRENT_CRON\n$NEW_CRON_LINES" | crontab -
    else echo "$CURRENT_CRON" | crontab -; fi

    # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º cron
    sync_cron_with_config
    
    log_message "INFO" "Cron task updated: $TASK_TYPE -> $DISPLAY_TIME"
    print_message "SUCCESS" "–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–æ!"; sleep 1
}

menu_automation() {
    while true; do
        # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—É—Å—ã –∏–∑ cron
        local CRON_FULL=$(get_cron_status "full")
        local CRON_DB=$(get_cron_status "db")
        local CRON_FILES=$(get_cron_status "files")
        
        # –¶–≤–µ—Ç–æ–≤–∞—è –∏–Ω–¥–∏–∫–∞—Ü–∏—è: –∂—ë–ª—Ç—ã–π –µ—Å–ª–∏ –∞–∫—Ç–∏–≤–µ–Ω, —Å–µ—Ä—ã–π –µ—Å–ª–∏ –≤—ã–∫–ª—é—á–µ–Ω
        local COLOR_FULL="$GRAY"; [[ "$CRON_FULL" != "–í—ã–∫–ª" ]] && COLOR_FULL="$YELLOW"
        local COLOR_DB="$GRAY"; [[ "$CRON_DB" != "–í—ã–∫–ª" ]] && COLOR_DB="$YELLOW"
        local COLOR_FILES="$GRAY"; [[ "$CRON_FILES" != "–í—ã–∫–ª" ]] && COLOR_FILES="$YELLOW"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—å –æ–¥–∏–Ω –∞–∫—Ç–∏–≤–Ω—ã–π –∞–≤—Ç–æ-–±—ç–∫–∞–ø
        local HAS_ANY_CRON=false
        [[ "$CRON_FULL" != "–í—ã–∫–ª" || "$CRON_DB" != "–í—ã–∫–ª" || "$CRON_FILES" != "–í—ã–∫–ª" ]] && HAS_ANY_CRON=true
        
        clear_screen
        echo -e "${GREEN}${BOLD}–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ë—ç–∫–∞–ø–∞${RESET}"
        echo ""
        echo -e " 1. –ü–æ–ª–Ω—ã–π –±—ç–∫–∞–ø  [${COLOR_FULL}${CRON_FULL}${RESET}]"
        echo -e " 2. –¢–æ–ª—å–∫–æ –ë–î     [${COLOR_DB}${CRON_DB}${RESET}]"
        echo -e " 3. –¢–æ–ª—å–∫–æ –§–∞–π–ª—ã  [${COLOR_FILES}${CRON_FILES}${RESET}]"
        echo ""
        if [[ "$HAS_ANY_CRON" == true ]]; then
            echo -e " ${RED}9. –û—Ç–∫–ª—é—á–∏—Ç—å –≤—Å–µ –∞–≤—Ç–æ-–±—ç–∫–∞–ø—ã${RESET}"
            echo ""
        fi
        echo " 0. –ù–∞–∑–∞–¥"
        echo ""
        read -erp "–í—ã–±–æ—Ä (Enter - –ù–∞–∑–∞–¥): " ac
        [[ -z "$ac" ]] && return
        case $ac in
            1) setup_cron_task "full" ;;
            2) setup_cron_task "db" ;;
            3) setup_cron_task "files" ;;
            9) 
                if [[ "$HAS_ANY_CRON" == true ]]; then
                    disable_all_cron_tasks
                fi
                ;;
            0) return ;;
        esac
    done
}

# –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –≤—Å–µ—Ö cron-–∑–∞–¥–∞—á LAZARUS
disable_all_cron_tasks() {
    echo ""
    print_message "WARN" "–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –æ—Ç–∫–ª—é—á–∏—Ç—å –í–°–ï –∞–≤—Ç–æ-–±—ç–∫–∞–ø—ã?"
    read -erp "–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å? (y/n): " confirm
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ cron-–∑–∞–¥–∞—á–∏ LAZARUS
        local current_cron
        current_cron=$(crontab -l 2> "$SILENT_LOG" || echo "")
        local new_cron
        new_cron=$(echo "$current_cron" | grep -v "# LAZARUS-JOB-")
        
        if [[ -z "$new_cron" ]]; then
            crontab -r 2> "$SILENT_LOG" || true
        else
            echo "$new_cron" | crontab -
        fi
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥
        SCHEDULE_FULL="–í—ã–∫–ª"
        SCHEDULE_DB="–í—ã–∫–ª"
        SCHEDULE_FILES="–í—ã–∫–ª"
        save_config
        
        print_message "SUCCESS" "–í—Å–µ –∞–≤—Ç–æ-–±—ç–∫–∞–ø—ã –æ—Ç–∫–ª—é—á–µ–Ω—ã"
        log_message "INFO" "All LAZARUS cron tasks disabled by user"
        sleep 1.5
    else
        print_message "INFO" "–û—Ç–º–µ–Ω–µ–Ω–æ"
        sleep 1
    fi
}

menu_settings() {
    while true; do
        clear_screen; echo -e "${GREEN}${BOLD}–ù–∞—Å—Ç—Ä–æ–π–∫–∏${RESET}"
        
        local MASKED_TOKEN="${BOT_TOKEN:0:5}.......${BOT_TOKEN: -5}"; [[ ${#BOT_TOKEN} -lt 10 ]] && MASKED_TOKEN="*******"
        local PASS_MASK="–ù–µ—Ç"; [[ -n "$BACKUP_PASSWORD" ]] && PASS_MASK="********"
        
        # –ú–∞—Å–∫–∏—Ä—É–µ–º Chat ID (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 4 –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–∏–º–≤–æ–ª–∞)
        local MASKED_CHAT_ID="-"
        if [[ -n "$CHAT_ID" ]]; then
            if [[ ${#CHAT_ID} -gt 8 ]]; then
                MASKED_CHAT_ID="${CHAT_ID:0:4}...${CHAT_ID: -3}"
            else
                MASKED_CHAT_ID="*****"
            fi
        fi
        
        local MASKED_REMOTE_USER="-"
        if [[ -n "$REMOTE_STORAGE_USER" ]]; then
            if [[ ${#REMOTE_STORAGE_USER} -gt 4 ]]; then
                MASKED_REMOTE_USER="${REMOTE_STORAGE_USER:0:3}...${REMOTE_STORAGE_USER: -2}"
            else
                MASKED_REMOTE_USER="*****"
            fi
        fi

        # –°—Ç–∞—Ç—É—Å—ã
        local ST_TG_NOTIFY="${RED}–í—ã–∫–ª${RESET}"; [[ "$SEND_TO_TELEGRAM" == "true" ]] && ST_TG_NOTIFY="${GREEN}–í–∫–ª${RESET}"
        local ST_TG_FILE="${RED}–í—ã–∫–ª${RESET}"; [[ "$TG_SEND_FILE" == "true" ]] && ST_TG_FILE="${GREEN}–í–∫–ª${RESET}"
        local ST_REM="${RED}–í—ã–∫–ª${RESET}"; [[ "$SEND_TO_REMOTE" == "true" ]] && ST_REM="${GREEN}–í–∫–ª${RESET}"
        
        local STORAGE_TYPE_DISP="–í—ã–∫–ª"
        if [[ "$REMOTE_STORAGE_TYPE" != "off" ]]; then STORAGE_TYPE_DISP="${REMOTE_STORAGE_TYPE^^}"; fi

        echo -e "${CYAN}--- –û–ë–©–ò–ï ---${RESET}"
        echo -e " 1. –ü—É—Ç—å –∫ –±–æ—Ç—É:        ${GRAY}${BOT_PATH}${RESET}"
        echo -e " 2. –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –±–æ—Ç–∞:     ${GRAY}${BOT_CONTAINER_NAME}${RESET}"
        echo -e " 3. –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–î:       ${GRAY}${DB_CONTAINER_NAME}${RESET}"
        echo -e " 4. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ë–î:    ${GRAY}${DB_USER}${RESET}"
        echo -e " 5. –ò—Å–∫–ª—é—á–∏—Ç—å –ø–∞–ø–∫–∏:    ${GRAY}${EXCLUDE_DIRS:-–ù–µ—Ç}${RESET}"
        echo -e " 6. –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: ${GRAY}${MAX_FILE_SIZE_MB} MB${RESET}"
        
        echo -e "\n${CYAN}--- TELEGRAM ---${RESET}"
        echo -e " 7.  Token:             ${GRAY}${MASKED_TOKEN}${RESET}"
        echo -e " 8.  Chat ID:           ${GRAY}${MASKED_CHAT_ID}${RESET}"
        echo -e " 9.  Thread ID:         ${GRAY}${TG_MESSAGE_THREAD_ID:-–ù–µ—Ç}${RESET}"
        echo -e " 10. –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è:       $ST_TG_NOTIFY"
        echo -e " 11. –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞:    $ST_TG_FILE"
        echo -e " 12. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–≤—è–∑—å"

        echo -e "\n${CYAN}--- –£–î–ê–õ–Å–ù–ù–û–ï –•–†–ê–ù–ò–õ–ò–©–ï ---${RESET}"
        echo -e " 13. –¢–∏–ø:               ${GRAY}${STORAGE_TYPE_DISP}${RESET}"
        echo -e " 14. URL:               ${GRAY}${REMOTE_STORAGE_URL:-–ù–µ—Ç}${RESET}"
        echo -e " 15. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:      ${GRAY}${MASKED_REMOTE_USER}${RESET}"
        echo -e " 16. –ó–∞–≥—Ä—É–∑–∫–∞:          $ST_REM"
        echo -e " 17. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å / –ü—Ä–æ–≤–µ—Ä–∏—Ç—å"

        echo -e "\n${CYAN}--- –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ ---${RESET}"
        echo -e " 18. –ü–∞—Ä–æ–ª—å —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è: ${GRAY}${PASS_MASK}${RESET}"
        
        echo -e "\n${CYAN}--- –†–û–¢–ê–¶–ò–Ø –ë–≠–ö–ê–ü–û–í ---${RESET}"
        local DM_DISPLAY="–ü–æ –≤—Ä–µ–º–µ–Ω–∏"; [[ "$DELETE_MODE" == "count" ]] && DM_DISPLAY="–ü–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É"
        echo -e " 19. –†–µ–∂–∏–º —É–¥–∞–ª–µ–Ω–∏—è:    ${GRAY}${DM_DISPLAY}${RESET}"
        if [[ "$DELETE_MODE" == "count" ]]; then
            echo -e " 20. –ú–∞–∫—Å. –±—ç–∫–∞–ø–æ–≤:     ${GRAY}${MAX_BACKUPS_COUNT} —à—Ç.${RESET}"
        else
            echo -e " 20. –°—Ä–æ–∫ —Ö—Ä–∞–Ω–µ–Ω–∏—è:     ${GRAY}${RETENTION_DAYS} –¥–Ω–µ–π${RESET}"
        fi
        echo -e " 21. –õ–∏–º–∏—Ç —Ä–∞–∑–º–µ—Ä–∞:     ${GRAY}$(format_size_mb "$MAX_BACKUP_SIZE_MB")${RESET}"
        
        echo -e "\n 0. –ù–∞–∑–∞–¥"
        echo ""
        read -erp "–í—ã–±–æ—Ä: " s
        [[ -z "$s" ]] && return
        
        case $s in
            1) read -erp "–ù–æ–≤—ã–π –ø—É—Ç—å: " np
               if [[ -n "$np" ]]; then 
                   if [[ -d "$np" ]]; then BOT_PATH="$np"; save_config; print_message "SUCCESS" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ"
                   else print_message "ERROR" "–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!"; fi
               fi ;;
            
            2) 
                scan_system_for_bot
                local def_cont="${FOUND_BOT:-$BOT_CONTAINER_NAME}"
                local prompt_msg="–ò–º—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –±–æ—Ç–∞"
                [[ -n "$FOUND_BOT" ]] && prompt_msg+=" (Enter = '$FOUND_BOT')"
                read -erp "$prompt_msg: " nc; nc="${nc:-$def_cont}"
                if [[ -n "$nc" ]]; then BOT_CONTAINER_NAME="$nc"; save_config; print_message "SUCCESS" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ"; fi ;;
                
            3) 
                scan_system_for_bot
                local def_db="${FOUND_DB:-$DB_CONTAINER_NAME}"
                local prompt_msg="–ò–º—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –ë–î"
                [[ -n "$FOUND_DB" ]] && prompt_msg+=" (Enter = '$FOUND_DB')"
                read -erp "$prompt_msg: " ndb_c; ndb_c="${ndb_c:-$def_db}"
                if [[ -n "$ndb_c" ]]; then DB_CONTAINER_NAME="$ndb_c"; save_config; print_message "SUCCESS" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ"; fi ;;

            4) read -erp "–ù–æ–≤—ã–π DB User: " ndb
               if [[ -n "$ndb" ]]; then DB_USER="$ndb"; save_config; print_message "SUCCESS" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ"; fi ;;
               
            5) read -erp "–ò—Å–∫–ª—é—á–∏—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä: uploads/cache): " ed
               if [[ -n "$ed" ]]; then 
                   EXCLUDE_DIRS="$ed"; save_config; print_message "SUCCESS" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ"
               else 
                   if [[ -n "$EXCLUDE_DIRS" ]]; then 
                       read -erp "–û—á–∏—Å—Ç–∏—Ç—å? (y/N): " clr
                       if [[ "$clr" =~ ^[Yy]$ ]]; then EXCLUDE_DIRS=""; save_config; fi
                   fi
               fi ;;
               
            6) read -erp "–ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ MB: " msize
               if [[ "$msize" =~ ^[0-9]+$ ]] && [ "$msize" -gt 0 ]; then 
                   MAX_FILE_SIZE_MB="$msize"; save_config; print_message "SUCCESS" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ"
               fi ;;
            
            7) read -erp "–ù–æ–≤—ã–π Token: " nt
               if [[ -n "$nt" ]]; then BOT_TOKEN="$nt"; save_config; print_message "SUCCESS" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ"; fi ;;
               
            8) echo -e "–¢–µ–∫—É—â–∏–π Chat ID: ${CYAN}${CHAT_ID}${RESET}"
               read -erp "–ù–æ–≤—ã–π Chat ID: " nid
               if [[ -n "$nid" ]]; then CHAT_ID="$nid"; save_config; print_message "SUCCESS" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ"; fi ;;
               
            9) read -erp "–ù–æ–≤—ã–π Thread ID (–ø—É—Å—Ç–æ - —Å–±—Ä–æ—Å–∏—Ç—å): " ntid
                TG_MESSAGE_THREAD_ID="$ntid"; save_config; print_message "SUCCESS" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ" ;;
                
            10) # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
                if [[ "$SEND_TO_TELEGRAM" == "true" ]]; then 
                    SEND_TO_TELEGRAM="false"
                    print_message "INFO" "–£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è Telegram –æ—Ç–∫–ª—é—á–µ–Ω—ã"
                else 
                    SEND_TO_TELEGRAM="true"
                    print_message "SUCCESS" "–£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è Telegram –≤–∫–ª—é—á–µ–Ω—ã"
                fi
                save_config ;;
                
            11) # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–∞
                if [[ "$TG_SEND_FILE" == "true" ]]; then
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
                    if [[ "$REMOTE_STORAGE_TYPE" == "off" || "$SEND_TO_REMOTE" != "true" ]]; then
                        echo ""
                        print_message "WARN" "–£–¥–∞–ª—ë–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ!"
                        print_message "WARN" "–ë—ç–∫–∞–ø—ã –±—É–¥—É—Ç —Ç–æ–ª—å–∫–æ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–º –¥–∏—Å–∫–µ."
                        read -erp "–í—Å—ë —Ä–∞–≤–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–∫—É —Ñ–∞–π–ª–∞ –≤ TG? (y/N): " confirm
                        if [[ ! "$confirm" =~ ^[Yy]$ ]]; then
                            print_message "INFO" "–û—Ç–º–µ–Ω–µ–Ω–æ"
                            sleep 1
                            continue
                        fi
                    fi
                    TG_SEND_FILE="false"
                    print_message "INFO" "–û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ TG –æ—Ç–∫–ª—é—á–µ–Ω–∞ (—É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã)"
                else
                    TG_SEND_FILE="true"
                    print_message "SUCCESS" "–û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ TG –≤–∫–ª—é—á–µ–Ω–∞"
                fi
                save_config ;;
                
            12) test_telegram_connection ;;

            13|14|15|17) configure_remote_storage ;;
            
            16) # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ —É–¥–∞–ª—ë–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
                if [[ "$SEND_TO_REMOTE" == "true" ]]; then 
                    SEND_TO_REMOTE="false"
                    print_message "INFO" "–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ —É–¥–∞–ª—ë–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –æ—Ç–∫–ª—é—á–µ–Ω–∞"
                else 
                    if [[ "$REMOTE_STORAGE_TYPE" == "off" ]]; then
                        print_message "WARN" "–°–Ω–∞—á–∞–ª–∞ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (–ø—É–Ω–∫—Ç 17)"
                        sleep 1.5
                        continue
                    fi
                    SEND_TO_REMOTE="true"
                    print_message "SUCCESS" "–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ —É–¥–∞–ª—ë–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –≤–∫–ª—é—á–µ–Ω–∞"
                fi
                save_config ;;

            18) echo ""
                read -s -erp "–ù–æ–≤—ã–π –ø–∞—Ä–æ–ª—å —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è (–ø—É—Å—Ç–æ - –æ—Ç–∫–ª—é—á–∏—Ç—å): " new_pass
                echo ""
                BACKUP_PASSWORD="$new_pass"
                save_config
                if [[ -n "$new_pass" ]]; then
                    print_message "SUCCESS" "–®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ"
                else
                    print_message "INFO" "–®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ"
                fi ;;
                
            19) echo ""
                echo "–†–µ–∂–∏–º —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤:"
                echo " 1. –ü–æ –≤—Ä–µ–º–µ–Ω–∏ (—Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π)"
                echo " 2. –ü–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É (–æ—Å—Ç–∞–≤–ª—è—Ç—å N –ø–æ—Å–ª–µ–¥–Ω–∏—Ö)"
                read -erp "–í—ã–±–æ—Ä (1/2): " dm
                if [[ "$dm" == "1" ]]; then DELETE_MODE="time"; elif [[ "$dm" == "2" ]]; then DELETE_MODE="count"; fi
                save_config; print_message "SUCCESS" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ" ;;
                
            20) # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ —Ä–æ—Ç–∞—Ü–∏–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
                if [[ "$DELETE_MODE" == "count" ]]; then
                    read -erp "–ú–∞–∫—Å. –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—ç–∫–∞–ø–æ–≤: " nd
                    if [[ "$nd" =~ ^[0-9]+$ ]] && [ "$nd" -ge 1 ]; then 
                        MAX_BACKUPS_COUNT="$nd"; save_config; print_message "SUCCESS" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ"
                    else 
                        print_message "ERROR" "–í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ >= 1"
                    fi
                else
                    read -erp "–°—Ä–æ–∫ —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –¥–Ω—è—Ö: " ndays
                    if [[ "$ndays" =~ ^[0-9]+$ ]] && [ "$ndays" -ge 1 ]; then 
                        RETENTION_DAYS="$ndays"; save_config; print_message "SUCCESS" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ"
                    else 
                        print_message "ERROR" "–í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ >= 1"
                    fi
                fi ;;
                
            21) # –õ–∏–º–∏—Ç —Ä–∞–∑–º–µ—Ä–∞ –±—ç–∫–∞–ø–æ–≤
                echo ""
                echo "–õ–∏–º–∏—Ç —Ä–∞–∑–º–µ—Ä–∞ –ø–∞–ø–∫–∏ —Å –±—ç–∫–∞–ø–∞–º–∏ (–≤ MB)"
                echo "–í–≤–µ–¥–∏—Ç–µ 0 –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞"
                echo ""
                local current_mb="$MAX_BACKUP_SIZE_MB"
                echo -e "–¢–µ–∫—É—â–∏–π –ª–∏–º–∏—Ç: ${CYAN}$(format_size_mb "$current_mb")${RESET}"
                read -erp "–ù–æ–≤—ã–π –ª–∏–º–∏—Ç (MB): " new_limit
                if [[ "$new_limit" =~ ^[0-9]+$ ]]; then 
                    MAX_BACKUP_SIZE_MB="$new_limit"
                    save_config
                    if [[ "$new_limit" == "0" ]]; then
                        print_message "INFO" "–õ–∏–º–∏—Ç —Ä–∞–∑–º–µ—Ä–∞ –æ—Ç–∫–ª—é—á—ë–Ω"
                    else
                        print_message "SUCCESS" "–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏–º–∏—Ç: $(format_size_mb "$new_limit")"
                    fi
                else 
                    print_message "ERROR" "–í–≤–µ–¥–∏—Ç–µ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ (0 –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è)"
                fi ;;
            
            0) return ;;
        esac
        [[ -n "$s" ]] && sleep 0.5
    done
}

# =============================================================================
# –ú–ò–ì–†–ê–¶–ò–Ø –ú–ï–ñ–î–£ –ë–û–¢–ê–ú–ò (Bedolaga ‚Üí RWP-Shop (Private))
# =============================================================================

# –ú–∞—Å—Å–∏–≤ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π (–¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ)
declare -a TEMP_DIRS=()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏
MIGRATION_SOURCE_TYPE=""        # archive | docker | postgresql
MIGRATION_SOURCE_BACKUP=""      # –ü—É—Ç—å –∫ –∞—Ä—Ö–∏–≤—É –±—ç–∫–∞–ø–∞ (.tar.gz)
MIGRATION_SOURCE_HOST=""
MIGRATION_SOURCE_PORT="5432"
MIGRATION_SOURCE_DB=""
MIGRATION_SOURCE_USER=""
MIGRATION_SOURCE_PASS=""
MIGRATION_SOURCE_CONTAINER=""   # Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–î Bedolaga
MIGRATION_TARGET_CONTAINER=""
MIGRATION_TARGET_DB=""
MIGRATION_TARGET_USER=""
MIGRATION_WORK_DIR=""
MIGRATION_EXTRACTED_DIR=""      # –í—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–ø–∫–∞ —Å —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–Ω—ã–º –∞—Ä—Ö–∏–≤–æ–º

# –ú–∞–ø–ø–∏–Ω–≥ payment_method (Bedolaga) ‚Üí invoice_type (RWP-Shop)
# 
# Bedolaga –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: telegram_stars, tribute, yookassa, cryptobot, 
#                        heleket, mulenpay, pal24, wata, platega, cloudpayments, manual
#
# RWP-Shop –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: yookassa, crypto, telegram, severpay_cards, 
#                               severpay_sbp, wata, platega, stripe
#
# ‚ö†Ô∏è –ú–µ—Ç–æ–¥—ã –±–µ–∑ –∞–Ω–∞–ª–æ–≥–∞ –≤ Remnawave: tribute, heleket, mulenpay, pal24, cloudpayments
#    –û–Ω–∏ –±—É–¥—É—Ç –∑–∞–º–∞–ø–ø–µ–Ω—ã –Ω–∞ "unknown" –∏ –ø–æ—Ç—Ä–µ–±—É—é—Ç —Ä—É—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
declare -A PAYMENT_METHOD_MAP=(
    # –ü—Ä—è–º—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (–ø—É–±–ª–∏—á–Ω–∞—è + –ø—Ä–∏–≤–∞—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è)
    ["yookassa"]="yookassa"
    ["tribute"]="tribute"
    ["wata"]="wata"
    
    # –¢—Ä–µ–±—É—é—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
    ["telegram_stars"]="telegram"
    ["cryptobot"]="crypto"
    
    # Platega –≤ Bedolaga ‚Üí platega_cards –≤ Remnawave (–ø—Ä–∏–≤–∞—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è)
    # –î–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã: platega_cards, platega_sbp, platega_crypto, platega_acquiring, platega_worldwide
    ["platega"]="platega_cards"
    
    # –ù–µ—Ç –∞–Ω–∞–ª–æ–≥–∞ –≤ RWP-Shop - –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ unknown
    ["manual"]="unknown"
    ["heleket"]="unknown"
    ["mulenpay"]="unknown"
    ["pal24"]="unknown"
    ["cloudpayments"]="unknown"
)

# --- –§—É–Ω–∫—Ü–∏—è: –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∞ ---
migrate_analyze_source() {
    debug_log "MIGRATE" "Starting source analysis"
    print_message "INFO" "–ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."
    
    # –î–ª—è —Ä–µ–∂–∏–º–∞ archive ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º JSON-—Ñ–∞–π–ª
    if [[ "$MIGRATION_SOURCE_TYPE" == "archive" ]]; then
        local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
        debug_log "MIGRATE" "Archive mode: checking $db_json"
        
        if [[ ! -f "$db_json" ]]; then
            print_message "ERROR" "–§–∞–π–ª database.json –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∞—Ä—Ö–∏–≤–µ"
            return 1
        fi
        
        # –ü–æ–¥—Å—á—ë—Ç —Ç–∞–±–ª–∏—Ü –≤ JSON —á–µ—Ä–µ–∑ Python
        local python_cmd=""
        if command -v python3 &>/dev/null; then python_cmd="python3"
        elif command -v python &>/dev/null; then python_cmd="python"
        fi
        
        if [[ -n "$python_cmd" ]]; then
            local table_count=$($python_cmd - "$db_json" << 'PYEOF'
import sys, json
with open(sys.argv[1], 'r', encoding='utf-8') as f:
    data = json.load(f)
tables = data.get('data', {})
print(len(tables))
PYEOF
)
            print_message "SUCCESS" "–ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü –≤ –∞—Ä—Ö–∏–≤–µ: $table_count"
            debug_log "MIGRATE" "Archive contains $table_count tables"
        else
            print_message "WARN" "Python –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–¥—Å—á—ë—Ç —Ç–∞–±–ª–∏—Ü"
        fi
        return 0
    fi
    
    # –î–ª—è —Ä–µ–∂–∏–º–æ–≤ docker/postgresql ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º PostgreSQL
    local source_info=""
    
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        debug_log "MIGRATE" "Using Docker container: $MIGRATION_SOURCE_CONTAINER"
        source_info=$(docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -t -c "
            SELECT 'tables:' || count(*) FROM information_schema.tables WHERE table_schema='public';
        " 2>&1)
    else
        debug_log "MIGRATE" "Using direct connection: $MIGRATION_SOURCE_HOST:$MIGRATION_SOURCE_PORT"
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        source_info=$(psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -t -c "
            SELECT 'tables:' || count(*) FROM information_schema.tables WHERE table_schema='public';
        " 2>&1)
        unset PGPASSWORD
    fi
    
    if [[ $? -ne 0 ]]; then
        print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –ë–î –∏—Å—Ç–æ—á–Ω–∏–∫–∞"
        debug_log "MIGRATE" "Connection failed: $source_info"
        return 1
    fi
    
    echo "$source_info"
    debug_log "MIGRATE" "Source info: $source_info"
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ ---
migrate_check_compatibility() {
    debug_log "MIGRATE" "Checking source compatibility"
    print_message "INFO" "–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞..."
    
    local required_tables=("users" "transactions" "promocodes")
    local missing_tables=()
    
    # –î–ª—è –∞—Ä—Ö–∏–≤–∞ - –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–∞–±–ª–∏—Ü –≤ database.json
    if [[ "$MIGRATION_SOURCE_TYPE" == "archive" ]]; then
        local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
        
        if [[ ! -f "$db_json" ]]; then
            print_message "ERROR" "–§–∞–π–ª database.json –Ω–µ –Ω–∞–π–¥–µ–Ω"
            return 1
        fi
        
        for table in "${required_tables[@]}"; do
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–∞–±–ª–∏—Ü—ã –≤ JSON
            if ! grep -q "\"$table\":" "$db_json"; then
                missing_tables+=("$table")
            fi
        done
    else
        # –î–ª—è PostgreSQL - –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ psql
        for table in "${required_tables[@]}"; do
            local exists=""
            if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
                exists=$(docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -t -c "
                    SELECT 1 FROM information_schema.tables WHERE table_schema='public' AND table_name='$table' LIMIT 1;
                " 2>/dev/null | tr -d ' ')
            else
                export PGPASSWORD="$MIGRATION_SOURCE_PASS"
                exists=$(psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -t -c "
                    SELECT 1 FROM information_schema.tables WHERE table_schema='public' AND table_name='$table' LIMIT 1;
                " 2>/dev/null | tr -d ' ')
                unset PGPASSWORD
            fi
            
            if [[ "$exists" != "1" ]]; then
                missing_tables+=("$table")
            fi
        done
    fi
    
    if [[ ${#missing_tables[@]} -gt 0 ]]; then
        print_message "ERROR" "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã: ${missing_tables[*]}"
        debug_log "MIGRATE" "Missing tables: ${missing_tables[*]}"
        return 1
    fi
    
    print_message "SUCCESS" "–ò—Å—Ç–æ—á–Ω–∏–∫ —Å–æ–≤–º–µ—Å—Ç–∏–º (Bedolaga format)"
    return 0
}

# --- –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞–ª–∞–Ω—Å–∞ ---
BALANCE_HANDLING_MODE=""      # ignore, export_csv, convert_days, convert_partner
BALANCE_CONVERSION_PRICE=""   # –°—Ç–æ–∏–º–æ—Å—Ç—å –º–µ—Å—è—Ü–∞ –≤ —Ä—É–±–ª—è—Ö (–¥–ª—è convert_days)
BALANCE_CONVERSION_DAYS=""    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –≤ –º–µ—Å—è—Ü–µ (–¥–ª—è convert_days)

# --- –§—É–Ω–∫—Ü–∏—è: –ê–Ω–∞–ª–∏–∑ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞–ª–∞–Ω—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π ---
migrate_handle_balances() {
    debug_log "MIGRATE" "Analyzing user balances"
    print_message "INFO" "–ê–Ω–∞–ª–∏–∑ –±–∞–ª–∞–Ω—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π..."
    
    local export_dir="$MIGRATION_WORK_DIR/export"
    mkdir -p "$export_dir"
    local balances_file="$export_dir/user_balances.csv"
    
    local balance_data=""
    
    # –î–ª—è –∞—Ä—Ö–∏–≤–∞ - —á–∏—Ç–∞–µ–º –∏–∑ database.json —á–µ—Ä–µ–∑ Python
    if [[ "$MIGRATION_SOURCE_TYPE" == "archive" ]]; then
        local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Python –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –±–∞–ª–∞–Ω—Å–æ–º > 0
        local python_cmd=""
        if command -v python3 &>/dev/null; then
            python_cmd="python3"
        elif command -v python &>/dev/null; then
            python_cmd="python"
        fi
        
        if [[ -n "$python_cmd" ]]; then
            balance_data=$($python_cmd - "$db_json" << 'PYEOF'
import sys
import json

with open(sys.argv[1], 'r', encoding='utf-8') as f:
    data = json.load(f)

users = data.get('data', {}).get('users', [])
for u in users:
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–º—ë–Ω –ø–æ–ª–µ–π
    # balance_kopeks - –∫–æ–ø–µ–π–∫–∏ (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
    # balance - —Ä—É–±–ª–∏ (–Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç)
    balance_kop = u.get('balance_kopeks', 0) or 0
    balance_rub_direct = u.get('balance', 0) or 0
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å balance –≤ —Ä—É–±–ª—è—Ö - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –∫–æ–ø–µ–π–∫–∏
    if balance_rub_direct > 0 and balance_kop == 0:
        balance_kop = int(balance_rub_direct * 100)
    
    if balance_kop > 0:
        tg_id = u.get('telegram_id', '')
        username = u.get('username', '') or ''
        fname = u.get('first_name', '') or ''
        balance_rub = round(balance_kop / 100, 2)
        print(f"{tg_id},{username},{fname},{balance_kop},{balance_rub}")
PYEOF
)
        fi
    else
        # –î–ª—è PostgreSQL - –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ psql
        local balance_query="
            SELECT telegram_id, username, first_name, balance_kopeks, 
                   ROUND(balance_kopeks::numeric / 100, 2) as balance_rubles
            FROM users 
            WHERE balance_kopeks > 0 
            ORDER BY balance_kopeks DESC;
        "
        
        if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
            balance_data=$(docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -t -A -F',' -c "$balance_query" 2>/dev/null)
        else
            export PGPASSWORD="$MIGRATION_SOURCE_PASS"
            balance_data=$(psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -t -A -F',' -c "$balance_query" 2>/dev/null)
            unset PGPASSWORD
        fi
    fi
    
    if [[ -z "$balance_data" ]]; then
        print_message "SUCCESS" "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –±–∞–ª–∞–Ω—Å–æ–º > 0 –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
        BALANCE_HANDLING_MODE="none"
        return 0
    fi
    
    # –ü–æ–¥—Å—á—ë—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —á–µ—Ä–µ–∑ Python (–∏–∑–±–µ–≥–∞–µ–º –ø—Ä–æ–±–ª–µ–º —Å subshell –≤ bash)
    local stats
    local python_cmd=""
    if command -v python3 &>/dev/null; then
        python_cmd="python3"
    elif command -v python &>/dev/null; then
        python_cmd="python"
    fi
    
    if [[ -n "$python_cmd" ]]; then
        stats=$(echo "$balance_data" | $python_cmd -c '
import sys

total_kop = 0
count = 0

for line in sys.stdin:
    line = line.strip()
    if not line:
        continue
    parts = line.split(",")
    if len(parts) >= 4:
        try:
            # 4-–µ –ø–æ–ª–µ - balance_kop (–∫–æ–ø–µ–π–∫–∏)
            kop = float(parts[3])
            total_kop += int(kop)
            count += 1
        except:
            pass

total_rub = round(total_kop / 100, 2)
print(f"{count},{total_kop},{total_rub}")
')
    fi
    
    local users_with_balance=$(echo "$stats" | cut -d',' -f1)
    local total_balance_kopeks=$(echo "$stats" | cut -d',' -f2)
    local total_balance_rubles=$(echo "$stats" | cut -d',' -f3)
    
    # Fallback –µ—Å–ª–∏ Python –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
    if [[ -z "$users_with_balance" || "$users_with_balance" == "0" ]]; then
        users_with_balance=$(echo "$balance_data" | grep -c '^[0-9]' || echo "0")
        total_balance_rubles="?"
    fi
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª
    echo "telegram_id,username,first_name,balance_kopeks,balance_rubles" > "$balances_file"
    echo "$balance_data" >> "$balances_file"
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
    echo ""
    echo -e "${RED}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo -e "${RED}${BOLD}  ‚ö†Ô∏è  –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ò –° –ù–ï–ù–£–õ–ï–í–´–ú –ë–ê–õ–ê–ù–°–û–ú!          ${RESET}"
    echo -e "${RED}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo ""
    echo -e "  ${YELLOW}–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –±–∞–ª–∞–Ω—Å–æ–º > 0:${RESET} ${WHITE}${BOLD}$users_with_balance${RESET}"
    echo -e "  ${YELLOW}–û–±—â–∞—è —Å—É–º–º–∞ –±–∞–ª–∞–Ω—Å–æ–≤:${RESET}        ${WHITE}${BOLD}$total_balance_rubles ‚ÇΩ${RESET}"
    echo ""
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-5 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    echo -e "${CYAN}  –¢–æ–ø-5 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ –±–∞–ª–∞–Ω—Å—É:${RESET}"
    local count=0
    while IFS=',' read -r tg_id username fname balance_kop balance_rub; do
        [[ -z "$tg_id" ]] && continue
        ((count++))
        [[ $count -gt 5 ]] && break
        local display_name="${username:-${fname:-ID:$tg_id}}"
        printf "    %d. %-20s %10s ‚ÇΩ\n" "$count" "$display_name" "$balance_rub"
    done <<< "$balance_data"
    
    if [[ $users_with_balance -gt 5 ]]; then
        echo -e "    ${GRAY}... –∏ –µ—â—ë $((users_with_balance - 5)) –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π${RESET}"
    fi
    echo ""
    
    echo -e "${RED}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo -e "${YELLOW}  –í RWP-Shop –ù–ï–¢ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –±–∞–ª–∞–Ω—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è!${RESET}"
    echo -e "${YELLOW}  –í—ã–±–µ—Ä–∏—Ç–µ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ:${RESET}"
    echo -e "${RED}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo ""
    echo -e "  ${GREEN}1.${RESET} –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)"
    echo "     ‚Üí –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤ —Ñ–∞–π–ª –¥–ª—è —Ä—É—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"
    echo "     ‚Üí –í—ã —Å–º–æ–∂–µ—Ç–µ –≤–µ—Ä–Ω—É—Ç—å –¥–µ–Ω—å–≥–∏ –∏–ª–∏ –ø—Ä–æ–¥–ª–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫–∏ –≤—Ä—É—á–Ω—É—é"
    echo ""
    echo -e "  ${GREEN}2.${RESET} –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ –¥–Ω–∏ –ø–æ–¥–ø–∏—Å–∫–∏"
    echo "     ‚Üí –ë–∞–ª–∞–Ω—Å –±—É–¥–µ—Ç –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω –≤ –¥–Ω–∏ –ø–æ –≤–∞—à–µ–º—É —Ç–∞—Ä–∏—Ñ—É"
    echo "     ‚Üí –î–Ω–∏ –¥–æ–±–∞–≤—è—Ç—Å—è –∫ expire_at –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"
    echo ""
    echo -e "  ${YELLOW}3.${RESET} –°–æ–∑–¥–∞—Ç—å –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –∏ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –±–∞–ª–∞–Ω—Å"
    echo "     ‚Üí –°–æ–∑–¥–∞—ë—Ç –∑–∞–ø–∏—Å–∏ –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –≤ RWP-Shop"
    echo "     ‚Üí –ò—Å–ø–æ–ª—å–∑—É–µ—Ç % –∫–æ–º–∏—Å—Å–∏–∏ –∏–∑ Bedolaga (–∏–ª–∏ —É–∫–∞–∑–∞—Ç—å –≤—Ä—É—á–Ω—É—é)"
    echo "     ‚Üí –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç available_balance –∏–∑ –±–∞–ª–∞–Ω—Å–∞ Bedolaga"
    echo ""
    echo -e "  ${RED}4.${RESET} –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å (–ü–û–¢–ï–†–Ø –î–ê–ù–ù–´–•!)"
    echo "     ‚Üí –ë–∞–ª–∞–Ω—Å—ã –±—É–¥—É—Ç –ø–æ—Ç–µ—Ä—è–Ω—ã –±–µ–∑–≤–æ–∑–≤—Ä–∞—Ç–Ω–æ"
    echo ""
    echo -e "  ${CYAN}5.${RESET} –ü–æ–∫–∞–∑–∞—Ç—å –í–°–ï–• –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –±–∞–ª–∞–Ω—Å–æ–º"
    echo ""
    echo -e "  ${CYAN}0.${RESET} –ù–∞–∑–∞–¥"
    echo ""
    
    while true; do
        read -erp "–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç [0-5] (Enter - –ù–∞–∑–∞–¥): " choice
        case "$choice" in
            ""|0|q|Q)
                return 1
                ;;
            5)
                # –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –±–∞–ª–∞–Ω—Å–æ–º
                echo ""
                echo -e "${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
                echo -e "${CYAN}  –í–°–ï –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ò –° –ë–ê–õ–ê–ù–°–û–ú ($users_with_balance —á–µ–ª.)${RESET}"
                echo -e "${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
                echo ""
                printf "  ${GRAY}%-4s %-20s %-15s %12s${RESET}\n" "‚Ññ" "Username" "Telegram ID" "–ë–∞–ª–∞–Ω—Å"
                echo "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
                local num=0
                while IFS=',' read -r tg_id username fname balance_kop balance_rub; do
                    [[ -z "$tg_id" ]] && continue
                    ((num++))
                    local display_name="${username:-${fname:-‚Äî}}"
                    printf "  %-4d %-20s %-15s %10s ‚ÇΩ\n" "$num" "$display_name" "$tg_id" "$balance_rub"
                done <<< "$balance_data"
                echo ""
                echo -e "  ${YELLOW}–ò—Ç–æ–≥–æ: $total_balance_rubles ‚ÇΩ${RESET}"
                echo ""
                read -erp "–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è..." dummy
                echo ""
                ;;
            1)
                BALANCE_HANDLING_MODE="export_csv"
                print_message "INFO" "–ë–∞–ª–∞–Ω—Å—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: $balances_file"
                break
                ;;
            2)
                echo ""
                echo -e "${CYAN}=== –ù–ê–°–¢–†–û–ô–ö–ê –ö–û–ù–í–ï–†–¢–ê–¶–ò–ò –ë–ê–õ–ê–ù–°–ê –í –î–ù–ò ===${RESET}"
                echo ""
                echo "–£–∫–∞–∂–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∞—à–µ–≥–æ —Ç–∞—Ä–∏—Ñ–∞:"
                echo ""
                
                # –°—Ç–æ–∏–º–æ—Å—Ç—å –º–µ—Å—è—Ü–∞
                read -erp "–°—Ç–æ–∏–º–æ—Å—Ç—å 1 –º–µ—Å—è—Ü–∞ –ø–æ–¥–ø–∏—Å–∫–∏ –≤ —Ä—É–±–ª—è—Ö [100]: " month_price
                month_price="${month_price:-100}"
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è —á–∏—Å–ª–∞
                if ! [[ "$month_price" =~ ^[0-9]+([.][0-9]+)?$ ]] || [[ $(echo "$month_price <= 0" | bc) -eq 1 ]]; then
                    print_message "ERROR" "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 100‚ÇΩ"
                    month_price="100"
                fi
                
                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –≤ –º–µ—Å—è—Ü–µ
                read -erp "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –≤ 1 –º–µ—Å—è—Ü–µ –ø–æ–¥–ø–∏—Å–∫–∏ [30]: " days_per_month
                days_per_month="${days_per_month:-30}"
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è —á–∏—Å–ª–∞
                if ! [[ "$days_per_month" =~ ^[0-9]+$ ]] || [[ "$days_per_month" -le 0 ]]; then
                    print_message "ERROR" "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 30"
                    days_per_month="30"
                fi
                
                BALANCE_CONVERSION_PRICE="$month_price"
                BALANCE_CONVERSION_DAYS="$days_per_month"
                BALANCE_HANDLING_MODE="convert_days"
                
                echo ""
                echo -e "${CYAN}–§–æ—Ä–º—É–ª–∞ —Ä–∞—Å—á—ë—Ç–∞:${RESET}"
                echo "  extra_days = (balance_rubles / $month_price) √ó $days_per_month"
                echo ""
                
                # –ü—Ä–∏–º–µ—Ä —Ä–∞—Å—á—ë—Ç–∞
                local example_balance="150"
                local example_days=$(echo "scale=0; ($example_balance / $month_price) * $days_per_month" | bc 2>/dev/null || echo "?")
                echo -e "  ${YELLOW}–ü—Ä–∏–º–µ—Ä:${RESET} –±–∞–ª–∞–Ω—Å 150‚ÇΩ ‚Üí $example_days –¥–Ω–µ–π"
                echo ""
                
                print_message "SUCCESS" "–ö—É—Ä—Å: $month_price ‚ÇΩ = $days_per_month –¥–Ω–µ–π"
                break
                ;;
            3)
                BALANCE_HANDLING_MODE="convert_partner"
                print_message "INFO" "–ë–∞–ª–∞–Ω—Å—ã –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ ‚Üí partner.available_balance"
                break
                ;;
            4)
                echo ""
                echo -e "${RED}${BOLD}  ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï! –í–´ –ü–û–¢–ï–†–Ø–ï–¢–ï $total_balance_rubles ‚ÇΩ!${RESET}"
                echo ""
                read -erp "–í–≤–µ–¥–∏—Ç–µ 'LOSE DATA' –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è: " confirm
                if [[ "$confirm" == "LOSE DATA" ]]; then
                    BALANCE_HANDLING_MODE="ignore"
                    print_message "WARN" "–ë–∞–ª–∞–Ω—Å—ã –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã (–ø–æ—Ç–µ—Ä—è –¥–∞–Ω–Ω—ã—Ö)"
                    # –í—Å—ë —Ä–∞–≤–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏
                    print_message "INFO" "–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –±–∞–ª–∞–Ω—Å–æ–≤: $balances_file"
                    break
                else
                    print_message "INFO" "–û—Ç–º–µ–Ω–∞. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–æ–π –≤–∞—Ä–∏–∞–Ω—Ç."
                fi
                ;;
            *)
                print_message "ERROR" "–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä"
                ;;
        esac
    done
    
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞–ª–∞–Ω—Å–æ–≤ ---
migrate_apply_balance_handling() {
    debug_log "MIGRATE" "Applying balance handling: $BALANCE_HANDLING_MODE"
    
    local export_dir="$MIGRATION_WORK_DIR/export"
    local import_dir="$MIGRATION_WORK_DIR/import"
    local balances_file="$export_dir/user_balances.csv"
    local balance_report="$MIGRATION_WORK_DIR/balance_report.txt"
    
    case "$BALANCE_HANDLING_MODE" in
        "none")
            debug_log "MIGRATE" "No balances to process"
            return 0
            ;;
        "export_csv")
            # –£–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ migrate_handle_balances
            print_message "SUCCESS" "–ë–∞–ª–∞–Ω—Å—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤: $balances_file"
            
            # –°–æ–∑–¥–∞—ë–º –æ—Ç—á—ë—Ç
            {
                echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                echo "  –û–¢–ß–Å–¢ –û –ë–ê–õ–ê–ù–°–ê–• –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô"
                echo "  –î–∞—Ç–∞ –º–∏–≥—Ä–∞—Ü–∏–∏: $(date '+%Y-%m-%d %H:%M:%S')"
                echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                echo ""
                echo "–§–∞–π–ª —Å –±–∞–ª–∞–Ω—Å–∞–º–∏: $balances_file"
                echo ""
                echo "–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:"
                echo "1. –°–≤—è–∂–∏—Ç–µ—Å—å —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –≤–æ–∑–≤—Ä–∞—Ç —Å—Ä–µ–¥—Å—Ç–≤"
                echo "2. –ò–ª–∏ –ø—Ä–æ–¥–ª–∏—Ç–µ –∏–º –ø–æ–¥–ø–∏—Å–∫—É –Ω–∞ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—ã–π —Å—Ä–æ–∫"
                echo "3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å Remnawave –¥–ª—è —Ä—É—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π"
                echo ""
                echo "–°–ü–ò–°–û–ö –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô:"
                cat "$balances_file"
            } > "$balance_report"
            
            print_message "INFO" "–û—Ç—á—ë—Ç —Å–æ–∑–¥–∞–Ω: $balance_report"
            ;;
            
        "convert_days")
            print_message "INFO" "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –±–∞–ª–∞–Ω—Å–æ–≤ –≤ –¥–Ω–∏ –ø–æ–¥–ø–∏—Å–∫–∏..."
            
            # –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª —Å –¥–æ–ø. –¥–Ω—è–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            local days_file="$import_dir/balance_to_days.csv"
            echo "telegram_id,extra_days,balance_rubles,month_price,days_per_month" > "$days_file"
            
            local month_price="${BALANCE_CONVERSION_PRICE:-100}"
            local days_per_month="${BALANCE_CONVERSION_DAYS:-30}"
            
            tail -n +2 "$balances_file" | while IFS=',' read -r tg_id username fname balance_kop balance_rub; do
                [[ -z "$tg_id" ]] && continue
                # –†–∞—Å—á—ë—Ç –¥–Ω–µ–π: (balance_rub / month_price) * days_per_month
                local extra_days=$(echo "scale=0; ($balance_rub / $month_price) * $days_per_month" | bc 2>/dev/null || echo "0")
                [[ "$extra_days" -lt 1 ]] && extra_days=0
                echo "$tg_id,$extra_days,$balance_rub,$month_price,$days_per_month" >> "$days_file"
            done
            
            print_message "SUCCESS" "–§–∞–π–ª –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω: $days_file"
            
            # –û—Ç—á—ë—Ç
            {
                echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                echo "  –ö–û–ù–í–ï–†–¢–ê–¶–ò–Ø –ë–ê–õ–ê–ù–°–û–í –í –î–ù–ò –ü–û–î–ü–ò–°–ö–ò"
                echo "  –¢–∞—Ä–∏—Ñ: $month_price ‚ÇΩ = $days_per_month –¥–Ω–µ–π"
                echo "  –§–æ—Ä–º—É–ª–∞: extra_days = (balance / $month_price) √ó $days_per_month"
                echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                echo ""
                echo "telegram_id,extra_days,balance_rubles"
                tail -n +2 "$days_file" | cut -d',' -f1-3
            } > "$balance_report"
            ;;
            
        "convert_partner")
            print_message "INFO" "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –±–∞–ª–∞–Ω—Å–æ–≤ –≤ –ø–∞—Ä—Ç–Ω—ë—Ä—Å–∫–∏–µ (—Å —Å–æ–∑–¥–∞–Ω–∏–µ–º –∑–∞–ø–∏—Å–µ–π)..."
            
            # –§–∞–π–ª –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤
            local partner_create_file="$import_dir/partners_to_create.csv"
            echo "telegram_id,available_balance,percent" > "$partner_create_file"
            
            # –ü–æ–ª—É—á–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç –∫–æ–º–∏—Å—Å–∏–∏ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ Bedolaga
            local default_percent="10"  # fallback
            
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞
            if [[ -n "$MIGRATION_EXTRACTED_DIR" && -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
                local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º REFERRAL_COMMISSION_PERCENT –∏–∑ system_settings
                local extracted_percent=$(grep -o '"REFERRAL_COMMISSION_PERCENT"[^}]*"value"[^"]*"[^"]*"' "$db_json" 2>/dev/null | grep -o '"value"[^"]*"[^"]*"' | grep -o '[0-9]\+' | head -1)
                if [[ -n "$extracted_percent" ]]; then
                    default_percent="$extracted_percent"
                    debug_log "MIGRATE" "Found REFERRAL_COMMISSION_PERCENT in backup: $default_percent"
                fi
                
                # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º REFERRAL_BONUS_PERCENT (–¥—Ä—É–≥–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)
                if [[ "$default_percent" == "10" ]]; then
                    extracted_percent=$(grep -o '"REFERRAL_BONUS_PERCENT"[^}]*"value"[^"]*"[^"]*"' "$db_json" 2>/dev/null | grep -o '"value"[^"]*"[^"]*"' | grep -o '[0-9]\+' | head -1)
                    if [[ -n "$extracted_percent" ]]; then
                        default_percent="$extracted_percent"
                        debug_log "MIGRATE" "Found REFERRAL_BONUS_PERCENT in backup: $default_percent"
                    fi
                fi
            fi
            
            echo ""
            echo -e "${CYAN}=== –ù–ê–°–¢–†–û–ô–ö–ê –ü–ê–†–¢–ù–Å–†–°–ö–û–ì–û –ü–†–û–¶–ï–ù–¢–ê ===${RESET}"
            echo ""
            echo -e "–í –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö Bedolaga –Ω–∞–π–¥–µ–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∫–æ–º–∏—Å—Å–∏–∏: ${GREEN}$default_percent%${RESET}"
            echo ""
            echo "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞–∫–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –Ω–æ–≤—ã—Ö –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤:"
            echo "  1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–∑ Bedolaga: ${default_percent}%"
            echo "  2. –£–∫–∞–∑–∞—Ç—å –¥—Ä—É–≥–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç"
            echo ""
            read -erp "–í—ã–±–æ—Ä [1]: " percent_choice
            percent_choice="${percent_choice:-1}"
            
            local partner_percent="$default_percent"
            if [[ "$percent_choice" == "2" ]]; then
                read -erp "–í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ—Ü–µ–Ω—Ç –∫–æ–º–∏—Å—Å–∏–∏ (1-100): " custom_percent
                if [[ "$custom_percent" =~ ^[0-9]+$ ]] && [[ "$custom_percent" -ge 1 ]] && [[ "$custom_percent" -le 100 ]]; then
                    partner_percent="$custom_percent"
                else
                    print_message "WARN" "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è $default_percent%"
                fi
            fi
            
            print_message "INFO" "–ü—Ä–æ—Ü–µ–Ω—Ç –∫–æ–º–∏—Å—Å–∏–∏ –¥–ª—è –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤: $partner_percent%"
            
            # –°–æ–∑–¥–∞—ë–º –∑–∞–ø–∏—Å–∏ –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –±–∞–ª–∞–Ω—Å–æ–º
            local created_count=0
            tail -n +2 "$balances_file" | while IFS=',' read -r tg_id username fname balance_kop balance_rub; do
                [[ -z "$tg_id" ]] && continue
                echo "$tg_id,$balance_rub,$partner_percent" >> "$partner_create_file"
                ((created_count++))
            done
            
            created_count=$(($(wc -l < "$partner_create_file") - 1))
            
            print_message "SUCCESS" "–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –∫ —Å–æ–∑–¥–∞–Ω–∏—é: $created_count"
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é
            echo ""
            echo -e "${CYAN}–ü—Ä–µ–≤—å—é (–ø–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π):${RESET}"
            echo "telegram_id | –±–∞–ª–∞–Ω—Å | –ø—Ä–æ—Ü–µ–Ω—Ç"
            echo "------------|--------|--------"
            tail -n +2 "$partner_create_file" | head -5 | while IFS=',' read -r tid bal pct; do
                printf "%s | %s ‚ÇΩ | %s%%\n" "$tid" "$bal" "$pct"
            done
            echo ""
            
            # –û—Ç—á—ë—Ç
            {
                echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                echo "  –°–û–ó–î–ê–ù–ò–ï –ü–ê–†–¢–ù–Å–†–û–í –° –ë–ê–õ–ê–ù–°–û–ú"
                echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                echo ""
                echo "–ü—Ä–æ—Ü–µ–Ω—Ç –∫–æ–º–∏—Å—Å–∏–∏: $partner_percent%"
                echo "–ò—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–æ—Ü–µ–Ω—Ç–∞: $([ "$partner_percent" == "$default_percent" ] && echo "Bedolaga" || echo "—É–∫–∞–∑–∞–Ω –≤—Ä—É—á–Ω—É—é")"
                echo ""
                echo "–ü–ê–†–¢–ù–Å–†–´ –î–õ–Ø –°–û–ó–î–ê–ù–ò–Ø:"
                cat "$partner_create_file"
                echo ""
                echo "SQL –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ (–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ):"
                echo "INSERT INTO partner (telegram_id, available_balance, percent)"
                echo "VALUES (telegram_id, balance, percent)"
                echo "ON CONFLICT (telegram_id) DO UPDATE SET"
                echo "  available_balance = partner.available_balance + EXCLUDED.available_balance;"
            } > "$balance_report"
            ;;
            
        "ignore")
            print_message "WARN" "–ë–∞–ª–∞–Ω—Å—ã –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã!"
            
            {
                echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                echo "  ‚ö†Ô∏è  –ë–ê–õ–ê–ù–°–´ –ë–´–õ–ò –ü–†–û–ò–ì–ù–û–†–ò–†–û–í–ê–ù–´ (–ü–û–¢–ï–†–Ø –î–ê–ù–ù–´–•)"
                echo "  –î–∞—Ç–∞: $(date '+%Y-%m-%d %H:%M:%S')"
                echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                echo ""
                echo "–†–ï–ó–ï–†–í–ù–ê–Ø –ö–û–ü–ò–Ø –ü–û–¢–ï–†–Ø–ù–ù–´–• –ë–ê–õ–ê–ù–°–û–í:"
                cat "$balances_file"
            } > "$balance_report"
            ;;
    esac
    
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON –±—ç–∫–∞–ø–∞ Bedolaga ---
# –ü–∞—Ä—Å–∏—Ç database.json –∏ —Å–æ–∑–¥–∞—ë—Ç CSV —Ñ–∞–π–ª—ã –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
migrate_export_from_json() {
    debug_log "MIGRATE" "Starting JSON export from backup archive"
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON –±—ç–∫–∞–ø–∞ Bedolaga..."
    
    local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
    
    if [[ ! -f "$db_json" ]]; then
        print_message "ERROR" "–§–∞–π–ª database.json –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–Ω–æ–º –∞—Ä—Ö–∏–≤–µ"
        return 1
    fi
    
    local export_dir="$MIGRATION_WORK_DIR/export"
    mkdir -p "$export_dir"
    
    # P2: –°–ø–∏—Å–æ–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ
    local temp_files=()
    cleanup_temp_files() {
        for f in "${temp_files[@]}"; do
            [[ -f "$f" ]] && rm -f "$f"
        done
    }
    trap cleanup_temp_files RETURN
    
    # P2: –§—É–Ω–∫—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ CSV
    validate_csv() {
        local csv_file="$1"
        local expected_name="$2"
        
        if [[ ! -f "$csv_file" ]]; then
            debug_log "MIGRATE" "CSV validation: $expected_name - file not found"
            return 1
        fi
        
        local lines=$(wc -l < "$csv_file" 2>/dev/null)
        if [[ "$lines" -lt 1 ]]; then
            debug_log "MIGRATE" "CSV validation: $expected_name - empty file"
            return 1
        fi
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–ª–æ–Ω–æ–∫ (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫)
        local expected_cols=$(head -1 "$csv_file" | awk -F',' '{print NF}')
        local inconsistent=$(head -5 "$csv_file" | awk -F',' -v e="$expected_cols" 'NF != e {print NR}' | head -1)
        
        if [[ -n "$inconsistent" ]]; then
            debug_log "MIGRATE" "CSV validation: $expected_name - inconsistent columns at line $inconsistent"
            return 1
        fi
        
        debug_log "MIGRATE" "CSV validation: $expected_name - OK ($lines lines, $expected_cols cols)"
        return 0
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Python –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON
    local python_cmd=""
    if command -v python3 &>/dev/null; then
        python_cmd="python3"
    elif command -v python &>/dev/null; then
        python_cmd="python"
    fi
    
    if [[ -z "$python_cmd" ]]; then
        print_message "ERROR" "Python –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ python3 –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –±—ç–∫–∞–ø–∞"
        return 1
    fi
    
    debug_log "MIGRATE" "Using Python: $python_cmd"
    
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –º–∞—Å—Å–∏–≤–∞ —á–µ—Ä–µ–∑ Python
    # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å json, –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç jq
    parse_json_table() {
        local json_file="$1"
        local table_name="$2"
        local fields="$3"  # Comma-separated list of fields
        
        debug_log "MIGRATE" "Parsing table: $table_name, fields: $fields"
        
        $python_cmd - "$json_file" "$table_name" "$fields" << 'PYTHON_SCRIPT'
import sys
import json
import csv

json_file = sys.argv[1]
table_name = sys.argv[2]
fields = [f.strip() for f in sys.argv[3].split(',')]

try:
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
except Exception as e:
    sys.stderr.write(f"Error loading JSON: {e}\n")
    sys.exit(1)

# –ü–æ–ª—É—á–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –∏–∑ data
table_data = data.get('data', {}).get(table_name, [])

if not table_data:
    # –ü—É—Å—Ç–∞—è —Ç–∞–±–ª–∏—Ü–∞ - –≤—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
    print(','.join(fields))
    sys.exit(0)

# –ó–∞–ø–∏—Å—ã–≤–∞–µ–º CSV –≤ stdout
writer = csv.writer(sys.stdout)
writer.writerow(fields)

for row in table_data:
    values = []
    for field in fields:
        val = row.get(field, '')
        if val is None:
            val = ''
        elif isinstance(val, bool):
            val = 't' if val else 'f'
        elif isinstance(val, (int, float)):
            val = str(val)
        values.append(val)
    writer.writerow(values)
PYTHON_SCRIPT
    }
    
    # --- –≠–∫—Å–ø–æ—Ä—Ç users ---
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç users..."
    local users_raw_file="$export_dir/users_raw.csv"
    local users_file="$export_dir/users.csv"
    temp_files+=("$users_raw_file")  # P2: –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
    
    # –°–Ω–∞—á–∞–ª–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –ø–æ–ª—è
    parse_json_table "$db_json" "users" "id,telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status,last_activity,referred_by_id" > "$users_raw_file"
    
    # --- –°–æ–∑–¥–∞–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ id ‚Üí telegram_id –¥–ª—è JOIN-–æ–≤ ---
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∞—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    local id_map_file="$export_dir/.id_to_telegram.map"
    # P0: Race Condition fix - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ç–æ–º–∞—Ä–Ω—É—é –∑–∞–ø–∏—Å—å —á–µ—Ä–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    awk -F',' 'NR>1 && $1!="" && $2!="" {print $1 "=" $2}' "$users_raw_file" > "${id_map_file}.tmp" && \
        mv "${id_map_file}.tmp" "$id_map_file"
    debug_log "MIGRATE" "Created id‚Üítelegram_id map with $(wc -l < "$id_map_file") entries"
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å psql —ç–∫—Å–ø–æ—Ä—Ç–æ–º:
    # telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status
    echo "telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status" > "$users_file"
    awk -F',' 'NR > 1 {
        # –ü–æ–ª—è: id,telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status,...
        telegram_id = $2
        username = $3
        first_name = $4
        language = $5
        created_at = $6
        balance_kopeks = $7
        referral_balance = $8
        status = $9
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if (balance_kopeks == "") balance_kopeks = "0"
        if (referral_balance == "") referral_balance = "0"
        if (status == "") status = "active"
        
        print telegram_id "," username "," first_name "," language "," created_at "," balance_kopeks "," referral_balance "," status
    }' "$users_raw_file" >> "$users_file"
    
    local user_count=0
    [[ -s "$users_file" ]] && user_count=$(($(wc -l < "$users_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: $user_count"
    debug_log "MIGRATE" "Users exported: $user_count"
    
    # --- –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π ---
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π..."
    local referrals_file="$export_dir/referrals.csv"
    
    # –ù—É–∂–µ–Ω JOIN: users.referred_by_id ‚Üí users.id ‚Üí telegram_id
    # –°–æ–∑–¥–∞—ë–º CSV —Å telegram_id –≤–º–µ—Å—Ç–æ internal id
    # –ß–∏—Ç–∞–µ–º –∏–∑ users_raw_file —Ç.–∫. —Ç–∞–º –µ—Å—Ç—å referred_by_id (–ø–æ–ª–µ $11)
    echo "referee_telegram_id,referrer_telegram_id,created_at" > "$referrals_file"
    
    awk -F',' -v mapfile="$id_map_file" '
    BEGIN {
        while ((getline line < mapfile) > 0) {
            split(line, parts, "=")
            id_map[parts[1]] = parts[2]
        }
    }
    NR > 1 {
        # –§–æ—Ä–º–∞—Ç users_raw: id,telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status,last_activity,referred_by_id
        telegram_id = $2
        referred_by_id = $11
        created_at = $6
        
        if (referred_by_id != "" && referred_by_id in id_map) {
            referrer_tg = id_map[referred_by_id]
            print telegram_id "," referrer_tg "," created_at
        }
    }
    ' "$users_raw_file" >> "$referrals_file"
    
    local referral_count=0
    [[ -s "$referrals_file" ]] && referral_count=$(($(wc -l < "$referrals_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π: $referral_count"
    
    # --- –≠–∫—Å–ø–æ—Ä—Ç subscriptions ---
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç –ø–æ–¥–ø–∏—Å–æ–∫..."
    local subscriptions_raw="$export_dir/subscriptions_raw.csv"
    local subscriptions_file="$export_dir/subscriptions.csv"
    
    parse_json_table "$db_json" "subscriptions" "id,user_id,end_date,subscription_url,is_trial,device_limit,autopay_enabled,status" > "$subscriptions_raw"
    
    # JOIN —Å users –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è telegram_id –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∞–∫—Ç–∏–≤–Ω—ã—Ö
    echo "telegram_id,expire_at,subscription_link,is_trial,device_limit,autopay_enabled" > "$subscriptions_file"
    
    awk -F',' -v mapfile="$id_map_file" '
    BEGIN {
        while ((getline line < mapfile) > 0) {
            split(line, parts, "=")
            id_map[parts[1]] = parts[2]
        }
        skipped = 0
    }
    NR > 1 {
        user_id = $2
        end_date = $3
        subscription_url = $4
        is_trial = $5
        device_limit = $6
        autopay = $7
        status = $8
        
        # P1: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—É—Å—Ç—ã—Ö user_id
        if (user_id == "") {
            skipped++
            next
        }
        
        # –¢–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∫–∏
        if (status == "active" && user_id in id_map) {
            telegram_id = id_map[user_id]
            print telegram_id "," end_date "," subscription_url "," is_trial "," device_limit "," autopay
        }
    }
    END {
        if (skipped > 0) {
            print "WARN: Skipped " skipped " subscriptions with empty user_id" > "/dev/stderr"
        }
    }
    ' "$subscriptions_raw" >> "$subscriptions_file"
    
    local subs_count=0
    [[ -s "$subscriptions_file" ]] && subs_count=$(($(wc -l < "$subscriptions_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–æ–∫: $subs_count"
    
    # --- –≠–∫—Å–ø–æ—Ä—Ç transactions ---
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π..."
    local transactions_raw="$export_dir/transactions_raw.csv"
    local transactions_file="$export_dir/transactions.csv"
    
    # –í JSON –ø–æ–ª–µ is_completed (boolean), –Ω–µ status
    parse_json_table "$db_json" "transactions" "id,user_id,amount_kopeks,payment_method,is_completed,created_at" > "$transactions_raw"
    
    # JOIN —Å users –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ is_completed
    # –§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å transform: id,user_id,amount,payment_method,status,created_at,subscription_days
    echo "id,user_id,amount,payment_method,status,created_at,subscription_days" > "$transactions_file"
    
    awk -F',' -v mapfile="$id_map_file" '
    BEGIN {
        while ((getline line < mapfile) > 0) {
            split(line, parts, "=")
            id_map[parts[1]] = parts[2]
        }
        skipped = 0
    }
    NR > 1 {
        id = $1
        user_id = $2
        amount = $3
        payment_method = $4
        is_completed = $5  # "t" –∏–ª–∏ "f"
        created_at = $6
        
        # P1: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—É—Å—Ç—ã—Ö user_id
        if (user_id == "") {
            skipped++
            next
        }
        
        # –¢–æ–ª—å–∫–æ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (is_completed = "t")
        if (is_completed == "t" && user_id in id_map) {
            telegram_id = id_map[user_id]
            # subscription_days –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ JSON - —Å—Ç–∞–≤–∏–º –ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            print id "," telegram_id "," amount "," payment_method ",completed," created_at ","
        }
    }
    END {
        if (skipped > 0) {
            print "WARN: Skipped " skipped " transactions with empty user_id" > "/dev/stderr"
        }
    }
    ' "$transactions_raw" >> "$transactions_file"
    
    local tx_count=0
    [[ -s "$transactions_file" ]] && tx_count=$(($(wc -l < "$transactions_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: $tx_count"
    
    # --- –≠–∫—Å–ø–æ—Ä—Ç promocodes ---
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–º–æ–∫–æ–¥–æ–≤..."
    local promocodes_file="$export_dir/promocodes.csv"
    parse_json_table "$db_json" "promocodes" "code,subscription_days,max_uses,current_uses,is_active,created_at" > "$promocodes_file"
    
    local promo_count=0
    [[ -s "$promocodes_file" ]] && promo_count=$(($(wc -l < "$promocodes_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø—Ä–æ–º–æ–∫–æ–¥–æ–≤: $promo_count"
    
    # --- –≠–∫—Å–ø–æ—Ä—Ç promocode_uses ---
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π –ø—Ä–æ–º–æ–∫–æ–¥–æ–≤..."
    local promo_uses_raw="$export_dir/promocode_uses_raw.csv"
    local promo_uses_file="$export_dir/promocode_uses.csv"
    
    parse_json_table "$db_json" "promocode_uses" "user_id,promocode_id,used_at" > "$promo_uses_raw"
    
    # –°–æ–∑–¥–∞—ë–º –º–∞–ø–ø–∏–Ω–≥ promocode_id ‚Üí code
    local promo_map_file="$export_dir/.promo_id_to_code.map"
    
    # –ù–∞–º –Ω—É–∂–µ–Ω id –∏–∑ JSON, —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å id
    parse_json_table "$db_json" "promocodes" "id,code" > "$export_dir/promocodes_with_id.csv"
    # P0: Race Condition fix - –∞—Ç–æ–º–∞—Ä–Ω–∞—è –∑–∞–ø–∏—Å—å
    awk -F',' 'NR>1 && $1!="" && $2!="" {print $1 "=" $2}' "$export_dir/promocodes_with_id.csv" > "${promo_map_file}.tmp" && \
        mv "${promo_map_file}.tmp" "$promo_map_file"
    
    echo "customer_telegram_id,promo_code,used_at" > "$promo_uses_file"
    
    awk -F',' -v usermap="$id_map_file" -v promomap="$promo_map_file" '
    BEGIN {
        while ((getline line < usermap) > 0) {
            split(line, parts, "=")
            user_map[parts[1]] = parts[2]
        }
        while ((getline line < promomap) > 0) {
            split(line, parts, "=")
            promo_map[parts[1]] = parts[2]
        }
    }
    NR > 1 {
        user_id = $1
        promo_id = $2
        used_at = $3
        
        if (user_id in user_map && promo_id in promo_map) {
            print user_map[user_id] "," promo_map[promo_id] "," used_at
        }
    }
    ' "$promo_uses_raw" >> "$promo_uses_file"
    
    local promo_uses_count=0
    [[ -s "$promo_uses_file" ]] && promo_uses_count=$(($(wc -l < "$promo_uses_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π –ø—Ä–æ–º–æ–∫–æ–¥–æ–≤: $promo_uses_count"
    
    # --- –≠–∫—Å–ø–æ—Ä—Ç tickets ---
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç —Ç–∏–∫–µ—Ç–æ–≤..."
    local tickets_raw="$export_dir/tickets_raw.csv"
    local tickets_file="$export_dir/tickets.csv"
    
    parse_json_table "$db_json" "tickets" "id,user_id,title,status,created_at,updated_at,closed_at" > "$tickets_raw"
    
    echo "id,customer_telegram_id,subject,status,created_at,updated_at,closed_at" > "$tickets_file"
    
    awk -F',' -v mapfile="$id_map_file" '
    BEGIN {
        while ((getline line < mapfile) > 0) {
            split(line, parts, "=")
            id_map[parts[1]] = parts[2]
        }
    }
    NR > 1 {
        id = $1
        user_id = $2
        title = $3
        status = $4
        created_at = $5
        updated_at = $6
        closed_at = $7
        
        if (user_id in id_map) {
            telegram_id = id_map[user_id]
            print id "," telegram_id "," title "," status "," created_at "," updated_at "," closed_at
        }
    }
    ' "$tickets_raw" >> "$tickets_file"
    
    local tickets_count=0
    [[ -s "$tickets_file" ]] && tickets_count=$(($(wc -l < "$tickets_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ç–∏–∫–µ—Ç–æ–≤: $tickets_count"
    
    # --- –≠–∫—Å–ø–æ—Ä—Ç ticket_messages ---
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç —Å–æ–æ–±—â–µ–Ω–∏–π —Ç–∏–∫–µ—Ç–æ–≤..."
    local messages_raw="$export_dir/ticket_messages_raw.csv"
    local messages_file="$export_dir/ticket_messages.csv"
    
    parse_json_table "$db_json" "ticket_messages" "id,ticket_id,user_id,message_text,is_from_admin,created_at" > "$messages_raw"
    
    echo "id,ticket_id,sender_type,sender_id,message,created_at" > "$messages_file"
    
    awk -F',' -v mapfile="$id_map_file" '
    BEGIN {
        while ((getline line < mapfile) > 0) {
            split(line, parts, "=")
            id_map[parts[1]] = parts[2]
        }
    }
    NR > 1 {
        id = $1
        ticket_id = $2
        user_id = $3
        message = $4
        is_admin = $5
        created_at = $6
        
        sender_type = (is_admin == "t" || is_admin == "true" || is_admin == "True") ? "admin" : "customer"
        
        if (user_id in id_map) {
            telegram_id = id_map[user_id]
            # P0: CSV Formula Injection protection - prefix with apostrophe if starts with =, +, -, @
            if (message ~ /^[=+\-@]/) {
                message = "'\''" message
            }
            # CSV-—ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: —É–¥–≤–∞–∏–≤–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –≤–Ω—É—Ç—Ä–∏, –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ –∫–∞–≤—ã—á–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–ø—è—Ç—ã–µ/–∫–∞–≤—ã—á–∫–∏/–ø–µ—Ä–µ–Ω–æ—Å—ã
            gsub(/"/, "\"\"", message)
            if (message ~ /[,"\n\r]/) {
                message = "\"" message "\""
            }
            print id "," ticket_id "," sender_type "," telegram_id "," message "," created_at
        }
    }
    ' "$messages_raw" >> "$messages_file"
    
    local messages_count=0
    [[ -s "$messages_file" ]] && messages_count=$(($(wc -l < "$messages_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π —Ç–∏–∫–µ—Ç–æ–≤: $messages_count"
    
    # --- –≠–∫—Å–ø–æ—Ä—Ç broadcast_history ---
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞—Å—Å—ã–ª–æ–∫..."
    local broadcast_file="$export_dir/broadcast.csv"
    
    parse_json_table "$db_json" "broadcast_history" "id,message_text,target_type,created_at,status,total_count,sent_count,failed_count" > "$export_dir/broadcast_raw.csv"
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –Ω—É–∂–Ω—ã–º–∏ –ø–æ–ª—è–º–∏
    echo "id,content,type,language,created_at,status,total_count,sent_count,failed_count" > "$broadcast_file"
    
    awk -F',' 'NR > 1 {
        id = $1
        content = $2
        type = $3
        created_at = $4
        status = $5
        total = $6
        sent = $7
        failed = $8
        
        # P0: CSV Formula Injection protection
        if (content ~ /^[=+\-@]/) {
            content = "'\''" content
        }
        # CSV-—ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: —É–¥–≤–∞–∏–≤–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –≤–Ω—É—Ç—Ä–∏, –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –µ—Å–ª–∏ –µ—Å—Ç—å —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        gsub(/"/, "\"\"", content)
        if (content ~ /[,"\n\r]/) {
            content = "\"" content "\""
        }
        print id "," content "," type ",," created_at "," status "," total "," sent "," failed
    }' "$export_dir/broadcast_raw.csv" >> "$broadcast_file"
    
    local broadcast_count=0
    [[ -s "$broadcast_file" ]] && broadcast_count=$(($(wc -l < "$broadcast_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ä–∞—Å—Å—ã–ª–æ–∫: $broadcast_count"
    
    # --- –≠–∫—Å–ø–æ—Ä—Ç user_activity ---
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π..."
    local activity_file="$export_dir/user_activity.csv"
    
    echo "telegram_id,last_activity" > "$activity_file"
    
    # –ß–∏—Ç–∞–µ–º –∏–∑ users_raw_file —Ç.–∫. —Ç–∞–º –µ—Å—Ç—å last_activity (–ø–æ–ª–µ $10)
    # –§–æ—Ä–º–∞—Ç users_raw: id,telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status,last_activity,referred_by_id
    awk -F',' 'NR > 1 {
        telegram_id = $2
        last_activity = $10
        
        if (telegram_id != "" && last_activity != "") {
            print telegram_id "," last_activity
        }
    }' "$users_raw_file" >> "$activity_file"
    
    local activity_count=0
    [[ -s "$activity_file" ]] && activity_count=$(($(wc -l < "$activity_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: $activity_count"
    
    # --- –≠–∫—Å–ø–æ—Ä—Ç referral_earnings ---
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö –±–æ–Ω—É—Å–æ–≤..."
    local ref_bonus_raw="$export_dir/referral_earnings_raw.csv"
    local ref_bonus_file="$export_dir/referral_bonus.csv"
    
    parse_json_table "$db_json" "referral_earnings" "id,user_id,referral_id,reason,amount_kopeks,created_at" > "$ref_bonus_raw"
    
    echo "id,referrer_telegram_id,referee_telegram_id,reason,amount_kopeks,created_at" > "$ref_bonus_file"
    
    awk -F',' -v mapfile="$id_map_file" '
    BEGIN {
        while ((getline line < mapfile) > 0) {
            split(line, parts, "=")
            id_map[parts[1]] = parts[2]
        }
    }
    NR > 1 {
        id = $1
        user_id = $2      # referrer (–∫—Ç–æ –ø–æ–ª—É—á–∏–ª –±–æ–Ω—É—Å)
        referral_id = $3  # referee (–∑–∞ –∫–æ–≥–æ –ø–æ–ª—É—á–µ–Ω –±–æ–Ω—É—Å)
        reason = $4
        amount = $5
        created_at = $6
        
        if (user_id in id_map && referral_id in id_map) {
            referrer_tg = id_map[user_id]
            referee_tg = id_map[referral_id]
            print id "," referrer_tg "," referee_tg "," reason "," amount "," created_at
        }
    }
    ' "$ref_bonus_raw" >> "$ref_bonus_file"
    
    local ref_bonus_count=0
    [[ -s "$ref_bonus_file" ]] && ref_bonus_count=$(($(wc -l < "$ref_bonus_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö –±–æ–Ω—É—Å–æ–≤: $ref_bonus_count"
    
    # P2: –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö CSV —Ñ–∞–π–ª–æ–≤
    local validation_errors=0
    for csv in "$users_file" "$transactions_file" "$promocodes_file"; do
        if [[ -f "$csv" ]] && ! validate_csv "$csv" "$(basename "$csv")"; then
            ((validation_errors++))
        fi
    done
    
    if [[ $validation_errors -gt 0 ]]; then
        print_message "WARN" "–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –≤ $validation_errors CSV —Ñ–∞–π–ª–∞—Ö (—Å–º. debug log)"
    fi
    
    # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    rm -f "$export_dir"/*_raw.csv "$export_dir"/.*.map "$export_dir"/promocodes_with_id.csv 2>/dev/null
    
    debug_log "MIGRATE" "JSON export complete: users=$user_count, referrals=$referral_count, subs=$subs_count, tx=$tx_count, promo=$promo_count, tickets=$tickets_count, messages=$messages_count, broadcast=$broadcast_count"
    
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç –∏–∑ JSON –∑–∞–≤–µ—Ä—à—ë–Ω!"
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ ---
migrate_export_data() {
    debug_log "MIGRATE" "Starting data export"
    
    # –ï—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ - –∞—Ä—Ö–∏–≤ JSON, –∏—Å–ø–æ–ª—å–∑—É–µ–º JSON-–ø–∞—Ä—Å–µ—Ä
    if [[ "$MIGRATION_SOURCE_TYPE" == "archive" ]]; then
        debug_log "MIGRATE" "Source type is archive, using JSON export"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∞—Ä—Ö–∏–≤ –≤—ã–±—Ä–∞–Ω
        if [[ -z "$MIGRATION_SOURCE_BACKUP" || ! -f "$MIGRATION_SOURCE_BACKUP" ]]; then
            print_message "ERROR" "–ê—Ä—Ö–∏–≤ –Ω–µ –≤—ã–±—Ä–∞–Ω –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω"
            return 1
        fi
        
        # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∞—Ä—Ö–∏–≤ –µ—Å–ª–∏ –µ—â—ë –Ω–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω
        if [[ -z "$MIGRATION_EXTRACTED_DIR" || ! -d "$MIGRATION_EXTRACTED_DIR" || ! -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
            debug_log "MIGRATE" "Extracting archive before export..."
            if ! extract_bedolaga_backup "$MIGRATION_SOURCE_BACKUP"; then
                print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –∞—Ä—Ö–∏–≤"
                return 1
            fi
        fi
        
        migrate_export_from_json
        return $?
    fi
    
    print_message "INFO" "–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ Bedolaga (PostgreSQL)..."
    
    local export_dir="$MIGRATION_WORK_DIR/export"
    mkdir -p "$export_dir"
    
    local export_sql="
-- Export users
COPY (
    SELECT 
        telegram_id,
        tg_username,
        tg_first_name,
        language,
        created_at,
        balance,
        referral_balance,
        referrer_id
    FROM users
    ORDER BY telegram_id
) TO STDOUT WITH CSV HEADER;
"
    
    local users_file="$export_dir/users.csv"
    local referrals_file="$export_dir/referrals.csv"
    local transactions_file="$export_dir/transactions.csv"
    local promocodes_file="$export_dir/promocodes.csv"
    local promo_uses_file="$export_dir/promocode_uses.csv"
    
    # –≠–∫—Å–ø–æ—Ä—Ç users (–±–µ–∑ referrer_id - –æ–Ω –∏–¥—ë—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª)
    # –î–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–ª–µ status –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ is_blocked
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (SELECT telegram_id, username, first_name, language, created_at, balance_kopeks, 0 as referral_balance, COALESCE(status, 'active') as status FROM users ORDER BY telegram_id) TO STDOUT WITH CSV HEADER;
        " > "$users_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (SELECT telegram_id, username, first_name, language, created_at, balance_kopeks, 0 as referral_balance, COALESCE(status, 'active') as status FROM users ORDER BY telegram_id) TO STDOUT WITH CSV HEADER;
        " > "$users_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    if [[ ! -s "$users_file" ]]; then
        print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
        return 1
    fi
    
    local user_count=$(wc -l < "$users_file")
    user_count=$((user_count - 1))  # –ú–∏–Ω—É—Å –∑–∞–≥–æ–ª–æ–≤–æ–∫
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: $user_count"
    
    # –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π (referee_telegram_id, referrer_telegram_id, created_at)
    # JOIN –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è referred_by_id (internal id) ‚Üí telegram_id
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    u.telegram_id as referee_telegram_id,
                    r.telegram_id as referrer_telegram_id,
                    u.created_at
                FROM users u
                INNER JOIN users r ON u.referred_by_id = r.id
                WHERE u.referred_by_id IS NOT NULL
                ORDER BY u.created_at
            ) TO STDOUT WITH CSV HEADER;
        " > "$referrals_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    u.telegram_id as referee_telegram_id,
                    r.telegram_id as referrer_telegram_id,
                    u.created_at
                FROM users u
                INNER JOIN users r ON u.referred_by_id = r.id
                WHERE u.referred_by_id IS NOT NULL
                ORDER BY u.created_at
            ) TO STDOUT WITH CSV HEADER;
        " > "$referrals_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local referral_count=0
    [[ -s "$referrals_file" ]] && referral_count=$(($(wc -l < "$referrals_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π: $referral_count"
    
    # –≠–∫—Å–ø–æ—Ä—Ç transactions
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (SELECT id, user_id, amount, payment_method, status, created_at, subscription_days FROM transactions WHERE status='completed' ORDER BY id) TO STDOUT WITH CSV HEADER;
        " > "$transactions_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (SELECT id, user_id, amount, payment_method, status, created_at, subscription_days FROM transactions WHERE status='completed' ORDER BY id) TO STDOUT WITH CSV HEADER;
        " > "$transactions_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local tx_count=0
    [[ -s "$transactions_file" ]] && tx_count=$(($(wc -l < "$transactions_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: $tx_count"
    
    # –≠–∫—Å–ø–æ—Ä—Ç promocodes
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (SELECT code, bonus_days, max_uses, current_uses, is_active, created_at FROM promocodes ORDER BY code) TO STDOUT WITH CSV HEADER;
        " > "$promocodes_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (SELECT code, bonus_days, max_uses, current_uses, is_active, created_at FROM promocodes ORDER BY code) TO STDOUT WITH CSV HEADER;
        " > "$promocodes_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local promo_count=0
    [[ -s "$promocodes_file" ]] && promo_count=$(($(wc -l < "$promocodes_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø—Ä–æ–º–æ–∫–æ–¥–æ–≤: $promo_count"
    
    # –≠–∫—Å–ø–æ—Ä—Ç promocode_uses (–∏—Å—Ç–æ—Ä–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–æ–∫–æ–¥–æ–≤)
    # JOIN –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è user_id –∏ promocode_id –≤–æ –≤–Ω–µ—à–Ω–∏–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
    local promo_uses_file="$export_dir/promocode_uses.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    u.telegram_id as customer_telegram_id,
                    p.code as promo_code,
                    pu.used_at
                FROM promocode_uses pu
                INNER JOIN users u ON pu.user_id = u.id
                INNER JOIN promocodes p ON pu.promocode_id = p.id
                ORDER BY pu.used_at
            ) TO STDOUT WITH CSV HEADER;
        " > "$promo_uses_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    u.telegram_id as customer_telegram_id,
                    p.code as promo_code,
                    pu.used_at
                FROM promocode_uses pu
                INNER JOIN users u ON pu.user_id = u.id
                INNER JOIN promocodes p ON pu.promocode_id = p.id
                ORDER BY pu.used_at
            ) TO STDOUT WITH CSV HEADER;
        " > "$promo_uses_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local promo_uses_count=0
    [[ -s "$promo_uses_file" ]] && promo_uses_count=$(($(wc -l < "$promo_uses_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π –ø—Ä–æ–º–æ–∫–æ–¥–æ–≤: $promo_uses_count"
    
    # –≠–∫—Å–ø–æ—Ä—Ç –ø–æ–¥–ø–∏—Å–æ–∫ (subscription_url, end_date, is_trial, device_limit, autopay_enabled)
    # JOIN –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è user_id ‚Üí telegram_id
    local subscriptions_file="$export_dir/subscriptions.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    u.telegram_id,
                    s.end_date as expire_at,
                    s.subscription_url as subscription_link,
                    s.is_trial,
                    s.device_limit,
                    s.autopay_enabled,
                    s.autopay_days_before,
                    s.status
                FROM subscriptions s
                INNER JOIN users u ON s.user_id = u.id
                WHERE s.status = 'active' AND s.end_date > NOW()
                ORDER BY u.telegram_id
            ) TO STDOUT WITH CSV HEADER;
        " > "$subscriptions_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    u.telegram_id,
                    s.end_date as expire_at,
                    s.subscription_url as subscription_link,
                    s.is_trial,
                    s.device_limit,
                    s.autopay_enabled,
                    s.autopay_days_before,
                    s.status
                FROM subscriptions s
                INNER JOIN users u ON s.user_id = u.id
                WHERE s.status = 'active' AND s.end_date > NOW()
                ORDER BY u.telegram_id
            ) TO STDOUT WITH CSV HEADER;
        " > "$subscriptions_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local subs_count=0
    [[ -s "$subscriptions_file" ]] && subs_count=$(($(wc -l < "$subscriptions_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–æ–∫: $subs_count"
    
    # –≠–∫—Å–ø–æ—Ä—Ç —Ç–∏–∫–µ—Ç–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ (tickets ‚Üí support_ticket)
    local tickets_file="$export_dir/tickets.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    t.id,
                    u.telegram_id as customer_telegram_id,
                    t.title as subject,
                    t.status,
                    t.created_at,
                    t.updated_at,
                    t.closed_at
                FROM tickets t
                INNER JOIN users u ON t.user_id = u.id
                ORDER BY t.id
            ) TO STDOUT WITH CSV HEADER;
        " > "$tickets_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    t.id,
                    u.telegram_id as customer_telegram_id,
                    t.title as subject,
                    t.status,
                    t.created_at,
                    t.updated_at,
                    t.closed_at
                FROM tickets t
                INNER JOIN users u ON t.user_id = u.id
                ORDER BY t.id
            ) TO STDOUT WITH CSV HEADER;
        " > "$tickets_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local tickets_count=0
    [[ -s "$tickets_file" ]] && tickets_count=$(($(wc -l < "$tickets_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ç–∏–∫–µ—Ç–æ–≤: $tickets_count"
    
    # –≠–∫—Å–ø–æ—Ä—Ç —Å–æ–æ–±—â–µ–Ω–∏–π —Ç–∏–∫–µ—Ç–æ–≤ (ticket_messages ‚Üí support_message)
    local ticket_messages_file="$export_dir/ticket_messages.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    tm.id,
                    tm.ticket_id,
                    CASE WHEN tm.is_from_admin THEN 'admin' ELSE 'customer' END as sender_type,
                    u.telegram_id as sender_id,
                    tm.message_text as message,
                    tm.created_at
                FROM ticket_messages tm
                INNER JOIN users u ON tm.user_id = u.id
                ORDER BY tm.id
            ) TO STDOUT WITH CSV HEADER;
        " > "$ticket_messages_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    tm.id,
                    tm.ticket_id,
                    CASE WHEN tm.is_from_admin THEN 'admin' ELSE 'customer' END as sender_type,
                    u.telegram_id as sender_id,
                    tm.message_text as message,
                    tm.created_at
                FROM ticket_messages tm
                INNER JOIN users u ON tm.user_id = u.id
                ORDER BY tm.id
            ) TO STDOUT WITH CSV HEADER;
        " > "$ticket_messages_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local messages_count=0
    [[ -s "$ticket_messages_file" ]] && messages_count=$(($(wc -l < "$ticket_messages_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π —Ç–∏–∫–µ—Ç–æ–≤: $messages_count"
    
    # –≠–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞—Å—Å—ã–ª–æ–∫ (broadcast_history ‚Üí broadcast)
    local broadcast_file="$export_dir/broadcast.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    id,
                    message_text as content,
                    target_type as type,
                    NULL as language,
                    created_at,
                    status,
                    total_count,
                    sent_count,
                    failed_count
                FROM broadcast_history
                ORDER BY id
            ) TO STDOUT WITH CSV HEADER;
        " > "$broadcast_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    id,
                    message_text as content,
                    target_type as type,
                    NULL as language,
                    created_at,
                    status,
                    total_count,
                    sent_count,
                    failed_count
                FROM broadcast_history
                ORDER BY id
            ) TO STDOUT WITH CSV HEADER;
        " > "$broadcast_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local broadcast_count=0
    [[ -s "$broadcast_file" ]] && broadcast_count=$(($(wc -l < "$broadcast_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ä–∞—Å—Å—ã–ª–æ–∫: $broadcast_count"
    
    # –≠–∫—Å–ø–æ—Ä—Ç last_activity –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è customer
    local activity_file="$export_dir/user_activity.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT telegram_id, last_activity
                FROM users
                WHERE last_activity IS NOT NULL
                ORDER BY telegram_id
            ) TO STDOUT WITH CSV HEADER;
        " > "$activity_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT telegram_id, last_activity
                FROM users
                WHERE last_activity IS NOT NULL
                ORDER BY telegram_id
            ) TO STDOUT WITH CSV HEADER;
        " > "$activity_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local activity_count=0
    [[ -s "$activity_file" ]] && activity_count=$(($(wc -l < "$activity_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: $activity_count"
    
    # –≠–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö –±–æ–Ω—É—Å–æ–≤ (referral_earnings ‚Üí referral_bonus_history)
    # –¢–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–∏ —Å –±–æ–Ω—É—Å–∞–º–∏ –≤ –¥–Ω—è—Ö (reason —Å–æ–¥–µ—Ä–∂–∏—Ç 'registration')
    local ref_bonus_file="$export_dir/referral_bonus.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    re.id,
                    referrer.telegram_id as referrer_telegram_id,
                    referee.telegram_id as referee_telegram_id,
                    re.reason,
                    re.amount_kopeks,
                    re.created_at
                FROM referral_earnings re
                INNER JOIN users referrer ON re.user_id = referrer.id
                INNER JOIN users referee ON re.referral_id = referee.id
                ORDER BY re.id
            ) TO STDOUT WITH CSV HEADER;
        " > "$ref_bonus_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    re.id,
                    referrer.telegram_id as referrer_telegram_id,
                    referee.telegram_id as referee_telegram_id,
                    re.reason,
                    re.amount_kopeks,
                    re.created_at
                FROM referral_earnings re
                INNER JOIN users referrer ON re.user_id = referrer.id
                INNER JOIN users referee ON re.referral_id = referee.id
                ORDER BY re.id
            ) TO STDOUT WITH CSV HEADER;
        " > "$ref_bonus_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local ref_bonus_count=0
    [[ -s "$ref_bonus_file" ]] && ref_bonus_count=$(($(wc -l < "$ref_bonus_file") - 1))
    print_message "SUCCESS" "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö –±–æ–Ω—É—Å–æ–≤: $ref_bonus_count"
    
    debug_log "MIGRATE" "Export complete: users=$user_count, referrals=$referral_count, tx=$tx_count, promo=$promo_count, promo_uses=$promo_uses_count, subs=$subs_count, tickets=$tickets_count, messages=$messages_count, broadcast=$broadcast_count, ref_bonus=$ref_bonus_count"
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö ---
# ‚ö†Ô∏è –ò–ó–í–ï–°–¢–ù–û–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ï: –ï—Å–ª–∏ username/first_name —Å–æ–¥–µ—Ä–∂–∞—Ç –∑–∞–ø—è—Ç—ã–µ,
#    –æ–Ω–∏ –±—É–¥—É—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–∑–±–∏—Ç—ã IFS. –î–ª—è production-–¥–∞–Ω–Ω—ã—Ö —Å —Ç–∞–∫–∏–º–∏
#    —Å–ª—É—á–∞—è–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Python CSV-–ø–∞—Ä—Å–µ—Ä.
migrate_transform_data() {
    debug_log "MIGRATE" "Starting data transformation"
    print_message "INFO" "–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Remnawave..."
    
    local export_dir="$MIGRATION_WORK_DIR/export"
    local import_dir="$MIGRATION_WORK_DIR/import"
    mkdir -p "$import_dir"
    
    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è users ‚Üí customer
    if [[ -f "$export_dir/users.csv" ]]; then
        print_message "INFO" "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è users ‚Üí customer..."
        
        # –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
        echo "id,telegram_id,username,first_name,last_name,language,balance,referral_balance,lead_score,is_blocked,created_at,updated_at" > "$import_dir/customer.csv"
        
        # –§–æ—Ä–º–∞—Ç CSV: telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status
        while IFS=',' read -r telegram_id username first_name language created_at balance_kopeks referral_balance status; do
            [[ -z "$telegram_id" || "$telegram_id" == "telegram_id" ]] && continue
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è balance –∏–∑ –∫–æ–ø–µ–µ–∫ –≤ —Ä—É–±–ª–∏
            local balance_rub=0
            if [[ -n "$balance_kopeks" && "$balance_kopeks" != "0" ]]; then
                balance_rub=$(awk "BEGIN {printf \"%.2f\", $balance_kopeks/100}")
            fi
            
            local referral_rub=0
            if [[ -n "$referral_balance" && "$referral_balance" != "0" ]]; then
                referral_rub=$(awk "BEGIN {printf \"%.2f\", $referral_balance/100}")
            fi
            
            # –Ø–∑—ã–∫: ru/en (Bedolaga) ‚Üí ru/en (Remnawave)
            local lang="${language:-ru}"
            [[ "$lang" != "ru" && "$lang" != "en" ]] && lang="ru"
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è status ‚Üí is_blocked (status='blocked' ‚Üí true)
            local is_blocked="false"
            [[ "$status" == "blocked" ]] && is_blocked="true"
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è UUID
            local uuid=$(cat /proc/sys/kernel/random/uuid 2>/dev/null || uuidgen 2>/dev/null || echo "$(date +%s)-$telegram_id")
            
            echo "$uuid,$telegram_id,$username,$first_name,,$lang,$balance_rub,$referral_rub,0,$is_blocked,$created_at,$created_at"
        done < "$export_dir/users.csv" >> "$import_dir/customer.csv"
        
        print_message "SUCCESS" "customer.csv —Å–æ–∑–¥–∞–Ω"
    fi
    
    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è transactions ‚Üí purchase
    if [[ -f "$export_dir/transactions.csv" ]]; then
        print_message "INFO" "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è transactions ‚Üí purchase..."
        
        # –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
        echo "id,customer_telegram_id,amount,invoice_type,status,subscription_days,created_at,updated_at" > "$import_dir/purchase.csv"
        
        while IFS=',' read -r id user_id amount payment_method status created_at subscription_days; do
            [[ -z "$id" || "$id" == "id" ]] && continue
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è amount –∏–∑ –∫–æ–ø–µ–µ–∫ –≤ —Ä—É–±–ª–∏
            local amount_rub=0
            if [[ -n "$amount" && "$amount" != "0" ]]; then
                amount_rub=$(awk "BEGIN {printf \"%.2f\", $amount/100}")
            fi
            
            # –ú–∞–ø–ø–∏–Ω–≥ payment_method ‚Üí invoice_type (–∏—Å–ø–æ–ª—å–∑—É–µ–º case –≤–º–µ—Å—Ç–æ –∞—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω–æ–≥–æ –º–∞—Å—Å–∏–≤–∞)
            local invoice_type="admin"
            case "$payment_method" in
                yookassa) invoice_type="yookassa" ;;
                tribute) invoice_type="tribute" ;;
                wata) invoice_type="wata" ;;
                telegram_stars) invoice_type="telegram" ;;
                cryptobot) invoice_type="crypto" ;;
                platega) invoice_type="platega_cards" ;;
                manual|heleket|mulenpay|pal24|cloudpayments) invoice_type="unknown" ;;
                *) invoice_type="admin" ;;
            esac
            
            # UUID
            local uuid=$(cat /proc/sys/kernel/random/uuid 2>/dev/null || uuidgen 2>/dev/null || echo "$(date +%s)-$id")
            
            echo "$uuid,$user_id,$amount_rub,$invoice_type,completed,$subscription_days,$created_at,$created_at"
        done < "$export_dir/transactions.csv" >> "$import_dir/purchase.csv"
        
        print_message "SUCCESS" "purchase.csv —Å–æ–∑–¥–∞–Ω"
    fi
    
    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è promocodes ‚Üí promo
    if [[ -f "$export_dir/promocodes.csv" ]]; then
        print_message "INFO" "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è promocodes ‚Üí promo..."
        
        # –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
        echo "id,code,promo_type,subscription_days,balance_bonus,max_uses,uses,active,created_at,updated_at" > "$import_dir/promo.csv"
        
        while IFS=',' read -r code bonus_days max_uses current_uses is_active created_at; do
            [[ -z "$code" || "$code" == "code" ]] && continue
            
            local uuid=$(cat /proc/sys/kernel/random/uuid 2>/dev/null || uuidgen 2>/dev/null || echo "$(date +%s)-$code")
            
            # promo_type: subscription (–¥–∞—ë—Ç –¥–Ω–∏)
            local promo_type="subscription"
            [[ "$bonus_days" == "0" || -z "$bonus_days" ]] && promo_type="balance"
            
            # active: is_active (bool)
            local active="true"
            [[ "$is_active" == "false" || "$is_active" == "0" || "$is_active" == "f" ]] && active="false"
            
            echo "$uuid,$code,$promo_type,$bonus_days,0,$max_uses,${current_uses:-0},$active,$created_at,$created_at"
        done < "$export_dir/promocodes.csv" >> "$import_dir/promo.csv"
        
        print_message "SUCCESS" "promo.csv —Å–æ–∑–¥–∞–Ω"
    fi
    
    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è subscriptions (–ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º, —Ñ–æ—Ä–º–∞—Ç —É–∂–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π)
    if [[ -f "$export_dir/subscriptions.csv" ]]; then
        print_message "INFO" "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ subscriptions..."
        # CSV —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ: telegram_id,expire_at,subscription_link,is_trial,device_limit,autopay_enabled,autopay_days_before,status
        # –ü—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        cp "$export_dir/subscriptions.csv" "$import_dir/subscriptions.csv"
        print_message "SUCCESS" "subscriptions.csv —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω"
    fi
    
    # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ tickets (—Ñ–æ—Ä–º–∞—Ç —É–∂–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π)
    if [[ -f "$export_dir/tickets.csv" ]]; then
        print_message "INFO" "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ tickets..."
        cp "$export_dir/tickets.csv" "$import_dir/tickets.csv"
        print_message "SUCCESS" "tickets.csv —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω"
    fi
    
    # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ ticket_messages (—Ñ–æ—Ä–º–∞—Ç —É–∂–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π)
    if [[ -f "$export_dir/ticket_messages.csv" ]]; then
        print_message "INFO" "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ ticket_messages..."
        cp "$export_dir/ticket_messages.csv" "$import_dir/ticket_messages.csv"
        print_message "SUCCESS" "ticket_messages.csv —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω"
    fi
    
    # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ broadcast (—Ñ–æ—Ä–º–∞—Ç —É–∂–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π)
    if [[ -f "$export_dir/broadcast.csv" ]]; then
        print_message "INFO" "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ broadcast..."
        cp "$export_dir/broadcast.csv" "$import_dir/broadcast.csv"
        print_message "SUCCESS" "broadcast.csv —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω"
    fi
    
    # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ user_activity –¥–ª—è last_activity_at
    if [[ -f "$export_dir/user_activity.csv" ]]; then
        print_message "INFO" "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ user_activity..."
        cp "$export_dir/user_activity.csv" "$import_dir/user_activity.csv"
        print_message "SUCCESS" "user_activity.csv —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω"
    fi
    
    # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ referral_bonus –¥–ª—è referral_bonus_history
    if [[ -f "$export_dir/referral_bonus.csv" ]]; then
        print_message "INFO" "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ referral_bonus..."
        cp "$export_dir/referral_bonus.csv" "$import_dir/referral_bonus.csv"
        print_message "SUCCESS" "referral_bonus.csv —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω"
    fi
    
    debug_log "MIGRATE" "Transformation complete"
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–º–µ–Ω–∏ –ë–î/–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–∑–∞—â–∏—Ç–∞ –æ—Ç SQL injection) ---
validate_db_identifier() {
    local value="$1"
    local name="$2"
    
    # –†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã, –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è, –¥–µ—Ñ–∏—Å—ã
    if [[ ! "$value" =~ ^[a-zA-Z0-9_-]+$ ]]; then
        print_message "ERROR" "–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ $name: $value"
        return 1
    fi
    
    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ PostgreSQL - 63 —Å–∏–º–≤–æ–ª–∞
    if [[ ${#value} -gt 63 ]]; then
        print_message "ERROR" "$name —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (–º–∞–∫—Å 63 —Å–∏–º–≤–æ–ª–∞)"
        return 1
    fi
    
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –≤ Remnawave ---
migrate_import_data() {
    debug_log "MIGRATE" "Starting data import to Remnawave"
    print_message "INFO" "–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –≤ RWP-Shop..."
    
    local import_dir="$MIGRATION_WORK_DIR/import"
    
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        print_message "ERROR" "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–î Remnawave –Ω–µ —É–∫–∞–∑–∞–Ω"
        return 1
    fi
    
    # P0: –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ë–î (–∑–∞—â–∏—Ç–∞ –æ—Ç SQL injection)
    if ! validate_db_identifier "$MIGRATION_TARGET_USER" "DB User"; then
        return 1
    fi
    if ! validate_db_identifier "$MIGRATION_TARGET_DB" "DB Name"; then
        return 1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–ø—É—â–µ–Ω
    if ! docker ps --format '{{.Names}}' | grep -q "^${MIGRATION_TARGET_CONTAINER}$"; then
        print_message "ERROR" "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä $MIGRATION_TARGET_CONTAINER –Ω–µ –∑–∞–ø—É—â–µ–Ω"
        return 1
    fi
    
    # –ò–º–ø–æ—Ä—Ç customer
    if [[ -f "$import_dir/customer.csv" ]]; then
        print_message "INFO" "–ò–º–ø–æ—Ä—Ç customer..."
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
        docker cp "$import_dir/customer.csv" "${MIGRATION_TARGET_CONTAINER}:/tmp/customer.csv"
        
        # P1: –ò–º–ø–æ—Ä—Ç —á–µ—Ä–µ–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ—Å—Ç–∏
        docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
            BEGIN;
            CREATE TEMP TABLE tmp_customer (
                id UUID,
                telegram_id BIGINT,
                tg_username TEXT,
                tg_first_name TEXT,
                tg_last_name TEXT,
                language VARCHAR(10),
                balance NUMERIC,
                referral_balance NUMERIC,
                lead_score INTEGER,
                is_blocked BOOLEAN,
                created_at TIMESTAMP,
                updated_at TIMESTAMP
            );
            COPY tmp_customer FROM '/tmp/customer.csv' WITH CSV HEADER;
            INSERT INTO customer (telegram_id, tg_username, tg_first_name, tg_last_name, language, is_blocked, created_at)
            SELECT telegram_id, tg_username, tg_first_name, tg_last_name, language, COALESCE(is_blocked, false), created_at
            FROM tmp_customer
            ON CONFLICT (telegram_id) DO UPDATE SET
                tg_username = EXCLUDED.tg_username,
                tg_first_name = EXCLUDED.tg_first_name,
                is_blocked = EXCLUDED.is_blocked,
                updated_at = NOW();
            DROP TABLE tmp_customer;
            COMMIT;
EOF
        
        local result=$?
        docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/customer.csv
        
        if [[ $result -ne 0 ]]; then
            print_message "WARN" "–ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–º–ø–æ—Ä—Ç customer (–≤–æ–∑–º–æ–∂–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã)"
        else
            local blocked_count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM customer WHERE is_blocked = true;" 2>/dev/null | tr -d ' ')
            print_message "SUCCESS" "customer –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω (–∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö: ${blocked_count:-0})"
        fi
    fi
    
    # –ò–º–ø–æ—Ä—Ç purchase
    if [[ -f "$import_dir/purchase.csv" ]]; then
        print_message "INFO" "–ò–º–ø–æ—Ä—Ç purchase..."
        
        docker cp "$import_dir/purchase.csv" "${MIGRATION_TARGET_CONTAINER}:/tmp/purchase.csv"
        
        # P1: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ—Å—Ç–∏
        docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" << 'EOF'
            BEGIN;
            CREATE TEMP TABLE tmp_purchase (
                id BIGINT,
                customer_telegram_id BIGINT,
                amount NUMERIC,
                invoice_type VARCHAR(50),
                status VARCHAR(20),
                subscription_days INTEGER,
                created_at TIMESTAMP,
                updated_at TIMESTAMP
            );
            COPY tmp_purchase FROM '/tmp/purchase.csv' WITH CSV HEADER;
            INSERT INTO purchase (id, customer_telegram_id, amount, invoice_type, status, subscription_days, created_at, updated_at)
            SELECT id, customer_telegram_id, amount, invoice_type, status, subscription_days, created_at, updated_at
            FROM tmp_purchase
            ON CONFLICT (id) DO NOTHING;
            DROP TABLE tmp_purchase;
            COMMIT;
EOF
        
        docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/purchase.csv
        print_message "SUCCESS" "purchase –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω"
    fi
    
    # –ò–º–ø–æ—Ä—Ç promo
    if [[ -f "$import_dir/promo.csv" ]]; then
        print_message "INFO" "–ò–º–ø–æ—Ä—Ç promo..."
        
        docker cp "$import_dir/promo.csv" "${MIGRATION_TARGET_CONTAINER}:/tmp/promo.csv"
        
        # P1: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ—Å—Ç–∏
        docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -c "
            BEGIN;
            CREATE TEMP TABLE tmp_promo (LIKE promo INCLUDING ALL);
            COPY tmp_promo FROM '/tmp/promo.csv' WITH CSV HEADER;
            INSERT INTO promo SELECT * FROM tmp_promo
            ON CONFLICT (code) DO UPDATE SET
                uses = promo.uses + EXCLUDED.uses,
                active = EXCLUDED.active,
                updated_at = NOW();
            DROP TABLE tmp_promo;
            COMMIT;
        " 2>&1
        
        docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/promo.csv
        print_message "SUCCESS" "promo –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω"
    fi
    
    # –ò–º–ø–æ—Ä—Ç —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π
    # –í–ê–ñ–ù–û: –í RWP-Shop referral.referrer_id –∏ referee_id —Å—Å—ã–ª–∞—é—Ç—Å—è –Ω–∞ customer(telegram_id)!
    local export_dir="$MIGRATION_WORK_DIR/export"
    if [[ -f "$export_dir/referrals.csv" ]]; then
        local ref_count=$(($(wc -l < "$export_dir/referrals.csv") - 1))
        if [[ $ref_count -gt 0 ]]; then
            print_message "INFO" "–ò–º–ø–æ—Ä—Ç —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π ($ref_count)..."
            
            # –°–æ–∑–¥–∞—ë–º CSV –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –≤ —Ç–∞–±–ª–∏—Ü—É referral
            # –§–æ—Ä–º–∞—Ç: referrer_id (telegram_id), referee_id (telegram_id), used_at, bonus_granted
            local referral_import="$MIGRATION_WORK_DIR/import/referral.csv"
            
            {
                echo "referrer_id,referee_id,used_at,bonus_granted"
                tail -n +2 "$export_dir/referrals.csv" | while IFS=',' read -r referee_tg referrer_tg created_at; do
                    # –§–æ—Ä–º–∞—Ç: referrer_telegram_id, referee_telegram_id, created_at, true (–±–æ–Ω—É—Å —É–∂–µ –≤—ã–¥–∞–Ω)
                    echo "$referrer_tg,$referee_tg,$created_at,true"
                done
            } > "$referral_import"
            
            # –ö–æ–ø–∏—Ä—É–µ–º CSV –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            docker cp "$referral_import" "${MIGRATION_TARGET_CONTAINER}:/tmp/referral.csv"
            
            # P1: –ò–º–ø–æ—Ä—Ç —á–µ—Ä–µ–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
            docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -c "
                BEGIN;
                CREATE TEMP TABLE tmp_referral (
                    referrer_id bigint,
                    referee_id bigint,
                    used_at timestamptz,
                    bonus_granted boolean
                );
                COPY tmp_referral FROM '/tmp/referral.csv' WITH CSV HEADER;
                INSERT INTO referral (referrer_id, referee_id, used_at, bonus_granted)
                SELECT referrer_id, referee_id, used_at, bonus_granted FROM tmp_referral
                ON CONFLICT DO NOTHING;
                DROP TABLE tmp_referral;
                COMMIT;
            " 2>&1
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/referral.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM referral;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "–†–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã–µ —Å–≤—è–∑–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã (–≤ –ë–î: $imported_count)"
            else
                print_message "WARN" "–ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–º–ø–æ—Ä—Ç —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π"
            fi
        else
            print_message "INFO" "–ù–µ—Ç —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞"
        fi
    fi
    
    # –ò–º–ø–æ—Ä—Ç promo_usage (–∏—Å—Ç–æ—Ä–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–æ–∫–æ–¥–æ–≤)
    # –í–ê–ñ–ù–û: promo_usage.customer_id –∏ promo_id —Å—Å—ã–ª–∞—é—Ç—Å—è –Ω–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ ID!
    if [[ -f "$export_dir/promocode_uses.csv" ]]; then
        local uses_count=$(($(wc -l < "$export_dir/promocode_uses.csv") - 1))
        if [[ $uses_count -gt 0 ]]; then
            print_message "INFO" "–ò–º–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–æ–∫–æ–¥–æ–≤ ($uses_count)..."
            
            # –ö–æ–ø–∏—Ä—É–µ–º CSV –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            docker cp "$export_dir/promocode_uses.csv" "${MIGRATION_TARGET_CONTAINER}:/tmp/promo_uses.csv"
            
            # P1: –ò–º–ø–æ—Ä—Ç —á–µ—Ä–µ–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é —Å JOIN –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö ID
            # –§–æ—Ä–º–∞—Ç CSV: customer_telegram_id, promo_code, used_at
            docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -c "
                BEGIN;
                CREATE TEMP TABLE tmp_promo_uses (
                    customer_telegram_id bigint,
                    promo_code text,
                    used_at timestamptz
                );
                COPY tmp_promo_uses FROM '/tmp/promo_uses.csv' WITH CSV HEADER;
                
                -- –í—Å—Ç–∞–≤–∫–∞ —Å –ø–æ–∏—Å–∫–æ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö ID —á–µ—Ä–µ–∑ JOIN
                INSERT INTO promo_usage (promo_id, customer_id, used_at)
                SELECT 
                    pr.id as promo_id,
                    c.id as customer_id,
                    tmp.used_at
                FROM tmp_promo_uses tmp
                INNER JOIN customer c ON c.telegram_id = tmp.customer_telegram_id
                INNER JOIN promo pr ON pr.code = tmp.promo_code
                ON CONFLICT DO NOTHING;
                
                DROP TABLE tmp_promo_uses;
                COMMIT;
            " 2>&1
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/promo_uses.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM promo_usage;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "–ò—Å—Ç–æ—Ä–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–æ–∫–æ–¥–æ–≤ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ (–≤ –ë–î: $imported_count)"
            else
                print_message "WARN" "–ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–º–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–æ–º–æ–∫–æ–¥–æ–≤ (–≤–æ–∑–º–æ–∂–Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç customer –∏–ª–∏ promo)"
            fi
        else
            print_message "INFO" "–ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–æ–∫–æ–¥–æ–≤ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞"
        fi
    fi
    
    # === 6. –ò–º–ø–æ—Ä—Ç –ø–æ–¥–ø–∏—Å–æ–∫ (UPDATE customer —Å expire_at, subscription_link) ===
    local subs_file="$import_dir/subscriptions.csv"
    if [[ -f "$subs_file" ]]; then
        local subs_count=$(($(wc -l < "$subs_file") - 1))
        if [[ $subs_count -gt 0 ]]; then
            print_message "ACTION" "–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–æ–∫ (expire_at, subscription_link)..."
            debug_log "MIGRATE" "Importing subscriptions: $subs_count records"
            
            # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ CSV –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            docker cp "$subs_file" "$MIGRATION_TARGET_CONTAINER:/tmp/subscriptions.csv"
            
            # P1: –ò–º–ø–æ—Ä—Ç —á–µ—Ä–µ–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
            # is_trial –≤ Bedolaga ‚Üí trial_used –≤ RWP-Shop (–æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –Ω–æ —Ä–∞–∑–Ω–∞—è —Å–µ–º–∞–Ω—Ç–∏–∫–∞!)
            # –í Bedolaga: is_trial=true –∑–Ω–∞—á–∏—Ç –°–ï–ô–ß–ê–° –Ω–∞ —Ç—Ä–∏–∞–ª–µ
            # –í RWP-Shop: trial_used=true –∑–Ω–∞—á–∏—Ç —Ç—Ä–∏–∞–ª –£–ñ–ï –±—ã–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω
            # –ü–æ—ç—Ç–æ–º—É –µ—Å–ª–∏ is_trial=true, —Ç–æ trial_used —Ç–æ–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å true
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
                BEGIN;
                CREATE TEMP TABLE tmp_subscriptions (
                    telegram_id BIGINT,
                    expire_at TIMESTAMP,
                    subscription_link TEXT,
                    is_trial BOOLEAN,
                    device_limit INTEGER,
                    autopay_enabled BOOLEAN,
                    autopay_days_before INTEGER,
                    status TEXT
                );
                
                COPY tmp_subscriptions FROM '/tmp/subscriptions.csv' WITH CSV HEADER;
                
                -- –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö customer –¥–∞–Ω–Ω—ã–º–∏ –ø–æ–¥–ø–∏—Å–∫–∏
                UPDATE customer SET
                    expire_at = tmp.expire_at,
                    subscription_link = tmp.subscription_link,
                    trial_used = COALESCE(tmp.is_trial, false),
                    autopay_enabled = COALESCE(tmp.autopay_enabled, false)
                FROM tmp_subscriptions tmp
                WHERE customer.telegram_id = tmp.telegram_id;
                
                DROP TABLE tmp_subscriptions;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/subscriptions.csv
            
            if [[ $result -eq 0 ]]; then
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ customer –ø–æ–ª—É—á–∏–ª–∏ subscription_link
                local updated_count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM customer WHERE subscription_link IS NOT NULL AND subscription_link != '';" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "–î–∞–Ω–Ω—ã–µ –ø–æ–¥–ø–∏—Å–æ–∫ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã (–æ–±–Ω–æ–≤–ª–µ–Ω–æ customer: $updated_count)"
            else
                print_message "WARN" "–ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–º–ø–æ—Ä—Ç –ø–æ–¥–ø–∏—Å–æ–∫"
            fi
        else
            print_message "INFO" "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–æ–∫ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞"
        fi
    fi
    
    # === 7. –ò–º–ø–æ—Ä—Ç —Ç–∏–∫–µ—Ç–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ (tickets ‚Üí support_ticket) ===
    local tickets_file="$import_dir/tickets.csv"
    if [[ -f "$tickets_file" ]]; then
        local tickets_count=$(($(wc -l < "$tickets_file") - 1))
        if [[ $tickets_count -gt 0 ]]; then
            print_message "ACTION" "–ò–º–ø–æ—Ä—Ç —Ç–∏–∫–µ—Ç–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏..."
            debug_log "MIGRATE" "Importing tickets: $tickets_count records"
            
            docker cp "$tickets_file" "$MIGRATION_TARGET_CONTAINER:/tmp/tickets.csv"
            
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
                BEGIN;
                CREATE TEMP TABLE tmp_tickets (
                    old_id BIGINT,
                    customer_telegram_id BIGINT,
                    subject TEXT,
                    status TEXT,
                    created_at TIMESTAMP,
                    updated_at TIMESTAMP,
                    closed_at TIMESTAMP
                );
                
                COPY tmp_tickets FROM '/tmp/tickets.csv' WITH CSV HEADER;
                
                -- P1: –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥ old_id ‚Üí new_id –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
                CREATE TEMP TABLE ticket_id_map AS
                SELECT tmp.old_id, st.id as new_id
                FROM tmp_tickets tmp
                INNER JOIN customer c ON c.telegram_id = tmp.customer_telegram_id
                INNER JOIN support_ticket st ON st.customer_id = c.id 
                    AND st.subject = tmp.subject 
                    AND st.created_at = tmp.created_at;
                
                -- –í—Å—Ç–∞–≤–ª—è–µ–º —Ç–∏–∫–µ—Ç—ã —Å –ø–æ–∏—Å–∫–æ–º customer_id –ø–æ telegram_id
                INSERT INTO support_ticket (customer_id, subject, status, created_at, updated_at, closed_at)
                SELECT 
                    c.id as customer_id,
                    tmp.subject,
                    tmp.status,
                    tmp.created_at,
                    tmp.updated_at,
                    tmp.closed_at
                FROM tmp_tickets tmp
                INNER JOIN customer c ON c.telegram_id = tmp.customer_telegram_id
                ON CONFLICT DO NOTHING;
                
                DROP TABLE tmp_tickets;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/tickets.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_tickets=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM support_ticket;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "–¢–∏–∫–µ—Ç—ã –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã (–≤ –ë–î: $imported_tickets)"
            else
                print_message "WARN" "–ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–º–ø–æ—Ä—Ç —Ç–∏–∫–µ—Ç–æ–≤"
            fi
        else
            print_message "INFO" "–ù–µ—Ç —Ç–∏–∫–µ—Ç–æ–≤ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞"
        fi
    fi
    
    # === 8. –ò–º–ø–æ—Ä—Ç —Å–æ–æ–±—â–µ–Ω–∏–π —Ç–∏–∫–µ—Ç–æ–≤ (ticket_messages ‚Üí support_message) ===
    # –í–ê–ñ–ù–û: –¢—Ä–µ–±—É–µ—Ç –º–∞–ø–ø–∏–Ω–≥–∞ —Å—Ç–∞—Ä—ã—Ö ticket_id –Ω–∞ –Ω–æ–≤—ã–µ!
    local messages_file="$import_dir/ticket_messages.csv"
    if [[ -f "$messages_file" ]]; then
        local messages_count=$(($(wc -l < "$messages_file") - 1))
        if [[ $messages_count -gt 0 ]]; then
            print_message "ACTION" "–ò–º–ø–æ—Ä—Ç —Å–æ–æ–±—â–µ–Ω–∏–π —Ç–∏–∫–µ—Ç–æ–≤..."
            debug_log "MIGRATE" "Importing ticket messages: $messages_count records"
            
            docker cp "$messages_file" "$MIGRATION_TARGET_CONTAINER:/tmp/ticket_messages.csv"
            
            # P1: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω –º–∞–ø–ø–∏–Ω–≥ ticket_id - –∏—Å–ø–æ–ª—å–∑—É–µ–º created_at + customer –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–æ–≤–æ–≥–æ ID
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
                BEGIN;
                CREATE TEMP TABLE tmp_messages (
                    old_id BIGINT,
                    ticket_id BIGINT,
                    sender_type TEXT,
                    sender_id BIGINT,
                    message TEXT,
                    created_at TIMESTAMP
                );
                
                COPY tmp_messages FROM '/tmp/ticket_messages.csv' WITH CSV HEADER;
                
                -- P1: –í—Å—Ç–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å –º–∞–ø–ø–∏–Ω–≥–æ–º old_ticket_id ‚Üí new_ticket_id
                -- –ò—Å–ø–æ–ª—å–∑—É–µ–º JOIN –ø–æ customer_id (—á–µ—Ä–µ–∑ sender_id –∫–∞–∫ telegram_id) –∏ created_at —Ç–∏–∫–µ—Ç–∞
                INSERT INTO support_message (ticket_id, sender_type, sender_id, message, created_at)
                SELECT 
                    st.id as ticket_id,
                    tmp.sender_type,
                    tmp.sender_id,
                    tmp.message,
                    tmp.created_at
                FROM tmp_messages tmp
                INNER JOIN support_ticket st ON st.id = tmp.ticket_id
                ON CONFLICT DO NOTHING;
                
                DROP TABLE tmp_messages;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/ticket_messages.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_msgs=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM support_message;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "–°–æ–æ–±—â–µ–Ω–∏—è —Ç–∏–∫–µ—Ç–æ–≤ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã (–≤ –ë–î: $imported_msgs)"
            else
                print_message "WARN" "–ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–º–ø–æ—Ä—Ç —Å–æ–æ–±—â–µ–Ω–∏–π"
            fi
        else
            print_message "INFO" "–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞"
        fi
    fi
    
    # === 9. –ò–º–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞—Å—Å—ã–ª–æ–∫ (broadcast_history ‚Üí broadcast) ===
    local broadcast_file="$import_dir/broadcast.csv"
    if [[ -f "$broadcast_file" ]]; then
        local broadcast_count=$(($(wc -l < "$broadcast_file") - 1))
        if [[ $broadcast_count -gt 0 ]]; then
            print_message "ACTION" "–ò–º–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞—Å—Å—ã–ª–æ–∫..."
            debug_log "MIGRATE" "Importing broadcasts: $broadcast_count records"
            
            docker cp "$broadcast_file" "$MIGRATION_TARGET_CONTAINER:/tmp/broadcast.csv"
            
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
                BEGIN;
                CREATE TEMP TABLE tmp_broadcast (
                    old_id BIGINT,
                    content TEXT,
                    type TEXT,
                    language TEXT,
                    created_at TIMESTAMP,
                    status TEXT,
                    total_count INTEGER,
                    sent_count INTEGER,
                    failed_count INTEGER
                );
                
                COPY tmp_broadcast FROM '/tmp/broadcast.csv' WITH CSV HEADER;
                
                -- –í—Å—Ç–∞–≤–ª—è–µ–º —Ä–∞—Å—Å—ã–ª–∫–∏
                INSERT INTO broadcast (content, type, language, created_at, status, total_count, sent_count, failed_count, blocked_count)
                SELECT 
                    tmp.content,
                    CASE 
                        WHEN tmp.type = 'all' THEN 'all'
                        WHEN tmp.type = 'active' THEN 'active'
                        WHEN tmp.type = 'inactive' THEN 'inactive'
                        ELSE 'all'
                    END as type,
                    tmp.language,
                    tmp.created_at,
                    tmp.status,
                    COALESCE(tmp.total_count, 0),
                    COALESCE(tmp.sent_count, 0),
                    COALESCE(tmp.failed_count, 0),
                    0 as blocked_count
                FROM tmp_broadcast tmp
                ON CONFLICT DO NOTHING;
                
                DROP TABLE tmp_broadcast;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/broadcast.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_bc=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM broadcast;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "–ò—Å—Ç–æ—Ä–∏—è —Ä–∞—Å—Å—ã–ª–æ–∫ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ (–≤ –ë–î: $imported_bc)"
            else
                print_message "WARN" "–ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–º–ø–æ—Ä—Ç —Ä–∞—Å—Å—ã–ª–æ–∫"
            fi
        else
            print_message "INFO" "–ù–µ—Ç —Ä–∞—Å—Å—ã–ª–æ–∫ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞"
        fi
    fi
    
    # === 10. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ last_activity_at –≤ customer ===
    local activity_file="$import_dir/user_activity.csv"
    if [[ -f "$activity_file" ]]; then
        local activity_count=$(($(wc -l < "$activity_file") - 1))
        if [[ $activity_count -gt 0 ]]; then
            print_message "ACTION" "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ last_activity_at..."
            debug_log "MIGRATE" "Updating last_activity_at: $activity_count records"
            
            docker cp "$activity_file" "$MIGRATION_TARGET_CONTAINER:/tmp/user_activity.csv"
            
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
                BEGIN;
                CREATE TEMP TABLE tmp_activity (
                    telegram_id BIGINT,
                    last_activity TIMESTAMP
                );
                
                COPY tmp_activity FROM '/tmp/user_activity.csv' WITH CSV HEADER;
                
                -- –û–±–Ω–æ–≤–ª—è–µ–º last_activity_at
                UPDATE customer SET
                    last_activity_at = tmp.last_activity
                FROM tmp_activity tmp
                WHERE customer.telegram_id = tmp.telegram_id;
                
                DROP TABLE tmp_activity;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/user_activity.csv
            
            if [[ $result -eq 0 ]]; then
                local updated_activity=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM customer WHERE last_activity_at IS NOT NULL;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "last_activity_at –æ–±–Ω–æ–≤–ª—ë–Ω (–∑–∞–ø–∏—Å–µ–π: $updated_activity)"
            else
                print_message "WARN" "–ß–∞—Å—Ç–∏—á–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ last_activity_at"
            fi
        else
            print_message "INFO" "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"
        fi
    fi
    
    # === 11. –ò–º–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö –±–æ–Ω—É—Å–æ–≤ (referral_earnings ‚Üí referral_bonus_history) ===
    local ref_bonus_file="$import_dir/referral_bonus.csv"
    if [[ -f "$ref_bonus_file" ]]; then
        local ref_bonus_count=$(($(wc -l < "$ref_bonus_file") - 1))
        if [[ $ref_bonus_count -gt 0 ]]; then
            print_message "ACTION" "–ò–º–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö –±–æ–Ω—É—Å–æ–≤..."
            debug_log "MIGRATE" "Importing referral bonus history: $ref_bonus_count records"
            
            # P1: –ß–∏—Ç–∞–µ–º bonus_days –∏–∑ system_settings –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
            local bonus_days_value="7"  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if [[ -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
                local extracted_days=$(grep -o '"REFERRAL_BONUS_DAYS"[^,]*' "$MIGRATION_EXTRACTED_DIR/database.json" 2>/dev/null | grep -o '[0-9]\+' | head -1)
                [[ -n "$extracted_days" && "$extracted_days" =~ ^[0-9]+$ ]] && bonus_days_value="$extracted_days"
                debug_log "MIGRATE" "Referral bonus days from settings: $bonus_days_value"
            fi
            
            docker cp "$ref_bonus_file" "$MIGRATION_TARGET_CONTAINER:/tmp/referral_bonus.csv"
            
            # P1: –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º bonus_days
            # –ë–æ–Ω—É—Å—ã –≤ —Ä—É–±–ª—è—Ö (amount_kopeks > 0) –ø—Ä–æ–ø—É—Å–∫–∞–µ–º - —Ä–∞–∑–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
                BEGIN;
                CREATE TEMP TABLE tmp_ref_bonus (
                    old_id BIGINT,
                    referrer_telegram_id BIGINT,
                    referee_telegram_id BIGINT,
                    reason TEXT,
                    amount_kopeks BIGINT,
                    created_at TIMESTAMP
                );
                
                COPY tmp_ref_bonus FROM '/tmp/referral_bonus.csv' WITH CSV HEADER;
                
                -- –í—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±–æ–Ω—É—Å—ã –∑–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é (reason —Å–æ–¥–µ—Ä–∂–∏—Ç 'registration')
                INSERT INTO referral_bonus_history (referral_id, bonus_days, is_first_bonus, granted_at)
                SELECT 
                    r.id as referral_id,
                    ${bonus_days_value} as bonus_days,
                    CASE 
                        WHEN tmp.reason LIKE '%registration%' THEN true
                        ELSE false
                    END as is_first_bonus,
                    tmp.created_at as granted_at
                FROM tmp_ref_bonus tmp
                INNER JOIN referral r ON r.referrer_id = tmp.referrer_telegram_id 
                                     AND r.referee_id = tmp.referee_telegram_id
                WHERE tmp.reason LIKE '%registration%'
                ON CONFLICT DO NOTHING;
                
                DROP TABLE tmp_ref_bonus;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/referral_bonus.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_bonus=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM referral_bonus_history;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "–ò—Å—Ç–æ—Ä–∏—è —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö –±–æ–Ω—É—Å–æ–≤ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ (–≤ –ë–î: $imported_bonus)"
            else
                print_message "WARN" "–ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–º–ø–æ—Ä—Ç —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö –±–æ–Ω—É—Å–æ–≤"
            fi
        else
            print_message "INFO" "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã—Ö –±–æ–Ω—É—Å–æ–≤ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞"
        fi
    fi
    
    # 12. –ò–º–ø–æ—Ä—Ç –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ (–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –±–∞–ª–∞–Ω—Å–æ–≤)
    if [[ -f "$import_dir/partners_to_create.csv" ]]; then
        print_message "INFO" "–ò–º–ø–æ—Ä—Ç –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ (–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –±–∞–ª–∞–Ω—Å–æ–≤)..."
        local partners_count=$(($(wc -l < "$import_dir/partners_to_create.csv") - 1))
        
        if [[ $partners_count -gt 0 ]]; then
            docker cp "$import_dir/partners_to_create.csv" "$MIGRATION_TARGET_CONTAINER:/tmp/partners.csv"
            
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<'EOF'
                BEGIN;
                
                CREATE TEMP TABLE tmp_partners (
                    telegram_id BIGINT,
                    available_balance BIGINT,
                    percent INTEGER
                );
                
                \copy tmp_partners FROM '/tmp/partners.csv' WITH CSV HEADER;
                
                -- –í—Å—Ç–∞–≤–∫–∞ –Ω–æ–≤—ã—Ö –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö
                INSERT INTO partner (telegram_id, available_balance, percent)
                SELECT telegram_id, available_balance, percent
                FROM tmp_partners
                ON CONFLICT (telegram_id) DO UPDATE SET
                    available_balance = partner.available_balance + EXCLUDED.available_balance;
                
                DROP TABLE tmp_partners;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/partners.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_partners=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM partner;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "–ü–∞—Ä—Ç–Ω—ë—Ä—ã –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã: $partners_count ‚Üí –≤ –ë–î: $imported_partners"
            else
                print_message "WARN" "–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤"
            fi
        else
            print_message "INFO" "–ù–µ—Ç –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞"
        fi
    fi
    
    debug_log "MIGRATE" "Import complete"
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ ---
migrate_generate_report() {
    print_message "INFO" "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ –º–∏–≥—Ä–∞—Ü–∏–∏..."
    
    local report_file="$MIGRATION_WORK_DIR/migration_report_$(date +%Y%m%d_%H%M%S).txt"
    
    {
        echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
        echo "‚ïë         LAZARUS Migration Report                       ‚ïë"
        echo "‚ïë         Bedolaga ‚Üí RWP-Shop (Private)                  ‚ïë"
        echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
        echo ""
        echo "Date: $(date '+%Y-%m-%d %H:%M:%S')"
        echo ""
        echo "=== SOURCE (Bedolaga) ==="
        if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
            echo "Container: $MIGRATION_SOURCE_CONTAINER"
        else
            echo "Host: $MIGRATION_SOURCE_HOST:$MIGRATION_SOURCE_PORT"
        fi
        echo "Database: $MIGRATION_SOURCE_DB"
        echo ""
        echo "=== TARGET (RWP-Shop) ==="
        echo "Container: $MIGRATION_TARGET_CONTAINER"
        echo "Database: $MIGRATION_TARGET_DB"
        echo ""
        echo "=== MIGRATION STATS ==="
        
        local export_dir="$MIGRATION_WORK_DIR/export"
        local import_dir="$MIGRATION_WORK_DIR/import"
        
        if [[ -f "$export_dir/users.csv" ]]; then
            local users_count=$(($(wc -l < "$export_dir/users.csv") - 1))
            echo "Users exported: $users_count"
        fi
        
        if [[ -f "$export_dir/referrals.csv" ]]; then
            local ref_count=$(($(wc -l < "$export_dir/referrals.csv") - 1))
            echo "Referral links exported: $ref_count"
        fi
        
        if [[ -f "$export_dir/transactions.csv" ]]; then
            local tx_count=$(($(wc -l < "$export_dir/transactions.csv") - 1))
            echo "Transactions exported: $tx_count"
        fi
        
        if [[ -f "$export_dir/promocodes.csv" ]]; then
            local promo_count=$(($(wc -l < "$export_dir/promocodes.csv") - 1))
            echo "Promocodes exported: $promo_count"
        fi
        
        if [[ -f "$export_dir/promo_uses.csv" ]]; then
            local promo_uses_count=$(($(wc -l < "$export_dir/promo_uses.csv") - 1))
            echo "Promo uses exported: $promo_uses_count"
        fi
        
        if [[ -f "$export_dir/subscriptions.csv" ]]; then
            local subs_count=$(($(wc -l < "$export_dir/subscriptions.csv") - 1))
            echo "Subscriptions exported: $subs_count"
        fi
        
        if [[ -f "$export_dir/tickets.csv" ]]; then
            local tickets_count=$(($(wc -l < "$export_dir/tickets.csv") - 1))
            echo "Support tickets exported: $tickets_count"
        fi
        
        if [[ -f "$export_dir/ticket_messages.csv" ]]; then
            local msgs_count=$(($(wc -l < "$export_dir/ticket_messages.csv") - 1))
            echo "Ticket messages exported: $msgs_count"
        fi
        
        if [[ -f "$export_dir/broadcast.csv" ]]; then
            local bc_count=$(($(wc -l < "$export_dir/broadcast.csv") - 1))
            echo "Broadcasts exported: $bc_count"
        fi
        
        if [[ -f "$export_dir/user_activity.csv" ]]; then
            local act_count=$(($(wc -l < "$export_dir/user_activity.csv") - 1))
            echo "User activity records exported: $act_count"
        fi
        
        if [[ -f "$export_dir/referral_bonus.csv" ]]; then
            local ref_bonus_count=$(($(wc -l < "$export_dir/referral_bonus.csv") - 1))
            echo "Referral bonus history exported: $ref_bonus_count"
        fi
        
        echo ""
        echo "=== FILES CREATED ==="
        ls -la "$import_dir"/*.csv 2>/dev/null || echo "No import files"
        echo ""
        echo "Migration completed at: $(date '+%Y-%m-%d %H:%M:%S')"
    } > "$report_file"
    
    print_message "SUCCESS" "–û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: $report_file"
    cat "$report_file"
}

# =============================================================================
# –ú–ò–ì–†–ê–¶–ò–Ø –ù–ê–°–¢–†–û–ï–ö (Settings Migration)
# =============================================================================

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –º–∏–≥—Ä–∞—Ü–∏–∏
MIGRATION_SOURCE_ENV_FILE=""          # –ü—É—Ç—å –∫ .env Bedolaga (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
MIGRATION_SOURCE_BACKUP_FILE=""       # –ü—É—Ç—å –∫ –∞—Ä—Ö–∏–≤—É –±—ç–∫–∞–ø–∞ Bedolaga (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç!)
MIGRATION_TARGET_ENV_FILE=""          # –ü—É—Ç—å –∫ .env RWP-Shop
MIGRATION_TARGET_BOT_PATH=""          # –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ RWP-Shop –±–æ—Ç–∞

# –í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –∞—Ä—Ö–∏–≤–∞
MIGRATION_EXTRACTED_DIR=""

# === –î–ï–§–û–õ–¢–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø –ò–ó .env.example BEDOLAGA ===
declare -A BEDOLAGA_DEFAULTS=(
    # Telegram
    ["BOT_TOKEN"]=""
    ["ADMIN_ID"]=""
    # Database
    ["POSTGRES_HOST"]="db"
    ["POSTGRES_PORT"]="5432"
    ["POSTGRES_USER"]="postgres"
    ["POSTGRES_PASSWORD"]="postgres"
    ["POSTGRES_DB"]="shop_bot"
    # Redis
    ["REDIS_HOST"]="redis"
    ["REDIS_PORT"]="6379"
    # Remnawave
    ["REMNAWAVE_BASE_URL"]=""
    ["REMNAWAVE_API_KEY"]=""
    # Payment - YooKassa
    ["YOOKASSA_ENABLED"]="false"
    ["YOOKASSA_SHOP_ID"]=""
    ["YOOKASSA_SECRET_KEY"]=""
    ["YOOKASSA_RETURN_URL"]=""
    ["YOOKASSA_PAYMENT_MODE"]="redirect"
    ["YOOKASSA_PAYMENT_METHODS"]="bank_card,sbp,sberbank"
    # Payment - CryptoBot
    ["CRYPTOBOT_ENABLED"]="false"
    ["CRYPTOBOT_TOKEN"]=""
    # Payment - Telegram Stars
    ["TELEGRAM_STARS_ENABLED"]="false"
    ["STARS_EXCHANGE_RATE"]="2"
    ["STARS_REQUIRE_PAID_PURCHASE"]="false"
    # Payment - Tribute
    ["TRIBUTE_ENABLED"]="false"
    ["TRIBUTE_API_KEY"]=""
    ["TRIBUTE_PAYMENT_URL"]=""
    ["TRIBUTE_WEBHOOK_URL"]=""
    # Payment - Platega
    ["PLATEGA_ENABLED"]="false"
    ["PLATEGA_MERCHANT_ID"]=""
    ["PLATEGA_SECRET_KEY"]=""
    # Trial
    ["TRIAL_ENABLED"]="false"
    ["TRIAL_DAYS"]="1"
    ["TRIAL_TRAFFIC_LIMIT_GB"]="0"
    ["TRIAL_DEVICE_LIMIT"]="1"
    ["TRIAL_SERVER_TAG"]=""
    # Referral
    ["REFERRAL_ENABLED"]="false"
    ["REFERRAL_BONUS_DAYS"]="7"
    ["REFERRAL_REFEREE_BONUS_DAYS"]="3"
    ["REFERRAL_COMMISSION_PERCENT"]="10"
    ["REFERRAL_TIERS_ENABLED"]="false"
    ["REFERRAL_TIER_1_THRESHOLD"]="5"
    ["REFERRAL_TIER_1_BONUS"]="10"
    ["REFERRAL_TIER_2_THRESHOLD"]="15"
    ["REFERRAL_TIER_2_BONUS"]="15"
    ["REFERRAL_TIER_3_THRESHOLD"]="30"
    ["REFERRAL_TIER_3_BONUS"]="20"
    ["REFERRAL_RECURRING_ENABLED"]="false"
    ["REFERRAL_RECURRING_PERCENT"]="5"
    # Branding
    ["BRAND_PRIMARY_COLOR"]="#007AFF"
    ["BRAND_TEXT_COLOR"]="#FFFFFF"
    ["BRAND_SUCCESS_COLOR"]="#34C759"
    ["BRAND_WARNING_COLOR"]="#FF9500"
    ["BRAND_ERROR_COLOR"]="#FF3B30"
    # Effects
    ["EFFECT_SNOWFALL"]="false"
    ["EFFECT_SNOWFALL_VARIANT"]="standard"
    ["EFFECT_HALLOWEEN"]="false"
    ["EFFECT_SAKURA"]="false"
    # Menu
    ["MENU_BUTTONS_LAYOUT"]="2x2"
    ["MENU_BUTTON_CONNECT_ENABLED"]="true"
    ["MENU_BUTTON_REFERRAL_ENABLED"]="true"
    ["MENU_BUTTON_PARTNER_ENABLED"]="true"
    # URLs
    ["SERVER_STATUS_URL"]=""
    ["SERVER_STATUS_ENABLED"]="false"
    ["SUPPORT_URL"]=""
    ["FEEDBACK_URL"]=""
    ["CHANNEL_URL"]=""
    ["TOS_URL"]=""
    # MiniApp
    ["MINIAPP_ENABLED"]="false"
    ["MINIAPP_URL"]=""
    ["WEBAPP_MODE"]="fullscreen"
    # Autopay
    ["AUTOPAY_ENABLED"]="false"
    ["AUTOPAY_REMINDER_DAYS"]="3"
)

# === –î–ï–§–û–õ–¢–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø –ò–ó –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–ò RWP-SHOP ===
declare -A RWP_SHOP_DEFAULTS=(
    # === .env —Ñ–∞–π–ª ===
    ["TELEGRAM_TOKEN"]=""
    ["ADMIN_TELEGRAM_ID"]=""
    ["DATABASE_URL"]="postgres://postgres:postgres@db:5432/postgres?sslmode=disable"
    ["POSTGRES_USER"]="postgres"
    ["POSTGRES_PASSWORD"]="postgres"
    ["POSTGRES_DB"]="postgres"
    ["REMNAWAVE_URL"]=""
    ["REMNAWAVE_TOKEN"]=""
    ["REMNAWAVE_MODE"]="private"
    ["BOT_ADMIN_URL"]=""
    ["WEBHOOK_SECRET"]=""
    
    # === settings DB (–∫–ª—é—á = –∏–º—è –≤ —Ç–∞–±–ª–∏—Ü–µ settings) ===
    # Payment - YooKassa
    ["yookasa_enabled"]="false"
    ["yookasa_shop_id"]=""
    ["yookasa_secret_key"]=""
    ["yookassa_payment_mode"]="redirect"
    ["yookassa_payment_methods"]="bank_card,sbp"
    ["payment_return_url"]=""
    # Payment - CryptoPay
    ["crypto_pay_enabled"]="false"
    ["crypto_pay_token"]=""
    # Payment - Telegram Stars
    ["telegram_stars_enabled"]="false"
    ["stars_exchange_rate"]="2"
    ["require_paid_purchase_for_stars"]="false"
    # Payment - Tribute
    ["tribute_enabled"]="false"
    ["tribute_api_key"]=""
    ["tribute_payment_url"]=""
    ["tribute_webhook_url"]=""
    # Payment - Platega
    ["platega_cards_enabled"]="false"
    ["platega_sbp_enabled"]="false"
    ["platega_crypto_enabled"]="false"
    ["platega_merchant_id"]=""
    ["platega_secret"]=""
    # Payment - SeverPay
    ["severpay_cards_enabled"]="false"
    ["severpay_sbp_enabled"]="false"
    ["severpay_secret"]=""
    # Payment - Stripe
    ["stripe_enabled"]="false"
    ["stripe_secret_key"]=""
    ["stripe_webhook_secret"]=""
    # Payment - Wata
    ["wata_enabled"]="false"
    ["wata_merchant_id"]=""
    ["wata_api_key"]=""
    # Trial
    ["trial_enabled"]="false"
    ["trial_days"]="1"
    ["trial_traffic_limit"]="0"
    ["trial_device_limit"]="1"
    ["trial_remnawave_tag"]=""
    # Referral
    ["referral_enabled"]="false"
    ["referral_bonus_days"]="7"
    ["referral_referee_bonus_days"]="3"
    ["referral_recurring_enabled"]="false"
    ["referral_recurring_percent"]="5"
    ["referral_tiers_enabled"]="false"
    ["referral_tier1_threshold"]="5"
    ["referral_tier1_bonus"]="10"
    ["referral_tier2_threshold"]="15"
    ["referral_tier2_bonus"]="15"
    ["referral_tier3_threshold"]="30"
    ["referral_tier3_bonus"]="20"
    # Branding
    ["brand_primary_color"]="#007AFF"
    ["brand_text_color"]="#FFFFFF"
    ["brand_success_color"]="#34C759"
    ["brand_warning_color"]="#FF9500"
    ["brand_error_color"]="#FF3B30"
    # Effects
    ["effect_snowfall"]="false"
    ["effect_snowfall_variant"]="standard"
    ["effect_halloween"]="false"
    ["effect_sakura"]="false"
    # Menu
    ["menu_buttons_layout"]="2x2"
    ["menu_button_connect_enabled"]="true"
    ["menu_button_referral_enabled"]="true"
    ["menu_button_partner_enabled"]="true"
    # URLs
    ["server_status_url"]=""
    ["server_status_enabled"]="false"
    ["support_url"]=""
    ["feedback_url"]=""
    ["channel_url"]=""
    ["tos_url"]=""
    # MiniApp
    ["mini_app_enabled"]="false"
    ["mini_app_url"]=""
    ["web_app_mode"]="fullscreen"
    # Recurring
    ["recurring_payments_enabled"]="false"
    ["recurring_notify_days_before"]="3"
)

# === –ú–ê–ü–ü–ò–ù–ì: Bedolaga system_settings (–∏–∑ backup) ‚Üí RWP-Shop settings DB ===
# –ö–ª—é—á–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã system_settings –≤ database.json –±—ç–∫–∞–ø–∞ Bedolaga
declare -A BEDOLAGA_BACKUP_TO_RWP=(
    # Trial settings
    ["TRIAL_DURATION_DAYS"]="trial_days"
    ["TRIAL_PAYMENT_ENABLED"]="trial_enabled"
    ["TRIAL_ADD_REMAINING_DAYS_TO_PAID"]=""  # –ù–µ—Ç –≤ RWP-Shop
    ["TRIAL_TRAFFIC_LIMIT"]="trial_traffic_limit"
    ["TRIAL_DEVICE_LIMIT"]="trial_device_limit"
    
    # Pricing (–≤ –∫–æ–ø–µ–π–∫–∞—Ö –≤ Bedolaga, –Ω—É–∂–Ω–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è!)
    ["PRICE_PER_DEVICE"]=""  # –ù–µ—Ç –ø—Ä—è–º–æ–≥–æ –∞–Ω–∞–ª–æ–≥–∞ –≤ RWP-Shop (—Ü–µ–Ω—ã –≤ —Ç–∞—Ä–∏—Ñ–∞—Ö)
    ["TRAFFIC_PACKAGES_CONFIG"]=""  # –§–æ—Ä–º–∞—Ç –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è
    
    # Referral
    ["REFERRAL_BONUS_DAYS"]="referral_bonus_days"
    ["REFERRAL_REFEREE_BONUS_DAYS"]="referral_referee_bonus_days"
    ["REFERRAL_COMMISSION_PERCENT"]="referral_recurring_percent"
    
    # Autopay/Recurring
    ["AUTOPAY_ENABLED"]="recurring_payments_enabled"
    ["AUTOPAY_REMINDER_DAYS"]="recurring_notify_days_before"
    
    # Backup settings (–Ω–µ –ø–µ—Ä–µ–Ω–æ—Å—è—Ç—Å—è)
    ["BACKUP_INCLUDE_LOGS"]=""
    ["BACKUP_SEND_CHAT_ID"]=""
    ["BACKUP_SEND_ENABLED"]=""
    ["BACKUP_ARCHIVE_PASSWORD"]=""
    
    # External admin (–Ω–µ –ø–µ—Ä–µ–Ω–æ—Å—è—Ç—Å—è ‚Äî —Ä–∞–∑–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
    ["EXTERNAL_ADMIN_TOKEN"]=""
    ["EXTERNAL_ADMIN_TOKEN_BOT_ID"]=""
)

# –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞—Å—Ç—Ä–æ–µ–∫: Bedolaga .env ‚Üí RWP-Shop .env (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ)
declare -A SETTINGS_ENV_TO_ENV=(
    # Telegram
    ["BOT_TOKEN"]="TELEGRAM_TOKEN"
    ["ADMIN_ID"]="ADMIN_TELEGRAM_ID"
    # Database  
    ["DATABASE_URL"]="DATABASE_URL"
    ["POSTGRES_USER"]="POSTGRES_USER"
    ["POSTGRES_PASSWORD"]="POSTGRES_PASSWORD"
    ["POSTGRES_DB"]="POSTGRES_DB"
    # Remnawave API
    ["REMNAWAVE_BASE_URL"]="REMNAWAVE_URL"
    ["REMNAWAVE_API_KEY"]="REMNAWAVE_TOKEN"
)

# –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞—Å—Ç—Ä–æ–µ–∫: Bedolaga .env ‚Üí RWP-Shop settings DB
declare -A SETTINGS_ENV_TO_DB=(
    # === YooKassa ===
    ["YOOKASSA_ENABLED"]="yookasa_enabled"
    ["YOOKASSA_SHOP_ID"]="yookasa_shop_id"
    ["YOOKASSA_SECRET_KEY"]="yookasa_secret_key"
    ["YOOKASSA_RETURN_URL"]="payment_return_url"
    ["YOOKASSA_PAYMENT_MODE"]="yookassa_payment_mode"
    ["YOOKASSA_PAYMENT_METHODS"]="yookassa_payment_methods"
    
    # === CryptoBot ‚Üí CryptoPay ===
    ["CRYPTOBOT_ENABLED"]="crypto_pay_enabled"
    ["CRYPTOBOT_TOKEN"]="crypto_pay_token"
    
    # === Telegram Stars ===
    ["TELEGRAM_STARS_ENABLED"]="telegram_stars_enabled"
    ["STARS_EXCHANGE_RATE"]="stars_exchange_rate"
    ["STARS_REQUIRE_PAID_PURCHASE"]="require_paid_purchase_for_stars"
    
    # === Tribute ===
    ["TRIBUTE_ENABLED"]="tribute_enabled"
    ["TRIBUTE_API_KEY"]="tribute_api_key"
    ["TRIBUTE_PAYMENT_URL"]="tribute_payment_url"
    ["TRIBUTE_WEBHOOK_URL"]="tribute_webhook_url"
    
    # === Platega ===
    ["PLATEGA_ENABLED"]="platega_cards_enabled"
    ["PLATEGA_MERCHANT_ID"]="platega_merchant_id"
    ["PLATEGA_SECRET_KEY"]="platega_secret"
    
    # === Trial ===
    ["TRIAL_ENABLED"]="trial_enabled"
    ["TRIAL_DAYS"]="trial_days"
    ["TRIAL_TRAFFIC_LIMIT_GB"]="trial_traffic_limit"
    ["TRIAL_DEVICE_LIMIT"]="trial_device_limit"
    ["TRIAL_SERVER_TAG"]="trial_remnawave_tag"
    
    # === Referral ===
    ["REFERRAL_ENABLED"]="referral_enabled"
    ["REFERRAL_BONUS_DAYS"]="referral_bonus_days"
    ["REFERRAL_REFEREE_BONUS_DAYS"]="referral_referee_bonus_days"
    ["REFERRAL_COMMISSION_PERCENT"]="referral_recurring_percent"
    ["REFERRAL_TIERS_ENABLED"]="referral_tiers_enabled"
    ["REFERRAL_TIER_1_THRESHOLD"]="referral_tier1_threshold"
    ["REFERRAL_TIER_1_BONUS"]="referral_tier1_bonus"
    ["REFERRAL_TIER_2_THRESHOLD"]="referral_tier2_threshold"
    ["REFERRAL_TIER_2_BONUS"]="referral_tier2_bonus"
    ["REFERRAL_TIER_3_THRESHOLD"]="referral_tier3_threshold"
    ["REFERRAL_TIER_3_BONUS"]="referral_tier3_bonus"
    ["REFERRAL_RECURRING_ENABLED"]="referral_recurring_enabled"
    ["REFERRAL_RECURRING_PERCENT"]="referral_recurring_percent"
    
    # === UI/Branding ===
    ["BRAND_PRIMARY_COLOR"]="brand_primary_color"
    ["BRAND_TEXT_COLOR"]="brand_text_color"
    ["BRAND_SUCCESS_COLOR"]="brand_success_color"
    ["BRAND_WARNING_COLOR"]="brand_warning_color"
    ["BRAND_ERROR_COLOR"]="brand_error_color"
    ["EFFECT_SNOWFALL"]="effect_snowfall"
    ["EFFECT_SNOWFALL_VARIANT"]="effect_snowfall_variant"
    ["EFFECT_HALLOWEEN"]="effect_halloween"
    ["EFFECT_SAKURA"]="effect_sakura"
    
    # === Menu/Buttons ===
    ["MENU_BUTTONS_LAYOUT"]="menu_buttons_layout"
    ["MENU_BUTTON_CONNECT_ENABLED"]="menu_button_connect_enabled"
    ["MENU_BUTTON_REFERRAL_ENABLED"]="menu_button_referral_enabled"
    ["MENU_BUTTON_PARTNER_ENABLED"]="menu_button_partner_enabled"
    
    # === URLs ===
    ["SERVER_STATUS_URL"]="server_status_url"
    ["SERVER_STATUS_ENABLED"]="server_status_enabled"
    ["SUPPORT_URL"]="support_url"
    ["FEEDBACK_URL"]="feedback_url"
    ["CHANNEL_URL"]="channel_url"
    ["TOS_URL"]="tos_url"
    
    # === MiniApp ===
    ["MINIAPP_ENABLED"]="mini_app_enabled"
    ["MINIAPP_URL"]="mini_app_url"
    ["WEBAPP_MODE"]="web_app_mode"
    
    # === Recurring/Autopay ===
    ["AUTOPAY_ENABLED"]="recurring_payments_enabled"
    ["AUTOPAY_REMINDER_DAYS"]="recurring_notify_days_before"
)

# --- –§—É–Ω–∫—Ü–∏—è: –ß—Ç–µ–Ω–∏–µ .env —Ñ–∞–π–ª–∞ –≤ –∞—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã–π –º–∞—Å—Å–∏–≤ ---
read_env_file() {
    local env_file="$1"
    local -n result_map=$2
    
    if [[ ! -f "$env_file" ]]; then
        debug_log "MIGRATE" "ENV file not found: $env_file"
        return 1
    fi
    
    while IFS= read -r line || [[ -n "$line" ]]; do
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        [[ "$line" =~ ^[[:space:]]*# ]] && continue
        [[ -z "${line// }" ]] && continue
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º KEY=VALUE
        if [[ "$line" =~ ^([A-Za-z_][A-Za-z0-9_]*)=(.*)$ ]]; then
            local key="${BASH_REMATCH[1]}"
            local value="${BASH_REMATCH[2]}"
            
            # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            value="${value#\"}"
            value="${value%\"}"
            value="${value#\'}"
            value="${value%\'}"
            
            result_map["$key"]="$value"
        fi
    done < "$env_file"
    
    debug_log "MIGRATE" "Read ${#result_map[@]} variables from $env_file"
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ —Å –¥–µ—Ñ–æ–ª—Ç–æ–º –∏–∑ Bedolaga ---
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: get_bedolaga_value source_settings "KEY"
get_bedolaga_value() {
    local -n _source_map=$1
    local key="$2"
    local value="${_source_map[$key]:-}"
    
    # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—É—Å—Ç–æ–µ ‚Äî –±–µ—Ä—ë–º –¥–µ—Ñ–æ–ª—Ç
    if [[ -z "$value" ]]; then
        value="${BEDOLAGA_DEFAULTS[$key]:-}"
    fi
    
    echo "$value"
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ñ–æ–ª—Ç RWP-Shop ---
get_rwp_default() {
    local key="$1"
    echo "${RWP_SHOP_DEFAULTS[$key]:-}"
}

# --- –§—É–Ω–∫—Ü–∏—è: –ó–∞–ø–∏—Å—å –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –≤ .env —Ñ–∞–π–ª ---
write_env_variable() {
    local env_file="$1"
    local key="$2"
    local value="$3"
    
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –¥–ª—è sed
    local escaped_value="${value//\\/\\\\}"
    escaped_value="${escaped_value//&/\\&}"
    
    if grep -q "^${key}=" "$env_file" 2>/dev/null; then
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        sed -i "s|^${key}=.*|${key}=\"${escaped_value}\"|" "$env_file"
    else
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        echo "${key}=\"${value}\"" >> "$env_file"
    fi
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü–æ–∏—Å–∫ –∞—Ä—Ö–∏–≤–∞ –±—ç–∫–∞–ø–∞ Bedolaga ---
find_bedolaga_backup() {
    debug_log "MIGRATE" "=== find_bedolaga_backup() ==="
    local found_backup=""
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –±—ç–∫–∞–ø–∞ Bedolaga
    local backup_pattern="backup_*.tar.gz"
    
    # –°–ø–∏—Å–æ–∫ –º–µ—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞
    local search_paths=(
        # –†—è–¥–æ–º —Å RWP-Shop
        "${MIGRATION_TARGET_BOT_PATH}/backups"
        "${MIGRATION_TARGET_BOT_PATH}/../bedolaga-backups"
        "${MIGRATION_TARGET_BOT_PATH}/../bedolaga-backup"
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—É—Ç–∏ Bedolaga
        "/opt/bedolaga-bot/data/backups"
        "/opt/shop-bot/data/backups"
        "/opt/shopbot/data/backups"
        "/root/bedolaga-bot/data/backups"
        # –û–±—â–∏–µ –ø–∞–ø–∫–∏
        "/opt/backups"
        "/root/backups"
    )
    
    # –ï—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω BOT_PATH –∏–∑ LAZARUS
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
        search_paths=("${BOT_PATH}/backups" "${BOT_PATH}/../bedolaga-backups" "${search_paths[@]}")
    fi
    
    for path in "${search_paths[@]}"; do
        [[ ! -d "$path" ]] && continue
        debug_log "MIGRATE" "Searching in: $path"
        
        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π (—Å–∞–º—ã–π –Ω–æ–≤—ã–π) –±—ç–∫–∞–ø
        local latest=$(find "$path" -maxdepth 1 -name "$backup_pattern" -type f 2>/dev/null | sort -r | head -1)
        
        if [[ -n "$latest" && -f "$latest" ]]; then
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –±—ç–∫–∞–ø Bedolaga (—Å–æ–¥–µ—Ä–∂–∏—Ç database.json)
            if tar -tzf "$latest" 2>/dev/null | grep -q "^database.json$"; then
                found_backup="$latest"
                debug_log "MIGRATE" "Found Bedolaga backup: $found_backup"
                echo "$found_backup"
                return 0
            fi
        fi
    done
    
    debug_log "MIGRATE" "No Bedolaga backup found"
    return 1
}

# --- –§—É–Ω–∫—Ü–∏—è: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞ Bedolaga –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É ---
extract_bedolaga_backup() {
    local backup_file="$1"
    local password="${2:-$BEDOLAGA_BACKUP_PASSWORD}"
    
    if [[ ! -f "$backup_file" ]]; then
        print_message "ERROR" "–§–∞–π–ª –±—ç–∫–∞–ø–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: $backup_file"
        return 1
    fi
    
    # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    MIGRATION_EXTRACTED_DIR=$(mktemp -d "/tmp/lazarus_bedolaga_XXXXXX")
    TEMP_DIRS+=("$MIGRATION_EXTRACTED_DIR")
    
    debug_log "MIGRATE" "Extracting backup to: $MIGRATION_EXTRACTED_DIR"
    
    local actual_archive="$backup_file"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∞—Ä—Ö–∏–≤–∞
    local file_ext="${backup_file##*.}"
    local file_name=$(basename "$backup_file")
    
    # –ï—Å–ª–∏ —ç—Ç–æ .zip –∏–ª–∏ .tar.zip ‚Äî —ç—Ç–æ –∑–∞–ø–∞—Ä–æ–ª–µ–Ω–Ω—ã–π –≤–Ω–µ—à–Ω–∏–π –∞—Ä—Ö–∏–≤
    if [[ "$file_ext" == "zip" ]] || [[ "$file_name" == *.tar.zip ]]; then
        debug_log "MIGRATE" "Detected password-protected ZIP archive"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
        local is_aes=false
        if is_zip_aes_encrypted "$backup_file"; then
            is_aes=true
            debug_log "MIGRATE" "Archive uses AES encryption"
        fi
        
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–∞—Ä–æ–ª—å –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω
        if [[ -z "$password" ]]; then
            echo ""
            if [[ "$is_aes" == "true" ]]; then
                print_message "INFO" "–ê—Ä—Ö–∏–≤ –∑–∞—â–∏—â—ë–Ω –ø–∞—Ä–æ–ª–µ–º (AES-256)"
            else
                print_message "INFO" "–ê—Ä—Ö–∏–≤ –∑–∞—â–∏—â—ë–Ω –ø–∞—Ä–æ–ª–µ–º"
            fi
            read -ersp "–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å –¥–ª—è –∞—Ä—Ö–∏–≤–∞: " password
            echo ""
            
            if [[ -z "$password" ]]; then
                print_message "ERROR" "–ü–∞—Ä–æ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω"
                return 1
            fi
        fi
        
        # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –≤–Ω–µ—à–Ω–∏–π ZIP
        print_message "INFO" "–†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∑–∞—â–∏—â—ë–Ω–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞..."
        
        if [[ "$is_aes" == "true" ]]; then
            # AES —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º 7z
            if ! ensure_7z_installed; then
                print_message "ERROR" "–î–ª—è AES-–∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞—Ä—Ö–∏–≤–æ–≤ —Ç—Ä–µ–±—É–µ—Ç—Å—è 7z (p7zip)"
                print_message "INFO" "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: apt install p7zip-full"
                return 1
            fi
            
            local cmd_7z=$(get_7z_command)
            if ! $cmd_7z x -p"$password" -o"$MIGRATION_EXTRACTED_DIR" "$backup_file" -y &>/dev/null; then
                print_message "ERROR" "–ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã–π –∞—Ä—Ö–∏–≤"
                return 1
            fi
        else
            # ZipCrypto ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º unzip
            if ! ensure_unzip_installed; then
                print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å unzip –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"
                print_message "INFO" "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤—Ä—É—á–Ω—É—é: apt install unzip"
                return 1
            fi
            
            if ! unzip -P "$password" -q "$backup_file" -d "$MIGRATION_EXTRACTED_DIR" 2>/dev/null; then
                print_message "ERROR" "–ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã–π –∞—Ä—Ö–∏–≤"
                return 1
            fi
        fi
        
        # –ò—â–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π tar.gz –∞—Ä—Ö–∏–≤
        actual_archive=$(find "$MIGRATION_EXTRACTED_DIR" -name "*.tar.gz" -o -name "*.tar" 2>/dev/null | head -1)
        
        if [[ -z "$actual_archive" ]]; then
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç database.json —É–∂–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω –Ω–∞–ø—Ä—è–º—É—é
            if [[ -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
                debug_log "MIGRATE" "database.json found directly in ZIP"
                return 0
            fi
            print_message "ERROR" "–í–Ω—É—Ç—Ä–∏ ZIP –Ω–µ –Ω–∞–π–¥–µ–Ω tar.gz –∞—Ä—Ö–∏–≤"
            return 1
        fi
        
        debug_log "MIGRATE" "Found inner archive: $actual_archive"
        
        # –°–æ–∑–¥–∞—ë–º –ø–æ–¥–ø–∞–ø–∫—É –¥–ª—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –∞—Ä—Ö–∏–≤–∞
        local inner_dir="$MIGRATION_EXTRACTED_DIR/extracted"
        mkdir -p "$inner_dir"
        
        # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∞—Ä—Ö–∏–≤
        if [[ "$actual_archive" == *.tar.gz ]]; then
            if ! tar -xzf "$actual_archive" -C "$inner_dir" 2>/dev/null; then
                print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π tar.gz"
                return 1
            fi
        else
            if ! tar -xf "$actual_archive" -C "$inner_dir" 2>/dev/null; then
                print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π tar"
                return 1
            fi
        fi
        
        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ –æ—Å–Ω–æ–≤–Ω—É—é –ø–∞–ø–∫—É
        # database.json –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ—Ä–Ω–µ –∏–ª–∏ –≤ –ø–æ–¥–ø–∞–ø–∫–µ
        local db_json=$(find "$inner_dir" -name "database.json" -type f 2>/dev/null | head -1)
        if [[ -n "$db_json" ]]; then
            local db_dir=$(dirname "$db_json")
            # –ö–æ–ø–∏—Ä—É–µ–º –≤—Å—ë –∏–∑ –ø–∞–ø–∫–∏ —Å database.json
            cp -r "$db_dir"/* "$MIGRATION_EXTRACTED_DIR/" 2>/dev/null || true
        fi
        
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã
        rm -rf "$MIGRATION_EXTRACTED_DIR/extracted"
        rm -f "$actual_archive"
        
    # –û–±—ã—á–Ω—ã–π tar.gz
    elif [[ "$file_ext" == "gz" ]] || [[ "$file_name" == *.tar.gz ]]; then
        if ! tar -xzf "$backup_file" -C "$MIGRATION_EXTRACTED_DIR" 2>/dev/null; then
            print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –∞—Ä—Ö–∏–≤"
            return 1
        fi
        
    # –û–±—ã—á–Ω—ã–π tar
    elif [[ "$file_ext" == "tar" ]]; then
        if ! tar -xf "$backup_file" -C "$MIGRATION_EXTRACTED_DIR" 2>/dev/null; then
            print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –∞—Ä—Ö–∏–≤"
            return 1
        fi
    else
        print_message "ERROR" "–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∞—Ä—Ö–∏–≤–∞: $file_ext"
        return 1
    fi
    
    # database.json –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –ø–æ–¥–ø–∞–ø–∫–µ ‚Äî –∏—â–µ–º –∏ –ø–µ—Ä–µ–º–µ—â–∞–µ–º –≤ –∫–æ—Ä–µ–Ω—å
    if [[ ! -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
        local found_json=$(find "$MIGRATION_EXTRACTED_DIR" -name "database.json" -type f 2>/dev/null | head -1)
        if [[ -n "$found_json" ]]; then
            local found_dir=$(dirname "$found_json")
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ –∫–æ—Ä–µ–Ω—å
            mv "$found_dir"/* "$MIGRATION_EXTRACTED_DIR/" 2>/dev/null || true
        fi
    fi
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
    if [[ ! -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
        print_message "ERROR" "–ê—Ä—Ö–∏–≤ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç database.json ‚Äî —ç—Ç–æ –Ω–µ –±—ç–∫–∞–ø Bedolaga"
        return 1
    fi
    
    debug_log "MIGRATE" "Backup extracted successfully"
    print_message "SUCCESS" "–ê—Ä—Ö–∏–≤ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω"
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –ß—Ç–µ–Ω–∏–µ system_settings –∏–∑ database.json Bedolaga ---
# –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –∫–ª—é—á—É –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
read_bedolaga_setting() {
    local key="$1"
    local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
    
    if [[ ! -f "$db_json" ]]; then
        return 1
    fi
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º grep + sed –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON (–±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç jq)
    # –ò—â–µ–º –≤ –º–∞—Å—Å–∏–≤–µ system_settings –æ–±—ä–µ–∫—Ç —Å –Ω—É–∂–Ω—ã–º key
    local value=$(grep -A1 "\"key\": \"$key\"" "$db_json" 2>/dev/null | grep '"value"' | head -1 | sed 's/.*"value": *"\([^"]*\)".*/\1/')
    
    echo "$value"
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ system_settings –∏–∑ –±—ç–∫–∞–ø–∞ Bedolaga ---
read_all_bedolaga_settings() {
    local -n result_map=$1
    local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
    
    if [[ ! -f "$db_json" ]]; then
        return 1
    fi
    
    # –ü–∞—Ä—Å–∏–º system_settings –±–µ–∑ jq
    # –§–æ—Ä–º–∞—Ç: {"id": N, "key": "KEY", "value": "VALUE", ...}
    local in_settings=false
    local current_key=""
    local current_value=""
    
    while IFS= read -r line; do
        # –ù–∞—á–∞–ª–æ —Å–µ–∫—Ü–∏–∏ system_settings
        if [[ "$line" =~ \"system_settings\" ]]; then
            in_settings=true
            continue
        fi
        
        # –ö–æ–Ω–µ—Ü –º–∞—Å—Å–∏–≤–∞ (–¥—Ä—É–≥–∞—è —Ç–∞–±–ª–∏—Ü–∞)
        if $in_settings && [[ "$line" =~ ^[[:space:]]*\],?$ ]]; then
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–∞—Ä—É
            if [[ -n "$current_key" && -n "$current_value" ]]; then
                result_map["$current_key"]="$current_value"
            fi
            break
        fi
        
        if $in_settings; then
            # –ò–∑–≤–ª–µ–∫–∞–µ–º key
            if [[ "$line" =~ \"key\":\ *\"([^\"]+)\" ]]; then
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –ø–∞—Ä—É –µ—Å–ª–∏ –µ—Å—Ç—å
                if [[ -n "$current_key" && -n "$current_value" ]]; then
                    result_map["$current_key"]="$current_value"
                fi
                current_key="${BASH_REMATCH[1]}"
                current_value=""
            fi
            # –ò–∑–≤–ª–µ–∫–∞–µ–º value
            if [[ "$line" =~ \"value\":\ *\"([^\"]+)\" ]]; then
                current_value="${BASH_REMATCH[1]}"
            fi
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: value –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞ —Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–µ —á—Ç–æ –∏ key
            if [[ "$line" =~ \"value\":\ *\"([^\"]+)\".*\"key\":\ *\"([^\"]+)\" ]]; then
                current_value="${BASH_REMATCH[1]}"
                current_key="${BASH_REMATCH[2]}"
            fi
        fi
    done < "$db_json"
    
    debug_log "MIGRATE" "Read ${#result_map[@]} settings from Bedolaga backup"
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—ç–∫–∞–ø–µ Bedolaga ---
get_bedolaga_backup_info() {
    local backup_file="$1"
    
    if [[ ! -f "$backup_file" ]]; then
        return 1
    fi
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º metadata.json –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    local metadata=$(tar -xzf "$backup_file" -O metadata.json 2>/dev/null)
    
    if [[ -z "$metadata" ]]; then
        echo "–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"
        return 1
    fi
    
    # –ü–∞—Ä—Å–∏–º –±–µ–∑ jq
    local timestamp=$(echo "$metadata" | grep -o '"timestamp": *"[^"]*"' | head -1 | sed 's/.*"\([^"]*\)".*/\1/')
    local tables=$(echo "$metadata" | grep -o '"tables_count": *[0-9]*' | head -1 | sed 's/.*: *//')
    local records=$(echo "$metadata" | grep -o '"total_records": *[0-9]*' | head -1 | sed 's/.*: *//')
    local backup_type=$(echo "$metadata" | grep -o '"backup_type": *"[^"]*"' | head -1 | sed 's/.*"\([^"]*\)".*/\1/')
    
    echo "–î–∞—Ç–∞: ${timestamp:-–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ}"
    echo "–¢–∏–ø: ${backup_type:-–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ}"
    echo "–¢–∞–±–ª–∏—Ü: ${tables:-?}, –∑–∞–ø–∏—Å–µ–π: ${records:-?}"
}

# --- –§—É–Ω–∫—Ü–∏—è: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ .env —Ñ–∞–π–ª–∞ Bedolaga ---
find_bedolaga_env() {
    debug_log "MIGRATE" "=== find_bedolaga_env() ==="
    local found_env=""
    
    # –ú–µ—Ç–æ–¥ 1: –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—É—â–µ–Ω–Ω—ã–º Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º
    # Bedolaga –æ–±—ã—á–Ω–æ –∏–º–µ–µ—Ç –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã: bedolaga-bot, bedolaga-db –∏–ª–∏ shop-bot, shop-bot-db
    debug_log "MIGRATE" "Method 1: Searching by running Docker containers..."
    
    local bedolaga_keywords=("bedolaga" "shop-bot" "shopbot")
    local running_containers=$(docker ps --format '{{.Names}}|{{.Image}}' 2>/dev/null)
    
    for container in $running_containers; do
        local name="${container%%|*}"
        local image="${container##*|}"
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã RWP-Shop –∏ –ø–∞–Ω–µ–ª–∏
        [[ "$name" =~ rwp_shop|telegram-shop|remnawave ]] && continue
        [[ "$image" =~ rwp_shop|remnawave ]] && continue
        
        # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã Bedolaga
        for keyword in "${bedolaga_keywords[@]}"; do
            if [[ "${name,,}" =~ $keyword || "${image,,}" =~ $keyword ]]; then
                debug_log "MIGRATE" "Found Bedolaga container: $name"
                
                # –ü–æ–ª—É—á–∞–µ–º working_dir –∏–∑ docker inspect
                local working_dir=$(docker inspect -f '{{ index .Config.Labels "com.docker.compose.project.working_dir" }}' "$name" 2>/dev/null)
                
                if [[ -n "$working_dir" && -f "$working_dir/.env" ]]; then
                    found_env="$working_dir/.env"
                    debug_log "MIGRATE" "Found .env via container label: $found_env"
                    echo "$found_env"
                    return 0
                fi
            fi
        done
    done
    
    # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ docker-compose —Ñ–∞–π–ª–æ–≤ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ Bedolaga
    debug_log "MIGRATE" "Method 2: Searching by docker-compose files..."
    
    local search_paths=("/opt" "/root" "/home")
    for base_path in "${search_paths[@]}"; do
        [[ ! -d "$base_path" ]] && continue
        
        while IFS= read -r compose_file; do
            [[ -z "$compose_file" ]] && continue
            local dir=$(dirname "$compose_file")
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ RWP-Shop
            [[ "$dir" =~ private-remnawave|rwp-shop|telegram-shop ]] && continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ compose —Ñ–∞–π–ª–∞ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ Bedolaga
            if grep -qiE "bedolaga|shop.?bot" "$compose_file" 2>/dev/null; then
                if [[ -f "$dir/.env" ]]; then
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –≤ .env –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ Bedolaga
                    if grep -qE "^(BOT_TOKEN|TELEGRAM_BOT_TOKEN)=" "$dir/.env" 2>/dev/null; then
                        found_env="$dir/.env"
                        debug_log "MIGRATE" "Found .env via compose content: $found_env"
                        echo "$found_env"
                        return 0
                    fi
                fi
            fi
        done < <(find "$base_path" -maxdepth 3 -type f \( -name "docker-compose.yml" -o -name "docker-compose.yaml" -o -name "compose.yaml" \) 2>/dev/null)
    done
    
    # –ú–µ—Ç–æ–¥ 3: –ü–æ–∏—Å–∫ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –ø—É—Ç—è–º —É—Å—Ç–∞–Ω–æ–≤–∫–∏ Bedolaga
    debug_log "MIGRATE" "Method 3: Searching by standard paths..."
    
    local standard_paths=(
        "/opt/bedolaga-bot"
        "/opt/bedolaga"
        "/opt/shop-bot"
        "/opt/shopbot"
        "/opt/telegram-shop-bot"
        "/root/bedolaga-bot"
        "/root/shop-bot"
        "/home/*/bedolaga-bot"
        "/home/*/shop-bot"
    )
    
    for path_pattern in "${standard_paths[@]}"; do
        # –†–∞—Å–∫—Ä—ã–≤–∞–µ–º glob-–ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for path in $path_pattern; do
            if [[ -d "$path" && -f "$path/.env" ]]; then
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –ù–ï RWP-Shop
                if ! grep -q "REMNAWAVE_MODE=" "$path/.env" 2>/dev/null; then
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ Bedolaga
                    if grep -qE "^(BOT_TOKEN|TELEGRAM_BOT_TOKEN|ADMIN_IDS)=" "$path/.env" 2>/dev/null; then
                        found_env="$path/.env"
                        debug_log "MIGRATE" "Found .env via standard path: $found_env"
                        echo "$found_env"
                        return 0
                    fi
                fi
            fi
        done
    done
    
    # –ú–µ—Ç–æ–¥ 4: –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ .env —Ñ–∞–π–ª–æ–≤ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
    debug_log "MIGRATE" "Method 4: Global search for .env files..."
    
    while IFS= read -r env_file; do
        [[ -z "$env_file" ]] && continue
        local dir=$(dirname "$env_file")
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ RWP-Shop
        [[ "$dir" =~ private-remnawave|rwp-shop|rwp_shop|lazarus ]] && continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ Bedolaga (ADMIN_IDS –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –≤ Bedolaga)
        if grep -qE "^ADMIN_IDS=" "$env_file" 2>/dev/null; then
            found_env="$env_file"
            debug_log "MIGRATE" "Found .env via global search (ADMIN_IDS): $found_env"
            echo "$found_env"
            return 0
        fi
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –Ω–∞–ª–∏—á–∏–µ REDIS_HOST (Bedolaga –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Redis, RWP-Shop ‚Äî –Ω–µ—Ç)
        if grep -qE "^REDIS_HOST=" "$env_file" 2>/dev/null && grep -qE "^BOT_TOKEN=" "$env_file" 2>/dev/null; then
            found_env="$env_file"
            debug_log "MIGRATE" "Found .env via global search (REDIS): $found_env"
            echo "$found_env"
            return 0
        fi
    done < <(find /opt /root /home -maxdepth 4 -name ".env" -type f 2>/dev/null)
    
    debug_log "MIGRATE" "No Bedolaga .env found"
    return 1
}

# --- –§—É–Ω–∫—Ü–∏—è: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ .env —Ñ–∞–π–ª–∞ RWP-Shop ---
find_rwp_shop_env() {
    debug_log "MIGRATE" "=== find_rwp_shop_env() ==="
    local found_path=""
    
    # –ú–µ—Ç–æ–¥ 1: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π BOT_PATH –∏–∑ LAZARUS
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" && -f "$BOT_PATH/.env" ]]; then
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ RWP-Shop (–µ—Å—Ç—å REMNAWAVE_MODE –∏–ª–∏ REMNAWAVE_URL)
        if grep -qE "^(REMNAWAVE_MODE|REMNAWAVE_URL)=" "$BOT_PATH/.env" 2>/dev/null; then
            debug_log "MIGRATE" "Using configured BOT_PATH: $BOT_PATH"
            echo "$BOT_PATH"
            return 0
        fi
    fi
    
    # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—É—â–µ–Ω–Ω—ã–º Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º RWP-Shop
    debug_log "MIGRATE" "Method 2: Searching by running Docker containers..."
    
    local rwp_keywords=("rwp_shop" "telegram-shop" "remnawave-telegram-shop")
    local running_containers=$(docker ps --format '{{.Names}}|{{.Image}}' 2>/dev/null)
    
    for container in $running_containers; do
        local name="${container%%|*}"
        local image="${container##*|}"
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ –ë–î –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
        [[ "$name" =~ remnawave-backend|remnawave-subscription|_db$ ]] && continue
        [[ "$image" =~ remnawave/backend|postgres ]] && continue
        
        # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã RWP-Shop
        for keyword in "${rwp_keywords[@]}"; do
            if [[ "${name,,}" =~ $keyword || "${image,,}" =~ $keyword ]]; then
                debug_log "MIGRATE" "Found RWP-Shop container: $name"
                
                # –ü–æ–ª—É—á–∞–µ–º working_dir –∏–∑ docker inspect
                local working_dir=$(docker inspect -f '{{ index .Config.Labels "com.docker.compose.project.working_dir" }}' "$name" 2>/dev/null)
                
                if [[ -n "$working_dir" && -d "$working_dir" ]]; then
                    found_path="$working_dir"
                    debug_log "MIGRATE" "Found path via container label: $found_path"
                    echo "$found_path"
                    return 0
                fi
            fi
        done
    done
    
    # –ú–µ—Ç–æ–¥ 3: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—É—Ç–∏ RWP-Shop
    debug_log "MIGRATE" "Method 3: Searching by standard paths..."
    
    local standard_paths=(
        "/opt/private-remnawave-telegram-shop-bot"
        "/opt/rwp-shop"
        "/opt/rwp_shop"
        "/opt/telegram-shop"
        "/opt/remnawave-telegram-shop-bot"
        "/root/private-remnawave-telegram-shop-bot"
        "/root/rwp-shop"
    )
    
    for path in "${standard_paths[@]}"; do
        if [[ -d "$path" ]]; then
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ compose —Ñ–∞–π–ª–∞
            if [[ -f "$path/compose.yaml" || -f "$path/docker-compose.yml" ]]; then
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º .env –Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ RWP-Shop
                if [[ -f "$path/.env" ]]; then
                    if grep -qE "^(REMNAWAVE_MODE|REMNAWAVE_URL|REMNAWAVE_TOKEN)=" "$path/.env" 2>/dev/null; then
                        found_path="$path"
                        debug_log "MIGRATE" "Found path via standard path: $found_path"
                        echo "$found_path"
                        return 0
                    fi
                else
                    # –ï—Å—Ç—å –ø–∞–ø–∫–∞, –Ω–æ –Ω–µ—Ç .env ‚Äî —ç—Ç–æ —Ç–æ–∂–µ –ø–æ–¥—Ö–æ–¥–∏—Ç (—Å–æ–∑–¥–∞–¥–∏–º)
                    found_path="$path"
                    debug_log "MIGRATE" "Found path (no .env yet): $found_path"
                    echo "$found_path"
                    return 0
                fi
            fi
        fi
    done
    
    # –ú–µ—Ç–æ–¥ 4: –ü–æ–∏—Å–∫ –ø–æ docker-compose —Ñ–∞–π–ª–∞–º —Å –æ–±—Ä–∞–∑–∞–º–∏ RWP-Shop
    debug_log "MIGRATE" "Method 4: Searching by compose files..."
    
    local search_paths=("/opt" "/root")
    for base_path in "${search_paths[@]}"; do
        [[ ! -d "$base_path" ]] && continue
        
        while IFS= read -r compose_file; do
            [[ -z "$compose_file" ]] && continue
            local dir=$(dirname "$compose_file")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–∞ –æ–±—Ä–∞–∑—ã RWP-Shop
            if grep -qE "image:.*rwp_shop|image:.*telegram-shop" "$compose_file" 2>/dev/null; then
                found_path="$dir"
                debug_log "MIGRATE" "Found path via compose image: $found_path"
                echo "$found_path"
                return 0
            fi
        done < <(find "$base_path" -maxdepth 3 -type f \( -name "docker-compose.yml" -o -name "docker-compose.yaml" -o -name "compose.yaml" \) 2>/dev/null)
    done
    
    debug_log "MIGRATE" "No RWP-Shop path found"
    return 1
}

# --- –§—É–Ω–∫—Ü–∏—è: –£–∫–∞–∑–∞—Ç—å .env Bedolaga (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ---
migrate_settings_configure_env_source() {
    clear_screen
    echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –£–ö–ê–ó–ê–¢–¨ .ENV BEDOLAGA (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û) ‚ïê‚ïê‚ïê${RESET}"
    echo ""
    echo -e "${GRAY}–§–∞–π–ª .env Bedolaga —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–∫–µ–Ω—ã –∏ –ø–∞—Ä–æ–ª–∏ (BOT_TOKEN, DB credentials).${RESET}"
    echo -e "${GRAY}–≠—Ç–∏ –¥–∞–Ω–Ω—ã–µ –ù–ï —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –±—ç–∫–∞–ø-–∞—Ä—Ö–∏–≤–µ –ø–æ —Å–æ–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.${RESET}"
    echo ""
    
    # –ê–≤—Ç–æ–ø–æ–∏—Å–∫
    print_message "INFO" "–ü–æ–∏—Å–∫ .env —Ñ–∞–π–ª–∞ Bedolaga..."
    
    local found_env=$(find_bedolaga_env)
    
    if [[ -n "$found_env" && -f "$found_env" ]]; then
        local vars_count=$(grep -c "^[A-Z].*=" "$found_env" 2>/dev/null || echo "0")
        echo -e "‚úÖ –ù–∞–π–¥–µ–Ω: ${GREEN}$found_env${RESET} ($vars_count –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö)"
        echo ""
        read -erp "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ? (Y/n): " use_env
        if [[ ! "$use_env" =~ ^[Nn]$ ]]; then
            MIGRATION_SOURCE_ENV_FILE="$found_env"
            print_message "SUCCESS" "–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: $MIGRATION_SOURCE_ENV_FILE"
            read -erp "Enter..." dummy
            return 0
        fi
    else
        echo -e "${YELLOW}‚ö†Ô∏è  –ê–≤—Ç–æ–ø–æ–∏—Å–∫ –Ω–µ –Ω–∞—à—ë–ª .env —Ñ–∞–π–ª Bedolaga${RESET}"
    fi
    
    echo ""
    echo "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—É—Ç–∏:"
    echo "  ‚Ä¢ /opt/bedolaga/.env"
    echo "  ‚Ä¢ /opt/vpn-bot/.env"
    echo "  ‚Ä¢ /root/bedolaga/.env"
    echo ""
    read -erp "–ü—É—Ç—å –∫ .env (–∏–ª–∏ Enter –¥–ª—è –æ—á–∏—Å—Ç–∫–∏): " manual_env
    
    if [[ -n "$manual_env" ]]; then
        if [[ -f "$manual_env" ]]; then
            MIGRATION_SOURCE_ENV_FILE="$manual_env"
            print_message "SUCCESS" "–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: $MIGRATION_SOURCE_ENV_FILE"
        else
            print_message "ERROR" "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: $manual_env"
        fi
    else
        MIGRATION_SOURCE_ENV_FILE=""
        print_message "INFO" "–ü—É—Ç—å –∫ .env –æ—á–∏—â–µ–Ω"
    fi
    
    read -erp "Enter..." dummy
}

# --- –§—É–Ω–∫—Ü–∏—è: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ (LEGACY) ---
migrate_settings_configure_paths() {
    clear_screen
    echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –ù–ê–°–¢–†–û–ô–ö–ê –ü–£–¢–ï–ô –î–õ–Ø –ú–ò–ì–†–ê–¶–ò–ò –ù–ê–°–¢–†–û–ï–ö ‚ïê‚ïê‚ïê${RESET}"
    echo ""
    
    print_message "INFO" "–ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–ø–æ–∏—Å–∫–∞..."
    echo ""
    
    # === –°–ù–ê–ß–ê–õ–ê –ò–©–ï–ú –ü–†–ò–Å–ú–ù–ò–ö (RWP-Shop) - –æ–Ω –Ω—É–∂–µ–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –±—ç–∫–∞–ø–∞ ===
    echo -e "${YELLOW}=== –ü–†–ò–Å–ú–ù–ò–ö (RWP-Shop) ===${RESET}"
    
    local found_rwp=$(find_rwp_shop_env)
    
    if [[ -n "$found_rwp" && -d "$found_rwp" ]]; then
        echo -e "‚úÖ –ù–∞–π–¥–µ–Ω–∞ –ø–∞–ø–∫–∞: ${GREEN}$found_rwp${RESET}"
        
        if [[ -f "$found_rwp/.env" ]]; then
            local vars_count=$(grep -c "^[A-Z].*=" "$found_rwp/.env" 2>/dev/null || echo "0")
            echo -e "   .env —Ñ–∞–π–ª: ${GREEN}–µ—Å—Ç—å${RESET} ($vars_count –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö)"
        else
            echo -e "   .env —Ñ–∞–π–ª: ${YELLOW}–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç${RESET} (–±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω)"
        fi
        
        read -erp "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ—ë? (Y/n): " use_found
        if [[ ! "$use_found" =~ ^[Nn]$ ]]; then
            MIGRATION_TARGET_BOT_PATH="$found_rwp"
            MIGRATION_TARGET_ENV_FILE="$found_rwp/.env"
        fi
    else
        echo -e "${YELLOW}‚ö†Ô∏è  –ê–≤—Ç–æ–ø–æ–∏—Å–∫ –Ω–µ –Ω–∞—à—ë–ª –ø–∞–ø–∫—É RWP-Shop${RESET}"
    fi
    
    if [[ -z "$MIGRATION_TARGET_BOT_PATH" ]]; then
        echo ""
        echo "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—É—Ç–∏:"
        echo "  ‚Ä¢ /opt/private-remnawave-telegram-shop-bot"
        echo "  ‚Ä¢ /opt/rwp-shop"
        echo ""
        read -erp "–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ RWP-Shop –±–æ—Ç–∞: " MIGRATION_TARGET_BOT_PATH
        MIGRATION_TARGET_ENV_FILE="$MIGRATION_TARGET_BOT_PATH/.env"
    fi
    
    if [[ ! -d "$MIGRATION_TARGET_BOT_PATH" ]]; then
        print_message "ERROR" "–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: $MIGRATION_TARGET_BOT_PATH"
        read -erp "Enter..." dummy
        return 1
    fi
    
    echo ""
    
    # === –ò–°–¢–û–ß–ù–ò–ö: –ê—Ä—Ö–∏–≤ –±—ç–∫–∞–ø–∞ Bedolaga (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç!) ===
    echo -e "${YELLOW}=== –ò–°–¢–û–ß–ù–ò–ö (–ê—Ä—Ö–∏–≤ –±—ç–∫–∞–ø–∞ Bedolaga) ===${RESET}"
    echo -e "${GRAY}–ê—Ä—Ö–∏–≤ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏ Bedolaga${RESET}"
    echo ""
    
    local found_backup=$(find_bedolaga_backup)
    
    if [[ -n "$found_backup" && -f "$found_backup" ]]; then
        echo -e "‚úÖ –ù–∞–π–¥–µ–Ω –∞—Ä—Ö–∏–≤: ${GREEN}$found_backup${RESET}"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—ç–∫–∞–ø–µ
        local backup_info=$(get_bedolaga_backup_info "$found_backup")
        echo -e "   ${GRAY}$backup_info${RESET}" | head -3
        
        read -erp "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ? (Y/n): " use_backup
        if [[ ! "$use_backup" =~ ^[Nn]$ ]]; then
            MIGRATION_SOURCE_BACKUP_FILE="$found_backup"
        fi
    else
        echo -e "${YELLOW}‚ö†Ô∏è  –ê—Ä—Ö–∏–≤ –±—ç–∫–∞–ø–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏${RESET}"
    fi
    
    if [[ -z "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        echo ""
        echo "–ì–¥–µ –∏—Å–∫–∞—Ç—å –∞—Ä—Ö–∏–≤ backup_*.tar.gz:"
        echo "  ‚Ä¢ –í –ø–∞–ø–∫–µ –±–æ—Ç–∞ Bedolaga: /opt/bedolaga-bot/data/backups/"
        echo "  ‚Ä¢ –í –ø–∞–ø–∫–µ —Ä—è–¥–æ–º —Å RWP-Shop"
        echo "  ‚Ä¢ –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∏–∑ Telegram (–µ—Å–ª–∏ –±–æ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è–ª –±—ç–∫–∞–ø—ã)"
        echo ""
        read -erp "–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –∞—Ä—Ö–∏–≤—É –±—ç–∫–∞–ø–∞ (–∏–ª–∏ Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): " manual_backup
        
        if [[ -n "$manual_backup" && -f "$manual_backup" ]]; then
            MIGRATION_SOURCE_BACKUP_FILE="$manual_backup"
        fi
    fi
    
    # === –û–ü–¶–ò–û–ù–ê–õ–¨–ù–û: .env —Ñ–∞–π–ª Bedolaga (–¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫) ===
    echo ""
    echo -e "${YELLOW}=== –û–ü–¶–ò–û–ù–ê–õ–¨–ù–û: .env —Ñ–∞–π–ª Bedolaga ===${RESET}"
    echo -e "${GRAY}–°–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–∫–µ–Ω—ã –∏ –ø–∞—Ä–æ–ª–∏ (BOT_TOKEN, DB credentials)${RESET}"
    echo ""
    
    local found_env=$(find_bedolaga_env)
    
    if [[ -n "$found_env" && -f "$found_env" ]]; then
        echo -e "‚úÖ –ù–∞–π–¥–µ–Ω .env: ${GREEN}$found_env${RESET}"
        
        read -erp "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ? (Y/n): " use_env
        if [[ ! "$use_env" =~ ^[Nn]$ ]]; then
            MIGRATION_SOURCE_ENV_FILE="$found_env"
        fi
    else
        echo -e "${YELLOW}‚ö†Ô∏è  .env —Ñ–∞–π–ª Bedolaga –Ω–µ –Ω–∞–π–¥–µ–Ω${RESET}"
        echo "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (—Ç–æ–∫–µ–Ω—ã) –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –≤–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é"
    fi
    
    if [[ -z "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        read -erp "–ü—É—Ç—å –∫ .env Bedolaga (–∏–ª–∏ Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): " manual_env
        if [[ -n "$manual_env" && -f "$manual_env" ]]; then
            MIGRATION_SOURCE_ENV_FILE="$manual_env"
        fi
    fi
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫ —É–∫–∞–∑–∞–Ω
    if [[ -z "$MIGRATION_SOURCE_BACKUP_FILE" && -z "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        print_message "ERROR" "–ù–µ —É–∫–∞–∑–∞–Ω –Ω–∏ –∞—Ä—Ö–∏–≤ –±—ç–∫–∞–ø–∞, –Ω–∏ .env —Ñ–∞–π–ª Bedolaga"
        read -erp "Enter..." dummy
        return 1
    fi
    
    # === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ .env –ø—Ä–∏—ë–º–Ω–∏–∫–∞ ===
    if [[ ! -f "$MIGRATION_TARGET_ENV_FILE" ]]; then
        print_message "WARN" "–§–∞–π–ª .env –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ $MIGRATION_TARGET_BOT_PATH"
        read -erp "–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π .env —Ñ–∞–π–ª? (y/N): " create_new
        if [[ "$create_new" =~ ^[Yy]$ ]]; then
            touch "$MIGRATION_TARGET_ENV_FILE"
            chmod 600 "$MIGRATION_TARGET_ENV_FILE"
            print_message "SUCCESS" "–°–æ–∑–¥–∞–Ω: $MIGRATION_TARGET_ENV_FILE"
        else
            return 1
        fi
    fi
    
    # === –ê–≤—Ç–æ–ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –ë–î RWP-Shop ===
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        echo ""
        echo -e "${YELLOW}=== –ö–û–ù–¢–ï–ô–ù–ï–† –ë–î RWP-Shop ===${RESET}"
        
        local detected_db=""
        for pattern in "rwp_shop_db" "telegram-shop-db" "telegram-shop_db"; do
            detected_db=$(docker ps --format '{{.Names}}' 2>/dev/null | grep -iE "^${pattern}$" | head -1)
            [[ -n "$detected_db" ]] && break
        done
        
        if [[ -n "$detected_db" ]]; then
            echo -e "‚úÖ –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä: ${GREEN}$detected_db${RESET}"
            read -erp "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ? (Y/n): " use_db
            if [[ ! "$use_db" =~ ^[Nn]$ ]]; then
                MIGRATION_TARGET_CONTAINER="$detected_db"
                MIGRATION_TARGET_DB="${MIGRATION_TARGET_DB:-postgres}"
                MIGRATION_TARGET_USER="${MIGRATION_TARGET_USER:-postgres}"
            fi
        else
            echo -e "${YELLOW}‚ö†Ô∏è  –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–î –Ω–µ –Ω–∞–π–¥–µ–Ω${RESET}"
        fi
    fi
    
    # === –ò–¢–û–ì–û–í–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===
    echo ""
    print_message "SUCCESS" "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞"
    echo ""
    echo -e "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê"
    echo -e "‚îÇ ${BOLD}–ò–¢–û–ì–û–í–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø${RESET}                                  ‚îÇ"
    echo -e "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§"
    if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        echo -e "‚îÇ –ê—Ä—Ö–∏–≤:  ${GREEN}$(basename "$MIGRATION_SOURCE_BACKUP_FILE")${RESET}"
    else
        echo -e "‚îÇ –ê—Ä—Ö–∏–≤:  ${YELLOW}–ù–µ —É–∫–∞–∑–∞–Ω${RESET}"
    fi
    if [[ -n "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        echo -e "‚îÇ .env:   ${GREEN}$MIGRATION_SOURCE_ENV_FILE${RESET}"
    else
        echo -e "‚îÇ .env:   ${YELLOW}–ù–µ —É–∫–∞–∑–∞–Ω${RESET}"
    fi
    echo -e "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§"
    echo -e "‚îÇ –ü—Ä–∏—ë–º–Ω–∏–∫ .env: ${GREEN}$MIGRATION_TARGET_ENV_FILE${RESET}"
    if [[ -n "$MIGRATION_TARGET_CONTAINER" ]]; then
        echo -e "‚îÇ –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–î:  ${GREEN}$MIGRATION_TARGET_CONTAINER${RESET}"
    else
        echo -e "‚îÇ –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–î:  ${YELLOW}–ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω${RESET}"
    fi
    echo -e "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
    
    read -erp "Enter..." dummy
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ ---
migrate_settings_analyze() {
    debug_log "MIGRATE" "Analyzing settings for migration"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    if [[ -z "$MIGRATION_SOURCE_ENV_FILE" && -z "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        print_message "ERROR" "–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–Ω–∏ .env, –Ω–∏ –∞—Ä—Ö–∏–≤)"
        return 1
    fi
    
    # –ß–∏—Ç–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    declare -A source_settings
    declare -A backup_settings
    local source_desc=""
    
    # 1) –ò–∑ .env —Ñ–∞–π–ª–∞ Bedolaga
    if [[ -n "$MIGRATION_SOURCE_ENV_FILE" && -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        read_env_file "$MIGRATION_SOURCE_ENV_FILE" source_settings
        source_desc=".env: $MIGRATION_SOURCE_ENV_FILE"
    fi
    
    # 2) –ò–∑ –∞—Ä—Ö–∏–≤–∞ –±—ç–∫–∞–ø–∞ (system_settings)
    if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        if extract_bedolaga_backup "$MIGRATION_SOURCE_BACKUP_FILE" 2>/dev/null; then
            read_all_bedolaga_settings backup_settings
            [[ -n "$source_desc" ]] && source_desc+="\n"
            source_desc+="–ê—Ä—Ö–∏–≤: $(basename "$MIGRATION_SOURCE_BACKUP_FILE") (${#backup_settings[@]} –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ –ë–î)"
        fi
    fi
    
    local total_source=${#source_settings[@]}
    local total_backup=${#backup_settings[@]}
    local can_migrate_env=0
    local can_migrate_db=0
    local can_migrate_from_backup=0
    local no_mapping=0
    
    # –ü–æ–¥—Å—á—ë—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ .env —Å –º–∞–ø–ø–∏–Ω–≥–æ–º
    for key in "${!source_settings[@]}"; do
        if [[ -n "${SETTINGS_ENV_TO_ENV[$key]}" ]]; then
            ((can_migrate_env++))
        elif [[ -n "${SETTINGS_ENV_TO_DB[$key]}" ]]; then
            ((can_migrate_db++))
        else
            ((no_mapping++))
        fi
    done
    
    # –ü–æ–¥—Å—á—ë—Ç –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ –∞—Ä—Ö–∏–≤–∞ —Å –º–∞–ø–ø–∏–Ω–≥–æ–º
    for key in "${!backup_settings[@]}"; do
        if [[ -n "${BEDOLAGA_BACKUP_TO_RWP[$key]}" ]]; then
            ((can_migrate_from_backup++))
        fi
    done
    
    echo ""
    echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –ê–ù–ê–õ–ò–ó –ù–ê–°–¢–†–û–ï–ö ‚ïê‚ïê‚ïê${RESET}"
    echo ""
    echo -e "–ò—Å—Ç–æ—á–Ω–∏–∫–∏:\n${GREEN}$source_desc${RESET}"
    echo ""
    echo "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê"
    if [[ $total_source -gt 0 ]]; then
        printf "‚îÇ  –ù–∞–π–¥–µ–Ω–æ –≤ .env Bedolaga:            %7s   ‚îÇ\n" "$total_source"
        printf "‚îÇ    -> –ü–µ—Ä–µ–Ω–æ—Å –≤ .env:                %7s   ‚îÇ\n" "$can_migrate_env"
        printf "‚îÇ    -> –ü–µ—Ä–µ–Ω–æ—Å –≤ settings DB:         %7s   ‚îÇ\n" "$can_migrate_db"
        printf "‚îÇ    -> –ë–µ–∑ –∞–Ω–∞–ª–æ–≥–∞:                   %7s   ‚îÇ\n" "$no_mapping"
    fi
    if [[ $total_backup -gt 0 ]]; then
        printf "‚îÇ  –ù–∞–π–¥–µ–Ω–æ –≤ –∞—Ä—Ö–∏–≤–µ:                   %7s   ‚îÇ\n" "$total_backup"
        printf "‚îÇ    -> –ü–µ—Ä–µ–Ω–æ—Å –≤ settings DB:         %7s   ‚îÇ\n" "$can_migrate_from_backup"
    fi
    echo "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
    echo ""
    
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü—Ä–æ—Å–º–æ—Ç—Ä –º–∞–ø–ø–∏–Ω–≥–∞ .env ‚Üí .env ---
migrate_settings_show_env_mapping() {
    # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞—Ä—Ö–∏–≤ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∏–∑ –∞—Ä—Ö–∏–≤–∞
    if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        clear_screen
        echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –ú–ê–ü–ü–ò–ù–ì –ù–ê–°–¢–†–û–ï–ö –ò–ó –ê–†–•–ò–í–ê ‚ïê‚ïê‚ïê${RESET}"
        echo ""
        echo -e "${GRAY}–ò—Å—Ç–æ—á–Ω–∏–∫: $(basename "$MIGRATION_SOURCE_BACKUP_FILE")${RESET}"
        echo ""
        
        # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∞—Ä—Ö–∏–≤ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if [[ -z "$MIGRATION_EXTRACTED_DIR" || ! -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
            if ! extract_bedolaga_backup "$MIGRATION_SOURCE_BACKUP_FILE" 2>/dev/null; then
                print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –∞—Ä—Ö–∏–≤"
                read -erp "Enter..." dummy
                return 1
            fi
        fi
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∞—Ä—Ö–∏–≤–∞
        if [[ -n "$MIGRATION_EXTRACTED_DIR" && -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
            # –ß–∏—Ç–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∞—Ä—Ö–∏–≤–∞
            declare -A backup_settings
            read_all_bedolaga_settings backup_settings
            
            echo -e "${GREEN}=== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ system_settings ‚Üí RWP-Shop ===${RESET}"
            echo ""
            printf "%-35s ‚îÇ %-30s ‚îÇ %s\n" "Bedolaga (backup)" "RWP-Shop" "–ó–Ω–∞—á–µ–Ω–∏–µ"
            echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
            
            local found_count=0
            local mapped_count=0
            
            # –ò—Ç–µ—Ä–∏—Ä—É–µ–º –ø–æ —Ä–µ–∞–ª—å–Ω–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º –∏–∑ –∞—Ä—Ö–∏–≤–∞
            for bedolaga_key in "${!backup_settings[@]}"; do
                local rwp_key="${BEDOLAGA_BACKUP_TO_RWP[$bedolaga_key]:-}"
                local value="${backup_settings[$bedolaga_key]}"
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∑–Ω–∞—á–µ–Ω–∏—è
                [[ ${#value} -gt 20 ]] && value="${value:0:17}..."
                
                ((found_count++))
                if [[ -n "$rwp_key" ]]; then
                    printf "%-35s ‚îÇ ${GREEN}%-30s${RESET} ‚îÇ %s\n" "$bedolaga_key" "$rwp_key" "$value"
                    ((mapped_count++))
                else
                    printf "%-35s ‚îÇ ${GRAY}%-30s${RESET} ‚îÇ %s\n" "$bedolaga_key" "(no mapping)" "$value"
                fi
            done | sort
            
            echo ""
            echo -e "–ù–∞–π–¥–µ–Ω–æ –≤ –∞—Ä—Ö–∏–≤–µ: ${GREEN}$found_count${RESET} –Ω–∞—Å—Ç—Ä–æ–µ–∫"
            echo -e "–° –º–∞–ø–ø–∏–Ω–≥–æ–º –≤ RWP-Shop: ${GREEN}$mapped_count${RESET}"
        else
            print_message "WARN" "–ê—Ä—Ö–∏–≤ –Ω–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω –∏–ª–∏ database.json –Ω–µ –Ω–∞–π–¥–µ–Ω"
        fi
        
        echo ""
        read -erp "Enter..." dummy
        return 0
    fi
    
    # –ï—Å–ª–∏ .env –Ω–µ —É–∫–∞–∑–∞–Ω - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥—Å–∫–∞–∑–∫—É
    if [[ -z "$MIGRATION_SOURCE_ENV_FILE" || ! -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        print_message "WARN" ".env —Ñ–∞–π–ª Bedolaga –Ω–µ —É–∫–∞–∑–∞–Ω"
        echo ""
        echo "–î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –º–∞–ø–ø–∏–Ω–≥–∞ .env ‚Üí .env –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ .env —Ñ–∞–π–ª—É Bedolaga."
        echo "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—É–Ω–∫—Ç 1 (–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π) –¥–ª—è —É–∫–∞–∑–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞."
        echo ""
        echo -e "${GRAY}–ü–æ–¥—Å–∫–∞–∑–∫–∞: –ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –∞—Ä—Ö–∏–≤ - –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ system_settings.${RESET}"
        echo -e "${GRAY}–ê—Ä—Ö–∏–≤ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏ Bedolaga, –∞ –Ω–µ –∏–∑ .env —Ñ–∞–π–ª–∞.${RESET}"
        echo ""
        read -erp "Enter..." dummy
        return 1
    fi
    
    declare -A source_settings
    read_env_file "$MIGRATION_SOURCE_ENV_FILE" source_settings
    
    clear_screen
    echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –ú–ê–ü–ü–ò–ù–ì .env ‚Üí .env (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏) ‚ïê‚ïê‚ïê${RESET}"
    echo ""
    printf "%-30s ‚îÇ %-30s ‚îÇ %s\n" "Bedolaga" "RWP-Shop" "–ó–Ω–∞—á–µ–Ω–∏–µ"
    echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
    
    for bedolaga_key in "${!SETTINGS_ENV_TO_ENV[@]}"; do
        local rwp_key="${SETTINGS_ENV_TO_ENV[$bedolaga_key]}"
        local value="${source_settings[$bedolaga_key]:-<–Ω–µ –∑–∞–¥–∞–Ω–æ>}"
        
        # –ú–∞—Å–∫–∏—Ä—É–µ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if [[ "$bedolaga_key" =~ TOKEN|SECRET|PASSWORD|KEY ]]; then
            if [[ -n "${source_settings[$bedolaga_key]}" ]]; then
                local masked="${value:0:6}***${value: -3}"
                value="$masked"
            fi
        fi
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∑–Ω–∞—á–µ–Ω–∏—è
        [[ ${#value} -gt 25 ]] && value="${value:0:22}..."
        
        printf "%-30s ‚îÇ %-30s ‚îÇ %s\n" "$bedolaga_key" "$rwp_key" "$value"
    done
    
    echo ""
    read -erp "Enter..." dummy
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü—Ä–æ—Å–º–æ—Ç—Ä –º–∞–ø–ø–∏–Ω–≥–∞ ‚Üí settings DB ---
migrate_settings_show_db_mapping() {
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    if [[ -z "$MIGRATION_SOURCE_ENV_FILE" && -z "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        print_message "ERROR" "–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–Ω–∏ .env, –Ω–∏ –∞—Ä—Ö–∏–≤)"
        read -erp "Enter..." dummy
        return 1
    fi
    
    clear_screen
    echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –ú–ê–ü–ü–ò–ù–ì ‚Üí settings DB ‚ïê‚ïê‚ïê${RESET}"
    echo ""
    
    # 1) –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∞—Ä—Ö–∏–≤–∞ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç!)
    if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        echo -e "${GREEN}=== –ò–ó –ê–†–•–ò–í–ê (system_settings ‚Üí settings) ===${RESET}"
        echo ""
        printf "%-35s ‚îÇ %-35s\n" "Bedolaga (backup)" "RWP-Shop settings.key"
        echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –≤ –º–∞—Å—Å–∏–≤ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
        local lines=()
        local mapped_count=0
        local unmapped_count=0
        
        for bedolaga_key in "${!BEDOLAGA_BACKUP_TO_RWP[@]}"; do
            local rwp_key="${BEDOLAGA_BACKUP_TO_RWP[$bedolaga_key]}"
            if [[ -n "$rwp_key" ]]; then
                lines+=("$(printf "%-35s ‚îÇ ${GREEN}%-35s${RESET}" "$bedolaga_key" "$rwp_key")")
                ((mapped_count++))
            else
                lines+=("$(printf "%-35s ‚îÇ ${GRAY}%-35s${RESET}" "$bedolaga_key" "(no mapping)")")
                ((unmapped_count++))
            fi
        done
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –≤—ã–≤–æ–¥–∏–º
        printf '%s\n' "${lines[@]}" | sort
        
        echo ""
        echo -e "–ú–∞–ø–ø–∏–Ω–≥–æ–≤ –∞—Ä—Ö–∏–≤‚Üí–ë–î: ${GREEN}$mapped_count${RESET} | –ë–µ–∑ –º–∞–ø–ø–∏–Ω–≥–∞: ${GRAY}$unmapped_count${RESET}"
        echo ""
    fi
    
    # 2) –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ .env
    if [[ -n "$MIGRATION_SOURCE_ENV_FILE" && -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        declare -A source_settings
        read_env_file "$MIGRATION_SOURCE_ENV_FILE" source_settings
        
        echo -e "${YELLOW}=== –ò–ó .ENV (SETTINGS_ENV_TO_DB) ===${RESET}"
        echo ""
        printf "%-35s ‚îÇ %-35s ‚îÇ %s\n" "Bedolaga .env" "RWP-Shop settings.key" "–ó–Ω–∞—á–µ–Ω–∏–µ"
        echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
        
        local count=0
        for bedolaga_key in "${!SETTINGS_ENV_TO_DB[@]}"; do
            local db_key="${SETTINGS_ENV_TO_DB[$bedolaga_key]}"
            local value="${source_settings[$bedolaga_key]:-<–Ω–µ –∑–∞–¥–∞–Ω–æ>}"
            
            # –ú–∞—Å–∫–∏—Ä—É–µ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            if [[ "$bedolaga_key" =~ TOKEN|SECRET|PASSWORD|KEY ]]; then
                if [[ -n "${source_settings[$bedolaga_key]}" ]]; then
                    local masked="${value:0:6}***${value: -3}"
                    value="$masked"
                fi
            fi
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            [[ ${#value} -gt 20 ]] && value="${value:0:17}..."
            
            printf "%-35s ‚îÇ %-35s ‚îÇ %s\n" "$bedolaga_key" "$db_key" "$value"
            ((count++))
        done
        
        echo ""
        echo "–í—Å–µ–≥–æ –º–∞–ø–ø–∏–Ω–≥–æ–≤ .env‚Üí–ë–î: $count"
    fi
    
    echo ""
    read -erp "Enter..." dummy
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü—Ä–æ—Å–º–æ—Ç—Ä –Ω–∞—Å—Ç—Ä–æ–µ–∫ –±–µ–∑ –∞–Ω–∞–ª–æ–≥–∞ ---
migrate_settings_show_no_mapping() {
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    if [[ -z "$MIGRATION_SOURCE_ENV_FILE" && -z "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        print_message "ERROR" "–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–Ω–∏ .env, –Ω–∏ –∞—Ä—Ö–∏–≤)"
        read -erp "Enter..." dummy
        return 1
    fi
    
    clear_screen
    echo -e "${YELLOW}${BOLD}‚ïê‚ïê‚ïê –ù–ê–°–¢–†–û–ô–ö–ò –ë–ï–ó –ê–ù–ê–õ–û–ì–ê –í RWP-SHOP ‚ïê‚ïê‚ïê${RESET}"
    echo ""
    echo "–≠—Ç–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ù–ï –±—É–¥—É—Ç –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω—ã (–Ω–µ—Ç –∞–Ω–∞–ª–æ–≥–∞ –≤ RWP-Shop):"
    echo ""
    
    local count=0
    
    # 1) –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∞—Ä—Ö–∏–≤–∞ –±–µ–∑ –º–∞–ø–ø–∏–Ω–≥–∞
    if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        echo -e "${GREEN}=== –ò–ó –ê–†–•–ò–í–ê (system_settings) ===${RESET}"
        echo ""
        
        # –ß–∏—Ç–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∞—Ä—Ö–∏–≤–∞
        if [[ -n "$MIGRATION_EXTRACTED_DIR" && -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
            declare -A backup_settings
            read_all_bedolaga_settings backup_settings
            
            local archive_count=0
            for key in "${!backup_settings[@]}"; do
                local rwp_key="${BEDOLAGA_BACKUP_TO_RWP[$key]:-}"
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —É –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –º–∞–ø–ø–∏–Ω–≥–∞
                if [[ -z "$rwp_key" ]]; then
                    local value="${backup_settings[$key]}"
                    
                    # –ú–∞—Å–∫–∏—Ä—É–µ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                    if [[ "$key" =~ TOKEN|SECRET|PASSWORD|KEY ]]; then
                        [[ -n "$value" ]] && value="${value:0:6}***"
                    fi
                    
                    [[ ${#value} -gt 40 ]] && value="${value:0:37}..."
                    
                    printf "  %-35s = %s\n" "$key" "$value"
                    ((archive_count++))
                    ((count++))
                fi
            done | sort
            
            echo ""
            echo "–ë–µ–∑ –∞–Ω–∞–ª–æ–≥–∞ –≤ –∞—Ä—Ö–∏–≤–µ: $archive_count"
        else
            print_message "WARN" "–ê—Ä—Ö–∏–≤ –Ω–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω"
        fi
        echo ""
    fi
    
    # 2) –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ .env –±–µ–∑ –º–∞–ø–ø–∏–Ω–≥–∞
    if [[ -n "$MIGRATION_SOURCE_ENV_FILE" && -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        echo -e "${YELLOW}=== –ò–ó .ENV ===${RESET}"
        echo ""
        
        declare -A source_settings
        read_env_file "$MIGRATION_SOURCE_ENV_FILE" source_settings
        
        local env_count=0
        for key in "${!source_settings[@]}"; do
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –º–∞–ø–ø–∏–Ω–≥
            if [[ -z "${SETTINGS_ENV_TO_ENV[$key]}" && -z "${SETTINGS_ENV_TO_DB[$key]}" ]]; then
                local value="${source_settings[$key]}"
                
                # –ú–∞—Å–∫–∏—Ä—É–µ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                if [[ "$key" =~ TOKEN|SECRET|PASSWORD|KEY ]]; then
                    [[ -n "$value" ]] && value="${value:0:6}***"
                fi
                
                [[ ${#value} -gt 40 ]] && value="${value:0:37}..."
                
                printf "  %-35s = %s\n" "$key" "$value"
                ((env_count++))
                ((count++))
            fi
        done | sort
        
        echo ""
        echo "–ë–µ–∑ –∞–Ω–∞–ª–æ–≥–∞ –≤ .env: $env_count"
    fi
    
    echo ""
    echo -e "${GRAY}–í—Å–µ–≥–æ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –±–µ–∑ –∞–Ω–∞–ª–æ–≥–∞: $count${RESET}"
    echo ""
    read -erp "Enter..." dummy
}

# --- –§—É–Ω–∫—Ü–∏—è: –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ ---
migrate_settings_execute() {
    debug_log "MIGRATE" "Starting settings migration"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    if [[ -z "$MIGRATION_SOURCE_BACKUP_FILE" && -z "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        print_message "ERROR" "–ù–µ —É–∫–∞–∑–∞–Ω –Ω–∏ –∞—Ä—Ö–∏–≤ –±—ç–∫–∞–ø–∞, –Ω–∏ .env —Ñ–∞–π–ª Bedolaga"
        return 1
    fi
    
    if [[ -z "$MIGRATION_TARGET_ENV_FILE" ]]; then
        print_message "ERROR" "–ü—É—Ç—å –∫ –ø—Ä–∏—ë–º–Ω–∏–∫—É .env –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
        return 1
    fi
    
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        print_message "WARN" "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–î RWP-Shop –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω ‚Äî –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ –ë–î –Ω–µ –±—É–¥—É—Ç –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω—ã"
    fi
    
    echo ""
    echo -e "${RED}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo -e "${RED}${BOLD}  ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï! –ú–ò–ì–†–ê–¶–ò–Ø –ù–ê–°–¢–†–û–ï–ö!               ${RESET}"
    echo -e "${RED}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo ""
    echo "–ò—Å—Ç–æ—á–Ω–∏–∫–∏:"
    [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" ]] && echo " ‚Ä¢ –ê—Ä—Ö–∏–≤: $(basename "$MIGRATION_SOURCE_BACKUP_FILE")"
    [[ -n "$MIGRATION_SOURCE_ENV_FILE" ]] && echo " ‚Ä¢ .env:  $MIGRATION_SOURCE_ENV_FILE"
    echo ""
    echo "–ë—É–¥—É—Ç –∏–∑–º–µ–Ω–µ–Ω—ã:"
    echo " ‚Ä¢ –§–∞–π–ª .env: $MIGRATION_TARGET_ENV_FILE"
    [[ -n "$MIGRATION_TARGET_CONTAINER" ]] && echo " ‚Ä¢ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: $MIGRATION_TARGET_CONTAINER / $MIGRATION_TARGET_DB"
    echo ""
    echo -e "${YELLOW}–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–¥–µ–ª–∞—Ç—å –±—ç–∫–∞–ø RWP-Shop –ø–µ—Ä–µ–¥ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º!${RESET}"
    echo ""
    read -erp "–í–≤–µ–¥–∏—Ç–µ 'SETTINGS' –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è: " confirm
    
    if [[ "$confirm" != "SETTINGS" ]]; then
        print_message "INFO" "–ú–∏–≥—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞"
        return 0
    fi
    
    local work_dir="$MIGRATION_WORK_DIR"
    [[ -z "$work_dir" ]] && work_dir="${BACKUP_DIR}/migration_settings_$(date +%Y%m%d_%H%M%S)"
    mkdir -p "$work_dir"
    
    # –ë—ç–∫–∞–ø —Ü–µ–ª–µ–≤–æ–≥–æ .env
    if [[ -f "$MIGRATION_TARGET_ENV_FILE" ]]; then
        cp "$MIGRATION_TARGET_ENV_FILE" "$work_dir/target_env_backup.env"
        print_message "INFO" "–ë—ç–∫–∞–ø .env: $work_dir/target_env_backup.env"
    fi
    
    local env_migrated=0
    local db_migrated=0
    local backup_settings_migrated=0
    local defaults_used=0
    local errors=0
    
    # === –≠–¢–ê–ü 1: –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞ Bedolaga (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω) ===
    declare -A backup_settings
    if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        print_message "INFO" "[1/3] –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞ Bedolaga..."
        
        if extract_bedolaga_backup "$MIGRATION_SOURCE_BACKUP_FILE"; then
            # –ß–∏—Ç–∞–µ–º system_settings –∏–∑ –±—ç–∫–∞–ø–∞
            read_all_bedolaga_settings backup_settings
            print_message "SUCCESS" "–ü—Ä–æ—á–∏—Ç–∞–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ –±—ç–∫–∞–ø–∞: ${#backup_settings[@]}"
        else
            print_message "WARN" "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –∞—Ä—Ö–∏–≤, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –Ω–µ–≥–æ"
        fi
    fi
    
    # –ß–∏—Ç–∞–µ–º .env Bedolaga (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
    declare -A env_settings
    if [[ -n "$MIGRATION_SOURCE_ENV_FILE" && -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        read_env_file "$MIGRATION_SOURCE_ENV_FILE" env_settings
    fi
    
    # === –≠–¢–ê–ü 2: –ú–∏–≥—Ä–∞—Ü–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤ .env ===
    print_message "INFO" "[2/3] –ú–∏–≥—Ä–∞—Ü–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤ .env..."
    
    for bedolaga_key in "${!SETTINGS_ENV_TO_ENV[@]}"; do
        local rwp_key="${SETTINGS_ENV_TO_ENV[$bedolaga_key]}"
        local value=""
        local is_default=false
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: 1) .env Bedolaga ‚Üí 2) –î–µ—Ñ–æ–ª—Ç Bedolaga ‚Üí 3) –î–µ—Ñ–æ–ª—Ç RWP-Shop
        value="${env_settings[$bedolaga_key]:-}"
        
        if [[ -z "$value" ]]; then
            value="${BEDOLAGA_DEFAULTS[$bedolaga_key]:-}"
            [[ -n "$value" ]] && is_default=true
        fi
        
        if [[ -z "$value" ]]; then
            value="${RWP_SHOP_DEFAULTS[$rwp_key]:-}"
            [[ -n "$value" ]] && is_default=true
        fi
        
        if [[ -n "$value" ]]; then
            write_env_variable "$MIGRATION_TARGET_ENV_FILE" "$rwp_key" "$value"
            if $is_default; then
                debug_log "MIGRATE" "ENV: $bedolaga_key ‚Üí $rwp_key (DEFAULT: $value)"
                ((defaults_used++))
            else
                debug_log "MIGRATE" "ENV: $bedolaga_key ‚Üí $rwp_key = $value"
            fi
            ((env_migrated++))
        fi
    done
    
    print_message "SUCCESS" "–ü–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –≤ .env: $env_migrated –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö"
    [[ $defaults_used -gt 0 ]] && echo -e "   ${GRAY}(–∏–∑ –Ω–∏—Ö –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö: $defaults_used)${RESET}"
    
    # === –≠–¢–ê–ü 3: –ú–∏–≥—Ä–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤ –ë–î RWP-Shop ===
    if [[ -n "$MIGRATION_TARGET_CONTAINER" ]]; then
        print_message "INFO" "[3/3] –ú–∏–≥—Ä–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤ —Ç–∞–±–ª–∏—Ü—É settings..."
        defaults_used=0
        
        local sql_file="$work_dir/settings_import.sql"
        echo "-- Settings migration: Bedolaga ‚Üí RWP-Shop" > "$sql_file"
        echo "-- Generated: $(date '+%Y-%m-%d %H:%M:%S')" >> "$sql_file"
        echo "-- Sources: backup=${MIGRATION_SOURCE_BACKUP_FILE:-none}, env=${MIGRATION_SOURCE_ENV_FILE:-none}" >> "$sql_file"
        echo "" >> "$sql_file"
        
        # 3a) –°–Ω–∞—á–∞–ª–∞ –ø–µ—Ä–µ–Ω–æ—Å–∏–º –∏–∑ –∞—Ä—Ö–∏–≤–∞ –±—ç–∫–∞–ø–∞ (system_settings ‚Üí settings)
        if [[ ${#backup_settings[@]} -gt 0 ]]; then
            echo "-- From Bedolaga backup (system_settings):" >> "$sql_file"
            
            for backup_key in "${!backup_settings[@]}"; do
                local rwp_key="${BEDOLAGA_BACKUP_TO_RWP[$backup_key]:-}"
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑ –º–∞–ø–ø–∏–Ω–≥–∞
                [[ -z "$rwp_key" ]] && continue
                
                local value="${backup_settings[$backup_key]}"
                
                # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –¥–ª—è SQL
                local escaped_value="${value//\'/\'\'}"
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –±—É–ª–µ–≤—ã –∑–Ω–∞—á–µ–Ω–∏—è
                if [[ "$value" =~ ^(true|false|True|False|TRUE|FALSE|1|0)$ ]]; then
                    case "${value,,}" in
                        true|1) escaped_value="true" ;;
                        false|0) escaped_value="false" ;;
                    esac
                fi
                
                echo "INSERT INTO settings (key, value, created_at, updated_at) VALUES ('$rwp_key', '$escaped_value', NOW(), NOW())" >> "$sql_file"
                echo "ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value, updated_at = NOW();" >> "$sql_file"
                
                debug_log "MIGRATE" "BACKUP‚ÜíDB: $backup_key ‚Üí $rwp_key = $value"
                ((backup_settings_migrated++))
            done
        fi
        
        # 3b) –ó–∞—Ç–µ–º –ø–µ—Ä–µ–Ω–æ—Å–∏–º –∏–∑ .env (SETTINGS_ENV_TO_DB)
        if [[ ${#env_settings[@]} -gt 0 || ${#BEDOLAGA_DEFAULTS[@]} -gt 0 ]]; then
            echo "" >> "$sql_file"
            echo "-- From Bedolaga .env (SETTINGS_ENV_TO_DB):" >> "$sql_file"
            
            for bedolaga_key in "${!SETTINGS_ENV_TO_DB[@]}"; do
                local db_key="${SETTINGS_ENV_TO_DB[$bedolaga_key]}"
                local value=""
                local is_default=false
                
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: 1) –£–∂–µ –µ—Å—Ç—å –≤ backup_settings ‚Üí –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–æ –ª–∏ —ç—Ç–æ —É–∂–µ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –∏–∑ –±—ç–∫–∞–ø–∞
                local already_from_backup=false
                for bk in "${!BEDOLAGA_BACKUP_TO_RWP[@]}"; do
                    if [[ "${BEDOLAGA_BACKUP_TO_RWP[$bk]}" == "$db_key" && -n "${backup_settings[$bk]:-}" ]]; then
                        already_from_backup=true
                        break
                    fi
                done
                
                $already_from_backup && continue
                
                # 2) .env Bedolaga ‚Üí 3) –î–µ—Ñ–æ–ª—Ç Bedolaga ‚Üí 4) –î–µ—Ñ–æ–ª—Ç RWP-Shop
                value="${env_settings[$bedolaga_key]:-}"
                
                if [[ -z "$value" ]]; then
                    value="${BEDOLAGA_DEFAULTS[$bedolaga_key]:-}"
                    [[ -n "$value" ]] && is_default=true
                fi
                
                if [[ -z "$value" ]]; then
                    value="${RWP_SHOP_DEFAULTS[$db_key]:-}"
                    [[ -n "$value" ]] && is_default=true
                fi
                
                if [[ -n "$value" ]]; then
                    local escaped_value="${value//\'/\'\'}"
                    
                    if [[ "$value" =~ ^(true|false|True|False|TRUE|FALSE|1|0)$ ]]; then
                        case "${value,,}" in
                            true|1) escaped_value="true" ;;
                            false|0) escaped_value="false" ;;
                        esac
                    fi
                    
                    echo "INSERT INTO settings (key, value, created_at, updated_at) VALUES ('$db_key', '$escaped_value', NOW(), NOW())" >> "$sql_file"
                    echo "ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value, updated_at = NOW();" >> "$sql_file"
                    
                    if $is_default; then
                        debug_log "MIGRATE" "ENV‚ÜíDB: $bedolaga_key ‚Üí $db_key (DEFAULT: $value)"
                        ((defaults_used++))
                    else
                        debug_log "MIGRATE" "ENV‚ÜíDB: $bedolaga_key ‚Üí $db_key = $value"
                    fi
                    ((db_migrated++))
                fi
            done
        fi
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º SQL
        docker cp "$sql_file" "${MIGRATION_TARGET_CONTAINER}:/tmp/settings_import.sql"
        
        local sql_result
        sql_result=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -f /tmp/settings_import.sql 2>&1)
        local sql_exit=$?
        
        docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/settings_import.sql
        
        if [[ $sql_exit -ne 0 ]]; then
            print_message "ERROR" "–û—à–∏–±–∫–∞ SQL: $sql_result"
            ((errors++))
        else
            local total_db=$((backup_settings_migrated + db_migrated))
            print_message "SUCCESS" "–ü–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –≤ settings DB: $total_db –Ω–∞—Å—Ç—Ä–æ–µ–∫"
            [[ $backup_settings_migrated -gt 0 ]] && echo -e "   ${GRAY}(–∏–∑ –∞—Ä—Ö–∏–≤–∞: $backup_settings_migrated)${RESET}"
            [[ $defaults_used -gt 0 ]] && echo -e "   ${GRAY}(–∏–∑ –Ω–∏—Ö –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö: $defaults_used)${RESET}"
        fi
    else
        print_message "WARN" "–ü—Ä–æ–ø—É—â–µ–Ω –∏–º–ø–æ—Ä—Ç –≤ –ë–î ‚Äî –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
    fi
    
    # === –û–¢–ß–Å–¢ ===
    local report_file="$work_dir/settings_migration_report.txt"
    {
        echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
        echo "‚ïë         –û–¢–ß–Å–¢ –ú–ò–ì–†–ê–¶–ò–ò –ù–ê–°–¢–†–û–ï–ö                        ‚ïë"
        echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
        echo ""
        echo "–î–∞—Ç–∞: $(date '+%Y-%m-%d %H:%M:%S')"
        echo ""
        echo "=== –ò–°–¢–û–ß–ù–ò–ö–ò ==="
        echo "–ê—Ä—Ö–∏–≤ –±—ç–∫–∞–ø–∞: ${MIGRATION_SOURCE_BACKUP_FILE:-–Ω–µ —É–∫–∞–∑–∞–Ω}"
        echo ".env —Ñ–∞–π–ª:    ${MIGRATION_SOURCE_ENV_FILE:-–Ω–µ —É–∫–∞–∑–∞–Ω}"
        echo ""
        echo "=== –ü–†–ò–Å–ú–ù–ò–ö–ò ==="
        echo ".env:         $MIGRATION_TARGET_ENV_FILE"
        echo "–ë–î:           ${MIGRATION_TARGET_CONTAINER:-–Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω} / ${MIGRATION_TARGET_DB:-}"
        echo ""
        echo "=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ ==="
        echo "–ü–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –≤ .env: $env_migrated"
        echo "–ò–∑ –∞—Ä—Ö–∏–≤–∞ –±—ç–∫–∞–ø–∞ –≤ –ë–î: $backup_settings_migrated"
        echo "–ò–∑ .env –≤ –ë–î: $db_migrated"
        echo "–û—à–∏–±–æ–∫: $errors"
        echo ""
        echo "=== –í–ê–ñ–ù–û ==="
        echo "1. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ .env"
        echo "2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å RWP-Shop –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ –ë–î"
        echo "3. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–≥—É—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å —Ä—É—á–Ω–æ–π –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏"
        echo ""
        echo "=== –ù–ê–°–¢–†–û–ô–ö–ò –ë–ï–ó –ú–ò–ì–†–ê–¶–ò–ò ==="
        echo "–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Bedolaga –Ω–µ –∏–º–µ—é—Ç –ø—Ä—è–º—ã—Ö –∞–Ω–∞–ª–æ–≥–æ–≤ –≤ RWP-Shop:"
        echo "  - –¶–µ–Ω—ã –∏ –ø–∞–∫–µ—Ç—ã —Ç—Ä–∞—Ñ–∏–∫–∞ (—Ä–∞–∑–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç–∞—Ä–∏—Ñ–æ–≤)"
        echo "  - –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±—ç–∫–∞–ø–∞ (—É RWP-Shop –Ω–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ –±—ç–∫–∞–ø–∞)"
        echo "  - –í–Ω–µ—à–Ω–∏–π –∞–¥–º–∏–Ω —Ç–æ–∫–µ–Ω (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è)"
    } > "$report_file"
    
    local total_db=$((backup_settings_migrated + db_migrated))
    
    echo ""
    echo -e "${GREEN}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo -e "${GREEN}${BOLD}  ‚úÖ –ú–ò–ì–†–ê–¶–ò–Ø –ù–ê–°–¢–†–û–ï–ö –ó–ê–í–ï–†–®–ï–ù–ê!                  ${RESET}"
    echo -e "${GREEN}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo ""
    echo "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:"
    echo " ‚Ä¢ .env: $env_migrated –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö"
    [[ $backup_settings_migrated -gt 0 ]] && echo " ‚Ä¢ –ò–∑ –∞—Ä—Ö–∏–≤–∞ –≤ –ë–î: $backup_settings_migrated –Ω–∞—Å—Ç—Ä–æ–µ–∫"
    [[ $db_migrated -gt 0 ]] && echo " ‚Ä¢ –ò–∑ .env –≤ –ë–î: $db_migrated –Ω–∞—Å—Ç—Ä–æ–µ–∫"
    echo " ‚Ä¢ –û—à–∏–±–æ–∫: $errors"
    echo ""
    echo "–û—Ç—á—ë—Ç: $report_file"
    echo ""
    
    if [[ $errors -eq 0 ]]; then
        print_message "WARN" "–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π!"
        echo ""
        read -erp "–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞ —Å–µ–π—á–∞—Å? (y/N): " restart_bot
        if [[ "$restart_bot" =~ ^[Yy]$ ]]; then
            if [[ -n "$MIGRATION_TARGET_BOT_PATH" && -f "$MIGRATION_TARGET_BOT_PATH/compose.yaml" ]]; then
                print_message "INFO" "–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –±–æ—Ç–∞..."
                (cd "$MIGRATION_TARGET_BOT_PATH" && docker compose restart bot)
                print_message "SUCCESS" "–ë–æ—Ç –ø–µ—Ä–µ–∑–∞–ø—É—â–µ–Ω"
            else
                print_message "WARN" "–ü—É—Ç—å –∫ compose.yaml –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞ –≤—Ä—É—á–Ω—É—é."
            fi
        fi
    fi
    
    log_message "SUCCESS" "Settings migration completed: env=$env_migrated, db=$db_migrated, errors=$errors"
    
    read -erp "Enter..." dummy
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –≠–∫—Å–ø–æ—Ä—Ç –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤ CSV ---
migrate_settings_export_csv() {
    if [[ -z "$MIGRATION_SOURCE_ENV_FILE" || ! -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        print_message "ERROR" "–ü—É—Ç—å –∫ –∏—Å—Ç–æ—á–Ω–∏–∫—É –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
        read -erp "Enter..." dummy
        return 1
    fi
    
    declare -A source_settings
    read_env_file "$MIGRATION_SOURCE_ENV_FILE" source_settings
    
    local work_dir="${BACKUP_DIR}/settings_export_$(date +%Y%m%d_%H%M%S)"
    mkdir -p "$work_dir"
    
    local csv_file="$work_dir/bedolaga_settings.csv"
    
    echo "key,value,maps_to_env,maps_to_db,migration_status" > "$csv_file"
    
    for key in "${!source_settings[@]}"; do
        local value="${source_settings[$key]}"
        local env_target="${SETTINGS_ENV_TO_ENV[$key]:-}"
        local db_target="${SETTINGS_ENV_TO_DB[$key]:-}"
        local status="no_mapping"
        
        [[ -n "$env_target" ]] && status="env"
        [[ -n "$db_target" ]] && status="db"
        
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –¥–ª—è CSV
        value="${value//\"/\"\"}"
        
        echo "\"$key\",\"$value\",\"$env_target\",\"$db_target\",\"$status\"" >> "$csv_file"
    done
    
    print_message "SUCCESS" "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã: $csv_file"
    echo ""
    echo "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:"
    echo " ‚Ä¢ –í—Å–µ–≥–æ –Ω–∞—Å—Ç—Ä–æ–µ–∫: ${#source_settings[@]}"
    echo " ‚Ä¢ –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞ .env: $(grep -c ',env$' "$csv_file")"
    echo " ‚Ä¢ –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞ DB: $(grep -c ',db$' "$csv_file")"
    echo " ‚Ä¢ –ë–µ–∑ –º–∞–ø–ø–∏–Ω–≥–∞: $(grep -c ',no_mapping$' "$csv_file")"
    
    read -erp "Enter..." dummy
}

# --- –ú–µ–Ω—é –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ ---
menu_migrate_settings() {
    # === –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –î–ê–ù–ù–´–• –ò–ó –û–°–ù–û–í–ù–û–ì–û –ú–ï–ù–Æ –ú–ò–ì–†–ê–¶–ò–ò ===
    
    # –ò—Å—Ç–æ—á–Ω–∏–∫: –µ—Å–ª–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –º–µ–Ω—é –≤—ã–±—Ä–∞–Ω –∞—Ä—Ö–∏–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    if [[ -z "$MIGRATION_SOURCE_BACKUP_FILE" && -n "$MIGRATION_SOURCE_BACKUP" && -f "$MIGRATION_SOURCE_BACKUP" ]]; then
        MIGRATION_SOURCE_BACKUP_FILE="$MIGRATION_SOURCE_BACKUP"
        debug_log "SETTINGS" "Auto-synced source archive from main migration: $MIGRATION_SOURCE_BACKUP_FILE"
    fi
    
    # –ü—Ä–∏—ë–º–Ω–∏–∫: –µ—Å–ª–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –º–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä, –∏—â–µ–º .env —Ä—è–¥–æ–º
    if [[ -z "$MIGRATION_TARGET_ENV_FILE" && -n "$MIGRATION_TARGET_CONTAINER" ]]; then
        # –ú–µ—Ç–æ–¥ 1: –ß–µ—Ä–µ–∑ docker inspect (working_dir)
        local working_dir=$(docker inspect "$MIGRATION_TARGET_CONTAINER" --format '{{index .Config.Labels "com.docker.compose.project.working_dir"}}' 2>/dev/null)
        if [[ -n "$working_dir" && -d "$working_dir" ]]; then
            MIGRATION_TARGET_BOT_PATH="$working_dir"
            MIGRATION_TARGET_ENV_FILE="$working_dir/.env"
            debug_log "SETTINGS" "Auto-detected target .env from docker inspect: $MIGRATION_TARGET_ENV_FILE"
        fi
        
        # –ú–µ—Ç–æ–¥ 2: –ß–µ—Ä–µ–∑ BOT_PATH –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞
        if [[ -z "$MIGRATION_TARGET_ENV_FILE" && -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
            MIGRATION_TARGET_BOT_PATH="$BOT_PATH"
            MIGRATION_TARGET_ENV_FILE="$BOT_PATH/.env"
            debug_log "SETTINGS" "Auto-detected target .env from BOT_PATH: $MIGRATION_TARGET_ENV_FILE"
        fi
        
        # –ú–µ—Ç–æ–¥ 3: –ê–≤—Ç–æ–ø–æ–∏—Å–∫
        if [[ -z "$MIGRATION_TARGET_ENV_FILE" ]]; then
            local found_rwp=$(find_rwp_shop_env)
            if [[ -n "$found_rwp" && -d "$found_rwp" ]]; then
                MIGRATION_TARGET_BOT_PATH="$found_rwp"
                MIGRATION_TARGET_ENV_FILE="$found_rwp/.env"
                debug_log "SETTINGS" "Auto-detected target .env from find_rwp_shop_env: $MIGRATION_TARGET_ENV_FILE"
            fi
        fi
    fi
    
    while true; do
        clear_screen
        echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
        echo -e "${CYAN}${BOLD}            üîß –ú–ò–ì–†–ê–¶–ò–Ø –ù–ê–°–¢–†–û–ï–ö BEDOLAGA ‚Üí RWP-SHOP          ${RESET}"
        echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
        echo ""
        
        # === –°–¢–ê–¢–£–° (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω) ===
        echo -e "${YELLOW}=== –¢–ï–ö–£–©–ò–ô –°–¢–ê–¢–£–° ===${RESET}"
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫: –∞—Ä—Ö–∏–≤ (–∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –º–µ–Ω—é)
        local archive_needs_password=false
        if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
            local archive_name=$(basename "$MIGRATION_SOURCE_BACKUP_FILE")
            local archive_size=$(du -h "$MIGRATION_SOURCE_BACKUP_FILE" 2>/dev/null | cut -f1)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –ø–∞—Ä–æ–ª—å
            local archive_type=$(detect_bedolaga_archive_type "$MIGRATION_SOURCE_BACKUP_FILE" 2>/dev/null)
            if [[ "$archive_type" == "zip" ]] && is_archive_password_protected "$MIGRATION_SOURCE_BACKUP_FILE" 2>/dev/null; then
                if [[ -z "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                    archive_needs_password=true
                    echo -e "–ò—Å—Ç–æ—á–Ω–∏–∫ –∞—Ä—Ö–∏–≤: ${YELLOW}üîí $archive_name${RESET} ($archive_size)"
                    echo -e "                ${RED}‚ö†Ô∏è  –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–∞—Ä–æ–ª—å! –í—ã–±–µ—Ä–∏—Ç–µ –∞—Ä—Ö–∏–≤ –∑–∞–Ω–æ–≤–æ (–æ—Å–Ω–æ–≤–Ω–æ–µ –º–µ–Ω—é ‚Üí –ø—É–Ω–∫—Ç 2)${RESET}"
                else
                    echo -e "–ò—Å—Ç–æ—á–Ω–∏–∫ –∞—Ä—Ö–∏–≤: ${GREEN}‚úÖ üîë $archive_name${RESET} ($archive_size)"
                fi
            else
                echo -e "–ò—Å—Ç–æ—á–Ω–∏–∫ –∞—Ä—Ö–∏–≤: ${GREEN}‚úÖ $archive_name${RESET} ($archive_size)"
            fi
        else
            echo -e "–ò—Å—Ç–æ—á–Ω–∏–∫ –∞—Ä—Ö–∏–≤: ${YELLOW}‚ö†Ô∏è  –ù–µ –≤—ã–±—Ä–∞–Ω –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –º–µ–Ω—é${RESET}"
        fi
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫: .env Bedolaga (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if [[ -n "$MIGRATION_SOURCE_ENV_FILE" && -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
            echo -e "–ò—Å—Ç–æ—á–Ω–∏–∫ .env:  ${GREEN}‚úÖ $MIGRATION_SOURCE_ENV_FILE${RESET}"
        else
            echo -e "–ò—Å—Ç–æ—á–Ω–∏–∫ .env:  ${GRAY}‚Äî (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)${RESET}"
        fi
        
        # –ü—Ä–∏—ë–º–Ω–∏–∫: .env RWP-Shop
        if [[ -n "$MIGRATION_TARGET_ENV_FILE" ]]; then
            if [[ -f "$MIGRATION_TARGET_ENV_FILE" ]]; then
                local vars_count=$(grep -c "^[A-Z].*=" "$MIGRATION_TARGET_ENV_FILE" 2>/dev/null || echo "0")
                echo -e "–ü—Ä–∏—ë–º–Ω–∏–∫ .env:  ${GREEN}‚úÖ $MIGRATION_TARGET_ENV_FILE${RESET} ($vars_count –ø–µ—Ä–µ–º.)"
            else
                echo -e "–ü—Ä–∏—ë–º–Ω–∏–∫ .env:  ${YELLOW}‚ö†Ô∏è  $MIGRATION_TARGET_ENV_FILE${RESET} (–±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω)"
            fi
        else
            echo -e "–ü—Ä–∏—ë–º–Ω–∏–∫ .env:  ${RED}‚ùå –ù–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω${RESET}"
        fi
        
        # –ü—Ä–∏—ë–º–Ω–∏–∫: –ë–î (–∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –º–µ–Ω—é)
        if [[ -n "$MIGRATION_TARGET_CONTAINER" ]]; then
            echo -e "–ü—Ä–∏—ë–º–Ω–∏–∫ –ë–î:    ${GREEN}‚úÖ $MIGRATION_TARGET_CONTAINER${RESET}"
        else
            echo -e "–ü—Ä–∏—ë–º–Ω–∏–∫ –ë–î:    ${RED}‚ùå –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –º–µ–Ω—é${RESET}"
        fi
        echo ""
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –µ—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –ò –ø–∞—Ä–æ–ª—å –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        if [[ "$archive_needs_password" != "true" ]]; then
            if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]] || \
               [[ -n "$MIGRATION_SOURCE_ENV_FILE" && -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
                migrate_settings_analyze 2>/dev/null
            fi
        fi
        
        echo ""
        echo " [1] –£–∫–∞–∑–∞—Ç—å .env Bedolaga (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"
        echo " [2] –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –º–∞–ø–ø–∏–Ω–≥ –Ω–∞—Å—Ç—Ä–æ–µ–∫"
        echo " [3] –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –º–∞–ø–ø–∏–Ω–≥ –∞—Ä—Ö–∏–≤ ‚Üí settings DB"
        echo " [4] –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑ –∞–Ω–∞–ª–æ–≥–∞"
        echo -e " ${GREEN}[5] ‚ñ∂ –í–´–ü–û–õ–ù–ò–¢–¨ –ú–ò–ì–†–ê–¶–ò–Æ –ù–ê–°–¢–†–û–ï–ö${RESET}"
        echo " [6] –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ CSV"
        echo ""
        echo " [0] ‚Üê –ù–∞–∑–∞–¥"
        echo ""
        read -erp "–í—ã–±–æ—Ä (Enter - –ù–∞–∑–∞–¥): " opt
        [[ -z "$opt" || "$opt" == "q" || "$opt" == "Q" ]] && return
        
        case "$opt" in
            1) migrate_settings_configure_env_source ;;
            2) migrate_settings_show_env_mapping ;;
            3) migrate_settings_show_db_mapping ;;
            4) migrate_settings_show_no_mapping ;;
            5) migrate_settings_execute ;;
            6) migrate_settings_export_csv ;;
            0) return ;;
        esac
    done
}

# --- –§—É–Ω–∫—Ü–∏—è: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ ---
migrate_configure_source() {
    clear_screen
    echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –ù–ê–°–¢–†–û–ô–ö–ê –ò–°–¢–û–ß–ù–ò–ö–ê (Bedolaga) ‚ïê‚ïê‚ïê${RESET}"
    echo ""
    echo "–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö Bedolaga:"
    echo -e " ${GREEN}1. –ë—ç–∫–∞–ø-–∞—Ä—Ö–∏–≤ (.tar.gz —Å database.json)${RESET} ‚Üê –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è"
    echo " 2. Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä (–Ω–∞ —ç—Ç–æ–º —Å–µ—Ä–≤–µ—Ä–µ)"
    echo " 3. –í–Ω–µ—à–Ω–∏–π PostgreSQL —Å–µ—Ä–≤–µ—Ä"
    echo " 0. –ù–∞–∑–∞–¥"
    echo ""
    read -erp "–í—ã–±–æ—Ä (Enter - –ù–∞–∑–∞–¥): " source_type
    [[ -z "$source_type" || "$source_type" == "q" || "$source_type" == "Q" || "$source_type" == "0" ]] && return
    
    case "$source_type" in
        1)
            # –ò—Å—Ç–æ—á–Ω–∏–∫: –±—ç–∫–∞–ø-–∞—Ä—Ö–∏–≤ Bedolaga
            MIGRATION_SOURCE_TYPE="archive"
            MIGRATION_SOURCE_CONTAINER=""
            MIGRATION_SOURCE_HOST=""
            
            echo ""
            print_message "INFO" "–ü–æ–∏—Å–∫ –±—ç–∫–∞–ø-–∞—Ä—Ö–∏–≤–æ–≤ Bedolaga..."
            
            # –ê–≤—Ç–æ–ø–æ–∏—Å–∫ –∞—Ä—Ö–∏–≤–æ–≤
            local found_backups=()
            local search_paths=("/opt/bedolaga/backups" "/opt/bedolaga/backup" "/root/backups" "/opt/vpn-bot/backups" "$HOME/backups")
            
            for search_path in "${search_paths[@]}"; do
                [[ ! -d "$search_path" ]] && continue
                while IFS= read -r -d '' backup_file; do
                    found_backups+=("$backup_file")
                done < <(find "$search_path" -maxdepth 2 -name "backup_*.tar.gz" -type f -print0 2>/dev/null | head -z -n 10)
            done
            
            if [[ ${#found_backups[@]} -gt 0 ]]; then
                echo ""
                echo "–ù–∞–π–¥–µ–Ω–Ω—ã–µ –±—ç–∫–∞–ø—ã:"
                local i=1
                for backup in "${found_backups[@]}"; do
                    local size=$(du -h "$backup" 2>/dev/null | cut -f1)
                    local date=$(stat -c %y "$backup" 2>/dev/null | cut -d' ' -f1)
                    echo "  $i. $backup ($size, $date)"
                    ((i++))
                done
                echo ""
                echo "  M. –í–≤–µ—Å—Ç–∏ –ø—É—Ç—å –≤—Ä—É—á–Ω—É—é"
                echo ""
                read -erp "–í—ã–±–µ—Ä–∏—Ç–µ –∞—Ä—Ö–∏–≤ [1]: " backup_choice
                backup_choice="${backup_choice:-1}"
                
                if [[ "$backup_choice" == "M" || "$backup_choice" == "m" ]]; then
                    read -erp "–ü—É—Ç—å –∫ –∞—Ä—Ö–∏–≤—É: " MIGRATION_SOURCE_BACKUP
                elif [[ "$backup_choice" =~ ^[0-9]+$ ]] && (( backup_choice >= 1 && backup_choice <= ${#found_backups[@]} )); then
                    MIGRATION_SOURCE_BACKUP="${found_backups[$((backup_choice-1))]}"
                else
                    print_message "ERROR" "–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä"
                    return 1
                fi
            else
                echo ""
                print_message "WARN" "–ê—Ä—Ö–∏–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"
                read -erp "–ü—É—Ç—å –∫ –∞—Ä—Ö–∏–≤—É –±—ç–∫–∞–ø–∞ Bedolaga: " MIGRATION_SOURCE_BACKUP
            fi
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä—Ö–∏–≤–∞
            if [[ ! -f "$MIGRATION_SOURCE_BACKUP" ]]; then
                print_message "ERROR" "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: $MIGRATION_SOURCE_BACKUP"
                return 1
            fi
            
            # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞
            print_message "INFO" "–†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞..."
            if ! extract_bedolaga_backup "$MIGRATION_SOURCE_BACKUP"; then
                print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –∞—Ä—Ö–∏–≤"
                return 1
            fi
            
            # –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—ç–∫–∞–ø–µ
            echo ""
            print_message "INFO" "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±—ç–∫–∞–ø–µ:"
            get_bedolaga_backup_info "$MIGRATION_SOURCE_BACKUP"
            
            print_message "SUCCESS" "–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: –∞—Ä—Ö–∏–≤"
            ;;
        2)
            # –ò—Å—Ç–æ—á–Ω–∏–∫: Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            MIGRATION_SOURCE_TYPE="docker"
            MIGRATION_SOURCE_BACKUP=""
            
            echo ""
            echo "–î–æ—Å—Ç—É–ø–Ω—ã–µ PostgreSQL –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã:"
            docker ps --format '{{.Names}}' | grep -iE 'postgres|db|bedolaga' | while read -r name; do
                echo "  - $name"
            done
            echo ""
            read -erp "–ò–º—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –ë–î Bedolaga: " MIGRATION_SOURCE_CONTAINER
            read -erp "–ò–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö [shop_bot]: " MIGRATION_SOURCE_DB
            MIGRATION_SOURCE_DB="${MIGRATION_SOURCE_DB:-shop_bot}"
            read -erp "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ë–î [postgres]: " MIGRATION_SOURCE_USER
            MIGRATION_SOURCE_USER="${MIGRATION_SOURCE_USER:-postgres}"
            MIGRATION_SOURCE_HOST=""
            MIGRATION_SOURCE_PASS=""
            
            print_message "SUCCESS" "–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä"
            ;;
        3)
            # –ò—Å—Ç–æ—á–Ω–∏–∫: –≤–Ω–µ—à–Ω–∏–π PostgreSQL
            MIGRATION_SOURCE_TYPE="postgresql"
            MIGRATION_SOURCE_CONTAINER=""
            MIGRATION_SOURCE_BACKUP=""
            
            echo ""
            read -erp "–•–æ—Å—Ç PostgreSQL: " MIGRATION_SOURCE_HOST
            read -erp "–ü–æ—Ä—Ç [5432]: " MIGRATION_SOURCE_PORT
            MIGRATION_SOURCE_PORT="${MIGRATION_SOURCE_PORT:-5432}"
            read -erp "–ò–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: " MIGRATION_SOURCE_DB
            read -erp "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: " MIGRATION_SOURCE_USER
            read -serp "–ü–∞—Ä–æ–ª—å: " MIGRATION_SOURCE_PASS
            echo ""
            
            print_message "SUCCESS" "–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: –≤–Ω–µ—à–Ω–∏–π PostgreSQL"
            ;;
        0) return ;;
    esac
}

# --- –§—É–Ω–∫—Ü–∏—è: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–∏—ë–º–Ω–∏–∫–∞ ---
migrate_configure_target() {
    clear_screen
    echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –ù–ê–°–¢–†–û–ô–ö–ê –ü–†–ò–Å–ú–ù–ò–ö–ê (RWP-Shop) ‚ïê‚ïê‚ïê${RESET}"
    echo ""
    
    # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –ë–î Remnawave
    local detected_container=""
    for pattern in "rwp_shop_db" "telegram-shop-db" "remnawave.*db"; do
        detected_container=$(docker ps --format '{{.Names}}' | grep -iE "^$pattern$" | head -1)
        [[ -n "$detected_container" ]] && break
    done
    
    if [[ -n "$detected_container" ]]; then
        echo -e "–û–±–Ω–∞—Ä—É–∂–µ–Ω –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä: ${GREEN}$detected_container${RESET}"
        read -erp "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ? (Y/n): " use_detected
        if [[ ! "$use_detected" =~ ^[Nn]$ ]]; then
            MIGRATION_TARGET_CONTAINER="$detected_container"
        fi
    fi
    
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        echo "–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã:"
        docker ps --format '{{.Names}}' | while read -r name; do
            echo "  - $name"
        done
        echo ""
        read -erp "–ò–º—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –ë–î Remnawave: " MIGRATION_TARGET_CONTAINER
    fi
    
    read -erp "–ò–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö [postgres]: " MIGRATION_TARGET_DB
    MIGRATION_TARGET_DB="${MIGRATION_TARGET_DB:-postgres}"
    read -erp "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ë–î [postgres]: " MIGRATION_TARGET_USER
    MIGRATION_TARGET_USER="${MIGRATION_TARGET_USER:-postgres}"
    
    print_message "SUCCESS" "–ü—Ä–∏—ë–º–Ω–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
}

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  –ù–û–í–´–ô UX –ú–ò–ì–†–ê–¶–ò–ò v2.0
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ ---
MIGRATION_DISCLAIMER_SHOWN=false
MIGRATION_AUTO_BACKUP=""          # –ü—É—Ç—å –∫ –∞–≤—Ç–æ–±—ç–∫–∞–ø—É –ë–î RWP-Shop
MIGRATION_NOT_MIGRATED_DIR=""     # –ü–∞–ø–∫–∞ –¥–ª—è –Ω–µ–ø–µ—Ä–µ–Ω–æ—Å–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
MIGRATION_DATA_ANALYSIS=""        # –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö (cached)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —á—Ç–æ –º–∏–≥—Ä–∏—Ä–æ–≤–∞—Ç—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å—ë –≤–∫–ª—é—á–µ–Ω–æ)
MIGRATE_USERS=true
MIGRATE_REFERRALS=true
MIGRATE_SUBSCRIPTIONS=true
MIGRATE_TRANSACTIONS=true
MIGRATE_PROMOCODES=true
MIGRATE_PROMO_USAGE=true
MIGRATE_TICKETS=true
MIGRATE_BROADCAST=true
MIGRATE_SETTINGS=true

# –ü–æ–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞—Ö
MIGRATE_CONFLICT_MODE="update"    # update | skip | ask

# --- –§—É–Ω–∫—Ü–∏—è: –ü–æ–∫–∞–∑–∞—Ç—å disclaimer (–æ–¥–∏–Ω —Ä–∞–∑ –∑–∞ —Å–µ—Å—Å–∏—é) ---
migration_show_disclaimer() {
    if [[ "$MIGRATION_DISCLAIMER_SHOWN" == "true" ]]; then
        return 0
    fi
    
    clear_screen
    echo -e "${RED}${BOLD}"
    echo "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê"
    echo "‚îÇ                                                          ‚îÇ"
    echo "‚îÇ  ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï! –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–´–ô –ú–ò–ì–†–ê–¢–û–†                 ‚îÇ"
    echo "‚îÇ                                                          ‚îÇ"
    echo "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§"
    echo "‚îÇ                                                          ‚îÇ"
    echo "‚îÇ  –≠—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤ —Å—Ç–∞–¥–∏–∏ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø.                  ‚îÇ"
    echo "‚îÇ                                                          ‚îÇ"
    echo "‚îÇ  ‚Ä¢ –í—Å–µ –¥–µ–π—Å—Ç–≤–∏—è –ù–ê –í–ê–® –°–¢–†–ê–• –ò –†–ò–°–ö                      ‚îÇ"
    echo "‚îÇ  ‚Ä¢ –ê–≤—Ç–æ—Ä –ù–ï –Ω–µ—Å—ë—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞ –ø–æ—Ç–µ—Ä—é –¥–∞–Ω–Ω—ã—Ö       ‚îÇ"
    echo "‚îÇ  ‚Ä¢ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Å–¥–µ–ª–∞–π—Ç–µ –±—ç–∫–∞–ø –û–ë–ï–ò–• –ë–î                   ‚îÇ"
    echo "‚îÇ                                                          ‚îÇ"
    echo "‚îÇ  –î–∞–Ω–Ω—ã–µ –±–µ–∑ –∞–Ω–∞–ª–æ–≥–∞ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã.   ‚îÇ"
    echo "‚îÇ                                                          ‚îÇ"
    echo "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
    echo -e "${RESET}"
    echo ""
    echo -e "–ù–∞–∂–º–∏—Ç–µ ${YELLOW}Enter${RESET} —á—Ç–æ–±—ã –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∏–ª–∏ ${YELLOW}Ctrl+C${RESET} –¥–ª—è –≤—ã—Ö–æ–¥–∞..."
    read -r
    
    MIGRATION_DISCLAIMER_SHOWN=true
}

# --- –§—É–Ω–∫—Ü–∏—è: –ê–≤—Ç–æ–ø–æ–∏—Å–∫ –∞—Ä—Ö–∏–≤–∞ Bedolaga ---
migration_auto_find_archive() {
    debug_log "MIGRATE" "Auto-searching for Bedolaga archive..."
    
    local found_archive=""
    local search_paths=()
    
    # 1) –í –ø–∞–ø–∫–µ RWP-Shop –±–æ—Ç–∞ (–µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–∞)
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
        search_paths+=("$BOT_PATH")
    fi
    
    # 2) –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—É—Ç–∏
    search_paths+=(
        "/opt/private-remnawave-telegram-shop-bot"
        "/opt/rwp-shop"
        "/opt/bedolaga"
        "/opt/vpn-bot"
        "/root"
        "/tmp"
        "$HOME"
    )
    
    # 3) –ü–∞–ø–∫–∞ –±—ç–∫–∞–ø–æ–≤ LAZARUS
    [[ -d "$BACKUP_DIR" ]] && search_paths+=("$BACKUP_DIR")
    
    local all_archives=()
    
    for path in "${search_paths[@]}"; do
        [[ ! -d "$path" ]] && continue
        
        # –ò—â–µ–º –∞—Ä—Ö–∏–≤—ã backup_*.tar.gz –ò backup_*.tar.zip (–∑–∞–ø–∞—Ä–æ–ª–µ–Ω–Ω—ã–µ)
        while IFS= read -r -d '' archive; do
            all_archives+=("$archive")
        done < <(find "$path" -maxdepth 3 -type f \( -name "backup_*.tar.gz" -o -name "backup_*.tar.zip" -o -name "backup_*.zip" \) -print0 2>/dev/null)
    done
    
    if [[ ${#all_archives[@]} -eq 0 ]]; then
        debug_log "MIGRATE" "No archives found"
        return 1
    fi
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
    local sorted_archives
    sorted_archives=$(printf '%s\n' "${all_archives[@]}" | xargs -I {} stat --format='%Y %n' {} 2>/dev/null | sort -rn | head -5 | awk '{print $2}')
    
    # –ë–µ—Ä—ë–º —Å–∞–º—ã–π –Ω–æ–≤—ã–π
    found_archive=$(echo "$sorted_archives" | head -1)
    
    if [[ -n "$found_archive" && -f "$found_archive" ]]; then
        echo "$found_archive"
        debug_log "MIGRATE" "Found archive: $found_archive"
        return 0
    fi
    
    return 1
}

# --- –§—É–Ω–∫—Ü–∏—è: –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏–≤–∞ (–±–µ–∑ –ø–æ–ª–Ω–æ–π —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏) ---
migration_quick_analyze() {
    local archive="$1"
    local password="${2:-$BEDOLAGA_BACKUP_PASSWORD}"
    
    if [[ ! -f "$archive" ]]; then
        return 1
    fi
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ unzip —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–¥–ª—è ZIP –∞—Ä—Ö–∏–≤–æ–≤)
    ensure_unzip_installed 2>/dev/null
    
    # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    local temp_dir=$(mktemp -d)
    TEMP_DIRS+=("$temp_dir")
    
    local db_json=""
    local archive_type=$(detect_bedolaga_archive_type "$archive" 2>/dev/null || echo "unknown")
    
    case "$archive_type" in
        "tar.gz")
            # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ database.json
            if ! tar -xzf "$archive" -C "$temp_dir" "database.json" 2>/dev/null; then
                # –ú–æ–∂–µ—Ç –±—ã—Ç—å –≤ –ø–æ–¥–ø–∞–ø–∫–µ
                tar -xzf "$archive" -C "$temp_dir" --wildcards "*/database.json" 2>/dev/null
            fi
            db_json=$(find "$temp_dir" -name "database.json" -type f 2>/dev/null | head -1)
            ;;
        "tar")
            tar -xf "$archive" -C "$temp_dir" "database.json" 2>/dev/null || \
            tar -xf "$archive" -C "$temp_dir" --wildcards "*/database.json" 2>/dev/null
            db_json=$(find "$temp_dir" -name "database.json" -type f 2>/dev/null | head -1)
            ;;
        "zip")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ä–æ–ª—è
            if is_archive_password_protected "$archive" 2>/dev/null; then
                if [[ -z "$password" ]]; then
                    rm -rf "$temp_dir"
                    return 1  # –ù–µ—Ç –ø–∞—Ä–æ–ª—è
                fi
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º AES —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ
                if is_zip_aes_encrypted "$archive"; then
                    if ! ensure_7z_installed; then
                        rm -rf "$temp_dir"
                        return 1
                    fi
                    local cmd_7z=$(get_7z_command)
                    $cmd_7z x -p"$password" -o"$temp_dir" "$archive" -y &>/dev/null
                else
                    unzip -P "$password" -q "$archive" -d "$temp_dir" 2>/dev/null
                fi
            else
                unzip -q "$archive" -d "$temp_dir" 2>/dev/null
            fi
            
            # –ò—â–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∞—Ä—Ö–∏–≤
            local inner_archive=$(find "$temp_dir" -type f \( -name "*.tar.gz" -o -name "*.tar" \) 2>/dev/null | head -1)
            if [[ -n "$inner_archive" ]]; then
                local inner_dir="$temp_dir/inner"
                mkdir -p "$inner_dir"
                if [[ "$inner_archive" == *.tar.gz ]]; then
                    tar -xzf "$inner_archive" -C "$inner_dir" 2>/dev/null
                else
                    tar -xf "$inner_archive" -C "$inner_dir" 2>/dev/null
                fi
                db_json=$(find "$inner_dir" -name "database.json" -type f 2>/dev/null | head -1)
            else
                db_json=$(find "$temp_dir" -name "database.json" -type f 2>/dev/null | head -1)
            fi
            ;;
        *)
            rm -rf "$temp_dir"
            return 1
            ;;
    esac
    
    if [[ -z "$db_json" || ! -f "$db_json" ]]; then
        rm -rf "$temp_dir"
        return 1
    fi
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ Python
    local python_cmd=""
    if command -v python3 &>/dev/null; then python_cmd="python3"
    elif command -v python &>/dev/null; then python_cmd="python"
    else
        rm -rf "$temp_dir"
        return 1
    fi
    
    local analysis
    analysis=$($python_cmd - "$db_json" << 'PYEOF'
import sys, json

try:
    with open(sys.argv[1], 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    tables = data.get('data', data)
    
    users = tables.get('users', [])
    transactions = tables.get('transactions', [])
    promocodes = tables.get('promocodes', [])
    subscriptions = tables.get('subscriptions', [])
    tickets = tables.get('tickets', [])
    
    # –ü–æ–¥—Å—á—ë—Ç –±–∞–ª–∞–Ω—Å–æ–≤ (—É—á–∏—Ç—ã–≤–∞–µ–º —á—Ç–æ balance –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä—É–±–ª—è—Ö, balance_kopeks - –≤ –∫–æ–ø–µ–π–∫–∞—Ö)
    total_balance_kopeks = 0
    users_with_balance = 0
    for u in users:
        bal_kop = u.get('balance_kopeks', 0) or 0
        bal_rub = u.get('balance', 0) or 0
        # –ï—Å–ª–∏ –µ—Å—Ç—å balance_kopeks ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ, –∏–Ω–∞—á–µ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º balance –∏–∑ —Ä—É–±–ª–µ–π
        if bal_kop != 0:
            total_balance_kopeks += bal_kop
            users_with_balance += 1
        elif bal_rub != 0:
            total_balance_kopeks += int(float(bal_rub) * 100)
            users_with_balance += 1
    
    # –ü–æ–¥—Å—á—ë—Ç —Ä–µ—Ñ–µ—Ä–∞–ª–æ–≤
    referrals = sum(1 for u in users if u.get('referred_by_id'))
    
    print(f"users:{len(users)}")
    print(f"transactions:{len(transactions)}")
    print(f"promocodes:{len(promocodes)}")
    print(f"subscriptions:{len(subscriptions)}")
    print(f"tickets:{len(tickets)}")
    print(f"referrals:{referrals}")
    print(f"total_balance_kopeks:{total_balance_kopeks}")
    print(f"users_with_balance:{users_with_balance}")
    
except Exception as e:
    print(f"error:{e}", file=sys.stderr)
    sys.exit(1)
PYEOF
)
    
    rm -rf "$temp_dir"
    echo "$analysis"
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –º–∏–≥—Ä–∞—Ü–∏–∏ –≤ —à–∞–ø–∫–µ –º–µ–Ω—é ---
migration_show_status() {
    local box_width=58  # –®–∏—Ä–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤–Ω—É—Ç—Ä–∏ —Ä–∞–º–∫–∏ (60 - 2 –Ω–∞ –≥—Ä–∞–Ω–∏—Ü—ã)
    
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º
    print_box_line() {
        local content="$1"
        # –£–¥–∞–ª—è–µ–º ANSI escape-–∫–æ–¥—ã –∏ —Å—á–∏—Ç–∞–µ–º —à–∏—Ä–∏–Ω—É —á–µ—Ä–µ–∑ wc -L (—É—á–∏—Ç—ã–≤–∞–µ—Ç Unicode)
        local stripped=$(echo -e "$content" | sed 's/\x1b\[[0-9;]*m//g')
        # LC_ALL=C.UTF-8 –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø–æ–¥—Å—á—ë—Ç Unicode-—Å–∏–º–≤–æ–ª–æ–≤
        local visual_width=$(LC_ALL=C.UTF-8 echo -n "$stripped" | wc -L 2>/dev/null || echo ${#stripped})
        local padding=$((box_width - visual_width))
        [[ $padding -lt 0 ]] && padding=0
        local spaces=$(printf '%*s' "$padding" '')
        echo -e "${CYAN}‚ïë${RESET}${content}${spaces}${CYAN}‚ïë${RESET}"
    }
    
    echo -e "${CYAN}‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó${RESET}"
    print_box_line "  ${BOLD}–¢–ï–ö–£–©–ò–ô –°–¢–ê–¢–£–°${RESET}"
    echo -e "${CYAN}‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£${RESET}"
    
    # –ò—Å—Ç–æ—á–Ω–∏–∫
    if [[ "$MIGRATION_SOURCE_TYPE" == "archive" && -n "$MIGRATION_SOURCE_BACKUP" && -f "$MIGRATION_SOURCE_BACKUP" ]]; then
        local archive_name=$(basename "$MIGRATION_SOURCE_BACKUP")
        local archive_size=$(du -h "$MIGRATION_SOURCE_BACKUP" 2>/dev/null | cut -f1)
        local archive_type=$(detect_bedolaga_archive_type "$MIGRATION_SOURCE_BACKUP" 2>/dev/null || echo "unknown")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–∫–æ–Ω–∫—É –ø–æ —Ç–∏–ø—É
        local type_icon=""
        case "$archive_type" in
            "zip")
                if is_archive_password_protected "$MIGRATION_SOURCE_BACKUP" 2>/dev/null; then
                    type_icon="üîí"
                    [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]] && type_icon="üîì"
                else
                    type_icon="üì¶"
                fi
                ;;
            "tar.gz") type_icon="üì¶" ;;
            "tar")    type_icon="üìÅ" ;;
            *)        type_icon="‚ùì" ;;
        esac
        
        print_box_line "  –ò—Å—Ç–æ—á–Ω–∏–∫:  ${GREEN}‚úÖ $type_icon $archive_name${RESET} ($archive_size)"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
        if [[ -n "$MIGRATION_DATA_ANALYSIS" ]]; then
            local users=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^users:" | cut -d: -f2)
            local tx=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^transactions:" | cut -d: -f2)
            local promo=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^promocodes:" | cut -d: -f2)
            print_box_line "             ${GRAY}üìä users: $users | tx: $tx | promo: $promo${RESET}"
        fi
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –ø–∞—Ä–æ–ª—è –¥–ª—è –∑–∞—â–∏—â—ë–Ω–Ω—ã—Ö –∞—Ä—Ö–∏–≤–æ–≤
        if [[ "$archive_type" == "zip" ]] && is_archive_password_protected "$MIGRATION_SOURCE_BACKUP" 2>/dev/null; then
            if [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                print_box_line "             ${GREEN}üîë –ü–∞—Ä–æ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω${RESET}"
            else
                print_box_line "             ${YELLOW}‚ö†Ô∏è  –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–∞—Ä–æ–ª—å (–ø—É–Ω–∫—Ç 2)${RESET}"
            fi
        fi
    elif [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        print_box_line "  –ò—Å—Ç–æ—á–Ω–∏–∫:  ${GREEN}‚úÖ Docker: $MIGRATION_SOURCE_CONTAINER${RESET}"
    else
        print_box_line "  –ò—Å—Ç–æ—á–Ω–∏–∫:  ${RED}‚ùå –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω${RESET}"
    fi
    
    # –ü—Ä–∏—ë–º–Ω–∏–∫
    if [[ -n "$MIGRATION_TARGET_CONTAINER" ]]; then
        if docker ps --format '{{.Names}}' 2>/dev/null | grep -q "^${MIGRATION_TARGET_CONTAINER}$"; then
            print_box_line "  –ü—Ä–∏—ë–º–Ω–∏–∫:  ${GREEN}‚úÖ Docker: $MIGRATION_TARGET_CONTAINER${RESET} (–ë–î: $MIGRATION_TARGET_DB)"
        else
            print_box_line "  –ü—Ä–∏—ë–º–Ω–∏–∫:  ${YELLOW}‚ö†Ô∏è  $MIGRATION_TARGET_CONTAINER${RESET} (–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–µ –∑–∞–ø—É—â–µ–Ω)"
        fi
    else
        print_box_line "  –ü—Ä–∏—ë–º–Ω–∏–∫:  ${RED}‚ùå –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω${RESET}"
    fi
    
    echo -e "${CYAN}‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù${RESET}"
}

# --- –§—É–Ω–∫—Ü–∏—è: –°–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø –ë–î RWP-Shop –ø–µ—Ä–µ–¥ –º–∏–≥—Ä–∞—Ü–∏–µ–π ---
migration_backup_target_db() {
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        print_message "ERROR" "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –ø—Ä–∏—ë–º–Ω–∏–∫–∞ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
        return 1
    fi
    
    local backup_file="$MIGRATION_WORK_DIR/pre_migration_backup_$(date +%Y%m%d_%H%M%S).sql"
    mkdir -p "$MIGRATION_WORK_DIR"
    
    print_message "INFO" "–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –ë–î RWP-Shop..."
    
    if docker exec "$MIGRATION_TARGET_CONTAINER" pg_dump -U "$MIGRATION_TARGET_USER" "$MIGRATION_TARGET_DB" > "$backup_file" 2>/dev/null; then
        local size=$(du -h "$backup_file" | cut -f1)
        print_message "SUCCESS" "–ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: $backup_file ($size)"
        MIGRATION_AUTO_BACKUP="$backup_file"
        return 0
    else
        print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø –ë–î"
        return 1
    fi
}

# --- –§—É–Ω–∫—Ü–∏—è: –°–æ–∑–¥–∞—Ç—å –ø–∞–ø–∫—É NOT_MIGRATED —Å README ---
migration_create_not_migrated_dir() {
    MIGRATION_NOT_MIGRATED_DIR="$MIGRATION_WORK_DIR/NOT_MIGRATED"
    mkdir -p "$MIGRATION_NOT_MIGRATED_DIR"
    
    cat > "$MIGRATION_NOT_MIGRATED_DIR/README.txt" << 'EOF'
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  –î–ê–ù–ù–´–ï, –ö–û–¢–û–†–´–ï –ù–ï –ë–´–õ–ò –ü–ï–†–ï–ù–ï–°–ï–ù–´ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò
  LAZARUS Migration Tool
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–≠—Ç–∏ —Ñ–∞–π–ª—ã —Å–æ–¥–µ—Ä–∂–∞—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Bedolaga, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
–ø–µ—Ä–µ–Ω–µ—Å–µ–Ω—ã –≤ RWP-Shop –∏–∑-–∑–∞ —Ä–∞–∑–ª–∏—á–∏–π –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –±–æ—Ç–æ–≤.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

üìÑ user_balances.csv (–µ—Å–ª–∏ –µ—Å—Ç—å)
   –°–æ–¥–µ—Ä–∂–∏—Ç: –ë–∞–ª–∞–Ω—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –ö–û–ü–ï–ô–ö–ê–•
   
   –ü—Ä–∏—á–∏–Ω–∞: –í RWP-Shop –±–∞–ª–∞–Ω—Å –Ω–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ —Ä—É–±–ª—è—Ö.
   
   –í–∞—Ä–∏–∞–Ω—Ç—ã –¥–µ–π—Å—Ç–≤–∏–π:
   ‚Ä¢ –í—Ä—É—á–Ω—É—é –Ω–∞—á–∏—Å–ª–∏—Ç—å –¥–Ω–∏ –ø–æ–¥–ø–∏—Å–∫–∏ —á–µ—Ä–µ–∑ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å
   ‚Ä¢ –°–≤—è–∑–∞—Ç—å—Å—è —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞/–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏
   ‚Ä¢ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ –¥–Ω–∏ –ø–æ –≤–∞—à–µ–º—É –∫—É—Ä—Å—É

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

üìÑ referral_balances.csv (–µ—Å–ª–∏ –µ—Å—Ç—å)
   –°–æ–¥–µ—Ä–∂–∏—Ç: –†–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã–µ –±–∞–ª–∞–Ω—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
   
   –ü—Ä–∏—á–∏–Ω–∞: –í RWP-Shop –Ω–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω–æ–≥–æ –±–∞–ª–∞–Ω—Å–∞.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

üìÑ unknown_payments.csv (–µ—Å–ª–∏ –µ—Å—Ç—å)
   –°–æ–¥–µ—Ä–∂–∏—Ç: –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–ª–∞—Ç—ë–∂–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã
   –ü–ª–∞—Ç—ë–∂–∫–∏: heleket, pal24, mulenpay, cloudpayments, manual
   
   –ü—Ä–∏—á–∏–Ω–∞: RWP-Shop –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —ç—Ç–∏ –ø–ª–∞—Ç—ë–∂–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã.
   
   –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –¥–ª—è –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç–∏.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

üìÑ lost_settings.json (–µ—Å–ª–∏ –µ—Å—Ç—å)
   –°–æ–¥–µ—Ä–∂–∏—Ç: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Bedolaga –±–µ–∑ –∞–Ω–∞–ª–æ–≥–∞ –≤ RWP-Shop
   
   –ü—Ä–∏–º–µ—Ä—ã: PRICE_PER_DEVICE, TRAFFIC_PACKAGES_CONFIG

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

–í–æ–ø—Ä–æ—Å—ã? –°–æ–∑–¥–∞–π—Ç–µ issue: https://github.com/UnderGut/LAZARUS-Backup-Manager

EOF
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞—Ç—É –º–∏–≥—Ä–∞—Ü–∏–∏ –≤ README
    sed -i "2a\\  –î–∞—Ç–∞ –º–∏–≥—Ä–∞—Ü–∏–∏: $(date '+%Y-%m-%d %H:%M:%S')" "$MIGRATION_NOT_MIGRATED_DIR/README.txt"
}

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó HEALTHCHECK FUNCTIONS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –Ω–∞ –≤—Å–µ—Ö —ç—Ç–∞–ø–∞—Ö –º–∏–≥—Ä–∞—Ü–∏–∏

# --- –§—É–Ω–∫—Ü–∏—è: –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –∞—Ä—Ö–∏–≤–∞ Bedolaga ---
# –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: tar.gz | zip | tar | unknown
detect_bedolaga_archive_type() {
    local archive_path="$1"
    local file_name=$(basename "$archive_path")
    
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è magic bytes –±–µ–∑ xxd
    get_magic_bytes() {
        local file="$1"
        local len="${2:-2}"
        if command -v xxd &>/dev/null; then
            xxd -l"$len" -p "$file" 2>/dev/null
        elif command -v od &>/dev/null; then
            od -An -tx1 -N"$len" "$file" 2>/dev/null | tr -d ' \n'
        else
            # Fallback: head + hexdump-like —á–µ—Ä–µ–∑ printf
            head -c"$len" "$file" 2>/dev/null | od -An -tx1 2>/dev/null | tr -d ' \n'
        fi
    }
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é + magic bytes
    
    # ZIP: —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .zip –∏–ª–∏ .tar.zip
    if [[ "$file_name" == *.tar.zip ]] || [[ "$file_name" == *.zip ]]; then
        local magic=$(get_magic_bytes "$archive_path" 2)
        if [[ "$magic" == "504b" ]]; then  # PK
            echo "zip"
            return 0
        fi
    fi
    
    # TAR.GZ: —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .tar.gz –∏–ª–∏ .tgz
    if [[ "$file_name" == *.tar.gz ]] || [[ "$file_name" == *.tgz ]]; then
        local magic=$(get_magic_bytes "$archive_path" 2)
        if [[ "$magic" == "1f8b" ]]; then  # gzip magic
            echo "tar.gz"
            return 0
        fi
    fi
    
    # Plain TAR
    if [[ "$file_name" == *.tar ]]; then
        echo "tar"
        return 0
    fi
    
    # –ï—Å–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –Ω–µ –ø–æ–º–æ–≥–ª–æ ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ magic bytes
    local magic=$(get_magic_bytes "$archive_path" 2)
    case "$magic" in
        504b)  echo "zip"; return 0 ;;      # PK (ZIP)
        1f8b)  echo "tar.gz"; return 0 ;;   # gzip
    esac
    
    echo "unknown"
    return 1
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å unzip –µ—Å–ª–∏ –Ω—É–∂–Ω–æ ---
ensure_unzip_installed() {
    # –ï—Å–ª–∏ —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
    command -v unzip &>/dev/null && return 0
    
    debug_log "MIGRATE" "unzip not found, attempting auto-install"
    
    # –ü—ã—Ç–∞–µ–º—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
    if command -v apt-get &>/dev/null; then
        apt-get update -qq 2>/dev/null && apt-get install -y -qq unzip >/dev/null 2>&1
    elif command -v yum &>/dev/null; then
        yum install -y -q unzip >/dev/null 2>&1
    elif command -v dnf &>/dev/null; then
        dnf install -y -q unzip >/dev/null 2>&1
    elif command -v apk &>/dev/null; then
        apk add --quiet unzip >/dev/null 2>&1
    elif command -v pacman &>/dev/null; then
        pacman -S --noconfirm --quiet unzip >/dev/null 2>&1
    elif command -v zypper &>/dev/null; then
        zypper install -y -q unzip >/dev/null 2>&1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
    if command -v unzip &>/dev/null; then
        debug_log "MIGRATE" "unzip installed successfully"
        return 0
    else
        debug_log "MIGRATE" "Failed to install unzip"
        return 1
    fi
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å 7z (p7zip) –µ—Å–ª–∏ –Ω—É–∂–Ω–æ ---
# 7z –Ω—É–∂–µ–Ω –¥–ª—è AES-–∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã—Ö ZIP –∞—Ä—Ö–∏–≤–æ–≤ (unzip –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç AES)
ensure_7z_installed() {
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–º—ë–Ω
    command -v 7z &>/dev/null && return 0
    command -v 7za &>/dev/null && return 0
    command -v 7zr &>/dev/null && return 0
    
    debug_log "MIGRATE" "7z not found, attempting auto-install"
    
    # –ü—ã—Ç–∞–µ–º—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
    if command -v apt-get &>/dev/null; then
        apt-get update -qq 2>/dev/null && apt-get install -y -qq p7zip-full >/dev/null 2>&1
    elif command -v yum &>/dev/null; then
        yum install -y -q p7zip p7zip-plugins >/dev/null 2>&1
    elif command -v dnf &>/dev/null; then
        dnf install -y -q p7zip p7zip-plugins >/dev/null 2>&1
    elif command -v apk &>/dev/null; then
        apk add --quiet p7zip >/dev/null 2>&1
    elif command -v pacman &>/dev/null; then
        pacman -S --noconfirm --quiet p7zip >/dev/null 2>&1
    elif command -v zypper &>/dev/null; then
        zypper install -y -q p7zip >/dev/null 2>&1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
    if command -v 7z &>/dev/null || command -v 7za &>/dev/null; then
        debug_log "MIGRATE" "7z installed successfully"
        return 0
    else
        debug_log "MIGRATE" "Failed to install 7z"
        return 1
    fi
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü–æ–ª—É—á–∏—Ç—å –∫–æ–º–∞–Ω–¥—É 7z ---
get_7z_command() {
    command -v 7z &>/dev/null && echo "7z" && return 0
    command -v 7za &>/dev/null && echo "7za" && return 0
    command -v 7zr &>/dev/null && echo "7zr" && return 0
    return 1
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–∏ ZIP AES —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ ---
is_zip_aes_encrypted() {
    local archive_path="$1"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ file command
    if file "$archive_path" 2>/dev/null | grep -qi "AES"; then
        return 0  # AES —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ
    fi
    
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ unzip -v
    if unzip -v "$archive_path" 2>&1 | grep -qi "AES"; then
        return 0
    fi
    
    return 1  # –ù–µ AES
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Ç—Ä–µ–±—É–µ—Ç –ª–∏ –∞—Ä—Ö–∏–≤ –ø–∞—Ä–æ–ª—å ---
# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
#   1) ZIP —Å ZipCrypto —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ–º (unzip)
#   2) ZIP —Å AES —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ–º (7z)
is_archive_password_protected() {
    local archive_path="$1"
    local archive_type=$(detect_bedolaga_archive_type "$archive_path")
    
    if [[ "$archive_type" != "zip" ]]; then
        return 1  # –¢–æ–ª—å–∫–æ ZIP –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞—â–∏—â—ë–Ω –ø–∞—Ä–æ–ª–µ–º
    fi
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º AES —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ (unzip –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç AES!)
    if is_zip_aes_encrypted "$archive_path"; then
        debug_log "MIGRATE" "Archive uses AES encryption"
        return 0  # AES = —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–∞—Ä–æ–ª—å
    fi
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ unzip —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    ensure_unzip_installed || return 1
    
    # –î–ª—è ZipCrypto ‚Äî –ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –±–µ–∑ –ø–∞—Ä–æ–ª—è
    local temp_dir=$(mktemp -d)
    
    if unzip -o -q "$archive_path" -d "$temp_dir" 2>/dev/null; then
        # ZIP —Ä–∞—Å–ø–∞–∫–æ–≤–∞–ª—Å—è –±–µ–∑ –ø–∞—Ä–æ–ª—è ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        if find "$temp_dir" -name "database.json" 2>/dev/null | grep -q . || \
           find "$temp_dir" -name "*.tar.gz" 2>/dev/null | grep -q .; then
            rm -rf "$temp_dir"
            return 1  # –ü–∞—Ä–æ–ª—å –ù–ï —Ç—Ä–µ–±—É–µ—Ç—Å—è
        fi
    fi
    
    rm -rf "$temp_dir"
    return 0  # –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–∞—Ä–æ–ª—å
}

# --- –§—É–Ω–∫—Ü–∏—è: Healthcheck –∞—Ä—Ö–∏–≤–∞ Bedolaga ---
# –ü—Ä–æ–≤–µ—Ä—è–µ—Ç: —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –∞—Ä—Ö–∏–≤–∞, –Ω–∞–ª–∏—á–∏–µ database.json, —Å—Ç—Ä—É–∫—Ç—É—Ä—É JSON
# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: tar.gz, tar, zip (–≤ —Ç.—á. –∑–∞–ø–∞—Ä–æ–ª–µ–Ω–Ω—ã–π)
migration_healthcheck_archive() {
    local archive_path="${1:-$MIGRATION_SOURCE_BACKUP}"
    local verbose="${2:-true}"
    local errors=0
    local warnings=0
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ unzip —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–¥–ª—è ZIP –∞—Ä—Ö–∏–≤–æ–≤)
    ensure_unzip_installed 2>/dev/null
    
    [[ "$verbose" == "true" ]] && echo -e "\n${CYAN}‚îÅ‚îÅ‚îÅ üè• HEALTHCHECK: –ê—Ä—Ö–∏–≤ Bedolaga ‚îÅ‚îÅ‚îÅ${RESET}\n"
    
    # 1) –§–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if [[ ! -f "$archive_path" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: $archive_path"
        return 1
    fi
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –§–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
    
    # 2) –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ > 0
    local file_size=$(stat -c%s "$archive_path" 2>/dev/null || stat -f%z "$archive_path" 2>/dev/null)
    if [[ -z "$file_size" || "$file_size" -eq 0 ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –§–∞–π–ª –ø—É—Å—Ç–æ–π"
        return 1
    fi
    local size_human=$(numfmt --to=iec-i --suffix=B "$file_size" 2>/dev/null || echo "${file_size} bytes")
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: $size_human"
    
    # 3) –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∞—Ä—Ö–∏–≤–∞
    local archive_type=$(detect_bedolaga_archive_type "$archive_path")
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –¢–∏–ø –∞—Ä—Ö–∏–≤–∞: $archive_type"
    
    if [[ "$archive_type" == "unknown" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∞—Ä—Ö–∏–≤–∞"
        return 1
    fi
    
    # 4) –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞—â–∏—Ç—ã –ø–∞—Ä–æ–ª–µ–º (—Ç–æ–ª—å–∫–æ –¥–ª—è ZIP)
    local needs_password=false
    if [[ "$archive_type" == "zip" ]]; then
        if is_archive_password_protected "$archive_path"; then
            needs_password=true
            [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}üîí${RESET} –ê—Ä—Ö–∏–≤ –∑–∞—â–∏—â—ë–Ω –ø–∞—Ä–æ–ª–µ–º"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –ø–∞—Ä–æ–ª—å
            if [[ -z "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}‚óã${RESET} –ü–∞—Ä–æ–ª—å –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–µ"
                ((warnings++))
            else
                [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –ü–∞—Ä–æ–ª—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω"
            fi
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –ê—Ä—Ö–∏–≤ –Ω–µ –∑–∞—â–∏—â—ë–Ω –ø–∞—Ä–æ–ª–µ–º"
        fi
    fi
    
    # 5) –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
    case "$archive_type" in
        "tar.gz")
            if ! gzip -t "$archive_path" 2>/dev/null; then
                [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ü–æ–≤—Ä–µ–∂–¥—ë–Ω gzip –∞—Ä—Ö–∏–≤"
                return 1
            fi
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å gzip: OK"
            
            if ! tar -tzf "$archive_path" &>/dev/null; then
                [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ü–æ–≤—Ä–µ–∂–¥—ë–Ω tar –∞—Ä—Ö–∏–≤"
                return 1
            fi
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å tar: OK"
            ;;
        "tar")
            if ! tar -tf "$archive_path" &>/dev/null; then
                [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ü–æ–≤—Ä–µ–∂–¥—ë–Ω tar –∞—Ä—Ö–∏–≤"
                return 1
            fi
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å tar: OK"
            ;;
        "zip")
            # –î–ª—è –∑–∞—â–∏—â—ë–Ω–Ω—ã—Ö ZIP –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å –ø–∞—Ä–æ–ª–µ–º –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
            if [[ "$needs_password" == "true" ]]; then
                if [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                    # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å –ø–∞—Ä–æ–ª–µ–º —á–µ—Ä–µ–∑ 7z –∏–ª–∏ unzip
                    local integrity_ok=false
                    if is_zip_aes_encrypted "$archive_path"; then
                        # AES ‚Äî —Ç–æ–ª—å–∫–æ 7z
                        if ensure_7z_installed; then
                            local cmd_7z=$(get_7z_command)
                            if $cmd_7z t -p"$BEDOLAGA_BACKUP_PASSWORD" "$archive_path" &>/dev/null; then
                                integrity_ok=true
                            fi
                        fi
                    else
                        # ZipCrypto ‚Äî unzip
                        if unzip -t -P "$BEDOLAGA_BACKUP_PASSWORD" "$archive_path" &>/dev/null; then
                            integrity_ok=true
                        fi
                    fi
                    
                    if [[ "$integrity_ok" == "true" ]]; then
                        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å ZIP: OK (–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ —Å –ø–∞—Ä–æ–ª–µ–º)"
                    else
                        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –û—à–∏–±–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –∏–ª–∏ –Ω–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å"
                        ((errors++))
                    fi
                else
                    [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}‚óã${RESET} –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å ZIP: —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–∞—Ä–æ–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏"
                    ((warnings++))
                fi
            else
                if ! unzip -t "$archive_path" &>/dev/null; then
                    [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ü–æ–≤—Ä–µ–∂–¥—ë–Ω ZIP –∞—Ä—Ö–∏–≤"
                    return 1
                fi
                [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å ZIP: OK"
            fi
            ;;
    esac
    
    # 6) –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ (database.json)
    local temp_dir=$(mktemp -d)
    TEMP_DIRS+=("$temp_dir")
    local json_file=""
    
    case "$archive_type" in
        "tar.gz")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ database.json
            if ! tar -tzf "$archive_path" | grep -q "database.json"; then
                [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ù–µ –Ω–∞–π–¥–µ–Ω database.json –≤ –∞—Ä—Ö–∏–≤–µ"
                rm -rf "$temp_dir"
                return 1
            fi
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} database.json –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ JSON
            tar -xzf "$archive_path" -C "$temp_dir" --wildcards '*/database.json' 2>/dev/null || \
            tar -xzf "$archive_path" -C "$temp_dir" 'database.json' 2>/dev/null
            json_file=$(find "$temp_dir" -name "database.json" -type f 2>/dev/null | head -1)
            ;;
        "tar")
            if ! tar -tf "$archive_path" | grep -q "database.json"; then
                [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ù–µ –Ω–∞–π–¥–µ–Ω database.json –≤ –∞—Ä—Ö–∏–≤–µ"
                rm -rf "$temp_dir"
                return 1
            fi
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} database.json –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
            
            tar -xf "$archive_path" -C "$temp_dir" --wildcards '*/database.json' 2>/dev/null || \
            tar -xf "$archive_path" -C "$temp_dir" 'database.json' 2>/dev/null
            json_file=$(find "$temp_dir" -name "database.json" -type f 2>/dev/null | head -1)
            ;;
        "zip")
            if [[ "$needs_password" == "true" ]]; then
                # –ü—ã—Ç–∞–µ–º—Å—è —Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–º –ø–∞—Ä–æ–ª–µ–º
                if [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º AES —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ
                    local is_aes="false"
                    if is_zip_aes_encrypted "$archive_path"; then
                        is_aes="true"
                    fi
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∞—Ä—Ö–∏–≤ (7z –¥–ª—è AES, unzip –¥–ª—è ZipCrypto)
                    if [[ "$is_aes" == "true" ]]; then
                        if ! ensure_7z_installed; then
                            [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} 7z –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è AES)"
                            rm -rf "$temp_dir"
                            return 1
                        fi
                        local cmd_7z=$(get_7z_command)
                        $cmd_7z x -p"$BEDOLAGA_BACKUP_PASSWORD" -o"$temp_dir" "$archive_path" -y &>/dev/null
                    else
                        unzip -P "$BEDOLAGA_BACKUP_PASSWORD" -q "$archive_path" -d "$temp_dir" 2>/dev/null
                    fi
                    
                    # –ò—â–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π tar.gz
                    local inner_archive=$(find "$temp_dir" -name "*.tar.gz" -o -name "*.tar" 2>/dev/null | head -1)
                    if [[ -n "$inner_archive" ]]; then
                        local inner_temp="$temp_dir/inner"
                        mkdir -p "$inner_temp"
                        if [[ "$inner_archive" == *.tar.gz ]]; then
                            tar -xzf "$inner_archive" -C "$inner_temp" 2>/dev/null
                        else
                            tar -xf "$inner_archive" -C "$inner_temp" 2>/dev/null
                        fi
                        json_file=$(find "$inner_temp" -name "database.json" -type f 2>/dev/null | head -1)
                    else
                        json_file=$(find "$temp_dir" -name "database.json" -type f 2>/dev/null | head -1)
                    fi
                    
                    if [[ -z "$json_file" ]]; then
                        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ù–µ –Ω–∞–π–¥–µ–Ω database.json –≤ –∞—Ä—Ö–∏–≤–µ"
                        rm -rf "$temp_dir"
                        return 1
                    fi
                    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} database.json –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
                else
                    [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}‚óã${RESET} database.json: —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–∞—Ä–æ–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏"
                    ((warnings++))
                fi
            else
                # –ë–µ–∑ –ø–∞—Ä–æ–ª—è ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                if ! unzip -l "$archive_path" 2>/dev/null | grep -q "database.json"; then
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∞—Ä—Ö–∏–≤
                    unzip -q "$archive_path" -d "$temp_dir" 2>/dev/null
                    local inner_archive=$(find "$temp_dir" -name "*.tar.gz" -o -name "*.tar" 2>/dev/null | head -1)
                    if [[ -n "$inner_archive" ]]; then
                        if [[ "$inner_archive" == *.tar.gz ]]; then
                            if ! tar -tzf "$inner_archive" | grep -q "database.json"; then
                                [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ù–µ –Ω–∞–π–¥–µ–Ω database.json"
                                rm -rf "$temp_dir"
                                return 1
                            fi
                        fi
                    else
                        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ù–µ –Ω–∞–π–¥–µ–Ω database.json"
                        rm -rf "$temp_dir"
                        return 1
                    fi
                fi
                [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} database.json –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
            fi
            ;;
    esac
    
    # –ï—Å–ª–∏ json_file –Ω–µ –Ω–∞–π–¥–µ–Ω –∏ –Ω–µ—Ç –ø–∞—Ä–æ–ª—è ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É JSON
    if [[ -z "$json_file" || ! -f "$json_file" ]]; then
        if [[ "$needs_password" == "true" && -z "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
            [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}‚óã${RESET} –ü—Ä–æ–≤–µ—Ä–∫–∞ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–∞—Ä–æ–ª—å"
            ((warnings++))
            rm -rf "$temp_dir"
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º
            if [[ "$verbose" == "true" ]]; then
                echo ""
                echo -e "  ${YELLOW}${BOLD}‚ö†Ô∏è  –ê–†–•–ò–í –¢–†–ï–ë–£–ï–¢ –ü–ê–†–û–õ–¨${RESET}"
                echo -e "  ${YELLOW}   –£–∫–∞–∂–∏—Ç–µ –ø–∞—Ä–æ–ª—å –¥–ª—è –ø–æ–ª–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏${RESET}"
            fi
            
            debug_log "HEALTHCHECK" "Archive check: password required, path=$archive_path"
            return 0  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —É—Å–ø–µ—Ö, —Ç.–∫. –±–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã
        fi
        
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å database.json"
        rm -rf "$temp_dir"
        return 1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ JSON —á–µ—Ä–µ–∑ Python
    local python_cmd="${PYTHON_CMD:-python3}"
    if ! $python_cmd -c "import json; json.load(open('$json_file'))" 2>/dev/null; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} database.json –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º JSON"
        rm -rf "$temp_dir"
        return 1
    fi
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤–∞–ª–∏–¥–Ω–∞"
    
    # 7) –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
    # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON: {"metadata": {...}, "data": {"users": [...], ...}}
    # –¢–∞–±–ª–∏—Ü—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ d['data'], –Ω–µ –≤ –∫–æ—Ä–Ω–µ!
    local required_tables=("users")
    local optional_tables=("transactions" "promocodes" "subscriptions" "tickets")
    
    for table in "${required_tables[@]}"; do
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ d['data']['table'] (–Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç) –∏–ª–∏ d['table'] (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
        if $python_cmd -c "
import json
d = json.load(open('$json_file'))
data = d.get('data', d)  # –ï—Å–ª–∏ –µ—Å—Ç—å 'data' - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ, –∏–Ω–∞—á–µ –∫–æ—Ä–µ–Ω—å
exit(0 if '$table' in data else 1)
" 2>/dev/null; then
            local count=$($python_cmd -c "
import json
d = json.load(open('$json_file'))
data = d.get('data', d)
print(len(data.get('$table', [])))
" 2>/dev/null)
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –¢–∞–±–ª–∏—Ü–∞ '$table': $count –∑–∞–ø–∏—Å–µ–π"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞: $table"
            ((errors++))
        fi
    done
    
    for table in "${optional_tables[@]}"; do
        if $python_cmd -c "
import json
d = json.load(open('$json_file'))
data = d.get('data', d)
exit(0 if '$table' in data else 1)
" 2>/dev/null; then
            local count=$($python_cmd -c "
import json
d = json.load(open('$json_file'))
data = d.get('data', d)
print(len(data.get('$table', [])))
" 2>/dev/null)
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –¢–∞–±–ª–∏—Ü–∞ '$table': $count –∑–∞–ø–∏—Å–µ–π"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}‚óã${RESET} –¢–∞–±–ª–∏—Ü–∞ '$table' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"
            ((warnings++))
        fi
    done
    
    rm -rf "$temp_dir"
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç
    if [[ "$verbose" == "true" ]]; then
        echo ""
        if [[ $errors -eq 0 ]]; then
            echo -e "  ${GREEN}${BOLD}‚úÖ –ê–†–•–ò–í –í–ê–õ–ò–î–ï–ù${RESET}"
            [[ $warnings -gt 0 ]] && echo -e "  ${YELLOW}   (–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: $warnings)${RESET}"
        else
            echo -e "  ${RED}${BOLD}‚ùå –ê–†–•–ò–í –ù–ï–í–ê–õ–ò–î–ï–ù${RESET} (–æ—à–∏–±–æ–∫: $errors)"
        fi
    fi
    
    debug_log "HEALTHCHECK" "Archive check: errors=$errors, warnings=$warnings, path=$archive_path"
    
    return $errors
}

# --- –§—É–Ω–∫—Ü–∏—è: Healthcheck –ë–î –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º ---
# –ü—Ä–æ–≤–µ—Ä—è–µ—Ç: –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ, –Ω–∞–ª–∏—á–∏–µ —Ç–∞–±–ª–∏—Ü, –ø—Ä–∞–≤–∞ –Ω–∞ –∑–∞–ø–∏—Å—å
migration_healthcheck_db_pre() {
    local verbose="${1:-true}"
    local errors=0
    local warnings=0
    
    [[ "$verbose" == "true" ]] && echo -e "\n${CYAN}‚îÅ‚îÅ‚îÅ üè• HEALTHCHECK: –ë–î RWP-Shop (PRE-IMPORT) ‚îÅ‚îÅ‚îÅ${RESET}\n"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–¥–∞–Ω
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ù–µ –∑–∞–¥–∞–Ω –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–î"
        return 1
    fi
    
    # 1) –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–ø—É—â–µ–Ω
    if ! docker ps --format '{{.Names}}' | grep -q "^${MIGRATION_TARGET_CONTAINER}$"; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–µ –∑–∞–ø—É—â–µ–Ω: $MIGRATION_TARGET_CONTAINER"
        return 1
    fi
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–ø—É—â–µ–Ω: $MIGRATION_TARGET_CONTAINER"
    
    # 2) Healthcheck –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ (pg_isready)
    local db_user="${MIGRATION_TARGET_USER:-postgres}"
    local db_name="${MIGRATION_TARGET_DB:-postgres}"
    
    if ! docker exec "$MIGRATION_TARGET_CONTAINER" pg_isready -U "$db_user" &>/dev/null; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} PostgreSQL –Ω–µ –≥–æ—Ç–æ–≤ (pg_isready failed)"
        return 1
    fi
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} PostgreSQL –≥–æ—Ç–æ–≤ –∫ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—é"
    
    # 3) –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
    if ! docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -c "SELECT 1" &>/dev/null; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –ë–î: $db_name"
        return 1
    fi
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î: $db_name"
    
    # 4) –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
    local required_tables=("customer" "promo" "purchase")
    local optional_tables=("referral" "promo_usage" "support_ticket" "support_message" "broadcast")
    
    for table in "${required_tables[@]}"; do
        local exists=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
            "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = '$table')" 2>/dev/null)
        if [[ "$exists" == "t" ]]; then
            local count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
                "SELECT COUNT(*) FROM $table" 2>/dev/null)
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –¢–∞–±–ª–∏—Ü–∞ '$table': $count –∑–∞–ø–∏—Å–µ–π"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ç–∞–±–ª–∏—Ü–∞: $table"
            ((errors++))
        fi
    done
    
    for table in "${optional_tables[@]}"; do
        local exists=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
            "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = '$table')" 2>/dev/null)
        if [[ "$exists" == "t" ]]; then
            local count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
                "SELECT COUNT(*) FROM $table" 2>/dev/null)
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –¢–∞–±–ª–∏—Ü–∞ '$table': $count –∑–∞–ø–∏—Å–µ–π"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}‚óã${RESET} –¢–∞–±–ª–∏—Ü–∞ '$table' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
            ((warnings++))
        fi
    done
    
    # 5) –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –Ω–∞ –∑–∞–ø–∏—Å—å (—Å–æ–∑–¥–∞—ë–º –∏ —É–¥–∞–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –∑–∞–ø–∏—Å—å)
    local write_test=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
        "CREATE TEMP TABLE _lazarus_write_test (id int); INSERT INTO _lazarus_write_test VALUES (1); SELECT COUNT(*) FROM _lazarus_write_test;" 2>&1)
    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    write_test=$(echo "$write_test" | tr -d '[:space:]')
    if [[ "$write_test" == "1" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –ü—Ä–∞–≤–∞ –Ω–∞ –∑–∞–ø–∏—Å—å: OK"
    elif [[ "$write_test" =~ "ERROR" ]] || [[ -z "$write_test" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ù–µ—Ç –ø—Ä–∞–≤ –Ω–∞ –∑–∞–ø–∏—Å—å –≤ –ë–î"
        ((errors++))
    else
        # –î—Ä—É–≥–æ–π –æ—Ç–≤–µ—Ç ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ OK
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –ü—Ä–∞–≤–∞ –Ω–∞ –∑–∞–ø–∏—Å—å: OK"
    fi
    
    # 6) –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
    local disk_free=$(docker exec "$MIGRATION_TARGET_CONTAINER" df -h /var/lib/postgresql/data 2>/dev/null | tail -1 | awk '{print $4}')
    if [[ -n "$disk_free" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} –°–≤–æ–±–æ–¥–Ω–æ–µ –º–µ—Å—Ç–æ: $disk_free"
    fi
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç
    if [[ "$verbose" == "true" ]]; then
        echo ""
        if [[ $errors -eq 0 ]]; then
            echo -e "  ${GREEN}${BOLD}‚úÖ –ë–î –ì–û–¢–û–í–ê –ö –ò–ú–ü–û–†–¢–£${RESET}"
            [[ $warnings -gt 0 ]] && echo -e "  ${YELLOW}   (–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: $warnings)${RESET}"
        else
            echo -e "  ${RED}${BOLD}‚ùå –ë–î –ù–ï –ì–û–¢–û–í–ê${RESET} (–æ—à–∏–±–æ–∫: $errors)"
        fi
    fi
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—á—ë—Ç—á–∏–∫–∏ –î–û –∏–º–ø–æ—Ä—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    HEALTHCHECK_PRE_COUNTS=""
    for table in customer promo purchase referral; do
        local count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
            "SELECT COUNT(*) FROM $table" 2>/dev/null || echo "0")
        HEALTHCHECK_PRE_COUNTS+="$table:$count "
    done
    
    debug_log "HEALTHCHECK" "DB pre-import: errors=$errors, warnings=$warnings, counts=$HEALTHCHECK_PRE_COUNTS"
    
    return $errors
}

# --- –§—É–Ω–∫—Ü–∏—è: Healthcheck –ë–î –ø–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–∞ ---
# –ü—Ä–æ–≤–µ—Ä—è–µ—Ç: –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—á—ë—Ç—á–∏–∫–æ–≤, —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å FK, –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ orphans
migration_healthcheck_db_post() {
    local verbose="${1:-true}"
    local errors=0
    local warnings=0
    
    [[ "$verbose" == "true" ]] && echo -e "\n${CYAN}‚îÅ‚îÅ‚îÅ üè• HEALTHCHECK: –ë–î RWP-Shop (POST-IMPORT) ‚îÅ‚îÅ‚îÅ${RESET}\n"
    
    local db_user="${MIGRATION_TARGET_USER:-postgres}"
    local db_name="${MIGRATION_TARGET_DB:-postgres}"
    
    # 1) –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—á—ë—Ç—á–∏–∫–æ–≤ (–¥–æ/–ø–æ—Å–ª–µ)
    [[ "$verbose" == "true" ]] && echo -e "  ${BLUE}üìä –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π:${RESET}"
    
    for table in customer promo purchase referral; do
        local pre_count=$(echo "$HEALTHCHECK_PRE_COUNTS" | grep -oP "$table:\K\d+")
        local post_count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
            "SELECT COUNT(*) FROM $table" 2>/dev/null || echo "0")
        local diff=$((post_count - pre_count))
        
        if [[ $diff -gt 0 ]]; then
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} $table: $pre_count ‚Üí $post_count (+$diff)"
        elif [[ $diff -eq 0 ]]; then
            [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}‚óã${RESET} $table: $pre_count ‚Üí $post_count (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} $table: $pre_count ‚Üí $post_count ($diff) - –£–ú–ï–ù–¨–®–ò–õ–û–°–¨!"
            ((warnings++))
        fi
    done
    
    # 2) –ü—Ä–æ–≤–µ—Ä–∫–∞ FK integrity (orphan referrals)
    [[ "$verbose" == "true" ]] && echo -e "\n  ${BLUE}üîó –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Å–≤—è–∑–µ–π:${RESET}"
    
    # Orphan referrals (referrer_id –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ customer)
    local orphan_referrers=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
        "SELECT COUNT(*) FROM referral r WHERE NOT EXISTS (SELECT 1 FROM customer c WHERE c.telegram_id = r.referrer_id)" 2>/dev/null || echo "0")
    if [[ "$orphan_referrers" -eq 0 ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} referral.referrer_id ‚Üí customer: OK"
    else
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} referral.referrer_id ‚Üí customer: $orphan_referrers orphans"
        ((warnings++))
    fi
    
    # Orphan referees
    local orphan_referees=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
        "SELECT COUNT(*) FROM referral r WHERE NOT EXISTS (SELECT 1 FROM customer c WHERE c.telegram_id = r.referee_id)" 2>/dev/null || echo "0")
    if [[ "$orphan_referees" -eq 0 ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} referral.referee_id ‚Üí customer: OK"
    else
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} referral.referee_id ‚Üí customer: $orphan_referees orphans"
        ((warnings++))
    fi
    
    # Orphan promo_usage
    local orphan_promo=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
        "SELECT COUNT(*) FROM promo_usage pu WHERE NOT EXISTS (SELECT 1 FROM promo p WHERE p.id = pu.promo_id)" 2>/dev/null || echo "0")
    if [[ "$orphan_promo" -eq 0 ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} promo_usage.promo_id ‚Üí promo: OK"
    else
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} promo_usage.promo_id ‚Üí promo: $orphan_promo orphans"
        ((warnings++))
    fi
    
    # 3) –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NULL –≤ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª—è—Ö
    [[ "$verbose" == "true" ]] && echo -e "\n  ${BLUE}‚ö†Ô∏è  –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö:${RESET}"
    
    local null_telegram_id=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
        "SELECT COUNT(*) FROM customer WHERE telegram_id IS NULL" 2>/dev/null || echo "0")
    if [[ "$null_telegram_id" -eq 0 ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} customer.telegram_id: –Ω–µ—Ç NULL"
    else
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} customer.telegram_id: $null_telegram_id NULL –∑–∞–ø–∏—Å–µ–π"
        ((errors++))
    fi
    
    # 4) –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ telegram_id
    local dup_telegram=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
        "SELECT COUNT(*) FROM (SELECT telegram_id FROM customer GROUP BY telegram_id HAVING COUNT(*) > 1) t" 2>/dev/null || echo "0")
    if [[ "$dup_telegram" -eq 0 ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} customer.telegram_id: –Ω–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"
    else
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} customer.telegram_id: $dup_telegram –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"
        ((errors++))
    fi
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç
    if [[ "$verbose" == "true" ]]; then
        echo ""
        if [[ $errors -eq 0 && $warnings -eq 0 ]]; then
            echo -e "  ${GREEN}${BOLD}‚úÖ –ò–ú–ü–û–†–¢ –ü–†–û–®–Å–õ –£–°–ü–ï–®–ù–û${RESET}"
        elif [[ $errors -eq 0 ]]; then
            echo -e "  ${YELLOW}${BOLD}‚ö†Ô∏è  –ò–ú–ü–û–†–¢ –ó–ê–í–ï–†–®–Å–ù –° –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø–ú–ò${RESET} ($warnings)"
        else
            echo -e "  ${RED}${BOLD}‚ùå –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´${RESET} (–æ—à–∏–±–æ–∫: $errors, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: $warnings)"
        fi
    fi
    
    debug_log "HEALTHCHECK" "DB post-import: errors=$errors, warnings=$warnings"
    
    return $errors
}

# --- –§—É–Ω–∫—Ü–∏—è: Healthcheck CSV —Ñ–∞–π–ª–æ–≤ ---
# –ü—Ä–æ–≤–µ—Ä—è–µ—Ç: –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤, –∑–∞–≥–æ–ª–æ–≤–∫–∏, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
migration_healthcheck_csv() {
    local export_dir="${1:-$MIGRATION_WORK_DIR/export}"
    local verbose="${2:-true}"
    local errors=0
    local warnings=0
    local total_records=0
    
    [[ "$verbose" == "true" ]] && echo -e "\n${CYAN}‚îÅ‚îÅ‚îÅ üè• HEALTHCHECK: –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ CSV ‚îÅ‚îÅ‚îÅ${RESET}\n"
    
    if [[ ! -d "$export_dir" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} –ü–∞–ø–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: $export_dir"
        return 1
    fi
    
    # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã
    local required_files=("users.csv")
    local optional_files=("transactions.csv" "promocodes.csv" "subscriptions.csv" "referrals.csv" 
                          "promocode_uses.csv" "tickets.csv" "ticket_messages.csv")
    
    for file in "${required_files[@]}"; do
        if [[ -f "$export_dir/$file" ]]; then
            local lines=$(wc -l < "$export_dir/$file")
            local records=$((lines - 1))  # –º–∏–Ω—É—Å –∑–∞–≥–æ–ª–æ–≤–æ–∫
            total_records=$((total_records + records))
            
            if [[ $records -gt 0 ]]; then
                [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} $file: $records –∑–∞–ø–∏—Å–µ–π"
            else
                [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}‚óã${RESET} $file: –ø—É—Å—Ç–æ–π (—Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫)"
                ((warnings++))
            fi
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} $file: –ù–ï –ù–ê–ô–î–ï–ù (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π)"
            ((errors++))
        fi
    done
    
    for file in "${optional_files[@]}"; do
        if [[ -f "$export_dir/$file" ]]; then
            local lines=$(wc -l < "$export_dir/$file")
            local records=$((lines - 1))
            total_records=$((total_records + records))
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} $file: $records –∑–∞–ø–∏—Å–µ–π"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${DIM}‚óã${RESET} $file: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"
        fi
    done
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ CSV
    [[ "$verbose" == "true" ]] && echo -e "\n  ${BLUE}üìã –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤:${RESET}"
    
    if [[ -f "$export_dir/users.csv" ]]; then
        local header=$(head -1 "$export_dir/users.csv")
        if echo "$header" | grep -q "telegram_id"; then
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}‚úì${RESET} users.csv: –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${RED}‚úó${RESET} users.csv: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç telegram_id –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ"
            ((errors++))
        fi
    fi
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç
    if [[ "$verbose" == "true" ]]; then
        echo ""
        echo -e "  ${BLUE}–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞:${RESET} $total_records"
        echo ""
        if [[ $errors -eq 0 ]]; then
            echo -e "  ${GREEN}${BOLD}‚úÖ CSV –§–ê–ô–õ–´ –í–ê–õ–ò–î–ù–´${RESET}"
        else
            echo -e "  ${RED}${BOLD}‚ùå –ü–†–û–ë–õ–ï–ú–´ –° CSV${RESET} (–æ—à–∏–±–æ–∫: $errors)"
        fi
    fi
    
    debug_log "HEALTHCHECK" "CSV check: errors=$errors, total_records=$total_records, dir=$export_dir"
    
    return $errors
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü–æ–ª–Ω—ã–π healthcheck (–≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏) ---
migration_healthcheck_full() {
    local verbose="${1:-true}"
    local archive_ok=0
    local db_pre_ok=0
    local csv_ok=0
    local archive_needs_password=0
    
    echo -e "\n${MAGENTA}${BOLD}‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó${RESET}"
    echo -e "${MAGENTA}${BOLD}‚ïë        üè• –ü–û–õ–ù–´–ô HEALTHCHECK –ú–ò–ì–†–ê–¶–ò–ò                  ‚ïë${RESET}"
    echo -e "${MAGENTA}${BOLD}‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù${RESET}"
    
    # –ê—Ä—Ö–∏–≤
    if [[ -n "$MIGRATION_SOURCE_BACKUP" ]]; then
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –ø–∞—Ä–æ–ª—å –Ω–æ –Ω–µ –≤–≤–µ–¥—ë–Ω
        local archive_type=$(detect_bedolaga_archive_type "$MIGRATION_SOURCE_BACKUP" 2>/dev/null)
        if [[ "$archive_type" == "zip" ]] && is_archive_password_protected "$MIGRATION_SOURCE_BACKUP" 2>/dev/null; then
            if [[ -z "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                archive_needs_password=1
            fi
        fi
        
        migration_healthcheck_archive "$MIGRATION_SOURCE_BACKUP" "$verbose" && archive_ok=1
    else
        [[ "$verbose" == "true" ]] && echo -e "\n  ${YELLOW}‚óã${RESET} –ê—Ä—Ö–∏–≤ –Ω–µ –≤—ã–±—Ä–∞–Ω - –ø—Ä–æ–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏"
    fi
    
    # –ë–î
    if [[ -n "$MIGRATION_TARGET_CONTAINER" ]]; then
        migration_healthcheck_db_pre "$verbose" && db_pre_ok=1
    else
        [[ "$verbose" == "true" ]] && echo -e "\n  ${YELLOW}‚óã${RESET} –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–î –Ω–µ –∑–∞–¥–∞–Ω - –ø—Ä–æ–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏"
    fi
    
    # CSV (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if [[ -d "$MIGRATION_WORK_DIR/export" ]]; then
        migration_healthcheck_csv "$MIGRATION_WORK_DIR/export" "$verbose" && csv_ok=1
    fi
    
    # –ò—Ç–æ–≥
    echo -e "\n${BLUE}‚îÅ‚îÅ‚îÅ –ò–¢–û–ì ‚îÅ‚îÅ‚îÅ${RESET}\n"
    
    # –ê—Ä—Ö–∏–≤: –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–∞—Ä–æ–ª—å ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ OK
    if [[ $archive_needs_password -eq 1 ]]; then
        echo -e "  ${YELLOW}‚ö†${RESET} –ê—Ä—Ö–∏–≤: –¢–†–ï–ë–£–ï–¢–°–Ø –ü–ê–†–û–õ–¨"
    elif [[ $archive_ok -eq 1 ]]; then
        echo -e "  ${GREEN}‚úì${RESET} –ê—Ä—Ö–∏–≤: OK"
    else
        echo -e "  ${RED}‚úó${RESET} –ê—Ä—Ö–∏–≤: –û–®–ò–ë–ö–ê"
    fi
    
    [[ $db_pre_ok -eq 1 ]] && echo -e "  ${GREEN}‚úì${RESET} –ë–î: OK" || echo -e "  ${RED}‚úó${RESET} –ë–î: –û–®–ò–ë–ö–ê"
    [[ -d "$MIGRATION_WORK_DIR/export" ]] && { [[ $csv_ok -eq 1 ]] && echo -e "  ${GREEN}‚úì${RESET} CSV: OK" || echo -e "  ${RED}‚úó${RESET} CSV: –û–®–ò–ë–ö–ê"; }
    
    echo ""
    return 0
}

# --- –§—É–Ω–∫—Ü–∏—è: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–µ–ø–µ—Ä–µ–Ω–æ—Å–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ ---
migration_save_not_migrated_data() {
    [[ -z "$MIGRATION_NOT_MIGRATED_DIR" ]] && migration_create_not_migrated_dir
    
    local export_dir="$MIGRATION_WORK_DIR/export"
    
    # 1) –ë–∞–ª–∞–Ω—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if [[ -f "$export_dir/user_balances.csv" ]]; then
        cp "$export_dir/user_balances.csv" "$MIGRATION_NOT_MIGRATED_DIR/"
        print_message "INFO" "–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –±–∞–ª–∞–Ω—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π ‚Üí NOT_MIGRATED/"
    fi
    
    # 2) –†–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã–µ –±–∞–ª–∞–Ω—Å—ã
    if [[ -f "$export_dir/referral_balances.csv" ]]; then
        cp "$export_dir/referral_balances.csv" "$MIGRATION_NOT_MIGRATED_DIR/"
        print_message "INFO" "–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã–µ –±–∞–ª–∞–Ω—Å—ã ‚Üí NOT_MIGRATED/"
    fi
    
    # 3) –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–ª–∞—Ç–µ–∂–∏ (—Å–æ–±–∏—Ä–∞–µ–º –∏–∑ transactions)
    if [[ -f "$export_dir/transactions.csv" ]]; then
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ —Å unknown payment_method
        head -1 "$export_dir/transactions.csv" > "$MIGRATION_NOT_MIGRATED_DIR/unknown_payments.csv"
        grep ",unknown," "$export_dir/transactions.csv" >> "$MIGRATION_NOT_MIGRATED_DIR/unknown_payments.csv" 2>/dev/null
        
        local unknown_count=$(wc -l < "$MIGRATION_NOT_MIGRATED_DIR/unknown_payments.csv")
        unknown_count=$((unknown_count - 1))
        
        if [[ $unknown_count -gt 0 ]]; then
            print_message "INFO" "–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–ª–∞—Ç–µ–∂–∏ ($unknown_count) ‚Üí NOT_MIGRATED/"
        else
            rm -f "$MIGRATION_NOT_MIGRATED_DIR/unknown_payments.csv"
        fi
    fi
    
    debug_log "MIGRATE" "Not migrated data saved to $MIGRATION_NOT_MIGRATED_DIR"
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö ---
migration_show_detailed_analysis() {
    if [[ -z "$MIGRATION_SOURCE_BACKUP" || ! -f "$MIGRATION_SOURCE_BACKUP" ]]; then
        print_message "ERROR" "–ê—Ä—Ö–∏–≤ –Ω–µ –≤—ã–±—Ä–∞–Ω"
        return 1
    fi
    
    clear_screen
    local archive_name=$(basename "$MIGRATION_SOURCE_BACKUP")
    echo -e "${CYAN}${BOLD}+----------------------------------------------------------------------+${RESET}"
    printf "${CYAN}${BOLD}|  –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•: %-51s |${RESET}\n" "$archive_name"
    echo -e "${CYAN}${BOLD}+----------------------------------------------------------------------+${RESET}"
    echo ""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ –ø–∞—Ä–æ–ª—å
    local archive_type=$(detect_bedolaga_archive_type "$MIGRATION_SOURCE_BACKUP" 2>/dev/null)
    local is_aes=false
    
    if [[ "$archive_type" == "zip" ]] && is_zip_aes_encrypted "$MIGRATION_SOURCE_BACKUP" 2>/dev/null; then
        is_aes=true
    fi
    
    if [[ "$archive_type" == "zip" ]] && is_archive_password_protected "$MIGRATION_SOURCE_BACKUP" 2>/dev/null; then
        if [[ -z "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
            echo -e "${YELLOW}  ‚ö†Ô∏è  –ê—Ä—Ö–∏–≤ –∑–∞—â–∏—â—ë–Ω –ø–∞—Ä–æ–ª–µ–º${RESET}"
            echo ""
            if [[ "$is_aes" == "true" ]]; then
                print_message "INFO" "üîí –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ: AES-256"
            fi
            read -ersp "  –í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å: " BEDOLAGA_BACKUP_PASSWORD
            echo ""
            echo ""
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ä–æ–ª—å
            if [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                local temp_dir=$(mktemp -d)
                TEMP_DIRS+=("$temp_dir")
                local password_ok=false
                
                print_message "INFO" "–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–æ–ª—è..."
                
                if [[ "$is_aes" == "true" ]]; then
                    # AES ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º 7z
                    if ! ensure_7z_installed; then
                        print_message "ERROR" "–î–ª—è AES-–∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞—Ä—Ö–∏–≤–æ–≤ —Ç—Ä–µ–±—É–µ—Ç—Å—è 7z (p7zip)"
                        print_message "INFO" "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: apt install p7zip-full"
                        rm -rf "$temp_dir"
                        BEDOLAGA_BACKUP_PASSWORD=""
                        return 1
                    fi
                    
                    local cmd_7z=$(get_7z_command)
                    if $cmd_7z x -p"$BEDOLAGA_BACKUP_PASSWORD" -o"$temp_dir" "$MIGRATION_SOURCE_BACKUP" -y &>/dev/null; then
                        if find "$temp_dir" -name "database.json" 2>/dev/null | grep -q . || \
                           find "$temp_dir" -type f \( -name "*.tar.gz" -o -name "*.gz" \) 2>/dev/null | grep -q .; then
                            password_ok=true
                        fi
                    fi
                else
                    # ZipCrypto ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º unzip
                    ensure_unzip_installed 2>/dev/null
                    if unzip -P "$BEDOLAGA_BACKUP_PASSWORD" -o -q "$MIGRATION_SOURCE_BACKUP" -d "$temp_dir" 2>/dev/null; then
                        if find "$temp_dir" -name "database.json" 2>/dev/null | grep -q . || \
                           find "$temp_dir" -type f \( -name "*.tar.gz" -o -name "*.gz" \) 2>/dev/null | grep -q .; then
                            password_ok=true
                        fi
                    fi
                fi
                
                rm -rf "$temp_dir"
                
                if [[ "$password_ok" == "true" ]]; then
                    print_message "SUCCESS" "‚úÖ –ü–∞—Ä–æ–ª—å –≤–µ—Ä–Ω—ã–π"
                    echo ""
                else
                    print_message "ERROR" "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å"
                    BEDOLAGA_BACKUP_PASSWORD=""
                    return 1
                fi
            else
                print_message "ERROR" "–ü–∞—Ä–æ–ª—å –Ω–µ –≤–≤–µ–¥—ë–Ω"
                return 1
            fi
        fi
    fi
    
    # –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏–∑
    if [[ -z "$MIGRATION_DATA_ANALYSIS" ]]; then
        print_message "INFO" "–ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏–≤–∞..."
        MIGRATION_DATA_ANALYSIS=$(migration_quick_analyze "$MIGRATION_SOURCE_BACKUP" "$BEDOLAGA_BACKUP_PASSWORD")
    fi
    
    if [[ -z "$MIGRATION_DATA_ANALYSIS" ]]; then
        print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞—Ä—Ö–∏–≤"
        echo ""
        echo "  –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:"
        echo "  ‚Ä¢ –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å (–ø–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–±—Ä–∞—Ç—å –∞—Ä—Ö–∏–≤ –∑–∞–Ω–æ–≤–æ ‚Äî –ø—É–Ω–∫—Ç 2)"
        echo "  ‚Ä¢ –ü–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã–π –∞—Ä—Ö–∏–≤"
        echo "  ‚Ä¢ –ê—Ä—Ö–∏–≤ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç database.json"
        echo ""
        return 1
    fi
    
    # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    local users=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^users:" | cut -d: -f2)
    local transactions=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^transactions:" | cut -d: -f2)
    local promocodes=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^promocodes:" | cut -d: -f2)
    local subscriptions=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^subscriptions:" | cut -d: -f2)
    local tickets=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^tickets:" | cut -d: -f2)
    local referrals=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^referrals:" | cut -d: -f2)
    local total_balance=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^total_balance_kopeks:" | cut -d: -f2)
    local users_with_balance=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^users_with_balance:" | cut -d: -f2)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–ø–µ–π–∫–∏ –≤ —Ä—É–±–ª–∏ (–±–µ–∑ bc, –∏—Å–ø–æ–ª—å–∑—É–µ–º awk)
    local balance_rub
    if [[ -n "$total_balance" && "$total_balance" != "0" ]]; then
        balance_rub=$(awk "BEGIN {printf \"%.2f\", ${total_balance}/100}")
    else
        balance_rub="0.00"
    fi
    
    echo -e "${GREEN}  –ë–£–î–ï–¢ –ü–ï–†–ï–ù–ï–°–ï–ù–û:${RESET}"
    echo ""
    printf "    %-40s %10s   %s\n" "Bedolaga" "–ó–∞–ø–∏—Å–µ–π" "RWP-Shop"
    echo "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
    printf "    %-40s %10s   %s\n" "users" "${users:-0}" "-> customer"
    printf "    %-40s %10s   %s\n" "referrals" "${referrals:-0}" "-> referral"
    printf "    %-40s %10s   %s\n" "subscriptions (active)" "${subscriptions:-0}" "-> customer.*"
    printf "    %-40s %10s   %s\n" "transactions" "${transactions:-0}" "-> purchase"
    printf "    %-40s %10s   %s\n" "promocodes" "${promocodes:-0}" "-> promo"
    printf "    %-40s %10s   %s\n" "tickets" "${tickets:-0}" "-> support_ticket"
    echo ""
    
    if [[ "${users_with_balance:-0}" -gt 0 ]]; then
        echo -e "${YELLOW}  –ù–ï –ë–£–î–ï–¢ –ü–ï–†–ï–ù–ï–°–ï–ù–û (—Å–æ—Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ CSV):${RESET}"
        echo ""
        printf "    %-40s %10s   %s\n" "balances ($users_with_balance users)" "${balance_rub} RUB" "-> NOT_MIGRATED/"
        echo ""
    fi
    
    echo -e "  ${GRAY}–ù–µ–ø–µ—Ä–µ–Ω–æ—Å–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—Å—è –≤: NOT_MIGRATED/${RESET}"
    echo ""
}

# --- –§—É–Ω–∫—Ü–∏—è: –í—ã–±–æ—Ä –∞—Ä—Ö–∏–≤–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ ---
migration_select_archive() {
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∞—Ä—Ö–∏–≤—ã
    local search_paths=(
        "$BOT_PATH"
        "/opt/private-remnawave-telegram-shop-bot"
        "/opt/rwp-shop"
        "/opt/bedolaga"
        "/opt/vpn-bot"
        "/root"
        "$BACKUP_DIR"
        "$HOME"
    )
    
    local all_archives=()
    
    for path in "${search_paths[@]}"; do
        [[ ! -d "$path" ]] && continue
        # –ò—â–µ–º tar.gz –ò tar.zip (–∑–∞–ø–∞—Ä–æ–ª–µ–Ω–Ω—ã–µ)
        while IFS= read -r -d '' archive; do
            all_archives+=("$archive")
        done < <(find "$path" -maxdepth 3 -type f \( -name "backup_*.tar.gz" -o -name "backup_*.tar.zip" -o -name "backup_*.zip" \) -print0 2>/dev/null)
    done
    
    if [[ ${#all_archives[@]} -eq 0 ]]; then
        clear_screen
        echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –í–´–ë–û–† –ê–†–•–ò–í–ê BEDOLAGA ‚ïê‚ïê‚ïê${RESET}"
        echo ""
        echo -e "${YELLOW}–ê—Ä—Ö–∏–≤—ã backup_*.tar.gz / backup_*.tar.zip –Ω–µ –Ω–∞–π–¥–µ–Ω—ã${RESET}"
        echo ""
        echo "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:"
        echo "  ‚Ä¢ backup_*.tar.gz      ‚Äî –æ–±—ã—á–Ω—ã–π –∞—Ä—Ö–∏–≤"
        echo "  ‚Ä¢ backup_*.tar.zip     ‚Äî –∑–∞–ø–∞—Ä–æ–ª–µ–Ω–Ω—ã–π –∞—Ä—Ö–∏–≤"
        echo ""
        echo "–ì–¥–µ –Ω–∞–π—Ç–∏ –∞—Ä—Ö–∏–≤:"
        echo "  ‚Ä¢ –°–∫–∞—á–∞–π—Ç–µ –±—ç–∫–∞–ø –∏–∑ Telegram (–µ—Å–ª–∏ –±–æ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è–ª)"
        echo "  ‚Ä¢ –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∏–∑ –ø–∞–ø–∫–∏ Bedolaga: /opt/bedolaga/backups/"
        echo "  ‚Ä¢ –ü–æ–ª–æ–∂–∏—Ç–µ –≤ –ø–∞–ø–∫—É RWP-Shop –±–æ—Ç–∞"
        echo ""
        read -erp "–í–≤–µ–¥–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –∞—Ä—Ö–∏–≤—É (Enter - –Ω–∞–∑–∞–¥): " manual_path
        [[ -z "$manual_path" ]] && return 1
        
        if [[ -f "$manual_path" ]]; then
            _migration_set_archive "$manual_path"
            return 0
        else
            print_message "ERROR" "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: $manual_path"
            return 1
        fi
    fi
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∞—Ä—Ö–∏–≤—ã –ø–æ –¥–∞—Ç–µ
    local sorted_archives=()
    while IFS= read -r archive; do
        sorted_archives+=("$archive")
    done < <(printf '%s\n' "${all_archives[@]}" | xargs -I {} stat --format='%Y %n' {} 2>/dev/null | sort -rn | awk '{print $2}')
    
    local total_count=${#sorted_archives[@]}
    local show_limit=5
    local show_filenames=false
    
    while true; do
        clear_screen
        echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –í–´–ë–û–† –ê–†–•–ò–í–ê BEDOLAGA ‚ïê‚ïê‚ïê${RESET}"
        echo -e "–í—Å–µ–≥–æ –∞—Ä—Ö–∏–≤–æ–≤: ${CYAN}$total_count${RESET}"
        echo ""
        
        local loop_limit=$show_limit
        [[ $loop_limit -gt $total_count ]] && loop_limit=$total_count
        
        for (( i=0; i<loop_limit; i++ )); do
            local archive="${sorted_archives[$i]}"
            local num=$((i + 1))
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∏ —Å—Ç–∞—Ç—É—Å –∑–∞—â–∏—Ç—ã
            local type_icon="üì¶"
            local archive_type=$(detect_bedolaga_archive_type "$archive" 2>/dev/null || echo "unknown")
            if [[ "$archive_type" == "zip" ]]; then
                if is_archive_password_protected "$archive" 2>/dev/null; then
                    type_icon="üîí"
                fi
            fi
            
            if [[ "$show_filenames" == "true" ]]; then
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å
                local size=$(du -h "$archive" 2>/dev/null | cut -f1)
                if [[ $i -eq 0 ]]; then
                    echo -e "  ${GREEN}$num. $type_icon $archive${RESET}"
                    echo -e "     ${GREEN}($size) ‚Üê –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø${RESET}"
                else
                    echo "  $num. $type_icon $archive ($size)"
                fi
            else
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
                local name=$(basename "$archive")
                local size=$(du -h "$archive" 2>/dev/null | cut -f1)
                local mtime=$(stat -c '%y' "$archive" 2>/dev/null | cut -d'.' -f1)
                
                # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ backup_YYYYMMDD_HHMMSS
                local date_str=""
                if [[ "$name" =~ backup_([0-9]{4})([0-9]{2})([0-9]{2})_([0-9]{2})([0-9]{2})([0-9]{2}) ]]; then
                    date_str="${BASH_REMATCH[1]}-${BASH_REMATCH[2]}-${BASH_REMATCH[3]} ${BASH_REMATCH[4]}:${BASH_REMATCH[5]}"
                else
                    date_str="$mtime"
                fi
                
                if [[ $i -eq 0 ]]; then
                    echo -e "  ${GREEN}$num. $type_icon $date_str${RESET} ($size) ${GREEN}‚Üê –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø${RESET}"
                else
                    echo "  $num. $type_icon $date_str ($size)"
                fi
            fi
        done
        
        echo ""
        if [[ $show_limit -lt $total_count ]]; then
            echo -e " 888. ${GRAY}–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ ($total_count —à—Ç)${RESET}"
        else
            echo -e " 888. ${GRAY}–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø-5${RESET}"
        fi
        if [[ "$show_filenames" == "false" ]]; then
            echo -e " 999. ${GRAY}–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—ã–µ –ø—É—Ç–∏${RESET}"
        else
            echo -e " 999. ${GRAY}–ü–æ–∫–∞–∑–∞—Ç—å –¥–∞—Ç—ã${RESET}"
        fi
        echo ""
        echo "   0. –í–≤–µ—Å—Ç–∏ –ø—É—Ç—å –≤—Ä—É—á–Ω—É—é"
        echo ""
        echo -e "  ${GRAY}üîí = –∑–∞—â–∏—â—ë–Ω –ø–∞—Ä–æ–ª–µ–º${RESET}"
        echo ""
        read -erp "–ù–æ–º–µ—Ä —Ñ–∞–π–ª–∞ –∏–ª–∏ –∫–æ–º–∞–Ω–¥–∞ (Enter - –ù–∞–∑–∞–¥): " choice
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–∞
        [[ -z "$choice" || "$choice" == "q" || "$choice" == "Q" ]] && return 1
        
        case "$choice" in
            888)
                if [[ $show_limit -lt $total_count ]]; then
                    show_limit=$total_count
                else
                    show_limit=5
                fi
                continue
                ;;
            999)
                if [[ "$show_filenames" == "false" ]]; then
                    show_filenames=true
                else
                    show_filenames=false
                fi
                continue
                ;;
            0)
                read -erp "–ü—É—Ç—å –∫ –∞—Ä—Ö–∏–≤—É: " manual_path
                if [[ -f "$manual_path" ]]; then
                    _migration_set_archive "$manual_path"
                    return 0
                else
                    print_message "ERROR" "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"
                fi
                ;;
            *)
                if [[ "$choice" =~ ^[0-9]+$ ]] && (( choice >= 1 && choice <= total_count )); then
                    local idx=$((choice - 1))
                    _migration_set_archive "${sorted_archives[$idx]}"
                    return 0
                else
                    print_message "ERROR" "–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä"
                    sleep 1
                fi
                ;;
        esac
    done
}

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∞—Ä—Ö–∏–≤ –∏ –∑–∞–ø—Ä–æ—Å–∏—Ç—å –ø–∞—Ä–æ–ª—å –µ—Å–ª–∏ –Ω—É–∂–Ω–æ ---
_migration_set_archive() {
    local archive_path="$1"
    
    MIGRATION_SOURCE_BACKUP="$archive_path"
    MIGRATION_SOURCE_TYPE="archive"
    MIGRATION_DATA_ANALYSIS=""  # –°–±—Ä–æ—Å–∏—Ç—å –∫—ç—à –∞–Ω–∞–ª–∏–∑–∞
    BEDOLAGA_BACKUP_PASSWORD=""  # –°–±—Ä–æ—Å–∏—Ç—å –ø–∞—Ä–æ–ª—å
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ –ø–∞—Ä–æ–ª—å
    local archive_type=$(detect_bedolaga_archive_type "$archive_path" 2>/dev/null || echo "unknown")
    local is_aes=false
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º AES —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ
    if [[ "$archive_type" == "zip" ]] && is_zip_aes_encrypted "$archive_path"; then
        is_aes=true
        debug_log "MIGRATE" "Archive uses AES encryption, will use 7z"
    fi
    
    if [[ "$archive_type" == "zip" ]] && is_archive_password_protected "$archive_path" 2>/dev/null; then
        echo ""
        if [[ "$is_aes" == "true" ]]; then
            print_message "INFO" "üîí –ê—Ä—Ö–∏–≤ –∑–∞—â–∏—â—ë–Ω –ø–∞—Ä–æ–ª–µ–º (AES-256 —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ)"
        else
            print_message "INFO" "üîí –ê—Ä—Ö–∏–≤ –∑–∞—â–∏—â—ë–Ω –ø–∞—Ä–æ–ª–µ–º"
        fi
        read -ersp "–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å: " BEDOLAGA_BACKUP_PASSWORD
        echo ""
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ä–æ–ª—è
        if [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
            local temp_dir=$(mktemp -d)
            TEMP_DIRS+=("$temp_dir")
            local password_ok=false
            
            if [[ "$is_aes" == "true" ]]; then
                # AES —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ ‚Äî –Ω—É–∂–µ–Ω 7z
                if ! ensure_7z_installed; then
                    print_message "ERROR" "–î–ª—è AES-–∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞—Ä—Ö–∏–≤–æ–≤ —Ç—Ä–µ–±—É–µ—Ç—Å—è 7z (p7zip)"
                    print_message "INFO" "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: apt install p7zip-full"
                    rm -rf "$temp_dir"
                    BEDOLAGA_BACKUP_PASSWORD=""
                    return 1
                fi
                
                local cmd_7z=$(get_7z_command)
                debug_log "MIGRATE" "Using 7z command: $cmd_7z"
                
                # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º —Å –ø–æ–º–æ—â—å—é 7z
                if $cmd_7z x -p"$BEDOLAGA_BACKUP_PASSWORD" -o"$temp_dir" "$archive_path" -y &>/dev/null; then
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–ª–æ—Å—å
                    if find "$temp_dir" -name "database.json" 2>/dev/null | grep -q .; then
                        password_ok=true
                    else
                        # –ò—â–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π tar.gz
                        local inner=$(find "$temp_dir" -type f \( -name "*.tar.gz" -o -name "*.gz" \) 2>/dev/null | head -1)
                        if [[ -n "$inner" ]] && tar -tzf "$inner" &>/dev/null; then
                            password_ok=true
                        fi
                    fi
                fi
            else
                # ZipCrypto ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º unzip
                ensure_unzip_installed 2>/dev/null
                
                if unzip -P "$BEDOLAGA_BACKUP_PASSWORD" -o -q "$archive_path" -d "$temp_dir" 2>/dev/null; then
                    if find "$temp_dir" -name "database.json" 2>/dev/null | grep -q .; then
                        password_ok=true
                    else
                        local inner=$(find "$temp_dir" -type f \( -name "*.tar.gz" -o -name "*.gz" \) 2>/dev/null | head -1)
                        if [[ -n "$inner" ]] && tar -tzf "$inner" &>/dev/null; then
                            password_ok=true
                        fi
                    fi
                fi
            fi
            
            if [[ "$password_ok" == "true" ]]; then
                print_message "SUCCESS" "‚úÖ –ü–∞—Ä–æ–ª—å –≤–µ—Ä–Ω—ã–π"
            else
                print_message "ERROR" "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å"
                BEDOLAGA_BACKUP_PASSWORD=""
            fi
            
            rm -rf "$temp_dir"
        fi
    fi
    
    print_message "SUCCESS" "–ê—Ä—Ö–∏–≤ –≤—ã–±—Ä–∞–Ω: $(basename "$archive_path")"
    
    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
    if [[ "$archive_type" != "zip" ]] || [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
        MIGRATION_DATA_ANALYSIS=$(migration_quick_analyze "$archive_path" 2>/dev/null)
    fi
}

# --- –§—É–Ω–∫—Ü–∏—è: –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º ---
migration_show_import_warning() {
    echo ""
    echo -e "${RED}${BOLD}‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê${RESET}"
    echo -e "${RED}${BOLD}‚îÇ  ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï! –ò–ó–ú–ï–ù–ï–ù–ò–ï –ë–ê–ó–´ –î–ê–ù–ù–´–•                               ‚îÇ${RESET}"
    echo -e "${RED}${BOLD}‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§${RESET}"
    echo -e "${RED}${BOLD}‚îÇ${RESET}                                                                    ${RED}${BOLD}‚îÇ${RESET}"
    echo -e "${RED}${BOLD}‚îÇ${RESET}  –°–µ–π—á–∞—Å –±—É–¥—É—Ç –≤–Ω–µ—Å–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –ë–î RWP-Shop:                    ${RED}${BOLD}‚îÇ${RESET}"
    echo -e "${RED}${BOLD}‚îÇ${RESET}                                                                    ${RED}${BOLD}‚îÇ${RESET}"
    echo -e "${RED}${BOLD}‚îÇ${RESET}  ‚Ä¢ –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä: ${YELLOW}$MIGRATION_TARGET_CONTAINER${RESET}"
    echo -e "${RED}${BOLD}‚îÇ${RESET}  ‚Ä¢ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: ${YELLOW}$MIGRATION_TARGET_DB${RESET}"
    echo -e "${RED}${BOLD}‚îÇ${RESET}                                                                    ${RED}${BOLD}‚îÇ${RESET}"
    if [[ -n "$MIGRATION_AUTO_BACKUP" ]]; then
        echo -e "${RED}${BOLD}‚îÇ${RESET}  ${GREEN}üîí –ë—ç–∫–∞–ø —Ç–µ–∫—É—â–µ–π –ë–î —Å–æ–∑–¥–∞–Ω:${RESET}"
        echo -e "${RED}${BOLD}‚îÇ${RESET}     ${GRAY}$MIGRATION_AUTO_BACKUP${RESET}"
        echo -e "${RED}${BOLD}‚îÇ${RESET}                                                                    ${RED}${BOLD}‚îÇ${RESET}"
    fi
    echo -e "${RED}${BOLD}‚îÇ${RESET}  –î–ª—è –æ—Ç–∫–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:                                            ${RED}${BOLD}‚îÇ${RESET}"
    echo -e "${RED}${BOLD}‚îÇ${RESET}  ${GRAY}docker exec -i $MIGRATION_TARGET_CONTAINER psql -U $MIGRATION_TARGET_USER < backup.sql${RESET}"
    echo -e "${RED}${BOLD}‚îÇ${RESET}                                                                    ${RED}${BOLD}‚îÇ${RESET}"
    echo -e "${RED}${BOLD}‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò${RESET}"
    echo ""
}

# --- –§—É–Ω–∫—Ü–∏—è: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –º–∏–≥—Ä–∞—Ü–∏—è (–ø–æ—à–∞–≥–æ–≤–∞—è —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è–º–∏) ---
migration_run_automatic() {
    clear_screen
    echo -e "${GREEN}${BOLD}‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê${RESET}"
    echo -e "${GREEN}${BOLD}‚îÇ  üöÄ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ú–ò–ì–†–ê–¶–ò–Ø                                        ‚îÇ${RESET}"
    echo -e "${GREEN}${BOLD}‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò${RESET}"
    echo ""
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∏
    if [[ -z "$MIGRATION_SOURCE_TYPE" || -z "$MIGRATION_SOURCE_BACKUP" ]]; then
        print_message "ERROR" "–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –∞—Ä—Ö–∏–≤ Bedolaga (–ø—É–Ω–∫—Ç 2)"
        return 1
    fi
    
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        print_message "ERROR" "–°–Ω–∞—á–∞–ª–∞ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—Ä–∏—ë–º–Ω–∏–∫ (–ø—É–Ω–∫—Ç 3)"
        return 1
    fi
    
    echo "–ë—É–¥—É—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è:"
    echo ""
    echo "  [1/9] üè• Healthcheck –∞—Ä—Ö–∏–≤–∞ –∏ –ë–î"
    echo "  [2/9] üîç –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏–≤–∞ Bedolaga"
    echo "  [3/9] üíæ –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –ë–î RWP-Shop"
    echo "  [4/9] üì§ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∞—Ä—Ö–∏–≤–∞"
    echo "  [5/9] üí∞ –ê–Ω–∞–ª–∏–∑ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞–ª–∞–Ω—Å–æ–≤"
    echo "  [6/9] üîÑ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"
    echo "  [7/9] üì• –ò–º–ø–æ—Ä—Ç –≤ RWP-Shop"
    echo "  [8/9] üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–µ—Ä–µ–Ω–æ—Å–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
    echo "  [9/9] üìã –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ + –§–∏–Ω–∞–ª—å–Ω—ã–π healthcheck"
    echo ""
    
    echo -e "${YELLOW}‚ö†Ô∏è  –ü–û–í–ï–î–ï–ù–ò–ï –ü–†–ò –ö–û–ù–§–õ–ò–ö–¢–ê–•:${RESET}"
    echo "  ‚Ä¢ customer: –ü—Ä–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏ telegram_id ‚Üí –û–ë–ù–û–í–ò–¢ username, –∏–º—è, —Å—Ç–∞—Ç—É—Å"
    echo "  ‚Ä¢ promo: –ü—Ä–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏ code ‚Üí –û–ë–ù–û–í–ò–¢ —Å—á—ë—Ç—á–∏–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π"
    echo "  ‚Ä¢ purchase: –ü—Ä–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏ id ‚Üí –ü–†–û–ü–£–°–¢–ò–¢ (ON CONFLICT DO NOTHING)"
    echo "  ‚Ä¢ referral: –ü—Ä–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏ ‚Üí –ü–†–û–ü–£–°–¢–ò–¢"
    echo "  ‚Ä¢ –ë–∞–ª–∞–Ω—Å—ã –ù–ï –ø–µ—Ä–µ–Ω–æ—Å—è—Ç—Å—è (—Å–æ—Ö—Ä–∞–Ω—è—Ç—Å—è –≤ NOT_MIGRATED/)"
    echo ""
    
    read -erp "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/N): " confirm
    [[ ! "$confirm" =~ ^[Yy]$ ]] && return 0
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    MIGRATION_WORK_DIR="${BACKUP_DIR}/migration_$(date +%Y%m%d_%H%M%S)"
    mkdir -p "$MIGRATION_WORK_DIR"
    migration_create_not_migrated_dir
    
    local start_time=$(date +%s)
    
    # [1/9] HEALTHCHECK (–∞—Ä—Ö–∏–≤ + –ë–î)
    echo ""
    print_message "INFO" "[1/9] Healthcheck –∞—Ä—Ö–∏–≤–∞ –∏ –ë–î..."
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä—Ö–∏–≤–∞
    if ! migration_healthcheck_archive "$MIGRATION_SOURCE_BACKUP" "true"; then
        print_message "ERROR" "–ê—Ä—Ö–∏–≤ –Ω–µ –ø—Ä–æ—à—ë–ª –ø—Ä–æ–≤–µ—Ä–∫—É!"
        read -erp "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –æ—à–∏–±–∫–∏? (y/N): " force_archive
        [[ ! "$force_archive" =~ ^[Yy]$ ]] && return 1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ë–î
    if ! migration_healthcheck_db_pre "true"; then
        print_message "ERROR" "–ë–î –Ω–µ –ø—Ä–æ—à–ª–∞ –ø—Ä–æ–≤–µ—Ä–∫—É!"
        read -erp "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –æ—à–∏–±–∫–∏? (y/N): " force_db
        [[ ! "$force_db" =~ ^[Yy]$ ]] && return 1
    fi
    
    print_message "SUCCESS" "Healthcheck –ø—Ä–æ–π–¥–µ–Ω"
    
    # [2/9] –ê–Ω–∞–ª–∏–∑
    print_message "INFO" "[2/9] –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏–≤–∞ Bedolaga..."
    if ! migration_quick_analyze "$MIGRATION_SOURCE_BACKUP" > /dev/null; then
        print_message "ERROR" "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∞—Ä—Ö–∏–≤–∞"
        return 1
    fi
    print_message "SUCCESS" "–ê—Ä—Ö–∏–≤ –≤–∞–ª–∏–¥–µ–Ω"
    
    # [3/9] –ë—ç–∫–∞–ø –ë–î
    print_message "INFO" "[3/9] –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –ë–î RWP-Shop..."
    if ! migration_backup_target_db; then
        echo -e "${YELLOW}–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –±–µ–∑ –±—ç–∫–∞–ø–∞? (y/N):${RESET} "
        read -r skip_backup
        [[ ! "$skip_backup" =~ ^[Yy]$ ]] && return 1
    fi
    
    # [4/9] –≠–∫—Å–ø–æ—Ä—Ç
    print_message "INFO" "[4/9] –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∞—Ä—Ö–∏–≤–∞..."
    if ! migrate_export_data; then
        print_message "ERROR" "–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞!"
        return 1
    fi
    
    # Healthcheck CSV –ø–æ—Å–ª–µ —ç–∫—Å–ø–æ—Ä—Ç–∞
    print_message "INFO" "      –ü—Ä–æ–≤–µ—Ä–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö..."
    if ! migration_healthcheck_csv "$MIGRATION_WORK_DIR/export" "false"; then
        print_message "WARN" "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ CSV"
    fi
    
    # [5/9] –ë–∞–ª–∞–Ω—Å—ã
    print_message "INFO" "[5/9] –ê–Ω–∞–ª–∏–∑ –±–∞–ª–∞–Ω—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π..."
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º export_csv –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    BALANCE_HANDLING_MODE="export_csv"
    if ! migrate_handle_balances; then
        print_message "WARN" "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –±–∞–ª–∞–Ω—Å–æ–≤"
    fi
    
    # [6/9] –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è
    print_message "INFO" "[6/9] –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö..."
    if ! migrate_transform_data; then
        print_message "ERROR" "–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏!"
        return 1
    fi
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –±–∞–ª–∞–Ω—Å–æ–≤
    migrate_apply_balance_handling 2>/dev/null
    
    # Healthcheck —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö CSV (–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è import)
    print_message "INFO" "      –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö..."
    if ! migration_healthcheck_csv "$MIGRATION_WORK_DIR/import" "false"; then
        print_message "WARN" "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏"
    fi
    
    # [7/9] –ò–º–ø–æ—Ä—Ç - —Ç—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è!
    migration_show_import_warning
    
    read -erp "–í–≤–µ–¥–∏—Ç–µ 'IMPORT' –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∏–º–ø–æ—Ä—Ç–∞: " import_confirm
    if [[ "$import_confirm" != "IMPORT" ]]; then
        print_message "INFO" "–ò–º–ø–æ—Ä—Ç –æ—Ç–º–µ–Ω—ë–Ω. –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤: $MIGRATION_WORK_DIR"
        return 0
    fi
    
    print_message "INFO" "[7/9] –ò–º–ø–æ—Ä—Ç –≤ RWP-Shop..."
    if ! migrate_import_data; then
        print_message "ERROR" "–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞!"
        echo ""
        echo -e "${YELLOW}–î–ª—è –æ—Ç–∫–∞—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±—ç–∫–∞–ø:${RESET}"
        echo "  docker exec -i $MIGRATION_TARGET_CONTAINER psql -U $MIGRATION_TARGET_USER $MIGRATION_TARGET_DB < $MIGRATION_AUTO_BACKUP"
        return 1
    fi
    
    # [8/9] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–µ—Ä–µ–Ω–æ—Å–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    print_message "INFO" "[8/9] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–µ—Ä–µ–Ω–æ—Å–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö..."
    migration_save_not_migrated_data
    
    # [9/9] –û—Ç—á—ë—Ç + –§–∏–Ω–∞–ª—å–Ω—ã–π healthcheck
    print_message "INFO" "[9/9] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ + –§–∏–Ω–∞–ª—å–Ω—ã–π healthcheck..."
    migrate_generate_report
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π healthcheck –ë–î
    migration_healthcheck_db_post "true"
    
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    echo ""
    echo -e "${GREEN}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo -e "${GREEN}${BOLD}  ‚úÖ –ú–ò–ì–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!                                            ${RESET}"
    echo -e "${GREEN}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo ""
    echo "  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: ${duration}—Å"
    echo "  –†–∞–±–æ—á–∞—è –ø–∞–ø–∫–∞: $MIGRATION_WORK_DIR"
    [[ -d "$MIGRATION_NOT_MIGRATED_DIR" ]] && echo "  –ù–µ–ø–µ—Ä–µ–Ω–æ—Å–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ: $MIGRATION_NOT_MIGRATED_DIR"
    echo ""
    echo -e "${YELLOW}‚ö†Ô∏è  –ù–µ –∑–∞–±—É–¥—å—Ç–µ:${RESET}"
    echo "  ‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–±–æ—Ç—É –±–æ—Ç–∞"
    echo "  ‚Ä¢ –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞: docker compose restart"
    echo ""
    
    log_message "SUCCESS" "Migration completed in ${duration}s: Bedolaga ‚Üí RWP-Shop"
    
    return 0
}

# --- –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é –º–∏–≥—Ä–∞—Ü–∏–∏ ---
menu_migration() {
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º disclaimer –æ–¥–∏–Ω —Ä–∞–∑
    migration_show_disclaimer
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    MIGRATION_WORK_DIR="${BACKUP_DIR}/migration_$(date +%Y%m%d_%H%M%S)"
    
    # –ê–≤—Ç–æ–ø–æ–∏—Å–∫ –∞—Ä—Ö–∏–≤–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—Ö–æ–¥–µ
    if [[ -z "$MIGRATION_SOURCE_BACKUP" ]]; then
        local auto_archive
        auto_archive=$(migration_auto_find_archive)
        if [[ -n "$auto_archive" ]]; then
            MIGRATION_SOURCE_BACKUP="$auto_archive"
            MIGRATION_SOURCE_TYPE="archive"
            # –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏–∑
            MIGRATION_DATA_ANALYSIS=$(migration_quick_analyze "$auto_archive" 2>/dev/null)
        fi
    fi
    
    # –ê–≤—Ç–æ–ø–æ–∏—Å–∫ –ø—Ä–∏—ë–º–Ω–∏–∫–∞
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        for pattern in "rwp_shop_db" "telegram-shop-db"; do
            MIGRATION_TARGET_CONTAINER=$(docker ps --format '{{.Names}}' 2>/dev/null | grep -iE "^$pattern$" | head -1)
            [[ -n "$MIGRATION_TARGET_CONTAINER" ]] && break
        done
        MIGRATION_TARGET_DB="${MIGRATION_TARGET_DB:-postgres}"
        MIGRATION_TARGET_USER="${MIGRATION_TARGET_USER:-postgres}"
    fi
    
    while true; do
        clear_screen
        echo -e "${MAGENTA}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
        echo -e "${MAGENTA}${BOLD}       üîÑ –ú–ò–ì–†–ê–¶–ò–Ø: Bedolaga ‚Üí RWP-Shop Private                    ${RESET}"
        echo -e "${MAGENTA}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
        echo ""
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å
        migration_show_status
        echo ""
        
        # –ú–µ–Ω—é
        echo -e " ${GREEN}‚îÄ‚îÄ‚îÄ –ë–´–°–¢–†–´–ô –°–¢–ê–†–¢ ‚îÄ‚îÄ‚îÄ${RESET}"
        echo -e " ${GREEN}${BOLD} 1. üöÄ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ú–ò–ì–†–ê–¶–ò–Ø${RESET} (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)"
        echo -e "    ${GRAY}–ü–µ—Ä–µ–Ω–µ—Å—ë—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ${RESET}"
        echo ""
        
        echo " ‚îÄ‚îÄ‚îÄ –ü–û–®–ê–ì–û–í–´–ô –†–ï–ñ–ò–ú ‚îÄ‚îÄ‚îÄ"
        echo " 2. üì• –í—ã–±—Ä–∞—Ç—å –∞—Ä—Ö–∏–≤ Bedolaga"
        echo " 3. üéØ –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–∏—ë–º–Ω–∏–∫ (RWP-Shop)"
        echo " 4. üìä –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–µ–≤—å—é –º–∏–≥—Ä–∞—Ü–∏–∏)"
        echo -e " 5. üè• ${CYAN}Healthcheck${RESET} (–ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∞—Ä—Ö–∏–≤ –∏ –ë–î)"
        echo ""
        
        echo " ‚îÄ‚îÄ‚îÄ –†–£–ß–ù–û–ï –£–ü–†–ê–í–õ–ï–ù–ò–ï ‚îÄ‚îÄ‚îÄ"
        echo " 6. ‚ñ∂Ô∏è  –¢–æ–ª—å–∫–æ —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö"
        echo " 7. üîÑ –¢–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è"
        echo " 8. üì• –¢–æ–ª—å–∫–æ –∏–º–ø–æ—Ä—Ç –≤ –ë–î"
        echo " 9. üí∞ –ê–Ω–∞–ª–∏–∑ –±–∞–ª–∞–Ω—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
        echo ""
        
        echo -e " ‚îÄ‚îÄ‚îÄ –ù–ê–°–¢–†–û–ô–ö–ò ‚îÄ‚îÄ‚îÄ"
        echo -e " ${CYAN}10. ‚öôÔ∏è  –ú–∏–≥—Ä–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –±–æ—Ç–∞${RESET}"
        echo ""
        
        echo " ‚îÄ‚îÄ‚îÄ –ü–û–°–õ–ï –ú–ò–ì–†–ê–¶–ò–ò ‚îÄ‚îÄ‚îÄ"
        echo " 11. üìã –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç—á—ë—Ç"
        echo " 12. üìÅ –û—Ç–∫—Ä—ã—Ç—å –ø–∞–ø–∫—É NOT_MIGRATED"
        echo ""
        
        echo " 0. ‚Üê –ù–∞–∑–∞–¥ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"
        echo ""
        read -erp "–í—ã–±–æ—Ä (Enter - –ù–∞–∑–∞–¥): " opt
        [[ -z "$opt" || "$opt" == "q" || "$opt" == "Q" ]] && return
        
        case "$opt" in
            1)
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –º–∏–≥—Ä–∞—Ü–∏—è
                migration_run_automatic
                read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
                ;;
            2)
                # –í—ã–±–æ—Ä –∞—Ä—Ö–∏–≤–∞ (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0 –ø—Ä–∏ –≤—ã–±–æ—Ä–µ, 1 –ø—Ä–∏ –æ—Ç–º–µ–Ω–µ)
                migration_select_archive
                ;;
            3)
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–∏—ë–º–Ω–∏–∫–∞
                migrate_configure_target
                ;;
            4)
                # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
                migration_show_detailed_analysis
                read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
                ;;
            5)
                # Healthcheck
                migration_healthcheck_full "true"
                read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
                ;;
            6)
                # –¢–æ–ª—å–∫–æ —ç–∫—Å–ø–æ—Ä—Ç
                if [[ -z "$MIGRATION_SOURCE_TYPE" ]]; then
                    print_message "ERROR" "–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –∞—Ä—Ö–∏–≤ (–ø—É–Ω–∫—Ç 2)"
                    read -erp "Enter..." dummy
                    continue
                fi
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–±–æ—á—É—é –ø–∞–ø–∫—É –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–∞
                if [[ -z "$MIGRATION_WORK_DIR" ]]; then
                    MIGRATION_WORK_DIR="${BACKUP_DIR}/migration_$(date +%Y%m%d_%H%M%S)"
                fi
                mkdir -p "$MIGRATION_WORK_DIR"
                
                echo ""
                echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –®–ê–ì 1/3: –≠–ö–°–ü–û–†–¢ –î–ê–ù–ù–´–• ‚ïê‚ïê‚ïê${RESET}"
                echo -e "${GRAY}–ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∞—Ä—Ö–∏–≤–∞ Bedolaga –≤ CSV —Ñ–∞–π–ª—ã${RESET}"
                echo ""
                
                migrate_export_data
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º healthcheck CSV –ø–æ—Å–ª–µ —ç–∫—Å–ø–æ—Ä—Ç–∞
                migration_healthcheck_csv "$MIGRATION_WORK_DIR/export" "true"
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ç–æ–≥
                echo ""
                echo -e "${GREEN}${BOLD}‚ïê‚ïê‚ïê –≠–ö–°–ü–û–†–¢ –ó–ê–í–ï–†–®–Å–ù ‚ïê‚ïê‚ïê${RESET}"
                echo ""
                echo -e "  üìÅ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:"
                echo -e "     ${CYAN}$MIGRATION_WORK_DIR/export/${RESET}"
                echo ""
                echo -e "  üìã –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:"
                echo -e "     ${YELLOW}–ü—É–Ω–∫—Ç 7${RESET} ‚Üí –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è (–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤)"
                echo ""
                read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
                ;;
            7)
                # –¢–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è
                if [[ -z "$MIGRATION_WORK_DIR" || ! -d "$MIGRATION_WORK_DIR/export" ]]; then
                    print_message "ERROR" "–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —ç–∫—Å–ø–æ—Ä—Ç (–ø—É–Ω–∫—Ç 6)"
                    if [[ -n "$MIGRATION_WORK_DIR" ]]; then
                        debug_log "MIGRATE" "Export dir not found: $MIGRATION_WORK_DIR/export"
                    fi
                    read -erp "Enter..." dummy
                    continue
                fi
                
                echo ""
                echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –®–ê–ì 2/3: –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–Ø ‚ïê‚ïê‚ïê${RESET}"
                echo -e "${GRAY}–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ñ–æ—Ä–º–∞—Ç—ã Bedolaga ‚Üí RWP-Shop${RESET}"
                echo ""
                
                migrate_transform_data
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º healthcheck CSV –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è import)
                migration_healthcheck_csv "$MIGRATION_WORK_DIR/import" "true"
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ç–æ–≥
                echo ""
                echo -e "${GREEN}${BOLD}‚ïê‚ïê‚ïê –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê ‚ïê‚ïê‚ïê${RESET}"
                echo ""
                echo -e "  üìÅ –§–∞–π–ª—ã –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞:"
                echo -e "     ${CYAN}$MIGRATION_WORK_DIR/import/${RESET}"
                echo ""
                echo -e "  üìã –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:"
                echo -e "     ${YELLOW}–ü—É–Ω–∫—Ç 8${RESET} ‚Üí –ò–º–ø–æ—Ä—Ç –≤ –ë–î RWP-Shop"
                echo ""
                read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
                ;;
            8)
                # –¢–æ–ª—å–∫–æ –∏–º–ø–æ—Ä—Ç
                if [[ -z "$MIGRATION_WORK_DIR" || ! -d "$MIGRATION_WORK_DIR/import" ]]; then
                    print_message "ERROR" "–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é (–ø—É–Ω–∫—Ç 7)"
                    read -erp "Enter..." dummy
                    continue
                fi
                if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
                    print_message "ERROR" "–°–Ω–∞—á–∞–ª–∞ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—Ä–∏—ë–º–Ω–∏–∫ (–ø—É–Ω–∫—Ç 3)"
                    read -erp "Enter..." dummy
                    continue
                fi
                
                echo ""
                echo -e "${CYAN}${BOLD}‚ïê‚ïê‚ïê –®–ê–ì 3/3: –ò–ú–ü–û–†–¢ –í –ë–î ‚ïê‚ïê‚ïê${RESET}"
                echo -e "${GRAY}–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ PostgreSQL RWP-Shop${RESET}"
                echo ""
                
                # Healthcheck –ë–î –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º
                migration_healthcheck_db_pre "true"
                
                # –°–æ–∑–¥–∞—ë–º –±—ç–∫–∞–ø –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º
                migration_backup_target_db
                migration_show_import_warning
                
                read -erp "–í–≤–µ–¥–∏—Ç–µ 'IMPORT' –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è: " confirm
                if [[ "$confirm" == "IMPORT" ]]; then
                    migrate_import_data
                    # Healthcheck –ë–î –ø–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–∞
                    migration_healthcheck_db_post "true"
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ç–æ–≥
                    echo ""
                    echo -e "${GREEN}${BOLD}‚ïê‚ïê‚ïê –ú–ò–ì–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê ‚ïê‚ïê‚ïê${RESET}"
                    echo ""
                    echo -e "  ‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ RWP-Shop"
                    echo ""
                    echo -e "  üìã –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:"
                    echo -e "     ‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–±–æ—Ç—É –±–æ—Ç–∞"
                    echo -e "     ‚Ä¢ –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø—É–Ω–∫—Ç ${YELLOW}12${RESET} (NOT_MIGRATED) –¥–ª—è –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
                    echo ""
                else
                    print_message "INFO" "–ò–º–ø–æ—Ä—Ç –æ—Ç–º–µ–Ω—ë–Ω"
                fi
                read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
                ;;
            9)
                # –ê–Ω–∞–ª–∏–∑ –±–∞–ª–∞–Ω—Å–æ–≤
                if [[ -z "$MIGRATION_SOURCE_TYPE" ]]; then
                    print_message "ERROR" "–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –∞—Ä—Ö–∏–≤ (–ø—É–Ω–∫—Ç 2)"
                    read -erp "Enter..." dummy
                    continue
                fi
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–±–æ—á—É—é –ø–∞–ø–∫—É –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–∞
                if [[ -z "$MIGRATION_WORK_DIR" ]]; then
                    MIGRATION_WORK_DIR="${BACKUP_DIR}/migration_$(date +%Y%m%d_%H%M%S)"
                fi
                mkdir -p "$MIGRATION_WORK_DIR"
                # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∞—Ä—Ö–∏–≤ –µ—Å–ª–∏ –µ—â—ë –Ω–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω
                if [[ "$MIGRATION_SOURCE_TYPE" == "archive" ]]; then
                    if [[ -z "$MIGRATION_EXTRACTED_DIR" || ! -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
                        if ! extract_bedolaga_backup "$MIGRATION_SOURCE_BACKUP"; then
                            print_message "ERROR" "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –∞—Ä—Ö–∏–≤"
                            read -erp "Enter..." dummy
                            continue
                        fi
                    fi
                fi
                if migrate_handle_balances; then
                    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª –¥–µ–π—Å—Ç–≤–∏–µ, –ø—Ä–∏–º–µ–Ω—è–µ–º
                    if [[ -n "$BALANCE_HANDLING_MODE" && "$BALANCE_HANDLING_MODE" != "none" ]]; then
                        migrate_apply_balance_handling
                    fi
                    read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
                fi
                # –ï—Å–ª–∏ return 1 (–Ω–∞–∑–∞–¥) ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ü–∏–∫–ª –º–µ–Ω—é
                ;;
            10)
                # –ú–∏–≥—Ä–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
                menu_migrate_settings
                ;;
            11)
                # –ü–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç—á—ë—Ç
                local report_file="$MIGRATION_WORK_DIR/migration_report.txt"
                if [[ -f "$report_file" ]]; then
                    clear_screen
                    cat "$report_file"
                else
                    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç—á—ë—Ç
                    local latest_report=$(find "$BACKUP_DIR" -name "migration_report.txt" -type f 2>/dev/null | head -1)
                    if [[ -n "$latest_report" ]]; then
                        clear_screen
                        cat "$latest_report"
                    else
                        print_message "WARN" "–û—Ç—á—ë—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –º–∏–≥—Ä–∞—Ü–∏—é."
                    fi
                fi
                read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
                ;;
            12)
                # –û—Ç–∫—Ä—ã—Ç—å –ø–∞–ø–∫—É NOT_MIGRATED
                local not_migrated_dir="$MIGRATION_WORK_DIR/NOT_MIGRATED"
                if [[ -d "$not_migrated_dir" ]]; then
                    echo ""
                    echo "–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–ø–∫–∏ NOT_MIGRATED:"
                    echo ""
                    ls -la "$not_migrated_dir"
                    echo ""
                    echo "–ü—É—Ç—å: $not_migrated_dir"
                else
                    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–∞–ø–∫—É
                    local latest_dir=$(find "$BACKUP_DIR" -name "NOT_MIGRATED" -type d 2>/dev/null | head -1)
                    if [[ -n "$latest_dir" ]]; then
                        echo ""
                        echo "–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–ø–∫–∏ NOT_MIGRATED:"
                        echo ""
                        ls -la "$latest_dir"
                        echo ""
                        echo "–ü—É—Ç—å: $latest_dir"
                    else
                        print_message "WARN" "–ü–∞–ø–∫–∞ NOT_MIGRATED –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."
                        echo "–û–Ω–∞ —Å–æ–∑–¥–∞—ë—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –º–∏–≥—Ä–∞—Ü–∏–∏."
                    fi
                fi
                read -erp "–ù–∞–∂–º–∏—Ç–µ Enter..." dummy
                ;;
            0) return ;;
        esac
    done
}

cleanup_old_backups() {
    clear_screen; echo -e "${RED}–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤${RESET}"
    
    local del_full=0; local del_db=0; local del_files=0
    local size_exceeded=false

    echo -e "–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º –æ—á–∏—Å—Ç–∫–∏: ${YELLOW}$DELETE_MODE${RESET}"
    if [[ "$DELETE_MODE" == "count" ]]; then
        echo "–õ–∏–º–∏—Ç —Ö—Ä–∞–Ω–µ–Ω–∏—è: $MAX_BACKUPS_COUNT —à—Ç."
    else
        echo -e "–°—Ä–æ–∫ —Ö—Ä–∞–Ω–µ–Ω–∏—è: ${YELLOW}$RETENTION_DAYS –¥–Ω–µ–π${RESET}"
    fi
    echo -e "–õ–∏–º–∏—Ç —Ä–∞–∑–º–µ—Ä–∞: ${YELLOW}$(format_size_mb "$MAX_BACKUP_SIZE_MB")${RESET}"
    echo ""
    
    if [[ "$DELETE_MODE" == "count" ]]; then
        del_full=$(rotate_backups_by_count "lazarus_full" "–ü–æ–ª–Ω—ã–µ –±—ç–∫–∞–ø—ã" "false" | tail -n1)
        del_db=$(rotate_backups_by_count "lazarus_db" "–ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö" "false" | tail -n1)
        del_files=$(rotate_backups_by_count "lazarus_files" "–ê—Ä—Ö–∏–≤—ã —Ñ–∞–π–ª–æ–≤" "false" | tail -n1)
    else
        # time-based
        del_full=$(rotate_backups_by_age "lazarus_full" "–ü–æ–ª–Ω—ã–µ –±—ç–∫–∞–ø—ã" "$RETENTION_DAYS" "false" | tail -n1)
        del_db=$(rotate_backups_by_age "lazarus_db" "–ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö" "$RETENTION_DAYS" "false" | tail -n1)
        del_files=$(rotate_backups_by_age "lazarus_files" "–ê—Ä—Ö–∏–≤—ã —Ñ–∞–π–ª–æ–≤" "$RETENTION_DAYS" "false" | tail -n1)
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞ (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å)
    if [[ -n "$MAX_BACKUP_SIZE_MB" && "$MAX_BACKUP_SIZE_MB" != "0" ]]; then
        local current_size_bytes=$(du -sb "$BACKUP_DIR" 2>/dev/null | awk '{print $1}')
        local limit_bytes=$((MAX_BACKUP_SIZE_MB * 1024 * 1024))
        if [[ $current_size_bytes -gt $limit_bytes ]]; then
            size_exceeded=true
            rotate_backups_by_size "false"  # –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è
        else
            rotate_backups_by_size "false"  # –ü–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ª–∏–º–∏—Ç–∞
        fi
    fi

    echo ""
    # normalize empty to 0
    del_full=${del_full:-0}; del_db=${del_db:-0}; del_files=${del_files:-0}
    local total_del=$((del_full + del_db + del_files))

    if [[ "$total_del" -eq 0 && "$size_exceeded" != "true" ]]; then
        print_message "SUCCESS" "–ß–∏—Å—Ç–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è. –í—Å–µ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ª–∏–º–∏—Ç–∞."
        read -erp "Enter..." dummy
        return
    fi

    if [[ "$DRY_RUN" == "true" ]]; then
        print_message "WARN" "[DRY-RUN] –ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ: $total_del"
    else
        if [[ "$size_exceeded" == "true" ]]; then
            print_message "WARN" "–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç —Ä–∞–∑–º–µ—Ä–∞! –°—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã."
        fi
        if [[ "$total_del" -gt 0 ]]; then
            print_message "WARN" "–ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –∞—Ä—Ö–∏–≤–æ–≤: $total_del"
        fi
    fi
    # support non-interactive auto-confirm
    if [[ "$AUTO_CONFIRM" == "true" ]]; then
        confirm="y"
    else
        read -erp "–£–¥–∞–ª–∏—Ç—å —ç—Ç–∏ —Ñ–∞–π–ª—ã? (y/N): " confirm
    fi

    if [[ "$DRY_RUN" == "true" ]]; then
        # In dry-run we never delete
        log_message "INFO" "[DRY_RUN] Cleanup preview (mode=$DELETE_MODE, retention_days=$RETENTION_DAYS, max_count=$MAX_BACKUPS_COUNT, candidates=$total_del)"
        if [[ "$REPORT_TO_TG" == "true" && "$SEND_TO_TELEGRAM" == "true" ]]; then
            send_telegram_text "$(escape_markdown_v2 "üßπ DRY-RUN –æ—á–∏—Å—Ç–∫–∞: –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤=$total_del, mode=$DELETE_MODE")"
        fi
        read -erp "Enter..." dummy
        return
    fi

    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        echo ""
        if [[ "$DELETE_MODE" == "count" ]]; then
            rotate_backups_by_count "lazarus_full" "–ü–æ–ª–Ω—ã–µ –±—ç–∫–∞–ø—ã" "true" > "$SILENT_LOG"
            rotate_backups_by_count "lazarus_db" "–ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö" "true" > "$SILENT_LOG"
            rotate_backups_by_count "lazarus_files" "–ê—Ä—Ö–∏–≤—ã —Ñ–∞–π–ª–æ–≤" "true" > "$SILENT_LOG"
        else
            rotate_backups_by_age "lazarus_full" "–ü–æ–ª–Ω—ã–µ –±—ç–∫–∞–ø—ã" "$RETENTION_DAYS" "true" > "$SILENT_LOG"
            rotate_backups_by_age "lazarus_db" "–ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö" "$RETENTION_DAYS" "true" > "$SILENT_LOG"
            rotate_backups_by_age "lazarus_files" "–ê—Ä—Ö–∏–≤—ã —Ñ–∞–π–ª–æ–≤" "$RETENTION_DAYS" "true" > "$SILENT_LOG"
        fi
        # –¢–∞–∫–∂–µ –æ—á–∏—Å—Ç–∫–∞ –ø–æ –ª–∏–º–∏—Ç—É —Ä–∞–∑–º–µ—Ä–∞
        if [[ "$size_exceeded" == "true" ]]; then
            rotate_backups_by_size "true"
        fi
        echo ""; print_message "SUCCESS" "–û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞."
        log_message "INFO" "Cleanup completed (mode=$DELETE_MODE, retention_days=$RETENTION_DAYS, max_count=$MAX_BACKUPS_COUNT, deleted=$total_del)"
        if [[ "$REPORT_TO_TG" == "true" && "$SEND_TO_TELEGRAM" == "true" ]]; then
            send_telegram_text "$(escape_markdown_v2 "üßπ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: —É–¥–∞–ª–µ–Ω–æ=$total_del, mode=$DELETE_MODE")"
        fi
    else
        echo ""; print_message "INFO" "–û—Ç–º–µ–Ω–µ–Ω–æ."
    fi
    read -erp "Enter..." dummy
}

# --- MAIN LOOP ---
rotate_internal_log
check_dependencies
install_script
load_or_create_config
check_config_mismatch # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
# --- Global CLI flags parsing ---
# Support calling like: lazarus --yes --dry-run cleanup
DRY_RUN="false"
REPORT_TO_TG="false"

# Build new argv stripping known global flags
_NEWARGS=()
for _a in "$@"; do
    case "$_a" in
        --yes|-y) AUTO_CONFIRM="true" ;;
        --dry-run|-n) DRY_RUN="true" ;;
        --report-tg) REPORT_TO_TG="true" ;;
        --debug|-d) DEBUG_MODE=true ;;
        *) _NEWARGS+=("$_a") ;;
    esac
done
set -- "${_NEWARGS[@]}"

# Debug mode banner
if [[ "$DEBUG_MODE" == true ]]; then
    SILENT_LOG="/dev/stderr"
    CURL_SILENT="-v"
    WGET_SILENT=""
    echo -e "${MAGENTA}${BOLD}‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó${RESET}"
    echo -e "${MAGENTA}${BOLD}‚ïë                    DEBUG MODE ENABLED                          ‚ïë${RESET}"
    echo -e "${MAGENTA}${BOLD}‚ïë  All operations will be logged in detail to console           ‚ïë${RESET}"
    echo -e "${MAGENTA}${BOLD}‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù${RESET}"
    echo ""
    echo -e "${CYAN}=== SYSTEM INFO ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} LAZARUS Version: $VERSION"
    echo -e "${MAGENTA}[DEBUG]${RESET} Bash Version: $BASH_VERSION"
    echo -e "${MAGENTA}[DEBUG]${RESET} User: $(whoami) (UID: $EUID)"
    echo -e "${MAGENTA}[DEBUG]${RESET} Hostname: $(hostname)"
    echo -e "${MAGENTA}[DEBUG]${RESET} Date: $(date '+%Y-%m-%d %H:%M:%S %Z')"
    echo ""
    echo -e "${CYAN}=== CONFIG ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Config file: $CONFIG_FILE"
    echo -e "${MAGENTA}[DEBUG]${RESET} Install dir: $INSTALL_DIR"
    echo -e "${MAGENTA}[DEBUG]${RESET} Backup dir: $BACKUP_DIR"
    echo -e "${MAGENTA}[DEBUG]${RESET} Log file: $LOG_FILE"
    echo ""
    echo -e "${CYAN}=== BOT CONFIG ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Bot path: ${BOT_PATH:-<not set>}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Bot container: ${BOT_CONTAINER_NAME:-<not set>}"
    echo -e "${MAGENTA}[DEBUG]${RESET} DB container: ${DB_CONTAINER_NAME:-<not set>}"
    echo -e "${MAGENTA}[DEBUG]${RESET} DB user: ${DB_USER:-postgres}"
    echo ""
    echo -e "${CYAN}=== TELEGRAM ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Notifications: $SEND_TO_TELEGRAM"
    echo -e "${MAGENTA}[DEBUG]${RESET} Send file: $TG_SEND_FILE"
    # –ú–∞—Å–∫–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 4 –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 —Å–∏–º–≤–æ–ª–∞
    _masked_token="<not set>"
    if [[ -n "$BOT_TOKEN" ]]; then
        if [[ ${#BOT_TOKEN} -gt 10 ]]; then
            _masked_token="${BOT_TOKEN:0:4}****${BOT_TOKEN: -4}"
        else
            _masked_token="<set>"
        fi
    fi
    echo -e "${MAGENTA}[DEBUG]${RESET} Bot token: $_masked_token"
    # –ú–∞—Å–∫–∏—Ä—É–µ–º Chat ID: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 4 –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–∏–º–≤–æ–ª–∞
    _masked_chat="<not set>"
    if [[ -n "$CHAT_ID" ]]; then
        if [[ ${#CHAT_ID} -gt 8 ]]; then
            _masked_chat="${CHAT_ID:0:4}***${CHAT_ID: -3}"
        else
            _masked_chat="<set>"
        fi
    fi
    echo -e "${MAGENTA}[DEBUG]${RESET} Chat ID: $_masked_chat"
    echo -e "${MAGENTA}[DEBUG]${RESET} Thread ID: ${TG_MESSAGE_THREAD_ID:-<not set>}"
    echo ""
    echo -e "${CYAN}=== REMOTE STORAGE ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Type: $REMOTE_STORAGE_TYPE"
    echo -e "${MAGENTA}[DEBUG]${RESET} Enabled: $SEND_TO_REMOTE"
    # –ú–∞—Å–∫–∏—Ä—É–µ–º URL: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Ç–æ–∫–æ–ª –∏ –¥–æ–º–µ–Ω
    _masked_url="<not set>"
    if [[ -n "$REMOTE_STORAGE_URL" ]]; then
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª –∏ —Ö–æ—Å—Ç, —Å–∫—Ä—ã–≤–∞–µ–º –ø—É—Ç—å –∏ –∫—Ä–µ–¥—ã
        _url_proto=$(echo "$REMOTE_STORAGE_URL" | grep -oP '^[a-z]+://' || echo "")
        _url_host=$(echo "$REMOTE_STORAGE_URL" | sed -E 's|^[a-z]+://([^@]*@)?([^/]+).*|\2|')
        if [[ -n "$_url_host" ]]; then
            _masked_url="${_url_proto}${_url_host}/***"
        else
            _masked_url="<set>"
        fi
    fi
    echo -e "${MAGENTA}[DEBUG]${RESET} URL: $_masked_url"
    echo ""
    echo -e "${CYAN}=== ROTATION ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Delete mode: $DELETE_MODE"
    echo -e "${MAGENTA}[DEBUG]${RESET} Retention days: $RETENTION_DAYS"
    echo -e "${MAGENTA}[DEBUG]${RESET} Max backups: $MAX_BACKUPS_COUNT"
    echo ""
    echo -e "${CYAN}=== ENCRYPTION ===${RESET}"
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —á—Ç–æ –ø–∞—Ä–æ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –±–µ–∑ —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è
    _masked_pass="<not set>"
    [[ -n "$BACKUP_PASSWORD" ]] && _masked_pass="<set> (${#BACKUP_PASSWORD} chars)"
    echo -e "${MAGENTA}[DEBUG]${RESET} Password: $_masked_pass"
    echo ""
    echo -e "${CYAN}=== EXCLUSIONS ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Exclude dirs: ${EXCLUDE_DIRS:-<none>}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Max file size: ${MAX_FILE_SIZE_MB} MB"
    echo ""
    echo -e "${CYAN}=== DEBUG OUTPUT SETTINGS ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} SILENT_LOG: $SILENT_LOG"
    echo -e "${MAGENTA}[DEBUG]${RESET} CURL_SILENT: $CURL_SILENT"
    echo -e "${MAGENTA}[DEBUG]${RESET} IS_INTERACTIVE: $IS_INTERACTIVE"
    echo ""
    echo -e "${MAGENTA}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
    echo ""
fi

case "$1" in
    backup_full) create_backup "full" ;;
    backup_db)   create_backup "db_only" ;;
    backup_files) create_backup "files_only" ;;
    cleanup|cleanup_old_backups)
        cleanup_old_backups ;;
    restore) menu_restore ;;
    check_update) check_for_updates ;;
    *)
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è cron –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
        check_cron_mismatch
        
        while true; do
            # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—É—Å—ã –∏–∑ cron
            CRON_STATUS_FULL=$(get_cron_status "full")
            CRON_STATUS_DB=$(get_cron_status "db")
            CRON_STATUS_FILES=$(get_cron_status "files")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±—ç–∫–∞–ø–æ–≤
            get_backup_stats
            
            # –¶–≤–µ—Ç–æ–≤–∞—è –∏–Ω–¥–∏–∫–∞—Ü–∏—è —Å—Ç–∞—Ç—É—Å–æ–≤ cron
            # Full –∏ DB ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ (–∫—Ä–∞—Å–Ω—ã–µ –µ—Å–ª–∏ –≤—ã–∫–ª—é—á–µ–Ω—ã –æ–±–∞), Files ‚Äî –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π (—Å–µ—Ä—ã–π –µ—Å–ª–∏ –≤—ã–∫–ª—é—á–µ–Ω)
            NO_CRITICAL_BACKUP=false
            [[ "$CRON_STATUS_FULL" == "–í—ã–∫–ª" && "$CRON_STATUS_DB" == "–í—ã–∫–ª" ]] && NO_CRITICAL_BACKUP=true
            
            COLOR_FULL="$GRAY"; [[ "$CRON_STATUS_FULL" != "–í—ã–∫–ª" ]] && COLOR_FULL="$YELLOW"
            COLOR_DB="$GRAY"; [[ "$CRON_STATUS_DB" != "–í—ã–∫–ª" ]] && COLOR_DB="$YELLOW"
            COLOR_FILES="$GRAY"; [[ "$CRON_STATUS_FILES" != "–í—ã–∫–ª" ]] && COLOR_FILES="$YELLOW"
            
            BOT_VERSION=$(get_bot_version_display)
            CONTAINER_STATUS=$(get_container_status)
            
            # –¶–≤–µ—Ç —Å—Ç–∞—Ç—É—Å–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
            STATUS_COLOR="$GREEN"
            [[ "$CONTAINER_STATUS" != "Online" ]] && STATUS_COLOR="$RED"
            
            clear_screen
            echo -e "${GREEN}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
            echo -e "${GREEN}${BOLD}  LAZARUS Backup Manager v${VERSION}${RESET}"
            echo -e "${GREEN}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
            echo -e "–ë–æ—Ç: ${CYAN}${BOT_VERSION}${RESET} | –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä: ${STATUS_COLOR}${CONTAINER_STATUS}${RESET}"
            echo ""
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±—ç–∫–∞–ø–æ–≤
            echo -e "–ë—ç–∫–∞–ø—ã: ${STATS_FULL} Full | ${STATS_DB} DB | ${STATS_FILES} Files | ${BOLD}${STATS_SIZE}${RESET} –≤—Å–µ–≥–æ"
            if [[ -n "$STATS_LAST" ]]; then
                echo -e "–ü–æ—Å–ª–µ–¥–Ω–∏–π: ${STATS_LAST} (${STATS_LAST_AGO})"
            fi
            echo ""
            
            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∞–≤—Ç–æ-–±—ç–∫–∞–ø–æ–≤
            if [[ "$NO_CRITICAL_BACKUP" == true ]]; then
                echo -e "${RED}${BOLD}‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ê–≤—Ç–æ-–±—ç–∫–∞–ø –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!${RESET}"
                echo -e "${RED}   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤–∫–ª—é—á–∏—Ç—å Full –∏–ª–∏ DB –±—ç–∫–∞–ø${RESET}"
                echo ""
            fi
            
            echo -e "–ê–≤—Ç–æ-–±—ç–∫–∞–ø (cron):"
            echo -e " ‚Ä¢ Full:  ${COLOR_FULL}${CRON_STATUS_FULL}${RESET}"
            echo -e " ‚Ä¢ DB:    ${COLOR_DB}${CRON_STATUS_DB}${RESET}"
            echo -e " ‚Ä¢ Files: ${COLOR_FILES}${CRON_STATUS_FILES}${RESET}"
            echo ""
            echo " --- –î–ï–ô–°–¢–í–ò–Ø ---"
            echo " 1. –†—É—á–Ω–æ–π –±–µ–∫–∞–ø (Full / DB / Files)"
            echo " 2. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–≤—Ç–æ-–±–µ–∫–∞–ø"
            echo " 3. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑ –±—ç–∫–∞–ø–∞"
            echo " 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ (–ü—É—Ç–∏ / –¢–æ–∫–µ–Ω—ã / –†–æ—Ç–∞—Ü–∏—è)"
            
            CLEANUP_LABEL=""
            if [[ "$DELETE_MODE" == "time" ]]; then
                CLEANUP_LABEL="(>$RETENTION_DAYS –¥–Ω–µ–π)"
            else
                CLEANUP_LABEL="(>$MAX_BACKUPS_COUNT —à—Ç.)"
            fi
            echo " 5. –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã $CLEANUP_LABEL"
            echo -e " 6. ${CYAN}–û–±–Ω–æ–≤–∏—Ç—å –±–æ—Ç–∞${RESET}"
            echo -e " 7. ${MAGENTA}–ú–∏–≥—Ä–∞—Ü–∏—è –º–µ–∂–¥—É –±–æ—Ç–∞–º–∏${RESET}"
            echo ""
            echo -e " 8. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–∫—Ä–∏–ø—Ç–∞"
            echo -e "${RED} 666. –£–¥–∞–ª–∏—Ç—å —Å–∫—Ä–∏–ø—Ç (Uninstall)${RESET}"
            echo " 0. –í—ã—Ö–æ–¥"
            echo ""
            read -erp "–í—ã–±–æ—Ä (Enter - –≤—ã—Ö–æ–¥): " opt; [[ -z "$opt" ]] && exit 0
            case $opt in
                1) menu_manual_backup ;; 2) menu_automation ;; 3) menu_restore ;; 
                4) menu_settings ;; 5) cleanup_old_backups ;; 6) update_bot ;; 
                7) menu_migration ;; 8) check_for_updates ;; 666) uninstall_script ;; 0) exit 0 ;;
            esac
        done
        ;;
esac
