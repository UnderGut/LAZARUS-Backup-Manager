#!/bin/bash

# --- ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜ ---
VERSION="4.29.1-dev"
SCRIPT_NAME="lazarus"
INSTALL_DIR="/opt/lazarus-backup"
BACKUP_DIR="$INSTALL_DIR/backup"
CONFIG_FILE="$INSTALL_DIR/config.env"
SYMLINK_PATH="/usr/local/bin/$SCRIPT_NAME"
REMOTE_URL="https://raw.githubusercontent.com/UnderGut/LAZARUS-Backup-Manager/dev/lazarus-backup"

# --- ĞšĞ›Ğ®Ğ§Ğ•Ğ’Ğ«Ğ• Ğ¡Ğ›ĞĞ’Ğ Ğ”Ğ›Ğ¯ ĞŸĞĞ˜Ğ¡ĞšĞ Ğ‘ĞĞ¢Ğ (ĞĞ• ĞŸĞĞĞ•Ğ›Ğ˜!) ---
# Ğ¡Ğ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸: rwp_shop, rwp_shop_db
# Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° legacy: telegram-shop, shop-bot, shopbot
# ĞŸĞ¾Ñ€ÑĞ´Ğ¾Ğº Ğ²Ğ°Ğ¶ĞµĞ½: ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ±Ğ¾Ğ»ĞµĞµ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹
KEYWORDS=("rwp_shop" "telegram-shop" "shop-bot" "shopbot")

# --- Ğ“Ğ›ĞĞ‘ĞĞ›Ğ¬ĞĞ«Ğ• ĞŸĞ•Ğ Ğ•ĞœĞ•ĞĞĞ«Ğ• ---
BOT_PATH=""
BOT_TOKEN=""
CHAT_ID=""
TG_MESSAGE_THREAD_ID=""
DB_USER="postgres"
IGNORE_MISMATCH="false"
EXCLUDE_DIRS=""
MAX_FILE_SIZE_MB="1"

# ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸
SEND_TO_TELEGRAM="true"      # Ğ£Ğ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ² Telegram
TG_SEND_FILE="true"          # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ±ÑĞºĞ°Ğ¿Ğ° Ğ² Telegram
SEND_TO_REMOTE="true"

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ñ€Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¸ (Ğ¿Ğ¾ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ñƒ)
MAX_BACKUPS_COUNT="100"

# Ğ£Ğ´Ğ°Ğ»ÑÑ‚ÑŒ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹: "time" Ğ¸Ğ»Ğ¸ "count" (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ time)
DELETE_MODE="time"
# Ğ¡Ñ€Ğ¾Ğº Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ² Ğ´Ğ½ÑÑ… Ğ¿Ñ€Ğ¸ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ time (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 7 Ğ´Ğ½ĞµĞ¹)
RETENTION_DAYS="7"

# Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ²ÑĞµÑ… Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ² (Ğ² MB). 0 = Ğ±ĞµĞ· Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ°
MAX_BACKUP_SIZE_MB="0"

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğ°
REMOTE_STORAGE_TYPE="off" # off, ftp, webdav
REMOTE_STORAGE_URL=""
REMOTE_STORAGE_USER=""
REMOTE_STORAGE_PASS=""
REMOTE_UPLOAD_STATUS_TEXT=""

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
BACKUP_PASSWORD=""

# Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
BOT_CONTAINER_NAME="" 
DB_CONTAINER_NAME=""
# ĞŸÑƒÑ‚ÑŒ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ (Ğ¸Ğ· Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸)
DEFAULT_BOT_PATH="/opt/private-remnawave-telegram-shop-bot"
# ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸: rwp_shop, rwp_shop_db
DEFAULT_BOT_CONTAINER="rwp_shop"
DEFAULT_DB_CONTAINER="rwp_shop_db"
# Volume Ğ¸Ğ¼ĞµĞ½Ğ° (Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑÑÑ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸)
DB_VOLUME_NAME=""  # Ğ‘ÑƒĞ´ĞµÑ‚ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¾ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ rwp_shop_db_data)
DB_SERVICE_NAME="db"  # Ğ˜Ğ¼Ñ ÑĞµÑ€Ğ²Ğ¸ÑĞ° Ğ² compose.yaml 

# Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑÑ‹ Ñ€Ğ°ÑĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¹
SCHEDULE_FULL="Ğ’Ñ‹ĞºĞ»"
SCHEDULE_DB="Ğ’Ñ‹ĞºĞ»"
SCHEDULE_FILES="Ğ’Ñ‹ĞºĞ»"

# Ğ¤Ğ»Ğ°Ğ³ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°
IS_INTERACTIVE=true
if [[ ! -t 0 ]]; then IS_INTERACTIVE=false; fi

# Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸ (--debug)
DEBUG_MODE=false
SILENT_LOG="/dev/null"
CURL_SILENT="-s"
WGET_SILENT="-q"

# ĞĞ²Ñ‚Ğ¾-Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ½ĞµĞ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, cron --yes)
AUTO_CONFIRM="false"

# Ğ›Ğ¾Ğ³-Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ñ… Ğ»Ğ¾Ğ³Ğ¾Ğ²
LOG_FILE="/var/log/lazarus_backup.log"

# Lock-Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°
LOCK_FILE="/var/run/lazarus_backup.lock"
LOCK_FD=200  # File descriptor Ğ´Ğ»Ñ flock

# Trap Ğ´Ğ»Ñ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğ¸ (Ğ¾ÑĞ²Ğ¾Ğ±Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸ + Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹)
cleanup_on_exit() {
    # ĞÑĞ²Ğ¾Ğ±Ğ¾Ğ¶Ğ´Ğ°ĞµĞ¼ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºÑƒ ĞµÑĞ»Ğ¸ Ğ±Ñ‹Ğ»Ğ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ°
    # NOTE: debug_log Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ·Ğ´ĞµÑÑŒ ĞµÑĞ»Ğ¸ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¿Ğ¾ÑĞ»Ğµ Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ stdout
    if [[ -n "$LOCK_FD" ]]; then
        flock -u "$LOCK_FD" 2>/dev/null || true
        eval "exec $LOCK_FD>&-" 2>/dev/null || true
    fi
    rm -f "$LOCK_FILE" 2>/dev/null || true
    
    # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸
    if [[ ${#TEMP_DIRS[@]} -gt 0 ]]; then
        for temp_dir in "${TEMP_DIRS[@]}"; do
            [[ -d "$temp_dir" ]] && rm -rf "$temp_dir" 2>/dev/null || true
        done
    fi
}
trap cleanup_on_exit EXIT INT TERM

# Ğ¦Ğ²ĞµÑ‚Ğ°
if [[ -t 0 ]]; then
    RED=$'\e[31m'; GREEN=$'\e[32m'; YELLOW=$'\e[33m'; GRAY=$'\e[90m'; CYAN=$'\e[36m'; MAGENTA=$'\e[35m'; RESET=$'\e[0m'; BOLD=$'\e[1m'
else
    RED=""; GREEN=""; YELLOW=""; GRAY=""; CYAN=""; MAGENTA=""; RESET=""; BOLD=""
fi

# --- Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ Ğ˜ĞĞ¢Ğ•Ğ Ğ¤Ğ•Ğ™Ğ¡Ğ ---

# ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° ÑĞºÑ€Ğ°Ğ½Ğ° (Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ÑÑ Ğ² debug Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ)
clear_screen() {
    if [[ "$DEBUG_MODE" == true ]]; then
        echo ""
        echo -e "${MAGENTA}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• [DEBUG: clear skipped] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
        echo ""
    else
        clear
    fi
}

# ĞÑ‚Ğ»Ğ°Ğ´Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ
# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: debug_log "message" Ğ¸Ğ»Ğ¸ debug_log "CATEGORY" "message"
debug_log() {
    if [[ "$DEBUG_MODE" == true ]]; then
        local ts=$(date '+%H:%M:%S.%3N')
        if [[ $# -eq 1 ]]; then
            echo -e "${MAGENTA}[$ts DEBUG]${RESET} $1"
        else
            local category="$1"
            shift
            echo -e "${MAGENTA}[$ts DEBUG]${RESET} ${CYAN}[$category]${RESET} $*"
        fi
    fi
}

escape_markdown_v2() {
    echo "$1" | sed -e 's/\\/\\\\/g' -e 's/_/\\_/g' -e 's/\[/\\[/g' -e 's/\]/\\]/g' \
        -e 's/(/\\(/g' -e 's/)/\\)/g' -e 's/~/\~/g' -e 's/`/\\`/g' -e 's/>/\\>/g' \
        -e 's/#/\\#/g' -e 's/+/\\+/g' -e 's/-/\\-/g' -e 's/=/\\=/g' -e 's/|/\\|/g' \
        -e 's/{/\\{/g' -e 's/}/\\}/g' -e 's/\./\\./g' -e 's/!/\\!/g'
}

send_telegram_notification() {
    local msg="$1"
    debug_log "TG" "=== send_telegram_notification ==="
    debug_log "TG" "SEND_TO_TELEGRAM=$SEND_TO_TELEGRAM"
    if [[ "$SEND_TO_TELEGRAM" == "true" && -n "$BOT_TOKEN" && -n "$CHAT_ID" ]]; then
        if command -v curl > "$SILENT_LOG" 2>&1; then
            local escaped_msg
            escaped_msg=$(escape_markdown_v2 "$msg")
            local thread_param=""
            [[ -n "$TG_MESSAGE_THREAD_ID" ]] && thread_param="-d message_thread_id=$TG_MESSAGE_THREAD_ID"
            local full_text="ğŸš¨ *Lazarus Error* ğŸš¨

${escaped_msg}"
            debug_log "TG" "Sending error notification to chat_id=$CHAT_ID"
            curl $CURL_SILENT -X POST "https://api.telegram.org/bot$BOT_TOKEN/sendMessage" \
                -d chat_id="$CHAT_ID" \
                -d parse_mode="MarkdownV2" \
                --data-urlencode text="$full_text" \
                $thread_param > "$SILENT_LOG" 2>&1 || true
            debug_log "TG" "Notification sent"
        else
            debug_log "TG" "curl not available, skipping notification"
        fi
    else
        debug_log "TG" "Notifications disabled or credentials missing"
    fi
}

print_message() {
    local type="$1"; local message="$2"; local color_code="$RESET"
    case "$type" in
        "INFO") color_code="$GRAY" ;;
        "SUCCESS") color_code="$GREEN" ;;
        "WARN") color_code="$YELLOW" ;;
        "ERROR") color_code="$RED" ;;
        "ACTION") color_code="$CYAN" ;;
    esac
    echo -e "${color_code}[$type]${RESET} $message"

    if [[ "$type" == "ERROR" ]]; then
        send_telegram_notification "$message"
    fi
}

log_message() {
    # Level, Message
    local level="$1"; local message="$2"
    # Ensure log dir exists and file is writable
    local logdir
    logdir=$(dirname "$LOG_FILE")
    if [[ ! -d "$logdir" ]]; then mkdir -p "$logdir" 2> "$SILENT_LOG" || true; fi
    if [[ ! -f "$LOG_FILE" ]]; then touch "$LOG_FILE" 2> "$SILENT_LOG" || true; fi
    local ts
    ts=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[$ts] [$level] $message" >> "$LOG_FILE" 2> "$SILENT_LOG" || true
}

rotate_internal_log() {
    # Rotate log if > 10MB
    local MAX_LOG_SIZE=$((10 * 1024 * 1024))
    if [[ -f "$LOG_FILE" ]]; then
        local size
        size=$(stat -c%s "$LOG_FILE" 2> "$SILENT_LOG" || echo 0)
        if [[ "$size" -gt "$MAX_LOG_SIZE" ]]; then
            mv "$LOG_FILE" "${LOG_FILE}.old"
            echo "Log rotated on $(date)" > "$LOG_FILE"
        fi
    fi
}

# --- Ğ‘Ğ›ĞĞšĞ˜Ğ ĞĞ’ĞšĞ ĞĞ¢ ĞŸĞĞ ĞĞ›Ğ›Ğ•Ğ›Ğ¬ĞĞĞ“Ğ Ğ—ĞĞŸĞ£Ğ¡ĞšĞ ---

acquire_lock() {
    # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞºÑĞºĞ»ÑĞ·Ğ¸Ğ²Ğ½ÑƒÑ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºÑƒ
    # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ¸Ğ· cron
    # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ 0 ĞµÑĞ»Ğ¸ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ°, 1 ĞµÑĞ»Ğ¸ Ğ·Ğ°Ğ½ÑÑ‚Ğ¾
    debug_log "LOCK" "=== acquire_lock ==="
    debug_log "LOCK" "Lock file: $LOCK_FILE"
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ lock-Ñ„Ğ°Ğ¹Ğ»Ğ° ĞµÑĞ»Ğ¸ Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚
    local lock_dir=$(dirname "$LOCK_FILE")
    if [[ ! -d "$lock_dir" ]]; then
        debug_log "LOCK" "Creating lock directory: $lock_dir"
        mkdir -p "$lock_dir" 2> "$SILENT_LOG" || true
    fi
    
    # ĞÑ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ» Ğ½Ğ° Ğ´ĞµÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾Ñ€ LOCK_FD
    debug_log "LOCK" "Opening lock file on FD $LOCK_FD"
    eval "exec $LOCK_FD>\"$LOCK_FILE\""
    
    # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ½ĞµĞ±Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒÑÑ‰ÑƒÑ ÑĞºÑĞºĞ»ÑĞ·Ğ¸Ğ²Ğ½ÑƒÑ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºÑƒ
    debug_log "LOCK" "Attempting flock..."
    if ! flock -n "$LOCK_FD" 2> "$SILENT_LOG"; then
        debug_log "LOCK" "FAILED - lock already held by another process"
        return 1  # Ğ‘Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ° ÑƒĞ¶Ğµ Ğ·Ğ°Ğ½ÑÑ‚Ğ° Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¼ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ğ¼
    fi
    
    # Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ PID Ğ² lock-Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸
    echo "$$" >&$LOCK_FD
    debug_log "LOCK" "Lock acquired, PID=$$ written to lock file"
    
    return 0
}

release_lock() {
    # ĞÑĞ²Ğ¾Ğ±Ğ¾Ğ¶Ğ´Ğ°ĞµĞ¼ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºÑƒ
    debug_log "LOCK" "=== release_lock ==="
    debug_log "LOCK" "Releasing FD $LOCK_FD"
    flock -u "$LOCK_FD" 2> "$SILENT_LOG" || true
    eval "exec $LOCK_FD>&-" 2> "$SILENT_LOG" || true
    rm -f "$LOCK_FILE" 2> "$SILENT_LOG" || true
    debug_log "LOCK" "Lock released and file removed"
}

check_lock_owner() {
    # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ PID Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°, Ğ²Ğ»Ğ°Ğ´ĞµÑÑ‰ĞµĞ³Ğ¾ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ¾Ğ¹
    debug_log "LOCK" "Checking lock owner..."
    if [[ -f "$LOCK_FILE" ]]; then
        local owner
        owner=$(cat "$LOCK_FILE" 2> "$SILENT_LOG" || echo "unknown")
        debug_log "LOCK" "Lock owner PID: $owner"
        echo "$owner"
    else
        debug_log "LOCK" "No lock file found"
        echo "none"
    fi
}

check_dependencies() {
    local deps=("tar" "gzip" "openssl" "docker" "find" "du" "date")
    local missing=()
    
    # Check for curl OR wget
    if ! command -v curl > "$SILENT_LOG" 2>&1 && ! command -v wget > "$SILENT_LOG" 2>&1; then
        missing+=("curl (or wget)")
    fi

    for cmd in "${deps[@]}"; do
        if ! command -v "$cmd" > "$SILENT_LOG" 2>&1; then
            missing+=("$cmd")
        fi
    done
    
    # Check for docker compose (v2)
    if command -v docker > "$SILENT_LOG" 2>&1; then
        if ! docker compose version > "$SILENT_LOG" 2>&1; then
             echo -e "${RED}[ERROR]${RESET} 'docker compose' plugin is required but not found."
             echo -e "${CYAN}[ACTION]${RESET} Please install docker-compose-plugin (v2)."
             exit 1
        fi
    fi

    if [[ ${#missing[@]} -gt 0 ]]; then
        echo -e "${RED}[ERROR]${RESET} Missing dependencies: ${missing[*]}"
        echo -e "${CYAN}[ACTION]${RESET} Please install them (e.g., apt install ${missing[*]})"
        exit 1
    fi
}

# --- Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ Ğ‘Ğ­ĞšĞĞŸĞĞ’ ---

get_backup_stats() {
    # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¿Ğ¾ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸ÑĞ¼
    local n_full=$(find "$BACKUP_DIR" -maxdepth 1 -type f \( -name "lazarus_full_*.tar.gz" -o -name "lazarus_full_*.tar.gz.enc" \) 2> "$SILENT_LOG" | wc -l)
    local n_db=$(find "$BACKUP_DIR" -maxdepth 1 -type f \( -name "lazarus_db_*.tar.gz" -o -name "lazarus_db_*.tar.gz.enc" \) 2> "$SILENT_LOG" | wc -l)
    local n_files=$(find "$BACKUP_DIR" -maxdepth 1 -type f \( -name "lazarus_files_*.tar.gz" -o -name "lazarus_files_*.tar.gz.enc" \) 2> "$SILENT_LOG" | wc -l)
    
    # ĞĞ±Ñ‰Ğ¸Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¿Ğ°Ğ¿ĞºĞ¸ Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²
    local total_size="0B"
    if [[ -d "$BACKUP_DIR" ]]; then
        total_size=$(du -sh "$BACKUP_DIR" 2> "$SILENT_LOG" | awk '{print $1}')
    fi
    
    # ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ±ÑĞºĞ°Ğ¿ (Ğ»ÑĞ±Ğ¾Ğ¹ Ñ‚Ğ¸Ğ¿)
    local last_backup=""
    local last_backup_ago=""
    local latest_file=$(find "$BACKUP_DIR" -maxdepth 1 -type f \( -name "lazarus_*.tar.gz" -o -name "lazarus_*.tar.gz.enc" \) -printf '%T@ %p\n' 2> "$SILENT_LOG" | sort -rn | head -1 | awk '{print $2}')
    
    if [[ -n "$latest_file" && -f "$latest_file" ]]; then
        local filename=$(basename "$latest_file")
        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ´Ğ°Ñ‚Ñƒ Ğ¸Ğ· Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ°: lazarus_type_YYYY-MM-DD_HH_MM_SS.tar.gz
        if [[ $filename =~ _([0-9]{4})-([0-9]{2})-([0-9]{2})_([0-9]{2})_([0-9]{2}) ]]; then
            local file_date="${BASH_REMATCH[3]}.${BASH_REMATCH[2]} ${BASH_REMATCH[4]}:${BASH_REMATCH[5]}"
            last_backup="$file_date"
            
            # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ "ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ½Ğ°Ğ·Ğ°Ğ´"
            local file_ts=$(stat -c %Y "$latest_file" 2> "$SILENT_LOG")
            local now_ts=$(date +%s)
            if [[ -n "$file_ts" ]]; then
                local diff_sec=$((now_ts - file_ts))
                if [[ $diff_sec -lt 60 ]]; then
                    last_backup_ago="Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ñ‚Ğ¾"
                elif [[ $diff_sec -lt 3600 ]]; then
                    local mins=$((diff_sec / 60))
                    last_backup_ago="${mins} Ğ¼Ğ¸Ğ½ Ğ½Ğ°Ğ·Ğ°Ğ´"
                elif [[ $diff_sec -lt 86400 ]]; then
                    local hours=$((diff_sec / 3600))
                    last_backup_ago="${hours} Ñ‡ Ğ½Ğ°Ğ·Ğ°Ğ´"
                else
                    local days=$((diff_sec / 86400))
                    last_backup_ago="${days} Ğ´Ğ½ Ğ½Ğ°Ğ·Ğ°Ğ´"
                fi
            fi
        fi
    fi
    
    # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ (bash Ğ½Ğµ ÑƒĞ¼ĞµĞµÑ‚ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°Ñ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹)
    STATS_FULL="$n_full"
    STATS_DB="$n_db"
    STATS_FILES="$n_files"
    STATS_SIZE="$total_size"
    STATS_LAST="$last_backup"
    STATS_LAST_AGO="$last_backup_ago"
}

# --- Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ ĞĞ‘ĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ¯ ---

check_for_updates() {
    clear_screen
    echo -e "${CYAN}ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹...${RESET}"
    
    local REMOTE_CONTENT=""
    local DOWNLOAD_OK=false
    local MAX_RETRIES=3
    local TIMEOUT=15
    
    for attempt in $(seq 1 $MAX_RETRIES); do
        if command -v curl > "$SILENT_LOG" 2>&1; then
            REMOTE_CONTENT=$(curl $CURL_SILENT -L --connect-timeout $TIMEOUT --max-time 30 "$REMOTE_URL" 2> "$SILENT_LOG")
        elif command -v wget > "$SILENT_LOG" 2>&1; then
            REMOTE_CONTENT=$(wget $WGET_SILENT -O- --timeout=$TIMEOUT "$REMOTE_URL" 2> "$SILENT_LOG")
        else
            print_message "ERROR" "ĞĞµÑ‚ curl Ğ¸Ğ»Ğ¸ wget Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹."
            read -erp "Enter..." dummy; return
        fi
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ ÑĞºÑ€Ğ¸Ğ¿Ñ‚
        if [[ -n "$REMOTE_CONTENT" ]] && echo "$REMOTE_CONTENT" | head -1 | grep -q "^#!/bin/bash"; then
            DOWNLOAD_OK=true
            break
        fi
        
        [[ $attempt -lt $MAX_RETRIES ]] && echo -e "${YELLOW}ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° $attempt/$MAX_RETRIES Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ, Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€...${RESET}" && sleep 2
    done
    
    if [[ "$DOWNLOAD_OK" != "true" ]]; then
        print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğº ÑĞµÑ€Ğ²ĞµÑ€Ñƒ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹."
        echo -e "${GRAY}URL: $REMOTE_URL${RESET}"
        read -erp "Enter..." dummy; return
    fi

    local REMOTE_VERSION=$(echo "$REMOTE_CONTENT" | grep '^VERSION=' | head -1 | cut -d'"' -f2)

    if [[ -z "$REMOTE_VERSION" ]]; then
        print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ²ĞµÑ€ÑĞ¸Ğ¸."
        echo -e "${GRAY}Ğ¤Ğ°Ğ¹Ğ» Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½, Ğ½Ğ¾ VERSION= Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½${RESET}"
        read -erp "Enter..." dummy; return
    fi

    local V_LOCAL=$(echo "$VERSION" | cut -d'-' -f1)
    local V_REMOTE=$(echo "$REMOTE_VERSION" | cut -d'-' -f1)
    local SUFFIX_LOCAL=$(echo "$VERSION" | grep -oE '\-.*$' || echo "")
    local SUFFIX_REMOTE=$(echo "$REMOTE_VERSION" | grep -oE '\-.*$' || echo "")

    echo -e "Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ: ${BOLD}$VERSION${RESET}"
    echo -e "ĞĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ: ${BOLD}$REMOTE_VERSION${RESET}"
    echo ""

    if [[ "$VERSION" == "$REMOTE_VERSION" ]]; then
        print_message "SUCCESS" "Ğ£ Ğ²Ğ°Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ²ĞµÑ€ÑĞ¸Ñ."
        read -erp "Enter..." dummy
        return
    fi

    local IS_UPGRADE=false
    # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ (X.Y.Z)
    if [[ "$(printf '%s\n' "$V_LOCAL" "$V_REMOTE" | sort -V | head -n1)" == "$V_LOCAL" && "$V_LOCAL" != "$V_REMOTE" ]]; then
        IS_UPGRADE=true
    # Ğ•ÑĞ»Ğ¸ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ñ€Ğ°Ğ²Ğ½Ñ‹, Ğ½Ğ¾ ĞµÑÑ‚ÑŒ Ñ€Ğ°Ğ·Ğ½Ğ¸Ñ†Ğ° Ğ² ÑÑƒÑ„Ñ„Ğ¸ĞºÑĞ°Ñ… â€” ÑÑ‚Ğ¾ Ñ‚Ğ¾Ğ¶Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ
    elif [[ "$V_LOCAL" == "$V_REMOTE" && "$SUFFIX_LOCAL" != "$SUFFIX_REMOTE" ]]; then
        IS_UPGRADE=true
    fi

    if [[ "$IS_UPGRADE" == "true" ]]; then
        print_message "WARN" "Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ!"
        read -erp "ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ ÑĞµĞ¹Ñ‡Ğ°Ñ? (y/N): " choice
        if [[ "$choice" =~ ^[Yy]$ ]]; then
            perform_update "$REMOTE_CONTENT"
        else
            print_message "INFO" "ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾."
            read -erp "Enter..." dummy
        fi
    else
        echo -e "${YELLOW}âš ï¸ Ğ’Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ: Ğ’ĞµÑ€ÑĞ¸Ñ Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€Ğµ ÑÑ‚Ğ°Ñ€ĞµĞµ Ğ¸Ğ»Ğ¸ Ñ‚Ğ°ĞºĞ°Ñ Ğ¶Ğµ.${RESET}"
        read -erp "Ğ’ÑĞµ Ñ€Ğ°Ğ²Ğ½Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ²ĞµÑ€ÑĞ¸Ñ Ñ ÑĞµÑ€Ğ²ĞµÑ€Ğ°? (y/N): " choice
        if [[ "$choice" =~ ^[Yy]$ ]]; then
            perform_update "$REMOTE_CONTENT"
        else
            print_message "INFO" "ĞÑ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾."
            read -erp "Enter..." dummy
        fi
    fi
}

perform_update() {
    local CONTENT="$1"
    local SCRIPT_PATH="$INSTALL_DIR/$SCRIPT_NAME"
    local BACKUP_PATH="$INSTALL_DIR/${SCRIPT_NAME}.backup"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğ³Ğ¾
    if ! echo "$CONTENT" | head -n 1 | grep -q "^#!/bin/bash"; then
        print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ğ½Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ bash-ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾Ğ¼."
        read -erp "Enter..." dummy
        return 1
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ (Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²)
    local CONTENT_SIZE=${#CONTENT}
    if [[ $CONTENT_SIZE -lt 10000 ]]; then
        print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼Ğ°Ğ» ($CONTENT_SIZE Ğ±Ğ°Ğ¹Ñ‚)."
        print_message "ERROR" "Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾, Ñ„Ğ°Ğ¹Ğ» Ğ±Ñ‹Ğ» Ğ¿Ğ¾Ğ²Ñ€ĞµĞ¶Ğ´Ñ‘Ğ½ Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞµ."
        read -erp "Enter..." dummy
        return 1
    fi
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ñ€ĞµĞ·ĞµÑ€Ğ²Ğ½ÑƒÑ ĞºĞ¾Ğ¿Ğ¸Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸
    if [[ -f "$SCRIPT_PATH" ]]; then
        cp "$SCRIPT_PATH" "$BACKUP_PATH"
        print_message "INFO" "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ° Ñ€ĞµĞ·ĞµÑ€Ğ²Ğ½Ğ°Ñ ĞºĞ¾Ğ¿Ğ¸Ñ: ${SCRIPT_NAME}.backup"
    fi
    
    # Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ğ½Ğ¾Ğ²ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ
    if echo "$CONTENT" > "$SCRIPT_PATH"; then
        chmod +x "$SCRIPT_PATH"
        print_message "SUCCESS" "ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾!"
        log_message "SUCCESS" "Script updated to new version"
        echo ""
        echo -e "${CYAN}ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞº ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ°...${RESET}"
        sleep 1
        exec "$SCRIPT_PATH"
    else
        print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ» Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ!"
        # Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¸Ğ· Ğ±ÑĞºĞ°Ğ¿Ğ°
        if [[ -f "$BACKUP_PATH" ]]; then
            mv "$BACKUP_PATH" "$SCRIPT_PATH"
            print_message "WARN" "Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ¸Ğ· Ğ±ÑĞºĞ°Ğ¿Ğ°."
        fi
        read -erp "Enter..." dummy
        return 1
    fi
}

# --- Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ Ğ£Ğ¡Ğ¢ĞĞĞĞ’ĞšĞ˜ ---

install_script() {
    if [[ "$EUID" -ne 0 ]]; then
        echo -e "${RED}ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ñ Ğ¿Ñ€Ğ°Ğ²Ğ°Ğ¼Ğ¸ root (sudo)!${RESET}"
        exit 1
    fi

    local CURRENT_SCRIPT_PATH=$(realpath "$0" 2> "$SILENT_LOG")
    local INSTALLED_SCRIPT_PATH="$INSTALL_DIR/$SCRIPT_NAME"

    if [[ "$CURRENT_SCRIPT_PATH" == "$INSTALLED_SCRIPT_PATH" ]]; then
        return
    fi

    echo -e "${CYAN}--- Ğ£Ğ¡Ğ¢ĞĞĞĞ’ĞšĞ LAZARUS BACKUP ---${RESET}"
    if [[ ! -d "$INSTALL_DIR" ]]; then
        mkdir -p "$INSTALL_DIR"
        print_message "SUCCESS" "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ° Ğ¿Ğ°Ğ¿ĞºĞ°: $INSTALL_DIR"
    fi

    local DOWNLOAD_SUCCESS=false
    local TEMP_FILE="/tmp/lazarus_install_tmp"

    if [[ -f "$0" && "$0" != "bash" && "$0" != "/dev/fd/"* ]]; then
        cp "$(realpath "$0")" "$INSTALLED_SCRIPT_PATH"
        DOWNLOAD_SUCCESS=true
    else
        print_message "INFO" "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸..."
        if command -v curl > "$SILENT_LOG" 2>&1; then
            curl $CURL_SILENT -L --connect-timeout 15 --max-time 60 "$REMOTE_URL" -o "$TEMP_FILE"
        elif command -v wget > "$SILENT_LOG" 2>&1; then
            wget $WGET_SILENT -O "$TEMP_FILE" --timeout=15 "$REMOTE_URL"
        else
            print_message "ERROR" "Ğ”Ğ»Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Ğ½ÑƒĞ¶ĞµĞ½ curl Ğ¸Ğ»Ğ¸ wget!"
            exit 1
        fi

        if [[ -f "$TEMP_FILE" ]]; then
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾ bash-ÑĞºÑ€Ğ¸Ğ¿Ñ‚
            if head -n 1 "$TEMP_FILE" | grep -q "^#!/bin/bash"; then
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€
                local FILE_SIZE=$(stat -c%s "$TEMP_FILE" 2> "$SILENT_LOG" || stat -f%z "$TEMP_FILE" 2> "$SILENT_LOG" || echo "0")
                if [[ $FILE_SIZE -lt 10000 ]]; then
                    print_message "ERROR" "Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼Ğ°Ğ» ($FILE_SIZE Ğ±Ğ°Ğ¹Ñ‚)."
                    rm -f "$TEMP_FILE"
                    exit 1
                fi
                mv "$TEMP_FILE" "$INSTALLED_SCRIPT_PATH"
                DOWNLOAD_SUCCESS=true
            else
                print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸! Ğ¡ĞµÑ€Ğ²ĞµÑ€ Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ½ĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»."
                rm -f "$TEMP_FILE"
                exit 1
            fi
        else
            print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ»."
            exit 1
        fi
    fi

    if [[ "$DOWNLOAD_SUCCESS" == "true" ]]; then
        chmod +x "$INSTALLED_SCRIPT_PATH"
        if [[ -L "$SYMLINK_PATH" || -f "$SYMLINK_PATH" ]]; then rm -f "$SYMLINK_PATH"; fi
        ln -s "$INSTALLED_SCRIPT_PATH" "$SYMLINK_PATH"
        
        print_message "SUCCESS" "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°. Ğ—Ğ°Ğ¿ÑƒÑĞº..."
        echo ""
        exec "$INSTALLED_SCRIPT_PATH"
        exit 0
    fi
}

# --- Ğ¯Ğ”Ğ Ğ Ğ˜ĞĞ¢Ğ•Ğ›Ğ›Ğ•ĞšĞ¢Ğ£ĞĞ›Ğ¬ĞĞĞ“Ğ ĞŸĞĞ˜Ğ¡ĞšĞ ---

scan_system_for_bot() {
    FOUND_PATH=""; FOUND_BOT=""; FOUND_DB=""
    debug_log "SCAN" "=== scan_system_for_bot ==="
    local running_containers=$(docker ps --format '{{.Names}}|{{.Image}}')
    debug_log "SCAN" "Running containers: $(echo "$running_containers" | wc -l)"
    
    # Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ² Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ (Ğ˜Ğ¡ĞšĞ›Ğ®Ğ§ĞĞ•Ğœ Ğ¸Ğ· Ğ¿Ğ¾Ğ¸ÑĞºĞ°)
    local PANEL_CONTAINERS=(
        "remnawave"              # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸
        "remnawave-db"           # Ğ‘Ğ” Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸
        "remnawave-redis"        # Redis Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸
        "remnawave-nginx"        # Nginx Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸
        "remnawave-subscription-page"   # Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸
        "remnawave-telegram-mini-app"   # Mini App Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸
        "certwardenclient"       # Cert Warden
    )
    
    for container in $running_containers; do
        local c_name=$(echo "$container" | cut -d'|' -f1)
        local c_image=$(echo "$container" | cut -d'|' -f2)
        debug_log "SCAN" "Checking: $c_name ($c_image)"
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ğ½Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸
        local is_panel=false
        for panel_c in "${PANEL_CONTAINERS[@]}"; do
            if [[ "$c_name" == "$panel_c" ]]; then
                is_panel=true
                debug_log "SCAN" "  -> Skip (panel container: $panel_c)"
                break
            fi
        done
        
        # Ğ˜ÑĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸ Ğ¿Ğ¾ image
        if [[ "$c_image" == *"remnawave/backend"* ]]; then is_panel=true; debug_log "SCAN" "  -> Skip (remnawave/backend)"; fi
        if [[ "$c_image" == *"remnawave/subscription-page"* ]]; then is_panel=true; debug_log "SCAN" "  -> Skip (subscription-page)"; fi
        if [[ "$c_image" == *"remnawave-telegram-sub-mini-app"* ]]; then is_panel=true; fi
        if [[ "$c_image" == *"certwarden-client"* ]]; then is_panel=true; fi
        if [[ "$c_image" == "nginx"* || "$c_image" == "postgres"* || "$c_image" == "redis"* ]]; then
            # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ¸Ğ¼Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ "remnawave" Ğ‘Ğ•Ğ— "shop"/"bot"
            if [[ "$c_name" == *"remnawave"* && "$c_name" != *"shop"* && "$c_name" != *"bot"* ]]; then
                is_panel=true
                debug_log "SCAN" "  -> Skip (panel infra)"
            fi
        fi
        
        if [[ "$is_panel" == true ]]; then continue; fi

        # Ğ˜Ñ‰ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘ĞĞ¢Ğ Ğ¿Ğ¾ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼
        for key in "${KEYWORDS[@]}"; do
            if [[ "$c_image" == *"$key"* || "$c_name" == *"$key"* ]]; then
                debug_log "SCAN" "  -> MATCH! keyword=$key"
                FOUND_BOT="$c_name"
                local work_dir=$(docker inspect --format '{{ index .Config.Labels "com.docker.compose.project.working_dir" }}' "$c_name")
                debug_log "SCAN" "  -> working_dir=$work_dir"
                if [[ -n "$work_dir" && -d "$work_dir" ]]; then FOUND_PATH="$work_dir"; fi
                break 2
            fi
        done
    done
    
    debug_log "SCAN" "After container scan: FOUND_BOT=$FOUND_BOT, FOUND_PATH=$FOUND_PATH"

    # Ğ•ÑĞ»Ğ¸ Ğ½Ğµ Ğ½Ğ°ÑˆĞ»Ğ¸ Ñ‡ĞµÑ€ĞµĞ· ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹ â€” Ğ¸Ñ‰ĞµĞ¼ Ğ¿Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼ docker-compose
    if [[ -z "$FOUND_PATH" ]]; then
        debug_log "SCAN" "No containers found, searching compose files..."
        local search_dirs=("/opt" "/home" "/root")
        local compose_files=$(find "${search_dirs[@]}" -maxdepth 4 -name "docker-compose.yml" -o -name "compose.yaml" 2> "$SILENT_LOG")
        for file in $compose_files; do
            # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ compose Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
            if grep -q "remnawave/backend" "$file"; then continue; fi
            if grep -q "remnawave/subscription-page" "$file"; then continue; fi
            
            # Ğ˜Ñ‰ĞµĞ¼ Ğ¿Ğ¾ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼ Ğ‘ĞĞ¢Ğ
            if grep -qE "image:.*($(IFS="|"; echo "${KEYWORDS[*]}"))" "$file" || grep -qE "container_name:.*($(IFS="|"; echo "${KEYWORDS[*]}"))" "$file"; then
                FOUND_PATH=$(dirname "$file")
                # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ container_name
                FOUND_BOT=$(grep -E "container_name:" "$file" | grep -E "($(IFS="|"; echo "${KEYWORDS[*]}"))" | head -1 | awk '{print $2}' | tr -d '"' | tr -d "'")
                
                # Ğ•ÑĞ»Ğ¸ container_name Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ docker compose Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ¼ĞµĞ½Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ°
                if [[ -z "$FOUND_BOT" && -d "$FOUND_PATH" ]]; then
                    cd "$FOUND_PATH" 2> "$SILENT_LOG"
                    # Ğ˜Ñ‰ĞµĞ¼ service ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ½Ğ°Ñˆ image
                    for key in "${KEYWORDS[@]}"; do
                        local services=$(grep -B 2 "image:.*$key" "$file" | grep "^[a-z]" | head -1 | awk '{print $1}' | tr -d ':')
                        if [[ -n "$services" ]]; then
                            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ¼Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ñ‡ĞµÑ€ĞµĞ· docker compose
                            FOUND_BOT=$(docker compose ps -a --format '{{.Name}}' "$services" 2> "$SILENT_LOG" | head -1)
                            [[ -n "$FOUND_BOT" ]] && break
                        fi
                    done
                    cd - > "$SILENT_LOG"
                fi
                break
            fi
        done
    fi

    # ĞŸĞ¾Ğ¸ÑĞº ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ğ‘Ğ”
    if [[ -n "$FOUND_PATH" ]]; then
        if cd "$FOUND_PATH" 2> "$SILENT_LOG"; then
            local db_services=("db" "postgres" "database" "postgresql")
            for svc in "${db_services[@]}"; do
                local db_c=$(docker compose ps -a --format '{{.Name}}' "$svc" 2> "$SILENT_LOG")
                # Ğ˜ÑĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ Ğ‘Ğ” Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸
                if [[ -n "$db_c" && "$db_c" != "remnawave-db" && "$db_c" != *"remnawave_"* ]]; then 
                    FOUND_DB="$db_c"
                    break
                fi
            done
            cd - > "$SILENT_LOG"
        fi
    fi
}

# --- Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ˜ Ğ˜ ĞŸĞĞ˜Ğ¡ĞšĞ ---

get_raw_bot_version() {
    if [[ -n "$BOT_CONTAINER_NAME" ]] && docker container inspect -f '{{.State.Running}}' "$BOT_CONTAINER_NAME" > /dev/null 2> "$SILENT_LOG"; then
        local full_image=$(docker inspect -f '{{.Config.Image}}' "$BOT_CONTAINER_NAME")
        local ver="${full_image##*:}"
        echo "${ver:-Unknown}"
    else
        echo ""
    fi
}

get_bot_version_display() {
    local ver=$(get_raw_bot_version)
    if [[ -n "$ver" ]]; then echo "$ver"; else echo "N/A"; fi
}

# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ğ±Ğ¾Ñ‚Ğ°
get_container_status() {
    if [[ -z "$BOT_CONTAINER_NAME" ]]; then
        echo "N/A"
        return
    fi
    
    local status
    status=$(docker inspect -f '{{.State.Status}}' "$BOT_CONTAINER_NAME" 2> "$SILENT_LOG")
    
    case "$status" in
        "running") echo "Online" ;;
        "exited"|"dead") echo "Offline" ;;
        "paused") echo "Paused" ;;
        "restarting") echo "Restarting" ;;
        *) echo "N/A" ;;
    esac
}

# ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ DB volume
get_db_volume_name() {
    debug_log "DB" "=== get_db_volume_name ==="
    debug_log "DB" "DB_CONTAINER_NAME=$DB_CONTAINER_NAME"
    
    if [[ -z "$DB_CONTAINER_NAME" ]]; then
        debug_log "DB" "ERROR: DB_CONTAINER_NAME is empty"
        echo ""
        return 1
    fi
    
    # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ¸Ğ¼Ñ volume Ğ¸Ğ· docker inspect
    debug_log "DB" "Trying docker inspect..."
    local volume=$(docker inspect -f '{{range .Mounts}}{{if eq .Type "volume"}}{{.Name}}{{end}}{{end}}' "$DB_CONTAINER_NAME" 2> "$SILENT_LOG")
    
    if [[ -n "$volume" ]]; then
        debug_log "DB" "Volume found via docker inspect: $volume"
        echo "$volume"
        return 0
    fi
    debug_log "DB" "No volume from docker inspect, trying compose fallback"
    
    # Fallback: Ğ¿Ñ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ğ¸Ğ· docker-compose.yml
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
        local compose_file=""
        [[ -f "$BOT_PATH/compose.yaml" ]] && compose_file="$BOT_PATH/compose.yaml"
        [[ -f "$BOT_PATH/docker-compose.yml" ]] && compose_file="$BOT_PATH/docker-compose.yml"
        debug_log "DB" "Compose file: $compose_file"
        
        if [[ -n "$compose_file" ]]; then
            # Ğ˜Ñ‰ĞµĞ¼ volume Ğ² ÑĞµĞºÑ†Ğ¸Ğ¸ volumes Ğ‘Ğ” (Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¾Ğ±Ğ¾Ğ¸Ñ… Ğ¿ÑƒÑ‚ĞµĞ¹)
            # ĞĞ¾Ğ²Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ: /var/lib/postgresql/data
            # Ğ¡Ñ‚Ğ°Ñ€Ñ‹Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸: /var/lib/postgresql
            local vol=$(grep -A 10 "^\s*$DB_SERVICE_NAME:" "$compose_file" | grep -E "volumes:" -A 5 | grep -oE "[a-zA-Z0-9_-]+:/var/lib/postgresql(/data)?" | cut -d':' -f1 | head -1)
            debug_log "DB" "Parsed volume name from compose: '$vol'"
            if [[ -n "$vol" ]]; then
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ñ‚Ğ°ĞºĞ¾Ğ¹ volume
                if docker volume inspect "$vol" > /dev/null 2> "$SILENT_LOG"; then
                    debug_log "DB" "Volume exists: $vol"
                    echo "$vol"
                    return 0
                else
                    debug_log "DB" "Volume '$vol' does not exist in docker"
                fi
            fi
        fi
    fi
    
    # Ğ•ÑĞ»Ğ¸ Ğ²ÑÑ‘ Ñ€Ğ°Ğ²Ğ½Ğ¾ Ğ½Ğµ Ğ½Ğ°ÑˆĞ»Ğ¸ â€” Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¿ÑƒÑÑ‚ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ
    debug_log "DB" "No volume found, returning empty"
    echo ""
    return 1
}

# Ğ§Ñ‚ĞµĞ½Ğ¸Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¸Ğ· .env Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ±Ğ¾Ñ‚Ğ°
# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: read_bot_env "POSTGRES_USER" â†’ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ
read_bot_env() {
    local var_name="$1"
    local env_file=""
    
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
        [[ -f "$BOT_PATH/.env" ]] && env_file="$BOT_PATH/.env"
    fi
    
    if [[ -z "$env_file" ]]; then
        debug_log "DB" "read_bot_env: no .env file found for '$var_name'"
        echo ""
        return 1
    fi
    
    # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¸Ğ· .env (Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ² KEY=value Ğ¸ KEY="value")
    local value=$(grep -E "^${var_name}=" "$env_file" 2>/dev/null | head -1 | cut -d'=' -f2- | sed -e 's/^"//' -e 's/"$//' -e "s/^'//" -e "s/'$//")
    debug_log "DB" "read_bot_env: $var_name='$value' from $env_file"
    echo "$value"
}

# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ‘Ğ” Ğ¸Ğ· .env Ğ±Ğ¾Ñ‚Ğ° Ğ¸Ğ»Ğ¸ fallback Ğ½Ğ° Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºÑƒ
get_db_user() {
    local env_user=$(read_bot_env "POSTGRES_USER")
    if [[ -n "$env_user" ]]; then
        debug_log "DB" "get_db_user: using env POSTGRES_USER=$env_user"
        echo "$env_user"
    else
        debug_log "DB" "get_db_user: using global DB_USER=$DB_USER"
        echo "$DB_USER"
    fi
}

# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· .env Ğ±Ğ¾Ñ‚Ğ° Ğ¸Ğ»Ğ¸ fallback Ğ½Ğ° postgres
get_db_name() {
    local env_db=$(read_bot_env "POSTGRES_DB")
    if [[ -n "$env_db" ]]; then
        debug_log "DB" "get_db_name: using env POSTGRES_DB=$env_db"
        echo "$env_db"
    else
        debug_log "DB" "get_db_name: using default 'postgres'"
        echo "postgres"
    fi
}

# --- Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯ ĞĞ‘ĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ¯ Ğ‘ĞĞ¢Ğ ---

# Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ¸Ğ· Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ° (rwp_shop-3.23.0-amd64.tar â†’ 3.23.0)
extract_version_from_filename() {
    local filename="$1"
    # ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ²:
    # - rwp_shop-3.23.0-amd64.tar (Ğ½Ğ¾Ğ²Ñ‹Ğ¹)
    # - rwp_shop-3.23.0.tar
    # - private-remnawave-telegram-shop-bot-3.21.2-amd64.tar (ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹)
    # - telegram-shop-2.0.0.tar
    echo "$filename" | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' | head -1
}

# Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ²ĞµÑ€ÑĞ¸Ğ¹ (Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ 0 ĞµÑĞ»Ğ¸ $1 > $2)
version_gt() {
    local v1="$1" v2="$2"
    # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ½Ğ° Ñ‡Ğ°ÑÑ‚Ğ¸
    local v1_major v1_minor v1_patch v2_major v2_minor v2_patch
    IFS='.' read -r v1_major v1_minor v1_patch <<< "$v1"
    IFS='.' read -r v2_major v2_minor v2_patch <<< "$v2"
    
    # ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğº Ñ‡Ğ¸ÑĞ»Ğ°Ğ¼ (ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ĞµĞ´ÑƒÑ‰Ğ¸Ğµ Ğ½ÑƒĞ»Ğ¸)
    v1_major=$((10#${v1_major:-0})); v1_minor=$((10#${v1_minor:-0})); v1_patch=$((10#${v1_patch:-0}))
    v2_major=$((10#${v2_major:-0})); v2_minor=$((10#${v2_minor:-0})); v2_patch=$((10#${v2_patch:-0}))
    
    if [[ $v1_major -gt $v2_major ]]; then return 0; fi
    if [[ $v1_major -lt $v2_major ]]; then return 1; fi
    if [[ $v1_minor -gt $v2_minor ]]; then return 0; fi
    if [[ $v1_minor -lt $v2_minor ]]; then return 1; fi
    if [[ $v1_patch -gt $v2_patch ]]; then return 0; fi
    return 1
}

# Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ²ĞµÑ€ÑĞ¸Ğ¹ (Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ 0 ĞµÑĞ»Ğ¸ $1 >= $2)
version_gte() {
    local v1="$1" v2="$2"
    
    # Ğ•ÑĞ»Ğ¸ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ñ€Ğ°Ğ²Ğ½Ñ‹ - true
    [[ "$v1" == "$v2" ]] && return 0
    
    # Ğ˜Ğ½Ğ°Ñ‡Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ >
    version_gt "$v1" "$v2"
}

# ĞŸĞ¾Ğ¸ÑĞº Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ° Ğ±Ğ¾Ñ‚Ğ° Ğ² ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ğ¿ĞºĞµ (Ğ±ĞµĞ· Ñ€ĞµĞºÑƒÑ€ÑĞ¸Ğ¸)
# ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²ÑĞµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹ Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ: Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¸ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ
find_bot_image_files() {
    local search_path="$1"
    # Ğ˜Ñ‰ĞµĞ¼ .tar Ñ„Ğ°Ğ¹Ğ»Ñ‹ ÑĞ¾ Ğ²ÑĞµĞ¼Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°Ğ¼Ğ¸:
    # - rwp_shop-*.tar (Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹)
    # - private-remnawave-telegram-shop-bot-*.tar (ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹)
    # - telegram-shop-*.tar (Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹)
    find "$search_path" -maxdepth 1 -type f \( \
        -name "rwp_shop*.tar" -o \
        -name "private-remnawave-telegram-shop-bot*.tar" -o \
        -name "telegram-shop*.tar" \
    \) 2> "$SILENT_LOG"
}

# ĞŸĞ¾Ğ¸ÑĞº Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ° Ğ²Ğ¾ Ğ²ÑĞµÑ… ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ñ… Ğ¿ÑƒÑ‚ÑÑ… + BOT_PATH
# Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ², Ğ¾Ñ‚ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾ Ğ²ĞµÑ€ÑĞ¸Ğ¸ (Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼Ğ¸)
find_all_bot_image_files() {
    debug_log "SCAN" "=== find_all_bot_image_files() start ==="
    local search_paths=()
    
    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ÑĞµ Ğ¿ÑƒÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
    # 1. ĞŸÑƒÑ‚ÑŒ Ğº Ğ±Ğ¾Ñ‚Ñƒ (ĞµÑĞ»Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½)
    [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]] && search_paths+=("$BOT_PATH")
    
    # 2. Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸
    [[ -d "/opt" ]] && search_paths+=("/opt")
    [[ -d "/root" ]] && search_paths+=("/root")
    
    # 3. ĞŸÑƒÑ‚ÑŒ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ (ĞµÑĞ»Ğ¸ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°ĞµÑ‚ÑÑ Ğ¾Ñ‚ BOT_PATH)
    if [[ -d "$DEFAULT_BOT_PATH" && "$DEFAULT_BOT_PATH" != "$BOT_PATH" ]]; then
        search_paths+=("$DEFAULT_BOT_PATH")
    fi
    
    debug_log "SCAN" "Search paths: ${search_paths[*]}"
    
    local all_files=""
    local seen_files=()
    
    for search_path in "${search_paths[@]}"; do
        debug_log "SCAN" "Searching in: $search_path (maxdepth=3)"
        # Ğ ĞµĞºÑƒÑ€ÑĞ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº (maxdepth 3 Ğ´Ğ»Ñ Ñ€Ğ°Ğ·ÑƒĞ¼Ğ½Ğ¾Ğ¹ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹)
        while IFS= read -r file; do
            [[ -z "$file" ]] && continue
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹ (Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ°)
            local fname=$(basename "$file")
            local is_dup=false
            for seen in "${seen_files[@]}"; do
                [[ "$seen" == "$fname" ]] && is_dup=true && break
            done
            
            if [[ "$is_dup" == "false" ]]; then
                debug_log "SCAN" "  Found: $file"
                seen_files+=("$fname")
                all_files+="$file"$'\n'
            else
                debug_log "SCAN" "  Duplicate skipped: $fname"
            fi
        done < <(find "$search_path" -maxdepth 3 -type f \( \
            -name "rwp_shop*.tar" -o \
            -name "private-remnawave-telegram-shop-bot*.tar" -o \
            -name "telegram-shop*.tar" \
        \) 2> "$SILENT_LOG")
    done
    
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ¿ĞµÑ€ĞµĞ½Ğ¾Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ¸
    all_files="${all_files%$'\n'}"
    
    if [[ -z "$all_files" ]]; then
        debug_log "SCAN" "No image files found"
        echo ""
        return 1
    fi
    
    debug_log "SCAN" "Total unique files found: $(echo "$all_files" | wc -l)"
    
    # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾ Ğ²ĞµÑ€ÑĞ¸Ğ¸ (Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ²ĞµÑ€ÑĞ¸Ñ, ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼, Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼)
    # ĞĞ¾Ğ²Ñ‹Ğµ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼Ğ¸ (sort -Vr)
    echo "$all_files" | while IFS= read -r file; do
        local version=$(extract_version_from_filename "$(basename "$file")")
        echo "$version|$file"
    done | sort -t'|' -k1 -Vr | cut -d'|' -f2
}

# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ (ÑĞ°Ğ¼Ğ¾Ğ³Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾) Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ°
get_latest_bot_image_file() {
    local search_path="$1"
    local files=$(find_bot_image_files "$search_path")
    
    if [[ -z "$files" ]]; then
        echo ""
        return 1
    fi
    
    local latest_file=""
    local latest_version="0.0.0"
    
    while IFS= read -r file; do
        local version=$(extract_version_from_filename "$(basename "$file")")
        if [[ -n "$version" ]] && version_gt "$version" "$latest_version"; then
            latest_version="$version"
            latest_file="$file"
        fi
    done <<< "$files"
    
    echo "$latest_file"
}

# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¸Ğ¼ĞµĞ½Ğ¸ image Ğ¸Ğ· Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ tar Ñ„Ğ°Ğ¹Ğ»Ğ°
get_image_name_from_tar() {
    local tar_file="$1"
    # ĞŸĞ¾ÑĞ»Ğµ docker load Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ Ñ‚Ğ¸Ğ¿Ğ° "Loaded image: rwp_shop:3.23.5"
    # ĞĞ¾ Ğ¼Ñ‹ Ğ¼Ğ¾Ğ¶ĞµĞ¼ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ°
    local filename=$(basename "$tar_file")
    
    if [[ "$filename" == rwp_shop* ]]; then
        echo "rwp_shop"
    elif [[ "$filename" == private-remnawave-telegram-shop-bot* ]]; then
        echo "private-remnawave-telegram-shop-bot"
    elif [[ "$filename" == telegram-shop* ]]; then
        echo "telegram-shop"
    else
        echo "rwp_shop"  # ĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
    fi
}

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ°, Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ»Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ· Ñ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸ĞµĞ¹ Ğ² Docker
# Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚: 0 ĞµÑĞ»Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½, 1 ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚
is_image_loaded_in_docker() {
    local image_name="$1"
    local version="$2"
    
    [[ -z "$image_name" || -z "$version" ]] && return 1
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ° Ğ² docker images
    if docker images --format "{{.Repository}}:{{.Tag}}" 2>/dev/null | grep -qE "^${image_name}:${version}$"; then
        return 0
    fi
    
    return 1
}

# Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ LICENSE_KEY Ğ² .env (Ğ±ĞµĞ· Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°)
# Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚: 0 ĞµÑĞ»Ğ¸ ĞºĞ»ÑÑ‡ ĞµÑÑ‚ÑŒ Ğ¸ Ğ½Ğµ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹, 1 ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚
has_license_key() {
    local env_file="${BOT_PATH}/.env"
    [[ ! -f "$env_file" ]] && return 1
    
    local key=$(grep "^LICENSE_KEY=" "$env_file" 2>/dev/null | cut -d'=' -f2-)
    [[ -n "$key" && "$key" =~ ^[0-9a-f]{64}$ ]] && return 0
    return 1
}

# Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ machine-id volume Ğ² compose (Ğ±ĞµĞ· Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°)
# Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚: 0 ĞµÑĞ»Ğ¸ volume ĞµÑÑ‚ÑŒ, 1 ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚
has_machine_id_volume() {
    local compose_file=""
    [[ -f "$BOT_PATH/compose.yaml" ]] && compose_file="$BOT_PATH/compose.yaml"
    [[ -f "$BOT_PATH/docker-compose.yml" ]] && compose_file="$BOT_PATH/docker-compose.yml"
    [[ -z "$compose_file" ]] && return 1
    
    grep -q "/etc/machine-id" "$compose_file" 2>/dev/null && return 0
    return 1
}

# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ²ĞµÑ€ÑĞ¸Ğ¸ image Ğ¸Ğ· docker-compose Ñ„Ğ°Ğ¹Ğ»Ğ°
# Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚: "image_name:version" Ğ¸Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ
get_compose_image_version() {
    local compose_file="$1"
    
    if [[ ! -f "$compose_file" ]]; then
        echo ""
        return 1
    fi
    
    # Ğ˜Ñ‰ĞµĞ¼ image Ğ±Ğ¾Ñ‚Ğ° Ğ² compose Ñ„Ğ°Ğ¹Ğ»Ğµ
    local image_patterns=("rwp_shop" "private-remnawave-telegram-shop-bot" "telegram-shop" "shopbot")
    
    for pattern in "${image_patterns[@]}"; do
        local match=$(grep -oE "image:\s*['\"]?${pattern}:[0-9]+\.[0-9]+\.[0-9]+" "$compose_file" | head -1)
        if [[ -n "$match" ]]; then
            # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ image:version (ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ "image:" Ğ¸ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹/ĞºĞ°Ğ²Ñ‹Ñ‡ĞºĞ¸)
            local image_ver=$(echo "$match" | sed -E "s/image:\s*['\"]?//g" | tr -d "'" | tr -d '"')
            echo "$image_ver"
            return 0
        fi
    done
    
    echo ""
    return 1
}

# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Docker image
# Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚: Ğ²ĞµÑ€ÑĞ¸Ñ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ "3.27.0") Ğ¸Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ
get_loaded_image_version() {
    local image_name="$1"
    
    [[ -z "$image_name" ]] && image_name="rwp_shop"
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ²ĞµÑ€ÑĞ¸Ñ image Ğ¸Ğ· docker images
    local version=$(docker images --format "{{.Tag}}" "$image_name" 2>/dev/null | grep -E "^[0-9]+\.[0-9]+\.[0-9]+" | sort -V | tail -1)
    
    if [[ -n "$version" ]]; then
        echo "$version"
        return 0
    fi
    
    echo ""
    return 1
}

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ² compose Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ image
# Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚: 0 ĞµÑĞ»Ğ¸ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ÑÑ‚, 1 ĞµÑĞ»Ğ¸ Ğ½Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ÑÑ‚, 2 ĞµÑĞ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°
check_image_version_match() {
    debug_log "VERSION" "=== check_image_version_match() ==="
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ compose Ñ„Ğ°Ğ¹Ğ»
    local compose_file=""
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
        [[ -f "$BOT_PATH/compose.yaml" ]] && compose_file="$BOT_PATH/compose.yaml"
        [[ -f "$BOT_PATH/docker-compose.yml" ]] && compose_file="$BOT_PATH/docker-compose.yml"
    fi
    
    if [[ -z "$compose_file" ]]; then
        debug_log "VERSION" "Compose file not found"
        return 2
    fi
    
    debug_log "VERSION" "Compose file: $compose_file"
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ¸Ğ· compose
    local compose_image=$(get_compose_image_version "$compose_file")
    debug_log "VERSION" "Compose image: $compose_image"
    
    if [[ -z "$compose_image" ]]; then
        debug_log "VERSION" "Could not get image from compose"
        return 2
    fi
    
    # Ğ Ğ°Ğ·Ğ´ĞµĞ»ÑĞµĞ¼ Ğ½Ğ° Ğ¸Ğ¼Ñ Ğ¸ Ğ²ĞµÑ€ÑĞ¸Ñ
    local compose_name="${compose_image%%:*}"
    local compose_version="${compose_image##*:}"
    debug_log "VERSION" "Compose: name=$compose_name version=$compose_version"
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ image
    local loaded_version=$(get_loaded_image_version "$compose_name")
    debug_log "VERSION" "Loaded image version: $loaded_version"
    
    if [[ -z "$loaded_version" ]]; then
        debug_log "VERSION" "No loaded image found for $compose_name"
        # Image Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ²Ğ¾Ğ¾Ğ±Ñ‰Ğµ - ÑÑ‚Ğ¾ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°
        echo "NOT_FOUND"
        return 1
    fi
    
    # Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ²ĞµÑ€ÑĞ¸Ğ¸
    if [[ "$compose_version" == "$loaded_version" ]]; then
        debug_log "VERSION" "Versions match: $compose_version"
        echo "MATCH:$compose_version"
        return 0
    else
        debug_log "VERSION" "Version MISMATCH: compose=$compose_version loaded=$loaded_version"
        
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ĞºĞ°ĞºĞ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ²Ñ‹ÑˆĞµ
        if version_gt "$loaded_version" "$compose_version"; then
            echo "UPGRADE:$compose_version:$loaded_version:$compose_name"
        else
            echo "DOWNGRADE:$compose_version:$loaded_version:$compose_name"
        fi
        return 1
    fi
}

# ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¾ Ğ½ĞµÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğ¸ Ğ²ĞµÑ€ÑĞ¸Ğ¹ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ
show_version_mismatch_warning() {
    local compose_version="$1"
    local loaded_version="$2"
    local is_upgrade="$3"  # "true" ĞµÑĞ»Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ²Ñ‹ÑˆĞµ
    local image_name="$4"
    
    # ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ Ğ°Ğ»Ğ¸Ğ°ÑÑ‹ Ğ´Ğ»Ñ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ²
    local R="${RESET}"
    local C="${CYAN}"
    local G="${GREEN}"
    local Y="${YELLOW}"
    
    # ĞŸĞ°Ğ´Ğ´Ğ¸Ğ½Ğ³ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ´Ğ¾ 8 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² (Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ñ‚Ğ¸Ğ¿Ğ° 3.26.0 = 6, 3.100.10 = 8)
    local cv_pad=$(printf "%-8s" "$compose_version")
    local lv_pad=$(printf "%-8s" "$loaded_version")
    
    echo ""
    if [[ "$is_upgrade" == "true" ]]; then
        local B="${YELLOW}${BOLD}"
        echo -e "${B}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${R}"
        echo -e "${B}â•‘${R}          [!] ĞĞ‘ĞĞĞ Ğ£Ğ–Ğ•ĞĞ ĞĞĞ’ĞĞ¯ Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ¯ IMAGE                   ${B}â•‘${R}"
        echo -e "${B}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${R}"
        echo -e "${B}â•‘${R}                                                              ${B}â•‘${R}"
        echo -e "${B}â•‘${R}  Ğ’ docker-compose ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ° Ğ²ĞµÑ€ÑĞ¸Ñ: ${C}${cv_pad}${R}                   ${B}â•‘${R}"
        echo -e "${B}â•‘${R}  Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Docker image:        ${G}${lv_pad}${R} (Ğ½Ğ¾Ğ²ĞµĞµ)           ${B}â•‘${R}"
        echo -e "${B}â•‘${R}                                                              ${B}â•‘${R}"
        echo -e "${B}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${R}"
        echo -e "${B}â•‘${R}  ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ ÑĞµĞ¹Ñ‡Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ° ÑÑ‚Ğ°Ñ€Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸.                 ${B}â•‘${R}"
        echo -e "${B}â•‘${R}  Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ compose Ñ„Ğ°Ğ¹Ğ».    ${B}â•‘${R}"
        echo -e "${B}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${R}"
    else
        local B="${RED}${BOLD}"
        echo -e "${B}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${R}"
        echo -e "${B}â•‘${R}            [!] ĞĞ•Ğ¡ĞĞĞ¢Ğ’Ğ•Ğ¢Ğ¡Ğ¢Ğ’Ğ˜Ğ• Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ™ IMAGE                   ${B}â•‘${R}"
        echo -e "${B}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${R}"
        echo -e "${B}â•‘${R}                                                              ${B}â•‘${R}"
        echo -e "${B}â•‘${R}  Ğ’ docker-compose ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ° Ğ²ĞµÑ€ÑĞ¸Ñ: ${C}${cv_pad}${R}                   ${B}â•‘${R}"
        echo -e "${B}â•‘${R}  Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Docker image:        ${Y}${lv_pad}${R} (ÑÑ‚Ğ°Ñ€ÑˆĞµ)          ${B}â•‘${R}"
        echo -e "${B}â•‘${R}                                                              ${B}â•‘${R}"
        echo -e "${B}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${R}"
        echo -e "${B}â•‘${R}  ${Y}Ğ¢Ñ€ĞµĞ±ÑƒĞµĞ¼Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ image Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°!${R}                         ${B}â•‘${R}"
        echo -e "${B}â•‘${R}                                                              ${B}â•‘${R}"
        echo -e "${B}â•‘${R}  Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ½ÑƒĞ¶Ğ½ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ: curl + docker load                 ${B}â•‘${R}"
        echo -e "${B}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${R}"
    fi
    echo ""
}

# ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ñ… .tar Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¿Ğ¾ÑĞ»Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ image
cleanup_tar_files() {
    # Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ ĞºÑƒĞ´Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¿Ğ¾Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ Ğ¿Ğ¾ SSH
    local search_dirs=(
        "/root"
        "/tmp"
        "/opt"
        "$BOT_PATH"
        "$(pwd)"
    )
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ´Ğ¾Ğ¼Ğ°ÑˆĞ½Ğ¸Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹
    if [[ -d "/home" ]]; then
        for user_home in /home/*; do
            [[ -d "$user_home" ]] && search_dirs+=("$user_home")
        done
    fi
    
    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ tar Ñ„Ğ°Ğ¹Ğ»Ñ‹
    local -A found_files  # Ğ°ÑÑĞ¾Ñ†Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¼Ğ°ÑÑĞ¸Ğ² Ğ´Ğ»Ñ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
    
    for dir in "${search_dirs[@]}"; do
        [[ ! -d "$dir" ]] && continue
        
        while IFS= read -r -d '' file; do
            # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ realpath Ğ´Ğ»Ñ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
            local real_path=$(realpath "$file" 2>/dev/null || echo "$file")
            found_files["$real_path"]=1
        done < <(find "$dir" -maxdepth 1 -name "rwp_shop*.tar" -type f -print0 2>/dev/null)
    done
    
    # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ğ² Ğ¼Ğ°ÑÑĞ¸Ğ²
    local tar_files=("${!found_files[@]}")
    
    # Ğ•ÑĞ»Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ½ĞµÑ‚ - Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¸Ğ¼
    [[ ${#tar_files[@]} -eq 0 ]] && return 0
    
    echo ""
    print_message "INFO" "ĞĞ°Ğ¹Ğ´ĞµĞ½Ñ‹ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Docker image:"
    echo ""
    
    local total_size=0
    for file in "${tar_files[@]}"; do
        local size=$(du -h "$file" 2>/dev/null | cut -f1)
        local size_bytes=$(stat -c %s "$file" 2>/dev/null || echo 0)
        total_size=$((total_size + size_bytes))
        echo -e "  ${CYAN}${file}${RESET}"
        echo -e "    Ğ Ğ°Ğ·Ğ¼ĞµÑ€: ${YELLOW}${size}${RESET}"
    done
    
    echo ""
    local total_human=$(numfmt --to=iec $total_size 2>/dev/null || echo "${total_size} bytes")
    echo -e "  ${WHITE}${BOLD}Ğ’ÑĞµĞ³Ğ¾: ${total_human}${RESET}"
    echo ""
    
    print_message "INFO" "Ğ­Ñ‚Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğµ Ğ½ÑƒĞ¶Ğ½Ñ‹ - image ÑƒĞ¶Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ² Docker"
    echo ""
    
    local confirm=""
    while [[ ! "$confirm" =~ ^[YyNn]$ ]]; do
        read -erp "Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹? (y/n): " confirm
        if [[ ! "$confirm" =~ ^[YyNn]$ ]]; then
            echo -e "${YELLOW}Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ 'y' Ğ´Ğ»Ñ Ğ´Ğ° Ğ¸Ğ»Ğ¸ 'n' Ğ´Ğ»Ñ Ğ½ĞµÑ‚${RESET}"
        fi
    done
    
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        local deleted=0
        for file in "${tar_files[@]}"; do
            local filename=$(basename "$file")
            if rm -f "$file" 2>/dev/null; then
                ((deleted++))
                print_message "OK" "Ğ£Ğ´Ğ°Ğ»Ñ‘Ğ½: ${file}"
                debug_log "CLEANUP" "Deleted: $file"
            else
                print_message "WARN" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑƒĞ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ: ${file}"
            fi
        done
        echo ""
        print_message "SUCCESS" "Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²: $deleted"
    else
        print_message "INFO" "Ğ¤Ğ°Ğ¹Ğ»Ñ‹ Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ñ‹"
    fi
}

# ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ compose Ñ„Ğ°Ğ¹Ğ»
offer_compose_update() {
    local compose_version="$1"
    local loaded_version="$2"
    local image_name="$3"
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ compose Ñ„Ğ°Ğ¹Ğ»
    local compose_file=""
    [[ -f "$BOT_PATH/compose.yaml" ]] && compose_file="$BOT_PATH/compose.yaml"
    [[ -f "$BOT_PATH/docker-compose.yml" ]] && compose_file="$BOT_PATH/docker-compose.yml"
    
    if [[ -z "$compose_file" ]]; then
        print_message "ERROR" "Compose Ñ„Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½"
        return 1
    fi
    
    echo -e "${CYAN}ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ² compose Ñ„Ğ°Ğ¹Ğ»Ğµ? ${compose_version} â†’ ${loaded_version}${RESET}"
    echo -e "  [1] Ğ”Ğ°, Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ¸ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹"
    echo -e "  [2] Ğ”Ğ°, Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ» (Ğ±ĞµĞ· Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞºĞ°)"
    echo -e "  [3] ĞĞµÑ‚, Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ"
    echo ""
    read -erp "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ [1-3]: " choice
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ² compose Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ»Ğ¸Ñ†ĞµĞ½Ğ·Ğ¸Ğ¸
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ LICENSE_KEY ĞµÑĞ»Ğ¸ Ğ¢Ğ•ĞšĞ£Ğ©ĞĞ¯ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ² compose >= 3.25.5
    # (Ğ½ĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ Ğ¾Ñ‚ Ñ‚Ğ¾Ğ³Ğ¾, Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¸Ğ»Ğ¸ Ğ½ĞµÑ‚)
    local current_needs_license=false
    if version_gte "$compose_version" "3.25.5"; then
        current_needs_license=true
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½ÑƒĞ¶ĞµĞ½ Ğ»Ğ¸ LICENSE_KEY Ğ´Ğ»Ñ ĞĞĞ’ĞĞ™ Ğ²ĞµÑ€ÑĞ¸Ğ¸
    local new_needs_license=false
    if version_gte "$loaded_version" "3.25.5"; then
        new_needs_license=true
    fi
    
    case "$choice" in
        1)
            print_message "INFO" "ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ compose Ñ„Ğ°Ğ¹Ğ»Ğ°..."
            if update_compose_image_version "$compose_file" "$loaded_version" "$image_name"; then
                print_message "SUCCESS" "Compose Ñ„Ğ°Ğ¹Ğ» Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½"
                
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ LICENSE_KEY Ğ¸ machine-id volume Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸
                if [[ "$new_needs_license" == true ]]; then
                    ensure_machine_id_volume "$compose_file"
                    ensure_license_key_in_env
                fi
                
                echo ""
                print_message "INFO" "ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞº ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²..."
                cd "$BOT_PATH" || return 1
                docker compose down 2>/dev/null
                sleep 2
                docker compose up -d 2>/dev/null
                sleep 3
                
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ
                if docker ps | grep -q "$BOT_CONTAINER_NAME"; then
                    print_message "SUCCESS" "ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ñ‹ Ñ Ğ²ĞµÑ€ÑĞ¸ĞµĞ¹ ${loaded_version}"
                else
                    print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²!"
                    print_message "INFO" "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ»Ğ¾Ğ³Ğ¸: docker compose logs"
                fi
                
                # ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… tar Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
                cleanup_tar_files
            else
                print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ compose Ñ„Ğ°Ğ¹Ğ»Ğ°"
            fi
            ;;
        2)
            print_message "INFO" "ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ compose Ñ„Ğ°Ğ¹Ğ»Ğ°..."
            if update_compose_image_version "$compose_file" "$loaded_version" "$image_name"; then
                print_message "SUCCESS" "Compose Ñ„Ğ°Ğ¹Ğ» Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½"
                
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ LICENSE_KEY Ğ¸ machine-id volume Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸
                if [[ "$new_needs_license" == true ]]; then
                    ensure_machine_id_volume "$compose_file"
                    ensure_license_key_in_env
                fi
                
                # ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… tar Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
                cleanup_tar_files
                
                print_message "INFO" "Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ: docker compose down && docker compose up -d"
            else
                print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ compose Ñ„Ğ°Ğ¹Ğ»Ğ°"
            fi
            ;;
        3|*)
            print_message "INFO" "Compose Ñ„Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½Ñ‘Ğ½"
            
            # Ğ’ĞĞ–ĞĞ: Ğ”Ğ°Ğ¶Ğµ ĞµÑĞ»Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¾Ñ‚ĞºĞ°Ğ·Ğ°Ğ»ÑÑ Ğ¾Ñ‚ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¸,
            # Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ LICENSE_KEY Ğ¸ machine-id Ğ´Ğ»Ñ Ğ¢Ğ•ĞšĞ£Ğ©Ğ•Ğ™ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ² compose
            if [[ "$current_needs_license" == true ]]; then
                echo ""
                print_message "INFO" "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ»Ğ¸Ñ†ĞµĞ½Ğ·Ğ¸Ğ¸ Ğ´Ğ»Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸ ${compose_version}..."
                ensure_machine_id_volume "$compose_file"
                ensure_license_key_in_env
            fi
            ;;
    esac
}

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ LICENSE_KEY Ğ² .env Ñ„Ğ°Ğ¹Ğ» (Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¸ 3.25.5+)
ensure_license_key_in_env() {
    local env_file="$BOT_PATH/.env"
    local compose_file=""
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ compose Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸
    [[ -f "$BOT_PATH/compose.yaml" ]] && compose_file="$BOT_PATH/compose.yaml"
    [[ -f "$BOT_PATH/docker-compose.yml" ]] && compose_file="$BOT_PATH/docker-compose.yml"
    
    if [[ ! -f "$env_file" ]]; then
        debug_log "LICENSE" ".env file not found: $env_file"
        return 1
    fi
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸: env_file Ğ¸Ğ»Ğ¸ environment
    # Ğ•ÑĞ»Ğ¸ Ğ² compose ĞµÑÑ‚ÑŒ "env_file:" Ğ´Ğ»Ñ ÑĞµÑ€Ğ²Ğ¸ÑĞ° bot â€” Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ñ‡Ğ¸Ñ‚Ğ°ÑÑ‚ÑÑ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ Ğ¸Ğ· .env
    # Ğ•ÑĞ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ "environment:" â€” Ğ½ÑƒĞ¶Ğ½Ğ° ÑĞ²Ğ½Ğ°Ñ ÑÑÑ‹Ğ»ĞºĞ° LICENSE_KEY=${LICENSE_KEY:-}
    local uses_env_file=false
    if [[ -n "$compose_file" ]]; then
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ env_file Ğ² ÑĞµĞºÑ†Ğ¸Ğ¸ bot
        if grep -A 30 "^\s*bot:" "$compose_file" | grep -q "env_file:"; then
            uses_env_file=true
            debug_log "LICENSE" "Compose uses env_file: direct .env reading"
        else
            debug_log "LICENSE" "Compose uses environment: variables via \${VAR}"
        fi
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ ÑƒĞ¶Ğµ LICENSE_KEY Ğ² .env
    if grep -q "^LICENSE_KEY=" "$env_file"; then
        local existing_key=$(grep "^LICENSE_KEY=" "$env_file" | cut -d'=' -f2-)
        if [[ -n "$existing_key" && "$existing_key" != '""' && "$existing_key" != "''" ]]; then
            debug_log "LICENSE" "LICENSE_KEY already exists in .env (value set)"
            return 0
        fi
        debug_log "LICENSE" "LICENSE_KEY exists but is empty"
    fi
    
    # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑĞºÑ€Ğ°Ğ½ Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ñ€Ğ°Ğ¼ĞºĞ° Ğ±Ñ‹Ğ»Ğ° Ğ²Ğ²ĞµÑ€Ñ…Ñƒ (Ğ² debug Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ)
    clear_screen
    
    # Ğ Ğ°Ğ¼ĞºĞ° LICENSE_KEY (64 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ° Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ = 62 ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ + 2 Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹)
    local B="${RED}${BOLD}"  # Border color
    local R="${RESET}"
    local C="${CYAN}"
    local Y="${YELLOW}"
    
    echo -e "${B}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${R}"
    echo -e "${B}â•‘${R}            [!] Ğ¢Ğ Ğ•Ğ‘Ğ£Ğ•Ğ¢Ğ¡Ğ¯ LICENSE_KEY                         ${B}â•‘${R}"
    echo -e "${B}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${R}"
    echo -e "${B}â•‘${R}                                                              ${B}â•‘${R}"
    echo -e "${B}â•‘${R}  ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¸ ${C}3.25.5${R} Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ±Ğ¾Ñ‚Ğ° Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ           ${B}â•‘${R}"
    echo -e "${B}â•‘${R}  Ğ»Ğ¸Ñ†ĞµĞ½Ğ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ»ÑÑ‡ (LICENSE_KEY).                            ${B}â•‘${R}"
    echo -e "${B}â•‘${R}                                                              ${B}â•‘${R}"
    echo -e "${B}â•‘${R}  ${Y}LICENSE_KEY Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ¸Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ² .env Ñ„Ğ°Ğ¹Ğ»Ğµ!${R}              ${B}â•‘${R}"
    echo -e "${B}â•‘${R}                                                              ${B}â•‘${R}"
    echo -e "${B}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${R}"
    echo -e "${B}â•‘${R}  ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ»ÑÑ‡ Ğ² Ğ±Ğ¾Ñ‚Ğµ: ${C}https://t.me/rwp_shop_bot${R}             ${B}â•‘${R}"
    echo -e "${B}â•‘${R}  Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ ĞºĞ»ÑÑ‡Ğ°: 64 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ° (hex)                              ${B}â•‘${R}"
    echo -e "${B}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${R}"
    echo ""
    
    # Ğ¦Ğ¸ĞºĞ» Ğ²Ğ²Ğ¾Ğ´Ğ° Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸ĞµĞ¹
    local license_key=""
    while true; do
        read -erp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ LICENSE_KEY (Ğ¸Ğ»Ğ¸ Enter Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ): " license_key
        
        # ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ğ²Ğ²Ğ¾Ğ´ â€” Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ
        if [[ -z "$license_key" ]]; then
            break
        fi
        
        # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹ Ğ¿Ğ¾ ĞºÑ€Ğ°ÑĞ¼
        license_key=$(echo "$license_key" | tr -d '[:space:]')
        
        # ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğº Ğ½Ğ¸Ğ¶Ğ½ĞµĞ¼Ñƒ Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ñƒ
        license_key=$(echo "$license_key" | tr '[:upper:]' '[:lower:]')
        
        # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ: Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ 64 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ° hex (0-9, a-f)
        if [[ "$license_key" =~ ^[0-9a-f]{64}$ ]]; then
            break
        else
            echo ""
            print_message "ERROR" "ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ LICENSE_KEY!"
            echo -e "  ĞĞ¶Ğ¸Ğ´Ğ°ĞµÑ‚ÑÑ: ${CYAN}64 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ° (0-9, a-f)${RESET}"
            echo -e "  ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾:  ${YELLOW}${#license_key} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²${RESET}"
            echo ""
        fi
    done
    
    if [[ -n "$license_key" ]]; then
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ ÑƒĞ¶Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ° LICENSE_KEY= (Ğ¿ÑƒÑÑ‚Ğ°Ñ)
        if grep -q "^LICENSE_KEY=" "$env_file"; then
            # Ğ—Ğ°Ğ¼ĞµĞ½ÑĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ÑƒÑ Ğ¿ÑƒÑÑ‚ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ
            sed -i "s|^LICENSE_KEY=.*|LICENSE_KEY=$license_key|" "$env_file"
        else
            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ LICENSE_KEY Ğ² ĞºĞ¾Ğ½ĞµÑ† .env Ñ„Ğ°Ğ¹Ğ»Ğ°
            echo "" >> "$env_file"
            echo "# License key (required from v3.25.5)" >> "$env_file"
            echo "LICENSE_KEY=$license_key" >> "$env_file"
        fi
        print_message "SUCCESS" "LICENSE_KEY Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½ Ğ² .env"
        
        # ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ environment (Ğ½Ğµ env_file)
        # ĞŸÑ€Ğ¸ env_file Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ñ‡Ğ¸Ñ‚Ğ°ÑÑ‚ÑÑ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ Ğ¸Ğ· .env â€” Ğ²ÑÑ‘ ĞĞš
        if [[ "$uses_env_file" == false && -n "$compose_file" ]]; then
            if ! grep -q "LICENSE_KEY" "$compose_file"; then
                echo ""
                print_message "WARN" "Ğ’ compose Ñ„Ğ°Ğ¹Ğ»Ğµ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ LICENSE_KEY Ğ² environment!"
                echo -e "${YELLOW}Ğ’Ğ°Ñˆ compose Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞµĞºÑ†Ğ¸Ñ environment (Ğ½Ğµ env_file).${RESET}"
                echo -e "${YELLOW}Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ² ÑĞµĞºÑ†Ğ¸Ñ environment ÑĞµÑ€Ğ²Ğ¸ÑĞ° bot:${RESET}"
                echo -e "${CYAN}      - LICENSE_KEY=\${LICENSE_KEY:-}${RESET}"
                echo ""
                echo -e "Ğ˜Ğ»Ğ¸ Ğ¿ĞµÑ€ĞµĞ¹Ğ´Ğ¸Ñ‚Ğµ Ğ½Ğ° Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ñ env_file â€” Ñ‚Ğ¾Ğ³Ğ´Ğ° Ğ²ÑĞµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ"
                echo -e "Ğ¸Ğ· .env Ğ±ÑƒĞ´ÑƒÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸."
                echo ""
                print_message "INFO" "Ğ¡ĞºĞ°Ñ‡Ğ°Ğ¹Ñ‚Ğµ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ compose Ñ„Ğ°Ğ¹Ğ» Ğ¸Ğ· Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸"
                read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ..." dummy
            fi
        fi
        return 0
    else
        echo ""
        # Ğ Ğ°Ğ¼ĞºĞ° Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ (62 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ° ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°)
        local B="${RED}${BOLD}"
        local R="${RESET}"
        local Y="${YELLOW}${BOLD}"
        local C="${CYAN}"
        local W="${WHITE}${BOLD}"
        
        echo -e "${B}â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”${R}"
        echo -e "${B}â”‚${R}   ${Y}[!] LICENSE_KEY Ğ½Ğµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½. Ğ‘Ğ¾Ñ‚ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒÑÑ!${R}     ${B}â”‚${R}"
        echo -e "${B}â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤${R}"
        echo -e "${B}â”‚${R}                                                              ${B}â”‚${R}"
        echo -e "${B}â”‚${R}  Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ Ğ² .env:                                    ${B}â”‚${R}"
        echo -e "${B}â”‚${R}     ${C}LICENSE_KEY=Ğ²Ğ°Ñˆ_ĞºĞ»ÑÑ‡_64_ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°${R}                          ${B}â”‚${R}"
        echo -e "${B}â”‚${R}                                                              ${B}â”‚${R}"
        echo -e "${B}â”‚${R}   ${W}ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ĞºĞ»ÑÑ‡:${R} ${C}https://t.me/rwp_shop_bot${R}                   ${B}â”‚${R}"
        echo -e "${B}â”‚${R}                                                              ${B}â”‚${R}"
        echo -e "${B}â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜${R}"
        echo ""
        read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ..." dummy
        return 1
    fi
}

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ machine-id volume Ğ² compose Ñ„Ğ°Ğ¹Ğ» (Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¸ 3.25.5+ Ğ´Ğ»Ñ Ğ»Ğ¸Ñ†ĞµĞ½Ğ·Ğ¸Ğ¸)
ensure_machine_id_volume() {
    local compose_file="$1"
    
    if [[ ! -f "$compose_file" ]]; then
        debug_log "MACHINE_ID" "Compose file not found: $compose_file"
        return 1
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ ÑƒĞ¶Ğµ machine-id volume
    if grep -q "/etc/machine-id" "$compose_file"; then
        debug_log "MACHINE_ID" "machine-id volume already exists in compose"
        return 0
    fi
    
    # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑĞºÑ€Ğ°Ğ½ Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ñ€Ğ°Ğ¼ĞºĞ° Ğ±Ñ‹Ğ»Ğ° Ğ²Ğ²ĞµÑ€Ñ…Ñƒ (Ğ² debug Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ)
    clear_screen
    
    # ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ Ğ°Ğ»Ğ¸Ğ°ÑÑ‹
    local B="${RED}${BOLD}"
    local R="${RESET}"
    local C="${CYAN}"
    local Y="${YELLOW}"
    
    echo -e "${B}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${R}"
    echo -e "${B}â•‘${R}          [!] ĞĞ¢Ğ¡Ğ£Ğ¢Ğ¡Ğ¢Ğ’Ğ£Ğ•Ğ¢ VOLUME Ğ”Ğ›Ğ¯ Ğ›Ğ˜Ğ¦Ğ•ĞĞ—Ğ˜Ğ˜                 ${B}â•‘${R}"
    echo -e "${B}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${R}"
    echo -e "${B}â•‘${R}                                                              ${B}â•‘${R}"
    echo -e "${B}â•‘${R}  Ğ’ compose Ñ„Ğ°Ğ¹Ğ»Ğµ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ volume:              ${B}â•‘${R}"
    echo -e "${B}â•‘${R}  ${C}/etc/machine-id:/etc/machine-id:ro${R}                          ${B}â•‘${R}"
    echo -e "${B}â•‘${R}                                                              ${B}â•‘${R}"
    echo -e "${B}â•‘${R}  Ğ­Ñ‚Ğ¾Ñ‚ volume Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ²ÑĞ·ĞºĞ¸ Ğ»Ğ¸Ñ†ĞµĞ½Ğ·Ğ¸Ğ¸ Ğº ÑĞµÑ€Ğ²ĞµÑ€Ñƒ.      ${B}â•‘${R}"
    echo -e "${B}â•‘${R}  ${Y}Ğ‘ĞµĞ· Ğ½ĞµĞ³Ğ¾ Ğ±Ğ¾Ñ‚ Ğ½Ğµ ÑĞ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ»Ğ¸Ñ†ĞµĞ½Ğ·Ğ¸Ñ!${R}                  ${B}â•‘${R}"
    echo -e "${B}â•‘${R}                                                              ${B}â•‘${R}"
    echo -e "${B}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${R}"
    echo -e "${B}â•‘${R}  ĞÑƒĞ¶Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ² ÑĞµĞºÑ†Ğ¸Ñ volumes ÑĞµÑ€Ğ²Ğ¸ÑĞ° bot:                ${B}â•‘${R}"
    echo -e "${B}â•‘${R}  ${C}volumes:${R}                                                    ${B}â•‘${R}"
    echo -e "${B}â•‘${R}  ${C}  - /etc/machine-id:/etc/machine-id:ro${R}                      ${B}â•‘${R}"
    echo -e "${B}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${R}"
    echo ""
    
    local confirm=""
    while [[ ! "$confirm" =~ ^[YyNn]$ ]]; do
        read -erp "Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸? (y/n): " confirm
        if [[ ! "$confirm" =~ ^[YyNn]$ ]]; then
            echo -e "${YELLOW}Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ 'y' Ğ´Ğ»Ñ Ğ´Ğ° Ğ¸Ğ»Ğ¸ 'n' Ğ´Ğ»Ñ Ğ½ĞµÑ‚${RESET}"
        fi
    done
    
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ±ÑĞºĞ°Ğ¿
        cp "$compose_file" "${compose_file}.bak.machine-id"
        
        # Ğ˜Ñ‰ĞµĞ¼ ÑĞµĞºÑ†Ğ¸Ñ volumes Ğ² ÑĞµÑ€Ğ²Ğ¸ÑĞµ bot Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ machine-id
        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ sed Ğ´Ğ»Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ÑĞ»Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ñ volumes: Ğ² ÑĞµĞºÑ†Ğ¸Ğ¸ bot
        
        # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ ÑƒĞ¶Ğµ ÑĞµĞºÑ†Ğ¸Ñ volumes Ñƒ bot
        if grep -A 20 "^\s*bot:" "$compose_file" | grep -q "^\s*volumes:"; then
            # Ğ•ÑÑ‚ÑŒ ÑĞµĞºÑ†Ğ¸Ñ volumes - Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ğ¾ÑĞ»Ğµ Ğ½ĞµÑ‘
            # Ğ˜Ñ‰ĞµĞ¼ Ğ¿ĞµÑ€Ğ²ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ volumes: Ğ¿Ğ¾ÑĞ»Ğµ bot: Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ğ¾ÑĞ»Ğµ Ğ½ĞµÑ‘
            local in_bot=false
            local volumes_found=false
            local temp_file=$(mktemp)
            
            while IFS= read -r line; do
                echo "$line" >> "$temp_file"
                
                # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ğ¼Ñ‹ Ğ² ÑĞµĞºÑ†Ğ¸Ğ¸ bot
                if [[ "$line" =~ ^[[:space:]]*bot: ]]; then
                    in_bot=true
                    volumes_found=false
                fi
                
                # Ğ’Ñ‹Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ¸Ğ· ÑĞµĞºÑ†Ğ¸Ğ¸ bot ĞµÑĞ»Ğ¸ Ğ²ÑÑ‚Ñ€ĞµÑ‚Ğ¸Ğ»Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ
                if [[ "$in_bot" == true && "$line" =~ ^[[:space:]]{2}[a-z] && ! "$line" =~ ^[[:space:]]*bot: && ! "$line" =~ ^[[:space:]]{4} ]]; then
                    in_bot=false
                fi
                
                # Ğ•ÑĞ»Ğ¸ Ğ¼Ñ‹ Ğ² bot Ğ¸ Ğ½Ğ°ÑˆĞ»Ğ¸ volumes: - Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ machine-id
                if [[ "$in_bot" == true && "$volumes_found" == false && "$line" =~ ^[[:space:]]*volumes: ]]; then
                    volumes_found=true
                    echo "      - /etc/machine-id:/etc/machine-id:ro" >> "$temp_file"
                fi
            done < "$compose_file"
            
            mv "$temp_file" "$compose_file"
            print_message "SUCCESS" "Volume /etc/machine-id Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½ Ğ² compose Ñ„Ğ°Ğ¹Ğ»"
            print_message "INFO" "Ğ‘ÑĞºĞ°Ğ¿ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½: ${compose_file}.bak.machine-id"
            echo ""
            read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ..." dummy
        else
            # ĞĞµÑ‚ ÑĞµĞºÑ†Ğ¸Ğ¸ volumes - Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ
            print_message "ERROR" "Ğ¡ĞµĞºÑ†Ğ¸Ñ volumes Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° Ğ² ÑĞµÑ€Ğ²Ğ¸ÑĞµ bot"
            print_message "INFO" "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ Ğ² docker-compose.yml:"
            echo ""
            echo -e "${CYAN}services:"
            echo -e "  bot:"
            echo -e "    volumes:"
            echo -e "      - /etc/machine-id:/etc/machine-id:ro${RESET}"
            read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ..." dummy
            return 1
        fi
        return 0
    else
        print_message "WARN" "Volume Ğ½Ğµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½. Ğ›Ğ¸Ñ†ĞµĞ½Ğ·Ğ¸Ñ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ!"
        print_message "INFO" "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ: /etc/machine-id:/etc/machine-id:ro"
        read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ..." dummy
        return 1
    fi
}

# ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ image Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ² docker-compose Ñ„Ğ°Ğ¹Ğ»Ğµ
# ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²ÑĞµ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ image
update_compose_image_version() {
    local compose_file="$1"
    local new_version="$2"
    local new_image_name="$3"  # ĞĞ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾: Ğ¸Ğ¼Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ image
    
    debug_log "COMPOSE" "=== update_compose_image_version() ==="
    debug_log "COMPOSE" "  compose_file=$compose_file"
    debug_log "COMPOSE" "  new_version=$new_version"
    debug_log "COMPOSE" "  new_image_name=$new_image_name"
    
    if [[ ! -f "$compose_file" ]]; then
        debug_log "COMPOSE" "Compose file not found: $compose_file"
        print_message "ERROR" "Compose Ñ„Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: $compose_file"
        return 1
    fi
    
    # Ğ•ÑĞ»Ğ¸ Ğ½Ğ¾Ğ²Ğ¾Ğµ Ğ¸Ğ¼Ñ image Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ rwp_shop (Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ)
    [[ -z "$new_image_name" ]] && new_image_name="rwp_shop"
    debug_log "COMPOSE" "Target image name: $new_image_name"
    
    # Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ²ÑĞµÑ… Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¸Ğ¼Ñ‘Ğ½ image Ğ±Ğ¾Ñ‚Ğ°
    local image_patterns=(
        "rwp_shop"
        "private-remnawave-telegram-shop-bot"
        "telegram-shop"
        "shopbot"
    )
    
    local found=false
    for pattern in "${image_patterns[@]}"; do
        debug_log "COMPOSE" "Checking for pattern: $pattern"
        if grep -qE "image:\s*['\"]?${pattern}:" "$compose_file"; then
            debug_log "COMPOSE" "Pattern matched: $pattern"
            # Ğ—Ğ°Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ½Ğ° Ğ½Ğ¾Ğ²Ğ¾Ğµ Ğ¸Ğ¼Ñ Ğ¸ Ğ²ĞµÑ€ÑĞ¸Ñ
            sed -i -E "s|(image:\s*['\"]?)${pattern}:[0-9]+\.[0-9]+\.[0-9]+|\1${new_image_name}:${new_version}|g" "$compose_file"
            found=true
            debug_log "COMPOSE" "Sed replacement done: ${pattern} -> ${new_image_name}:${new_version}"
            print_message "SUCCESS" "Image Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½: ${pattern} â†’ ${new_image_name}:${new_version}"
            break
        fi
    done
    
    if [[ "$found" == "false" ]]; then
        debug_log "COMPOSE" "No matching image pattern found in compose file"
        print_message "ERROR" "ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ image Ğ±Ğ¾Ñ‚Ğ° Ğ² compose Ñ„Ğ°Ğ¹Ğ»Ğµ"
        print_message "INFO" "Ğ˜ÑĞºĞ°Ğ»Ğ¸ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹: ${image_patterns[*]}"
        return 1
    fi
    
    debug_log "COMPOSE" "update_compose_image_version() completed successfully"
    return 0
}

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ Ğ‘Ğ”
check_db_health() {
    local db_container="$1"
    local max_attempts="${2:-30}"
    local attempt=1
    
    debug_log "HEALTH" "check_db_health($db_container, max=$max_attempts)"
    
    while [[ $attempt -le $max_attempts ]]; do
        local health=$(docker inspect -f '{{.State.Health.Status}}' "$db_container" 2> "$SILENT_LOG")
        debug_log "HEALTH" "  attempt $attempt: health=$health"
        
        if [[ "$health" == "healthy" ]]; then
            debug_log "HEALTH" "DB healthy via docker healthcheck"
            return 0
        fi
        
        # ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· pg_isready
        if docker exec "$db_container" pg_isready -U "$DB_USER" > "$SILENT_LOG" 2>&1; then
            debug_log "HEALTH" "DB healthy via pg_isready"
            return 0
        fi
        
        echo -ne "\r  ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ‘Ğ”... ($attempt/$max_attempts)"
        sleep 1
        ((attempt++))
    done
    
    debug_log "HEALTH" "DB health check failed after $max_attempts attempts"
    echo ""
    return 1
}

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‡Ñ‚Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ±Ğ¾Ñ‚Ğ° Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ğ»ÑÑ Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚
check_bot_health() {
    local bot_container="$1"
    local max_attempts="${2:-20}"
    local attempt=1
    
    debug_log "HEALTH" "check_bot_health($bot_container, max=$max_attempts)"
    
    while [[ $attempt -le $max_attempts ]]; do
        local status=$(docker inspect -f '{{.State.Status}}' "$bot_container" 2> "$SILENT_LOG")
        local running=$(docker inspect -f '{{.State.Running}}' "$bot_container" 2> "$SILENT_LOG")
        debug_log "HEALTH" "  attempt $attempt: status=$status, running=$running"
        
        if [[ "$status" == "running" && "$running" == "true" ]]; then
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ½Ğµ Ñ€ĞµÑÑ‚Ğ°Ñ€Ñ‚ÑƒĞµÑ‚
            sleep 2
            local status2=$(docker inspect -f '{{.State.Status}}' "$bot_container" 2> "$SILENT_LOG")
            debug_log "HEALTH" "  stability check: status2=$status2"
            if [[ "$status2" == "running" ]]; then
                debug_log "HEALTH" "Bot healthy and stable"
                return 0
            fi
        fi
        
        echo -ne "\r  ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ¾Ñ‚Ğ°... ($attempt/$max_attempts)"
        sleep 1
        ((attempt++))
    done
    
    debug_log "HEALTH" "Bot health check failed after $max_attempts attempts"
    echo ""
    return 1
}

# ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ±ÑĞºĞ°Ğ¿ Ğ‘Ğ” Ğ´Ğ»Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ rollback
get_latest_db_backup() {
    local latest=$(find "$BACKUP_DIR" -maxdepth 1 -type f \( -name "lazarus_db_*.tar.gz" -o -name "lazarus_db_*.tar.gz.enc" \) -printf '%T@ %p\n' 2> "$SILENT_LOG" | sort -rn | head -1 | awk '{print $2}')
    echo "$latest"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AUTO UPDATE - ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ñ‚Ğ° Ğ±ĞµĞ· Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: lazarus auto_update [LICENSE_KEY]
#   LICENSE_KEY - Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾, ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ½ Ğ¸ Ğ½ÑƒĞ¶ĞµĞ½ - Ğ±ÑƒĞ´ĞµÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑˆĞµĞ½
#
# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:
#   lazarus auto_update                           # ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ, ÑĞ¿Ñ€Ğ¾ÑĞ¸Ñ‚ ĞºĞ»ÑÑ‡ ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶ĞµĞ½
#   lazarus auto_update abc123...                 # ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ñ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¼ ĞºĞ»ÑÑ‡Ğ¾Ğ¼
#   LICENSE_KEY=abc123 lazarus auto_update        # Ğ§ĞµÑ€ĞµĞ· Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
auto_update_bot() {
    local provided_key="${1:-$LICENSE_KEY}"  # Ğ˜Ğ· Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¸Ğ»Ğ¸ env
    
    echo -e "${GREEN}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo -e "${GREEN}${BOLD}  LAZARUS Auto Update v${VERSION}${RESET}"
    echo -e "${GREEN}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo ""
    
    # === 1. ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞŸĞ£Ğ¢Ğ˜ Ğš Ğ‘ĞĞ¢Ğ£ ===
    log_message "INFO" "[AUTO] Starting auto update..."
    
    if [[ -z "$BOT_PATH" || ! -d "$BOT_PATH" ]]; then
        # ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸
        if [[ -d "$DEFAULT_BOT_PATH" && ( -f "$DEFAULT_BOT_PATH/docker-compose.yml" || -f "$DEFAULT_BOT_PATH/compose.yaml" ) ]]; then
            BOT_PATH="$DEFAULT_BOT_PATH"
            save_config
        else
            ensure_bot_path || {
                print_message "ERROR" "ĞŸÑƒÑ‚ÑŒ Ğº Ğ±Ğ¾Ñ‚Ñƒ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½!"
                echo "Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ BOT_PATH Ğ² config.env Ğ¸Ğ»Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ±Ğ¾Ñ‚Ğ°"
                return 1
            }
        fi
    fi
    
    print_message "INFO" "ĞŸÑƒÑ‚ÑŒ Ğº Ğ±Ğ¾Ñ‚Ñƒ: $BOT_PATH"
    
    # === 2. ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ¯Ğ•Ğœ COMPOSE Ğ¤ĞĞ™Ğ› ===
    local compose_file=""
    [[ -f "$BOT_PATH/compose.yaml" ]] && compose_file="$BOT_PATH/compose.yaml"
    [[ -f "$BOT_PATH/docker-compose.yml" ]] && compose_file="$BOT_PATH/docker-compose.yml"
    
    if [[ -z "$compose_file" ]]; then
        print_message "ERROR" "Compose Ñ„Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² $BOT_PATH"
        return 1
    fi
    
    # === 3. Ğ¢Ğ•ĞšĞ£Ğ©ĞĞ¯ Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ¯ ===
    local current_version=$(get_current_bot_version)
    print_message "INFO" "Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ: ${current_version:-Ğ½Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°}"
    
    # === 4. ĞŸĞĞ˜Ğ¡Ğš ĞĞĞ’ĞĞ™ Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ˜ ===
    # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Docker images
    local latest_docker_version=""
    local latest_docker_image=""
    local docker_images=$(get_loaded_bot_images)
    
    if [[ -n "$docker_images" ]]; then
        while IFS='|' read -r img_name img_ver; do
            [[ -z "$img_ver" ]] && continue
            if [[ -z "$latest_docker_version" ]] || version_gt "$img_ver" "$latest_docker_version"; then
                latest_docker_version="$img_ver"
                latest_docker_image="$img_name"
            fi
        done <<< "$docker_images"
    fi
    
    # Ğ—Ğ°Ñ‚ĞµĞ¼ Ğ¸Ñ‰ĞµĞ¼ .tar Ñ„Ğ°Ğ¹Ğ»Ñ‹
    local latest_tar_version=""
    local latest_tar_file=""
    local tar_files=$(find_all_bot_image_files)
    
    if [[ -n "$tar_files" ]]; then
        while IFS= read -r file; do
            [[ -z "$file" ]] && continue
            local fversion=$(extract_version_from_filename "$(basename "$file")")
            if [[ -n "$fversion" ]]; then
                if [[ -z "$latest_tar_version" ]] || version_gt "$fversion" "$latest_tar_version"; then
                    latest_tar_version="$fversion"
                    latest_tar_file="$file"
                fi
            fi
        done <<< "$tar_files"
    fi
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ
    local selected_version=""
    local selected_file=""
    local selected_image=""
    local need_docker_load=false
    
    # ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚: Docker image > tar file
    if [[ -n "$latest_docker_version" ]]; then
        if [[ -z "$current_version" ]] || version_gt "$latest_docker_version" "$current_version"; then
            selected_version="$latest_docker_version"
            selected_image="$latest_docker_image"
            print_message "SUCCESS" "ĞĞ°Ğ¹Ğ´ĞµĞ½ Ğ¾Ğ±Ñ€Ğ°Ğ· Ğ² Docker: ${selected_image}:${selected_version}"
        fi
    fi
    
    if [[ -z "$selected_version" && -n "$latest_tar_version" ]]; then
        if [[ -z "$current_version" ]] || version_gt "$latest_tar_version" "$current_version"; then
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ»Ğ¸ ÑƒĞ¶Ğµ ÑÑ‚Ğ¾Ñ‚ tar Ğ² Docker
            local tar_image=$(get_image_name_from_tar "$latest_tar_file")
            if is_image_loaded_in_docker "$tar_image" "$latest_tar_version"; then
                selected_version="$latest_tar_version"
                selected_image="$tar_image"
                print_message "SUCCESS" "ĞĞ±Ñ€Ğ°Ğ· Ğ¸Ğ· .tar ÑƒĞ¶Ğµ Ğ² Docker: ${selected_image}:${selected_version}"
            else
                selected_version="$latest_tar_version"
                selected_file="$latest_tar_file"
                need_docker_load=true
                print_message "SUCCESS" "ĞĞ°Ğ¹Ğ´ĞµĞ½ .tar Ñ„Ğ°Ğ¹Ğ»: $(basename "$latest_tar_file")"
            fi
        fi
    fi
    
    if [[ -z "$selected_version" ]]; then
        if [[ -n "$current_version" ]]; then
            print_message "SUCCESS" "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ²ĞµÑ€ÑĞ¸Ñ: $current_version"
        else
            print_message "ERROR" "ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ"
            echo ""
            echo "Ğ¡ĞºĞ°Ñ‡Ğ°Ğ¹Ñ‚Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ· Ğ±Ğ¾Ñ‚Ğ° Ğ¸ Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚Ğµ Ğ² $BOT_PATH"
            return 1
        fi
        # Ğ”Ğ°Ğ¶Ğµ ĞµÑĞ»Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ½ĞµÑ‚ - Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
        selected_version="$current_version"
    fi
    
    # === 5. ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ Ğ¢Ğ Ğ•Ğ‘ĞĞ’ĞĞĞ˜Ğ™ v3.25.5+ ===
    if version_gte "$selected_version" "3.25.5"; then
        echo ""
        print_message "INFO" "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ»Ñ v3.25.5+..."
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ machine-id volume
        if ! has_machine_id_volume; then
            print_message "WARN" "Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ machine-id volume Ğ² compose..."
            
            # ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ machine-id
            if grep -A 20 "^\s*bot:" "$compose_file" | grep -q "^\s*volumes:"; then
                cp "$compose_file" "${compose_file}.bak.auto"
                local temp_file=$(mktemp)
                local in_bot=false
                local volumes_found=false
                
                while IFS= read -r line; do
                    echo "$line" >> "$temp_file"
                    if [[ "$line" =~ ^[[:space:]]*bot: ]]; then
                        in_bot=true
                        volumes_found=false
                    fi
                    if [[ "$in_bot" == true && "$line" =~ ^[[:space:]]{2}[a-z] && ! "$line" =~ ^[[:space:]]*bot: && ! "$line" =~ ^[[:space:]]{4} ]]; then
                        in_bot=false
                    fi
                    if [[ "$in_bot" == true && "$volumes_found" == false && "$line" =~ ^[[:space:]]*volumes: ]]; then
                        volumes_found=true
                        echo "      - /etc/machine-id:/etc/machine-id:ro" >> "$temp_file"
                    fi
                done < "$compose_file"
                
                mv "$temp_file" "$compose_file"
                print_message "SUCCESS" "machine-id volume Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½"
            else
                print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ machine-id Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸"
                echo "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ Ğ² ÑĞµĞºÑ†Ğ¸Ñ volumes:"
                echo "  - /etc/machine-id:/etc/machine-id:ro"
                return 1
            fi
        else
            print_message "SUCCESS" "machine-id volume: âœ“"
        fi
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ LICENSE_KEY
        if ! has_license_key; then
            if [[ -n "$provided_key" && "$provided_key" =~ ^[0-9a-f]{64}$ ]]; then
                # ĞšĞ»ÑÑ‡ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ½ ĞºĞ°Ğº Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€
                local env_file="$BOT_PATH/.env"
                if grep -q "^LICENSE_KEY=" "$env_file" 2>/dev/null; then
                    sed -i "s|^LICENSE_KEY=.*|LICENSE_KEY=$provided_key|" "$env_file"
                else
                    echo "" >> "$env_file"
                    echo "# License key (required from v3.25.5)" >> "$env_file"
                    echo "LICENSE_KEY=$provided_key" >> "$env_file"
                fi
                print_message "SUCCESS" "LICENSE_KEY Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½"
            else
                print_message "WARN" "LICENSE_KEY Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½!"
                echo ""
                echo -e "ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ»ÑÑ‡: ${CYAN}https://t.me/rwp_shop_bot${RESET}"
                echo ""
                read -erp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ LICENSE_KEY (64 hex ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°): " input_key
                input_key=$(echo "$input_key" | tr -d '[:space:]' | tr '[:upper:]' '[:lower:]')
                
                if [[ "$input_key" =~ ^[0-9a-f]{64}$ ]]; then
                    local env_file="$BOT_PATH/.env"
                    if grep -q "^LICENSE_KEY=" "$env_file" 2>/dev/null; then
                        sed -i "s|^LICENSE_KEY=.*|LICENSE_KEY=$input_key|" "$env_file"
                    else
                        echo "" >> "$env_file"
                        echo "# License key (required from v3.25.5)" >> "$env_file"
                        echo "LICENSE_KEY=$input_key" >> "$env_file"
                    fi
                    print_message "SUCCESS" "LICENSE_KEY Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½"
                else
                    print_message "ERROR" "ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ LICENSE_KEY!"
                    return 1
                fi
            fi
        else
            print_message "SUCCESS" "LICENSE_KEY: âœ“"
        fi
    fi
    
    # === 6. ĞĞ‘ĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ• (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ½Ğ¾Ğ²Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ) ===
    if [[ -n "$selected_version" && "$selected_version" != "$current_version" ]]; then
        echo ""
        print_message "INFO" "ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ: $current_version â†’ $selected_version"
        
        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ· ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾
        if [[ "$need_docker_load" == true && -n "$selected_file" ]]; then
            print_message "INFO" "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ° Ğ² Docker..."
            if ! docker load -i "$selected_file"; then
                print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ°!"
                return 1
            fi
            selected_image=$(get_image_name_from_tar "$selected_file")
            print_message "SUCCESS" "ĞĞ±Ñ€Ğ°Ğ· Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½: ${selected_image}:${selected_version}"
        fi
        
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ² compose
        print_message "INFO" "ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ compose Ñ„Ğ°Ğ¹Ğ»Ğ°..."
        if ! update_compose_image_version "$compose_file" "$selected_version" "$selected_image"; then
            print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ compose Ñ„Ğ°Ğ¹Ğ»Ğ°!"
            return 1
        fi
        
        # ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€
        print_message "INFO" "ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞº Ğ±Ğ¾Ñ‚Ğ°..."
        cd "$BOT_PATH" || return 1
        
        docker compose down 2>/dev/null || docker-compose down 2>/dev/null
        sleep 2
        docker compose up -d 2>/dev/null || docker-compose up -d 2>/dev/null
        
        sleep 3
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ
        local new_status=$(docker compose ps --format "{{.Status}}" 2>/dev/null | head -1)
        if [[ "$new_status" == *"Up"* ]]; then
            print_message "SUCCESS" "Ğ‘Ğ¾Ñ‚ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½ Ğ´Ğ¾ Ğ²ĞµÑ€ÑĞ¸Ğ¸ $selected_version"
        else
            print_message "WARN" "Ğ‘Ğ¾Ñ‚ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½, Ğ½Ğ¾ ÑÑ‚Ğ°Ñ‚ÑƒÑ: $new_status"
            echo "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ»Ğ¾Ğ³Ğ¸: docker logs rwp_shop"
        fi
    else
        echo ""
        print_message "SUCCESS" "ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ"
    fi
    
    echo ""
    log_message "INFO" "[AUTO] Auto update completed"
    return 0
}

# Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ñ‚Ğ°
update_bot() {
    debug_log "UPDATE" "=== Starting update_bot() ==="
    clear_screen
    echo -e "${GREEN}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo -e "${GREEN}${BOLD}  ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ñ‚Ğ°${RESET}"
    echo -e "${GREEN}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo ""
    
    # === Ğ­Ğ¢ĞĞŸ 1: ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• ĞŸĞ£Ğ¢Ğ˜ Ğš Ğ‘ĞĞ¢Ğ£ ===
    debug_log "UPDATE" "[STAGE 1] Checking bot path..."
    local bot_path_ok=false
    
    # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ BOT_PATH
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" && ( -f "$BOT_PATH/docker-compose.yml" || -f "$BOT_PATH/compose.yaml" ) ]]; then
        bot_path_ok=true
        debug_log "UPDATE" "Bot path OK: $BOT_PATH"
    fi
    
    # Ğ•ÑĞ»Ğ¸ Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ â€” Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ½Ğ°Ğ¹Ñ‚Ğ¸
    if [[ "$bot_path_ok" == "false" ]]; then
        debug_log "UPDATE" "Bot path not configured, starting search..."
        print_message "INFO" "ĞŸÑƒÑ‚ÑŒ Ğº Ğ±Ğ¾Ñ‚Ñƒ Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½. Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿Ğ¾Ğ¸ÑĞº..."
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ· Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸
        if [[ -d "$DEFAULT_BOT_PATH" && ( -f "$DEFAULT_BOT_PATH/docker-compose.yml" || -f "$DEFAULT_BOT_PATH/compose.yaml" ) ]]; then
            debug_log "UPDATE" "Found bot at default path: $DEFAULT_BOT_PATH"
            print_message "SUCCESS" "ĞĞ°Ğ¹Ğ´ĞµĞ½ Ğ±Ğ¾Ñ‚ Ğ² $DEFAULT_BOT_PATH"
            BOT_PATH="$DEFAULT_BOT_PATH"
            save_config
            bot_path_ok=true
        else
            debug_log "UPDATE" "Default path not found, running ensure_bot_path()..."
            # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ°Ğ²Ñ‚Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº
            if ! ensure_bot_path; then
                debug_log "UPDATE" "ensure_bot_path() failed, prompting manual input"
                echo ""
                print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºÑƒ Ğ±Ğ¾Ñ‚Ğ°!"
                echo ""
                echo -e "ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸ (Ğ¸Ğ· Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸):"
                echo -e "  ${CYAN}/opt/private-remnawave-telegram-shop-bot/${RESET}"
                echo -e "  ${CYAN}/opt/remnawave-telegram-shop/${RESET}"
                echo ""
                echo -e "ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ğ°Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°:"
                echo -e "  â”œâ”€â”€ compose.yaml (Ğ¸Ğ»Ğ¸ docker-compose.yml)"
                echo -e "  â”œâ”€â”€ .env"
                echo -e "  â””â”€â”€ rwp_shop-X.Y.Z-amd64.tar"
                echo ""
                read -erp "Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ğ¿ÑƒÑ‚ÑŒ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ (Enter - $DEFAULT_BOT_PATH): " manual_path
                manual_path="${manual_path:-$DEFAULT_BOT_PATH}"
                
                if [[ -d "$manual_path" ]]; then
                    debug_log "UPDATE" "Manual path accepted: $manual_path"
                    BOT_PATH="$manual_path"
                    save_config
                    bot_path_ok=true
                else
                    debug_log "UPDATE" "Manual path not found: $manual_path"
                    print_message "ERROR" "ĞŸĞ°Ğ¿ĞºĞ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°: $manual_path"
                    read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
                    return 1
                fi
            else
                debug_log "UPDATE" "ensure_bot_path() success, BOT_PATH=$BOT_PATH"
                bot_path_ok=true
            fi
        fi
    fi
    
    # Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿ÑƒÑ‚Ğ¸
    debug_log "UPDATE" "Final path check: bot_path_ok=$bot_path_ok, BOT_PATH=$BOT_PATH"
    if [[ "$bot_path_ok" == "false" || -z "$BOT_PATH" || ! -d "$BOT_PATH" ]]; then
        debug_log "UPDATE" "Path validation failed, aborting"
        print_message "ERROR" "ĞŸÑƒÑ‚ÑŒ Ğº Ğ±Ğ¾Ñ‚Ñƒ Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½!"
        read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
        return 1
    fi
    
    # === Ğ­Ğ¢ĞĞŸ 2: Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ Ğ Ğ¢Ğ•ĞšĞ£Ğ©Ğ•Ğ™ Ğ£Ğ¡Ğ¢ĞĞĞĞ’ĞšĞ• ===
    debug_log "UPDATE" "[STAGE 2] Getting current installation info..."
    local current_version=$(get_raw_bot_version)
    debug_log "UPDATE" "Current version raw: $current_version"
    if [[ -z "$current_version" || "$current_version" == "Unknown" ]]; then
        print_message "WARN" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ±Ğ¾Ñ‚Ğ°"
        current_version="0.0.0"
    fi
    
    local container_status=$(get_container_status)
    debug_log "UPDATE" "Container status: $container_status"
    
    echo -e "ĞŸÑƒÑ‚ÑŒ Ğº Ğ±Ğ¾Ñ‚Ñƒ:     ${CYAN}$BOT_PATH${RESET}"
    echo -e "Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ:  ${CYAN}$current_version${RESET}"
    echo -e "Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:          ${CYAN}$container_status${RESET}"
    echo ""
    
    # === Ğ­Ğ¢ĞĞŸ 3: ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞĞ‘Ğ ĞĞ—ĞĞ’ Ğ’ DOCKER ===
    debug_log "UPDATE" "[STAGE 3] Checking loaded Docker images..."
    print_message "INFO" "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ² Docker..."
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ²ÑĞµ Ğ²ĞµÑ€ÑĞ¸Ğ¸ rwp_shop Ğ¸Ğ· docker images
    local docker_versions=$(docker images --format "{{.Tag}}" "rwp_shop" 2>/dev/null | grep -E "^[0-9]+\.[0-9]+\.[0-9]+" | sort -rV)
    
    # Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²
    local old_versions=$(docker images --format "{{.Tag}}" "private-remnawave-telegram-shop-bot" 2>/dev/null | grep -E "^[0-9]+\.[0-9]+\.[0-9]+" | sort -rV)
    
    # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ÑĞ°Ğ¼ÑƒÑ Ğ½Ğ¾Ğ²ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ² Docker
    local latest_docker_version=""
    local latest_docker_image=""
    
    if [[ -n "$docker_versions" ]]; then
        latest_docker_version=$(echo "$docker_versions" | head -1)
        latest_docker_image="rwp_shop"
    fi
    
    if [[ -n "$old_versions" ]]; then
        local old_latest=$(echo "$old_versions" | head -1)
        if [[ -z "$latest_docker_version" ]] || version_gt "$old_latest" "$latest_docker_version"; then
            latest_docker_version="$old_latest"
            latest_docker_image="private-remnawave-telegram-shop-bot"
        fi
    fi
    
    debug_log "UPDATE" "Latest Docker image: $latest_docker_image:$latest_docker_version"
    
    # Ğ•ÑĞ»Ğ¸ Ğ² Docker ĞµÑÑ‚ÑŒ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ½Ğ¾Ğ²ĞµĞµ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ â€” Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµĞ¼ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒÑÑ ÑÑ€Ğ°Ğ·Ñƒ
    if [[ -n "$latest_docker_version" ]] && version_gt "$latest_docker_version" "$current_version"; then
        debug_log "UPDATE" "Docker has newer version: $latest_docker_version > $current_version"
        print_message "SUCCESS" "ĞĞ°Ğ¹Ğ´ĞµĞ½ Ğ¾Ğ±Ñ€Ğ°Ğ· Ğ² Docker: ${latest_docker_image}:${latest_docker_version}"
        echo ""
        echo -e "${YELLOW}${BOLD}Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ: $current_version â†’ $latest_docker_version${RESET}"
        echo ""
        echo -e "${GREEN}ĞĞ±Ñ€Ğ°Ğ· ÑƒĞ¶Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ² Docker â€” Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ${RESET}"
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¹ 3.25.5+
        if version_gte "$latest_docker_version" "3.25.5"; then
            local has_key=false
            local has_volume=false
            has_license_key && has_key=true
            has_machine_id_volume && has_volume=true
            
            echo ""
            # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ (ĞºÑ€Ğ°ÑĞ½Ñ‹Ğµ) ĞµÑĞ»Ğ¸ Ñ‡ĞµĞ³Ğ¾-Ñ‚Ğ¾ Ğ½ĞµÑ‚
            if [[ "$has_key" == false ]]; then
                echo -e "${RED}${BOLD}âš ï¸  LICENSE_KEY Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ¸Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹!${RESET}"
                echo -e "${RED}   ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ»ÑÑ‡ Ğ² Ğ±Ğ¾Ñ‚Ğµ: https://t.me/rwp_shop_bot${RESET}"
                echo ""
            fi
            
            if [[ "$has_volume" == false ]]; then
                echo -e "${RED}${BOLD}âš ï¸  machine-id volume Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ² compose!${RESET}"
                echo -e "${RED}   Ğ‘ÑƒĞ´ĞµÑ‚ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸${RESET}"
                echo ""
            fi
            
            # Ğ—Ğ°Ñ‚ĞµĞ¼ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹
            echo -e "${YELLOW}${BOLD}Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¸ $latest_docker_version:${RESET}"
            echo ""
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ LICENSE_KEY
            if [[ "$has_key" == true ]]; then
                echo -e "   ${GREEN}âœ“${RESET} LICENSE_KEY: ${GREEN}Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
            else
                echo -e "   ${RED}âœ—${RESET} LICENSE_KEY: ${RED}Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
            fi
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ machine-id volume
            if [[ "$has_volume" == true ]]; then
                echo -e "   ${GREEN}âœ“${RESET} machine-id volume: ${GREEN}Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
            else
                echo -e "   ${RED}âœ—${RESET} machine-id volume: ${RED}Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
            fi
            echo ""
        fi
        
        local confirm=""
        while [[ ! "$confirm" =~ ^[YyNn]$ ]]; do
            read -erp "ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ´Ğ¾ Ğ²ĞµÑ€ÑĞ¸Ğ¸ $latest_docker_version? (y/n): " confirm
            if [[ ! "$confirm" =~ ^[YyNn]$ ]]; then
                echo -e "${YELLOW}Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ 'y' Ğ´Ğ»Ñ Ğ´Ğ° Ğ¸Ğ»Ğ¸ 'n' Ğ´Ğ»Ñ Ğ½ĞµÑ‚${RESET}"
            fi
        done
        
        if [[ "$confirm" =~ ^[Yy]$ ]]; then
            # Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞ³Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ
            local selected_version="$latest_docker_version"
            local selected_image_name="$latest_docker_image"
            local selected_file=""  # Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½ÑƒĞ¶ĞµĞ½
            local skip_docker_load=true
            
            # ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ğ¼ Ğº ÑÑ‚Ğ°Ğ¿Ñƒ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ
            # (ĞºĞ¾Ğ´ Ğ±ÑƒĞ´ĞµÑ‚ Ğ½Ğ¸Ğ¶Ğµ)
        else
            print_message "INFO" "ĞÑ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾"
            read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
            return 0
        fi
    else
        # Ğ’ Docker Ğ½ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ²ĞµÑ€ÑĞ¸Ğ¹ â€” Ğ¸Ñ‰ĞµĞ¼ .tar Ñ„Ğ°Ğ¹Ğ»Ñ‹
        debug_log "UPDATE" "No newer version in Docker, searching for tar files..."
        
        # === Ğ­Ğ¢ĞĞŸ 3b: ĞŸĞĞ˜Ğ¡Ğš Ğ¤ĞĞ™Ğ›ĞĞ’ ĞĞ‘Ğ ĞĞ—ĞĞ’ ===
        print_message "INFO" "ĞŸĞ¾Ğ¸ÑĞº Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ° Ğ² /opt/, /root/, $BOT_PATH..."
        local image_files=$(find_all_bot_image_files)
        debug_log "UPDATE" "Image files found: $(echo "$image_files" | wc -l) files"
        
        if [[ -z "$image_files" ]]; then
            debug_log "UPDATE" "No image files found"
            echo ""
            if [[ -n "$latest_docker_version" ]]; then
                # Ğ’ Docker ĞµÑÑ‚ÑŒ Ñ‚ĞµĞºÑƒÑ‰Ğ°Ñ Ğ¸Ğ»Ğ¸ ÑÑ‚Ğ°Ñ€Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ
                print_message "INFO" "ĞĞ¾Ğ²Ñ‹Ñ… Ğ²ĞµÑ€ÑĞ¸Ğ¹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾"
                echo ""
                echo -e "Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ² Docker: ${CYAN}${latest_docker_image}:${latest_docker_version}${RESET}"
                echo -e "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ:    ${CYAN}${current_version}${RESET}"
                
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¹ 3.25.5+ (Ğ´Ğ°Ğ¶Ğµ ĞµÑĞ»Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ½ĞµÑ‚)
                if version_gte "$current_version" "3.25.5"; then
                    echo ""
                    local has_key=false
                    local has_mid=false
                    has_license_key && has_key=true
                    has_machine_id_volume && has_mid=true
                    
                    if [[ "$has_key" == "false" || "$has_mid" == "false" ]]; then
                        echo -e "${YELLOW}${BOLD}ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ (v3.25.5+):${RESET}"
                        if [[ "$has_key" == "true" ]]; then
                            echo -e "  LICENSE_KEY:     ${GREEN}âœ“ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
                        else
                            echo -e "  LICENSE_KEY:     ${RED}âœ— Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚${RESET}"
                        fi
                        if [[ "$has_mid" == "true" ]]; then
                            echo -e "  machine-id:      ${GREEN}âœ“ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
                        else
                            echo -e "  machine-id:      ${RED}âœ— Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ² compose${RESET}"
                        fi
                        
                        if [[ "$has_key" == "false" || "$has_mid" == "false" ]]; then
                            echo ""
                            echo -e "${YELLOW}Ğ”Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ±Ğ¾Ñ‚Ğ° Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ LICENSE_KEY Ğ¸ machine-id volume.${RESET}"
                            echo -e "ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ĞºĞ»ÑÑ‡: ${CYAN}https://t.me/rwp_shop_bot${RESET}"
                            echo ""
                            read -erp "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ ÑĞµĞ¹Ñ‡Ğ°Ñ? [y/N]: " setup_now
                            if [[ "$setup_now" =~ ^[Yy]$ ]]; then
                                if [[ "$has_key" == "false" ]]; then
                                    ensure_license_key
                                fi
                                if [[ "$has_mid" == "false" ]]; then
                                    ensure_machine_id_volume
                                fi
                            fi
                        fi
                    else
                        echo ""
                        echo -e "${GREEN}âœ“ LICENSE_KEY Ğ¸ machine-id Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ñ‹${RESET}"
                    fi
                fi
            else
                print_message "WARN" "Ğ¤Ğ°Ğ¹Ğ»Ñ‹ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹"
                echo ""
                echo -e "${BOLD}ĞŸÑƒÑ‚Ğ¸ Ğ¿Ğ¾Ğ¸ÑĞºĞ°:${RESET}"
                echo -e "  ${CYAN}/opt/${RESET} (Ñ Ğ¿Ğ¾Ğ´Ğ¿Ğ°Ğ¿ĞºĞ°Ğ¼Ğ¸)"
                echo -e "  ${CYAN}/root/${RESET} (Ñ Ğ¿Ğ¾Ğ´Ğ¿Ğ°Ğ¿ĞºĞ°Ğ¼Ğ¸)"
                [[ -n "$BOT_PATH" ]] && echo -e "  ${CYAN}$BOT_PATH/${RESET}"
                echo ""
                echo -e "${BOLD}ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²:${RESET}"
                echo -e "  ${CYAN}rwp_shop-X.Y.Z-amd64.tar${RESET}  (Ğ½Ğ¾Ğ²Ñ‹Ğ¹, Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµĞ¼Ñ‹Ğ¹)"
                echo -e "  ${GRAY}private-remnawave-telegram-shop-bot-X.Y.Z-amd64.tar${RESET}  (ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹)"
                echo ""
                echo -e "Ğ¡ĞºĞ°Ñ‡Ğ°Ğ¹Ñ‚Ğµ Ñ„Ğ°Ğ¹Ğ» Ğ¸Ğ· Ğ¿Ñ€Ğ¸Ğ²Ğ°Ñ‚Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ°Ğ½Ğ°Ğ»Ğ° Ğ¸ Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚Ğµ Ğ²:"
                echo -e "  ${BOLD}$BOT_PATH/${RESET}"
            fi
            echo ""
            read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
            return 1
        fi
        
        # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼: Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ„Ğ°Ğ¹Ğ»Ñ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… ĞĞ•Ğ¢ Ğ² Docker
        local files_to_show=""
        while IFS= read -r file; do
            [[ -z "$file" ]] && continue
            local fname=$(basename "$file")
            local fversion=$(extract_version_from_filename "$fname")
            local fimage=$(get_image_name_from_tar "$file")
            
            if ! is_image_loaded_in_docker "$fimage" "$fversion"; then
                files_to_show+="$file"$'\n'
            fi
        done <<< "$image_files"
        files_to_show=$(echo -n "$files_to_show" | sed '/^$/d')
        
        if [[ -z "$files_to_show" ]]; then
            debug_log "UPDATE" "All tar files already loaded in Docker"
            print_message "INFO" "Ğ’ÑĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ‹ ÑƒĞ¶Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ² Docker"
            echo ""
            if [[ -n "$latest_docker_version" ]] && [[ "$latest_docker_version" == "$current_version" ]]; then
                print_message "SUCCESS" "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ²ĞµÑ€ÑĞ¸Ñ ($current_version)"
            elif [[ -n "$latest_docker_version" ]]; then
                echo -e "Ğ’ĞµÑ€ÑĞ¸Ñ Ğ² Docker: ${CYAN}${latest_docker_version}${RESET}"
                echo -e "Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ:  ${CYAN}${current_version}${RESET}"
            fi
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¹ 3.25.5+ (Ğ´Ğ°Ğ¶Ğµ ĞµÑĞ»Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ½ĞµÑ‚)
            if version_gte "$current_version" "3.25.5"; then
                echo ""
                local has_key=false
                local has_mid=false
                has_license_key && has_key=true
                has_machine_id_volume && has_mid=true
                
                if [[ "$has_key" == "false" || "$has_mid" == "false" ]]; then
                    echo -e "${YELLOW}${BOLD}ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ (v3.25.5+):${RESET}"
                    if [[ "$has_key" == "true" ]]; then
                        echo -e "  LICENSE_KEY:     ${GREEN}âœ“ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
                    else
                        echo -e "  LICENSE_KEY:     ${RED}âœ— Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚${RESET}"
                    fi
                    if [[ "$has_mid" == "true" ]]; then
                        echo -e "  machine-id:      ${GREEN}âœ“ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
                    else
                        echo -e "  machine-id:      ${RED}âœ— Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ² compose${RESET}"
                    fi
                    
                    if [[ "$has_key" == "false" || "$has_mid" == "false" ]]; then
                        echo ""
                        echo -e "${YELLOW}Ğ”Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ±Ğ¾Ñ‚Ğ° Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ LICENSE_KEY Ğ¸ machine-id volume.${RESET}"
                        echo -e "ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ĞºĞ»ÑÑ‡: ${CYAN}https://t.me/rwp_shop_bot${RESET}"
                        echo ""
                        read -erp "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ ÑĞµĞ¹Ñ‡Ğ°Ñ? [y/N]: " setup_now
                        if [[ "$setup_now" =~ ^[Yy]$ ]]; then
                            if [[ "$has_key" == "false" ]]; then
                                ensure_license_key
                            fi
                            if [[ "$has_mid" == "false" ]]; then
                                ensure_machine_id_volume
                            fi
                        fi
                    fi
                else
                    echo ""
                    echo -e "${GREEN}âœ“ LICENSE_KEY Ğ¸ machine-id Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ñ‹${RESET}"
                fi
            fi
            
            echo ""
            read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
            return 0
        fi
        
        # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ„Ğ°Ğ¹Ğ»Ñ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ ĞµÑ‰Ñ‘ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹
        local files_count=$(echo "$files_to_show" | wc -l)
        debug_log "UPDATE" "Files to show (not in Docker): $files_count"
        print_message "SUCCESS" "ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²: $files_count"
        
        # === Ğ­Ğ¢ĞĞŸ 4: ĞĞ¢ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ• ĞĞĞ™Ğ”Ğ•ĞĞĞ«Ğ¥ Ğ¤ĞĞ™Ğ›ĞĞ’ ===
        debug_log "UPDATE" "[STAGE 4] Displaying found files..."
        echo ""
        echo -e "${BOLD}ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ² (ĞµÑ‰Ñ‘ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ² Docker):${RESET}"
        local i=1
        local files_array=()
        while IFS= read -r file; do
            [[ -z "$file" ]] && continue
            local fname=$(basename "$file")
            local fdir=$(dirname "$file")
            local fversion=$(extract_version_from_filename "$fname")
            local fsize=$(du -h "$file" 2>/dev/null | cut -f1)
            files_array+=("$file")
            debug_log "UPDATE" "  [$i] $fname (v$fversion, size=$fsize)"
            
            # ĞŸĞ¾Ğ´ÑĞ²ĞµÑ‚ĞºĞ° ĞµÑĞ»Ğ¸ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ½Ğ¾Ğ²ĞµĞµ
            if version_gt "$fversion" "$current_version"; then
                echo -e " ${GREEN}$i. $fname${RESET}"
                echo -e "    v$fversion | $fsize ${GREEN}â† ĞĞ‘ĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ•${RESET}"
                echo -e "    ${GRAY}$fdir${RESET}"
            elif [[ "$fversion" == "$current_version" ]]; then
                echo -e " ${YELLOW}$i. $fname${RESET}"
                echo -e "    v$fversion | $fsize ${YELLOW}(Ñ‚ĞµĞºÑƒÑ‰Ğ°Ñ)${RESET}"
                echo -e "    ${GRAY}$fdir${RESET}"
            else
                echo -e " ${GRAY}$i. $fname${RESET}"
                echo -e "    v$fversion | $fsize"
                echo -e "    ${GRAY}$fdir${RESET}"
            fi
            ((i++))
        done <<< "$files_to_show"
        
        echo ""
        echo " 0. ĞĞ°Ğ·Ğ°Ğ´"
        echo ""
        
        # === Ğ­Ğ¢ĞĞŸ 5: Ğ’Ğ«Ğ‘ĞĞ  Ğ¤ĞĞ™Ğ›Ğ ===
        debug_log "UPDATE" "[STAGE 5] File selection..."
        local latest_file="${files_array[0]}"
        local latest_version=$(extract_version_from_filename "$(basename "$latest_file")")
        debug_log "UPDATE" "Latest file: $(basename "$latest_file"), version: $latest_version"
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¹ 3.25.5+
        if version_gte "$latest_version" "3.25.5"; then
            local has_key=false
            local has_volume=false
            has_license_key && has_key=true
            has_machine_id_volume && has_volume=true
            
            # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ (ĞºÑ€Ğ°ÑĞ½Ñ‹Ğµ) ĞµÑĞ»Ğ¸ Ñ‡ĞµĞ³Ğ¾-Ñ‚Ğ¾ Ğ½ĞµÑ‚
            if [[ "$has_key" == false ]]; then
                echo -e "${RED}${BOLD}âš ï¸  LICENSE_KEY Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ¸Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹!${RESET}"
                echo -e "${RED}   ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ»ÑÑ‡ Ğ² Ğ±Ğ¾Ñ‚Ğµ: https://t.me/rwp_shop_bot${RESET}"
                echo ""
            fi
            
            if [[ "$has_volume" == false ]]; then
                echo -e "${RED}${BOLD}âš ï¸  machine-id volume Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ² compose!${RESET}"
                echo -e "${RED}   Ğ‘ÑƒĞ´ĞµÑ‚ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸${RESET}"
                echo ""
            fi
            
            # Ğ—Ğ°Ñ‚ĞµĞ¼ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹
            echo -e "${YELLOW}${BOLD}Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¹ 3.25.5+:${RESET}"
            echo ""
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ LICENSE_KEY
            if [[ "$has_key" == true ]]; then
                echo -e "   ${GREEN}âœ“${RESET} LICENSE_KEY: ${GREEN}Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
            else
                echo -e "   ${RED}âœ—${RESET} LICENSE_KEY: ${RED}Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
            fi
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ machine-id volume
            if [[ "$has_volume" == true ]]; then
                echo -e "   ${GREEN}âœ“${RESET} machine-id volume: ${GREEN}Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
            else
                echo -e "   ${RED}âœ—${RESET} machine-id volume: ${RED}Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
            fi
            echo ""
        fi
        
        local choice=""
        if ! version_gt "$latest_version" "$current_version"; then
            debug_log "UPDATE" "Current version is latest ($current_version >= $latest_version)"
            print_message "INFO" "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ²ĞµÑ€ÑĞ¸Ñ ($current_version)"
            echo ""
            read -erp "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ (Ğ¸Ğ»Ğ¸ Enter - Ğ½Ğ°Ğ·Ğ°Ğ´): " choice
            [[ -z "$choice" || "$choice" == "0" ]] && return 0
        else
            debug_log "UPDATE" "Update available: $current_version -> $latest_version"
            echo -e "${YELLOW}${BOLD}Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ: $current_version â†’ $latest_version${RESET}"
            echo ""
            read -erp "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ñ„Ğ°Ğ¹Ğ» (Enter - Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ v$latest_version): " choice
            [[ -z "$choice" ]] && choice=1
        fi
        
        debug_log "UPDATE" "User choice: $choice"
        
        # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ°
        if [[ "$choice" == "0" ]]; then return 0; fi
        if ! [[ "$choice" =~ ^[0-9]+$ ]] || [[ "$choice" -lt 1 ]] || [[ "$choice" -gt "${#files_array[@]}" ]]; then
            debug_log "UPDATE" "Invalid choice: $choice (valid: 1-${#files_array[@]})"
            print_message "ERROR" "ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€"
            sleep 1
            return 1
        fi
        
        local selected_file="${files_array[$((choice-1))]}"
        local selected_version=$(extract_version_from_filename "$(basename "$selected_file")")
        local selected_image_name=$(get_image_name_from_tar "$selected_file")
        local skip_docker_load=false
        debug_log "UPDATE" "Selected: file=$selected_file, version=$selected_version, image=$selected_image_name"
    fi
    
    # === Ğ­Ğ¢ĞĞŸ 6: ĞŸĞĞ”Ğ¢Ğ’Ğ•Ğ Ğ–Ğ”Ğ•ĞĞ˜Ğ• ===
    debug_log "UPDATE" "[STAGE 6] User confirmation..."
    echo ""
    echo -e "${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    if [[ -n "$selected_file" ]]; then
        echo -e "${BOLD}Ğ¤Ğ°Ğ¹Ğ»:${RESET}    $(basename "$selected_file")"
    fi
    echo -e "${BOLD}Ğ’ĞµÑ€ÑĞ¸Ñ:${RESET}  $selected_version"
    echo -e "${BOLD}Image:${RESET}   $selected_image_name"
    if [[ "$skip_docker_load" == true ]]; then
        echo -e "${BOLD}Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:${RESET}  ${GREEN}Ğ£Ğ¶Ğµ Ğ² Docker${RESET}"
    fi
    echo -e "${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo ""
    
    echo -e "${YELLOW}${BOLD}âš ï¸  Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ• â€” ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ Ğš ĞŸĞ ĞĞ§Ğ¢Ğ•ĞĞ˜Ğ®:${RESET}"
    echo ""
    echo -e " ${GREEN}âœ“${RESET} Ğ‘ÑƒĞ´ĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ±ÑĞºĞ°Ğ¿ (Ğ‘Ğ” + Ñ„Ğ°Ğ¹Ğ»Ñ‹)"
    echo -e " ${GREEN}âœ“${RESET} Ğ‘ÑƒĞ´ĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ±ÑĞºĞ°Ğ¿ Ğ‘Ğ”"
    echo -e " ${GREEN}âœ“${RESET} Compose Ñ„Ğ°Ğ¹Ğ» Ğ±ÑƒĞ´ĞµÑ‚ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸"
    echo ""
    echo -e " ${YELLOW}!${RESET} Ğ‘Ğ¾Ñ‚ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ½Ğ° Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ"
    echo -e " ${YELLOW}!${RESET} ĞŸÑ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ Ğ¾Ñ‚ĞºĞ°Ñ‚ Ğ¸Ğ· Ğ±ÑĞºĞ°Ğ¿Ğ°"
    echo ""
    
    read -erp "ĞĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ? (y/N): " confirm
    if [[ "$confirm" != "y" && "$confirm" != "Y" ]]; then
        debug_log "UPDATE" "User cancelled update"
        print_message "INFO" "ĞÑ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾"
        return 0
    fi
    
    # === Ğ­Ğ¢ĞĞŸ 7: Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ• Ğ‘Ğ­ĞšĞĞŸĞĞ’ ===
    debug_log "UPDATE" "[STAGE 7] Creating pre-update backups..."
    echo ""
    echo -e "${CYAN}${BOLD}â•â•â• Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ• Ğ‘Ğ­ĞšĞĞŸĞĞ’ â•â•â•${RESET}"
    log_message "INFO" "Starting bot update: $current_version -> $selected_version"
    
    # Ğ—Ğ°Ğ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµĞ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²
    local update_start_time=$(date +%s)
    
    debug_log "UPDATE" "Creating full backup..."
    print_message "INFO" "[1/7] Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ³Ğ¾ Ğ±ÑĞºĞ°Ğ¿Ğ°..."
    create_backup "full"
    local backup_result=$?
    debug_log "UPDATE" "Full backup result: $backup_result"
    
    if [[ $backup_result -ne 0 ]]; then
        debug_log "UPDATE" "Full backup FAILED, aborting update"
        print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ±ÑĞºĞ°Ğ¿Ğ°! ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾."
        log_message "ERROR" "Bot update aborted: full backup failed"
        read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
        return 1
    fi
    print_message "SUCCESS" "ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ±ÑĞºĞ°Ğ¿ ÑĞ¾Ğ·Ğ´Ğ°Ğ½"
    
    debug_log "UPDATE" "Creating DB backup..."
    print_message "INFO" "[2/7] Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ±ÑĞºĞ°Ğ¿Ğ° Ğ‘Ğ”..."
    create_backup "db_only"
    local db_backup_result=$?
    debug_log "UPDATE" "DB backup result: $db_backup_result"
    
    if [[ $db_backup_result -ne 0 ]]; then
        print_message "WARN" "Ğ‘ÑĞºĞ°Ğ¿ Ğ‘Ğ” Ğ½Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½ (Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ±ÑĞºĞ°Ğ¿ ĞµÑÑ‚ÑŒ)"
    else
        print_message "SUCCESS" "Ğ‘ÑĞºĞ°Ğ¿ Ğ‘Ğ” ÑĞ¾Ğ·Ğ´Ğ°Ğ½"
    fi
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¼Ñƒ Ğ±ÑĞºĞ°Ğ¿Ñƒ Ğ‘Ğ” Ğ´Ğ»Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ rollback
    local rollback_backup=$(get_latest_db_backup)
    debug_log "UPDATE" "Rollback backup: $rollback_backup"
    
    # === Ğ­Ğ¢ĞĞŸ 8: Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ DOCKER IMAGE ===
    debug_log "UPDATE" "[STAGE 8] Loading Docker image..."
    echo ""
    echo -e "${CYAN}${BOLD}â•â•â• Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ IMAGE â•â•â•${RESET}"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ„Ğ»Ğ°Ğ³ skip_docker_load Ğ¸Ğ»Ğ¸ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ° Ğ² Docker
    if [[ "$skip_docker_load" == true ]] || is_image_loaded_in_docker "$selected_image_name" "$selected_version"; then
        debug_log "DOCKER" "Image $selected_image_name:$selected_version already loaded in Docker (skip_docker_load=$skip_docker_load)"
        print_message "INFO" "[3/7] Image ÑƒĞ¶Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ² Docker"
        print_message "SUCCESS" "ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ docker load: ${selected_image_name}:${selected_version}"
    else
        print_message "INFO" "[3/7] Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Docker image..."
        debug_log "DOCKER" "Running: docker load -i $selected_file"
        
        local load_output
        load_output=$(docker load -i "$selected_file" 2>&1)
        local load_result=$?
        debug_log "DOCKER" "docker load result: $load_result"
        debug_log "DOCKER" "docker load output: $load_output"
        
        if [[ $load_result -ne 0 ]]; then
            debug_log "DOCKER" "docker load FAILED"
            print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ image!"
            echo "$load_output"
            log_message "ERROR" "Bot update failed: docker load error"
            echo ""
            print_message "INFO" "Ğ‘ÑĞºĞ°Ğ¿Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ñ‹. Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğµ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑĞ½Ñ‹."
            read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
            return 1
        fi
        
        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ¼Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ image
        local loaded_image=$(echo "$load_output" | grep -oE "Loaded image: [^ ]+" | cut -d' ' -f3)
        debug_log "DOCKER" "Loaded image from output: $loaded_image"
        if [[ -n "$loaded_image" ]]; then
            print_message "SUCCESS" "Image Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½: $loaded_image"
            # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ¸Ğ¼Ñ image Ğ±ĞµĞ· Ğ²ĞµÑ€ÑĞ¸Ğ¸
            selected_image_name="${loaded_image%%:*}"
            debug_log "DOCKER" "Image name extracted: $selected_image_name"
        else
            print_message "SUCCESS" "Image Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½"
            echo "$load_output" | grep -i "loaded" | head -1
        fi
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ image Ğ¿Ğ¾ÑĞ²Ğ¸Ğ»ÑÑ
        debug_log "DOCKER" "Verifying image in docker images..."
        if ! docker images | grep -q "$selected_image_name.*$selected_version"; then
            debug_log "DOCKER" "Image not found in list, showing available:"
            print_message "WARN" "Image Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½, Ğ½Ğ¾ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² ÑĞ¿Ğ¸ÑĞºĞµ"
            docker images | grep -E "(rwp_shop|telegram-shop|private-remnawave)" | head -5
        else
            debug_log "DOCKER" "Image verified in docker images list"
        fi
    fi
    
    # === Ğ­Ğ¢ĞĞŸ 9: ĞĞ‘ĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ• COMPOSE Ğ¤ĞĞ™Ğ›Ğ ===
    debug_log "UPDATE" "[STAGE 9] Updating compose file..."
    echo ""
    echo -e "${CYAN}${BOLD}â•â•â• ĞĞ‘ĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ• ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ˜ â•â•â•${RESET}"
    
    local compose_file=""
    [[ -f "$BOT_PATH/compose.yaml" ]] && compose_file="$BOT_PATH/compose.yaml"
    [[ -f "$BOT_PATH/docker-compose.yml" ]] && compose_file="$BOT_PATH/docker-compose.yml"
    debug_log "COMPOSE" "Compose file: $compose_file"
    
    if [[ -z "$compose_file" ]]; then
        debug_log "COMPOSE" "No compose file found in $BOT_PATH"
        print_message "ERROR" "Compose Ñ„Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½!"
        log_message "ERROR" "Bot update failed: compose file not found"
        read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
        return 1
    fi
    
    print_message "INFO" "[4/7] ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ compose Ñ„Ğ°Ğ¹Ğ»Ğ°..."
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ±ÑĞºĞ°Ğ¿ compose Ñ„Ğ°Ğ¹Ğ»Ğ°
    debug_log "COMPOSE" "Creating backup: ${compose_file}.pre-update.bak"
    cp "$compose_file" "${compose_file}.pre-update.bak"
    
    debug_log "COMPOSE" "Calling update_compose_image_version($compose_file, $selected_version, $selected_image_name)"
    if ! update_compose_image_version "$compose_file" "$selected_version" "$selected_image_name"; then
        debug_log "COMPOSE" "update_compose_image_version FAILED, restoring backup"
        print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ compose!"
        mv "${compose_file}.pre-update.bak" "$compose_file"
        log_message "ERROR" "Bot update failed: compose update error"
        echo ""
        print_message "INFO" "Compose Ñ„Ğ°Ğ¹Ğ» Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ¸Ğ· Ğ±ÑĞºĞ°Ğ¿Ğ°."
        read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
        return 1
    fi
    
    # === Ğ­Ğ¢ĞĞŸ 9.5: ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ Ğ¢Ğ Ğ•Ğ‘ĞĞ’ĞĞĞ˜Ğ™ Ğ›Ğ˜Ğ¦Ğ•ĞĞ—Ğ˜Ğ˜ (v3.25.5+) ===
    if version_gte "$selected_version" "3.25.5"; then
        debug_log "UPDATE" "[STAGE 9.5] Checking license requirements for v$selected_version..."
        print_message "INFO" "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ»Ğ¸Ñ†ĞµĞ½Ğ·Ğ¸Ğ¸ Ğ´Ğ»Ñ v$selected_version..."
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ machine-id volume
        ensure_machine_id_volume "$compose_file"
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ LICENSE_KEY Ğ² .env
        ensure_license_key_in_env
    fi
    
    # === Ğ­Ğ¢ĞĞŸ 10: ĞĞ¡Ğ¢ĞĞĞĞ’ĞšĞ ĞšĞĞĞ¢Ğ•Ğ™ĞĞ•Ğ ĞĞ’ ===
    debug_log "UPDATE" "[STAGE 10] Stopping containers..."
    echo ""
    echo -e "${CYAN}${BOLD}â•â•â• ĞŸĞ•Ğ Ğ•Ğ—ĞĞŸĞ£Ğ¡Ğš ĞšĞĞĞ¢Ğ•Ğ™ĞĞ•Ğ ĞĞ’ â•â•â•${RESET}"
    print_message "INFO" "[5/7] ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²..."
    
    cd "$BOT_PATH"
    debug_log "CONTAINER" "Running: docker compose down in $BOT_PATH"
    docker compose down 2> "$SILENT_LOG"
    local down_result=$?
    debug_log "CONTAINER" "docker compose down result: $down_result"
    sleep 2
    
    # === Ğ­Ğ¢ĞĞŸ 11: Ğ—ĞĞŸĞ£Ğ¡Ğš ĞšĞĞĞ¢Ğ•Ğ™ĞĞ•Ğ ĞĞ’ ===
    debug_log "UPDATE" "[STAGE 11] Starting containers..."
    print_message "INFO" "[6/7] Ğ—Ğ°Ğ¿ÑƒÑĞº ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²..."
    debug_log "CONTAINER" "Running: docker compose up -d"
    docker compose up -d 2> "$SILENT_LOG"
    local up_result=$?
    debug_log "CONTAINER" "docker compose up result: $up_result"
    
    # === Ğ­Ğ¢ĞĞŸ 12: ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ Ğ—Ğ”ĞĞ ĞĞ’Ğ¬Ğ¯ ===
    debug_log "UPDATE" "[STAGE 12] Health checks..."
    print_message "INFO" "[7/7] ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸..."
    echo ""
    
    # Ğ–Ğ´Ñ‘Ğ¼ Ğ‘Ğ”
    if [[ -n "$DB_CONTAINER_NAME" ]]; then
        debug_log "HEALTH" "Checking DB health for: $DB_CONTAINER_NAME"
        echo -n "  ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ‘Ğ”..."
        if check_db_health "$DB_CONTAINER_NAME" 30; then
            debug_log "HEALTH" "DB health check: OK"
            echo -e " ${GREEN}OK${RESET}"
        else
            debug_log "HEALTH" "DB health check: WARN (may still be initializing)"
            echo -e " ${YELLOW}WARN${RESET}"
            print_message "WARN" "Ğ‘Ğ” Ğ½Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ĞµÑ‚, Ğ½Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ ĞµÑ‰Ñ‘ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ"
        fi
    fi
    
    # Ğ–Ğ´Ñ‘Ğ¼ Ğ±Ğ¾Ñ‚Ğ°
    if [[ -n "$BOT_CONTAINER_NAME" ]]; then
        debug_log "HEALTH" "Checking bot health for: $BOT_CONTAINER_NAME"
        echo -n "  ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ±Ğ¾Ñ‚Ğ°..."
        if check_bot_health "$BOT_CONTAINER_NAME" 20; then
            debug_log "HEALTH" "Bot health check: OK"
            echo -e " ${GREEN}OK${RESET}"
        else
            debug_log "HEALTH" "Bot health check: FAIL"
            echo -e " ${RED}FAIL${RESET}"
        fi
    fi
    
    sleep 2
    
    # === Ğ­Ğ¢ĞĞŸ 13: Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞĞ¯ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ===
    debug_log "UPDATE" "[STAGE 13] Final verification..."
    local new_version=$(get_raw_bot_version)
    local new_status=$(get_container_status)
    debug_log "UPDATE" "New version: $new_version, status: $new_status"
    
    echo ""
    echo -e "${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    
    if [[ "$new_status" == "Online" ]]; then
        if [[ "$new_version" == "$selected_version" ]]; then
            debug_log "UPDATE" "=== Update SUCCESS: $current_version -> $new_version ==="
            echo -e "${GREEN}${BOLD}âœ“ ĞĞ‘ĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ• Ğ£Ğ¡ĞŸĞ•Ğ¨ĞĞ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ${RESET}"
            echo ""
            echo -e "  Ğ’ĞµÑ€ÑĞ¸Ñ: ${CYAN}$current_version${RESET} â†’ ${GREEN}$new_version${RESET}"
            echo -e "  Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ: ${GREEN}$new_status${RESET}"
            log_message "SUCCESS" "Bot updated successfully: $current_version -> $new_version"
            
            # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ±ÑĞºĞ°Ğ¿ compose Ñ„Ğ°Ğ¹Ğ»Ğ°
            debug_log "UPDATE" "Removing compose backup file"
            rm -f "${compose_file}.pre-update.bak"
            
            echo ""
            read -erp "Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ» Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ° $(basename "$selected_file")? (y/N): " del_confirm
            if [[ "$del_confirm" == "y" || "$del_confirm" == "Y" ]]; then
                debug_log "UPDATE" "Deleting image file: $selected_file"
                rm -f "$selected_file"
                print_message "SUCCESS" "Ğ¤Ğ°Ğ¹Ğ» ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½"
            fi
        else
            debug_log "UPDATE" "=== Update WARN: version mismatch (expected=$selected_version, got=$new_version) ==="
            echo -e "${YELLOW}${BOLD}âš  ĞĞ‘ĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ• Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ Ğ¡ ĞŸĞ Ğ•Ğ”Ğ£ĞŸĞ Ğ•Ğ–Ğ”Ğ•ĞĞ˜Ğ•Ğœ${RESET}"
            echo ""
            echo -e "  ĞĞ¶Ğ¸Ğ´Ğ°Ğ»Ğ°ÑÑŒ Ğ²ĞµÑ€ÑĞ¸Ñ: ${CYAN}$selected_version${RESET}"
            echo -e "  Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ:   ${YELLOW}$new_version${RESET}"
            echo -e "  Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:           ${GREEN}$new_status${RESET}"
            echo ""
            print_message "INFO" "Ğ‘Ğ¾Ñ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚, Ğ½Ğ¾ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°ĞµÑ‚ÑÑ"
            log_message "WARN" "Bot update: version mismatch (expected=$selected_version, got=$new_version)"
        fi
    else
        debug_log "UPDATE" "=== Update FAILED: container not running (status=$new_status) ==="
        echo -e "${RED}${BOLD}âœ— ĞĞ‘ĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ• Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ Ğ¡ ĞĞ¨Ğ˜Ğ‘ĞšĞĞ™${RESET}"
        echo ""
        echo -e "  Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ: ${RED}$new_status${RESET}"
        echo ""
        log_message "ERROR" "Bot update failed: container not running after update"
        
        echo -e "${YELLOW}Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ°:${RESET}"
        echo "  docker compose ps"
        echo "  docker compose logs -f bot"
        echo ""
        
        echo -e "${YELLOW}Ğ”Ğ»Ñ Ğ¾Ñ‚ĞºĞ°Ñ‚Ğ°:${RESET}"
        if [[ -n "$rollback_backup" ]]; then
            echo "  1. Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ¸Ğ· Ğ±ÑĞºĞ°Ğ¿Ğ° (Ğ¼ĞµĞ½Ñ 3)"
            echo "  2. Ğ˜Ğ»Ğ¸ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ: docker compose down && mv ${compose_file}.pre-update.bak $compose_file && docker compose up -d"
        fi
        echo ""
        
        # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ Ğ»Ğ¾Ğ³Ğ¸
        echo -e "${GRAY}ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ Ğ»Ğ¾Ğ³Ğ¸ Ğ±Ğ¾Ñ‚Ğ°:${RESET}"
        docker compose logs --tail 10 bot 2> "$SILENT_LOG" | tail -5
    fi
    
    echo -e "${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo ""
    read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
    return 0
}

detect_bot_installation() {
    debug_log "SCAN" "=== detect_bot_installation ==="
    print_message "INFO" "Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°..."
    scan_system_for_bot 
    if [[ -n "$FOUND_PATH" ]]; then
        debug_log "SCAN" "Found installation: PATH=$FOUND_PATH, BOT=$FOUND_BOT, DB=$FOUND_DB"
        echo ""; print_message "SUCCESS" "ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ° ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°!"
        echo -e "   ĞŸÑƒÑ‚ÑŒ:      ${BOLD}$FOUND_PATH${RESET}"
        [[ -n "$FOUND_BOT" ]] && echo -e "   Ğ‘Ğ¾Ñ‚:       ${BOLD}$FOUND_BOT${RESET}"
        [[ -n "$FOUND_DB" ]]  && echo -e "   Ğ‘Ğ”:        ${BOLD}$FOUND_DB${RESET}"
        echo ""
        read -erp "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑÑ‚Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸? (Y/n): " confirm
        if [[ -z "$confirm" || "$confirm" =~ ^[Yy]$ ]]; then
            debug_log "SCAN" "User confirmed, applying settings"
            BOT_PATH="$FOUND_PATH"
            if [[ -n "$FOUND_BOT" ]]; then BOT_CONTAINER_NAME="$FOUND_BOT"; fi
            if [[ -n "$FOUND_DB" ]]; then DB_CONTAINER_NAME="$FOUND_DB"; fi
            save_config; print_message "SUCCESS" "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹."; return 0
        else
            debug_log "SCAN" "User declined auto-detected settings"
        fi
    else
        debug_log "SCAN" "No installation found by auto-detection"
    fi
    print_message "WARN" "ĞĞ²Ñ‚Ğ¾-Ğ¿Ğ¾Ğ¸ÑĞº Ğ½Ğµ Ğ´Ğ°Ğ» Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°. Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ Ğ² ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°Ñ…."
    return 1
}

# --- ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞĞ•Ğ¡ĞĞĞ¢Ğ’Ğ•Ğ¢Ğ¡Ğ¢Ğ’Ğ˜Ğ™ ---

check_config_mismatch() {
    debug_log "CONFIG" "=== check_config_mismatch ==="
    debug_log "CONFIG" "BOT_CONTAINER_NAME=$BOT_CONTAINER_NAME, IGNORE_MISMATCH=$IGNORE_MISMATCH"
    if [[ -n "$BOT_CONTAINER_NAME" && "$IGNORE_MISMATCH" != "true" ]]; then
        debug_log "CONFIG" "Checking if container exists..."
        if ! docker inspect "$BOT_CONTAINER_NAME" > /dev/null 2> "$SILENT_LOG"; then
            debug_log "CONFIG" "Container '$BOT_CONTAINER_NAME' NOT found, scanning for alternatives"
            scan_system_for_bot
            if [[ -n "$FOUND_BOT" && "$FOUND_BOT" != "$BOT_CONTAINER_NAME" ]]; then
                debug_log "CONFIG" "Found alternative: $FOUND_BOT (was: $BOT_CONTAINER_NAME)"
                echo ""; print_message "WARN" "ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ '$BOT_CONTAINER_NAME' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½, Ğ½Ğ¾ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ '$FOUND_BOT'."
                echo -e " ${GREEN}ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸.${RESET}"
                read -erp "ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ? (Y/n): " upd
                if [[ -z "$upd" || "$upd" =~ ^[Yy]$ ]]; then
                    debug_log "CONFIG" "User confirmed update to new container"
                    BOT_CONTAINER_NAME="$FOUND_BOT"
                    [[ -n "$FOUND_DB" ]] && DB_CONTAINER_NAME="$FOUND_DB"
                    [[ -n "$FOUND_PATH" ]] && BOT_PATH="$FOUND_PATH"
                    save_config; print_message "SUCCESS" "ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾."; sleep 1
                else
                    debug_log "CONFIG" "User declined, setting IGNORE_MISMATCH=true"
                    IGNORE_MISMATCH="true"; save_config
                fi
            fi
        else
            debug_log "CONFIG" "Container '$BOT_CONTAINER_NAME' exists"
        fi
    fi
}

ensure_bot_path() {
    debug_log "CONFIG" "=== ensure_bot_path ==="
    debug_log "CONFIG" "Current: BOT_PATH=$BOT_PATH, BOT=$BOT_CONTAINER_NAME, DB=$DB_CONTAINER_NAME"
    
    if [[ -z "$BOT_CONTAINER_NAME" || -z "$DB_CONTAINER_NAME" ]]; then
        debug_log "CONFIG" "Container names empty, starting detection"
        echo ""; print_message "WARN" "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ² Ğ¿ÑƒÑÑ‚Ñ‹."
        detect_bot_installation; load_or_create_config 
    fi

    local path_valid=false
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" && ( -f "$BOT_PATH/docker-compose.yml" || -f "$BOT_PATH/compose.yaml" ) ]]; then path_valid=true; fi
    debug_log "CONFIG" "path_valid=$path_valid (BOT_PATH=$BOT_PATH)"
    
    local container_valid=false
    if [[ -n "$BOT_CONTAINER_NAME" ]] && docker inspect "$BOT_CONTAINER_NAME" > /dev/null 2> "$SILENT_LOG"; then container_valid=true; fi
    debug_log "CONFIG" "container_valid=$container_valid (BOT_CONTAINER=$BOT_CONTAINER_NAME)"
    
    local db_valid=false
    if [[ -n "$DB_CONTAINER_NAME" ]] && docker inspect "$DB_CONTAINER_NAME" > /dev/null 2> "$SILENT_LOG"; then db_valid=true; fi
    debug_log "CONFIG" "db_valid=$db_valid (DB_CONTAINER=$DB_CONTAINER_NAME)"

    if [[ "$path_valid" == "false" || "$container_valid" == "false" || "$db_valid" == "false" ]]; then
        debug_log "CONFIG" "Some validations failed, attempting auto-detection"
        if [[ "$path_valid" == "false" ]]; then
            detect_bot_installation; load_or_create_config
            if [[ -n "$BOT_PATH" ]]; then path_valid=true; fi
            if [[ -n "$BOT_CONTAINER_NAME" ]]; then container_valid=true; fi
            if [[ -n "$DB_CONTAINER_NAME" ]]; then db_valid=true; fi
            debug_log "CONFIG" "After detection: path=$path_valid, container=$container_valid, db=$db_valid"
        fi

        if [[ -z "$BOT_PATH" || ! -d "$BOT_PATH" ]]; then
            debug_log "CONFIG" "BOT_PATH still invalid, prompting user"
            echo ""; print_message "ACTION" "Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ Ğ±Ğ¾Ñ‚Ğ° Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ."
            read -erp "ĞŸÑƒÑ‚ÑŒ (Enter Ğ´Ğ»Ñ '$DEFAULT_BOT_PATH'): " input_path
            BOT_PATH="${input_path:-$DEFAULT_BOT_PATH}"
            debug_log "CONFIG" "User entered BOT_PATH=$BOT_PATH"
            if [[ ! -d "$BOT_PATH" ]]; then 
                debug_log "CONFIG" "ERROR: Path does not exist"
                print_message "ERROR" "ĞŸĞ°Ğ¿ĞºĞ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°!"; return 1
            fi
            save_config
        fi

        if [[ -z "$BOT_CONTAINER_NAME" ]] || ! docker inspect "$BOT_CONTAINER_NAME" > /dev/null 2> "$SILENT_LOG"; then
            debug_log "CONFIG" "BOT_CONTAINER_NAME invalid, prompting user"
            echo ""; print_message "WARN" "ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ±Ğ¾Ñ‚Ğ° Ğ½Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½."
            print_message "ACTION" "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¸Ğ¼Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ğ±Ğ¾Ñ‚Ğ° (ĞºĞ°Ğº Ğ² 'docker ps')."
            read -erp "Ğ˜Ğ¼Ñ (Enter Ğ´Ğ»Ñ '$DEFAULT_BOT_CONTAINER'): " input_name
            BOT_CONTAINER_NAME="${input_name:-$DEFAULT_BOT_CONTAINER}"
            debug_log "CONFIG" "User entered BOT_CONTAINER_NAME=$BOT_CONTAINER_NAME"
            save_config
        fi

        if [[ -z "$DB_CONTAINER_NAME" ]] || ! docker inspect "$DB_CONTAINER_NAME" > /dev/null 2> "$SILENT_LOG"; then
            debug_log "CONFIG" "DB_CONTAINER_NAME invalid, prompting user"
            echo ""; print_message "WARN" "ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ°Ğ·Ñ‹ Ğ”Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½."
            print_message "ACTION" "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¸Ğ¼Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ğ‘Ğ”."
            read -erp "Ğ˜Ğ¼Ñ Ğ‘Ğ” (Enter Ğ´Ğ»Ñ '$DEFAULT_DB_CONTAINER'): " input_db
            DB_CONTAINER_NAME="${input_db:-$DEFAULT_DB_CONTAINER}"
            debug_log "CONFIG" "User entered DB_CONTAINER_NAME=$DB_CONTAINER_NAME"
            save_config
        fi
    fi
    debug_log "CONFIG" "=== ensure_bot_path completed ==="
    return 0
}

save_config() {
    debug_log "CONFIG" "=== save_config ==="
    debug_log "CONFIG" "Creating config dir: $INSTALL_DIR"
    mkdir -p "$INSTALL_DIR"
    debug_log "CONFIG" "Writing config to: $CONFIG_FILE"
    cat > "$CONFIG_FILE" <<EOF
BOT_TOKEN="$BOT_TOKEN"
CHAT_ID="$CHAT_ID"
TG_MESSAGE_THREAD_ID="$TG_MESSAGE_THREAD_ID"
BOT_PATH="$BOT_PATH"
DB_USER="$DB_USER"
SCHEDULE_FULL="$SCHEDULE_FULL"
SCHEDULE_DB="$SCHEDULE_DB"
SCHEDULE_FILES="$SCHEDULE_FILES"
MAX_BACKUPS_COUNT="$MAX_BACKUPS_COUNT"
BOT_CONTAINER_NAME="$BOT_CONTAINER_NAME"
DB_CONTAINER_NAME="$DB_CONTAINER_NAME"
IGNORE_MISMATCH="$IGNORE_MISMATCH"
EXCLUDE_DIRS="$EXCLUDE_DIRS"
MAX_FILE_SIZE_MB="$MAX_FILE_SIZE_MB"
REMOTE_STORAGE_TYPE="$REMOTE_STORAGE_TYPE"
REMOTE_STORAGE_URL="$REMOTE_STORAGE_URL"
REMOTE_STORAGE_USER="$REMOTE_STORAGE_USER"
REMOTE_STORAGE_PASS="$REMOTE_STORAGE_PASS"
BACKUP_PASSWORD="$BACKUP_PASSWORD"
SEND_TO_TELEGRAM="$SEND_TO_TELEGRAM"
TG_SEND_FILE="$TG_SEND_FILE"
SEND_TO_REMOTE="$SEND_TO_REMOTE"
DELETE_MODE="$DELETE_MODE"
RETENTION_DAYS="$RETENTION_DAYS"
MAX_BACKUP_SIZE_MB="$MAX_BACKUP_SIZE_MB"
EOF
    chmod 600 "$CONFIG_FILE"
    debug_log "CONFIG" "Config saved, chmod 600 applied"
    debug_log "CONFIG" "BOT_PATH=$BOT_PATH"
    debug_log "CONFIG" "BOT_CONTAINER=$BOT_CONTAINER_NAME, DB_CONTAINER=$DB_CONTAINER_NAME"
    debug_log "CONFIG" "REMOTE_STORAGE_TYPE=$REMOTE_STORAGE_TYPE"
    debug_log "CONFIG" "DELETE_MODE=$DELETE_MODE, MAX_BACKUPS=$MAX_BACKUPS_COUNT, RETENTION=$RETENTION_DAYS days"
    debug_log "CONFIG" "MAX_BACKUP_SIZE_MB=$MAX_BACKUP_SIZE_MB"
}

load_or_create_config() {
    debug_log "CONFIG" "=== load_or_create_config ==="
    debug_log "CONFIG" "Config file: $CONFIG_FILE"
    if [[ -f "$CONFIG_FILE" ]]; then 
        debug_log "CONFIG" "Config exists, sourcing..."
        source "$CONFIG_FILE"
        debug_log "CONFIG" "Config loaded successfully"
    else
        debug_log "CONFIG" "Config file not found, using defaults"
    fi
    if [[ -z "$MAX_BACKUPS_COUNT" ]]; then MAX_BACKUPS_COUNT=100; fi
    if [[ -z "$IGNORE_MISMATCH" ]]; then IGNORE_MISMATCH="false"; fi
    if [[ -z "$MAX_FILE_SIZE_MB" ]]; then MAX_FILE_SIZE_MB="1"; fi
    if [[ -z "$REMOTE_STORAGE_TYPE" ]]; then REMOTE_STORAGE_TYPE="off"; fi
    if [[ -z "$SEND_TO_TELEGRAM" ]]; then SEND_TO_TELEGRAM="true"; fi
    if [[ -z "$TG_SEND_FILE" ]]; then TG_SEND_FILE="true"; fi
    if [[ -z "$SEND_TO_REMOTE" ]]; then SEND_TO_REMOTE="true"; fi
    if [[ -z "$DELETE_MODE" ]]; then DELETE_MODE="time"; fi
    if [[ -z "$RETENTION_DAYS" ]]; then RETENTION_DAYS="7"; fi
    if [[ -z "$MAX_BACKUP_SIZE_MB" ]]; then MAX_BACKUP_SIZE_MB="0"; fi
    debug_log "CONFIG" "Defaults applied: MAX_BACKUPS=$MAX_BACKUPS_COUNT, DELETE_MODE=$DELETE_MODE"
    debug_log "CONFIG" "Creating backup dir: $BACKUP_DIR"
    mkdir -p "$BACKUP_DIR"

    local updated=false
    if [[ -z "$BOT_TOKEN" || -z "$CHAT_ID" ]]; then
        debug_log "CONFIG" "Telegram settings missing, prompting user"
        echo ""; print_message "WARN" "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Telegram Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹."
        [[ -z "$BOT_TOKEN" ]] && read -erp " Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Bot Token: " BOT_TOKEN
        [[ -z "$CHAT_ID" ]] && read -erp " Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Chat ID: " CHAT_ID
        [[ -z "$TG_MESSAGE_THREAD_ID" ]] && read -erp " Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ ID Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ° (Ğ¸Ğ»Ğ¸ Enter): " TG_MESSAGE_THREAD_ID
        updated=true
        debug_log "CONFIG" "Telegram settings received from user"
    fi
    
    if [[ -z "$BOT_PATH" || -z "$BOT_CONTAINER_NAME" || -z "$DB_CONTAINER_NAME" ]]; then 
        debug_log "CONFIG" "Bot installation not configured, starting detection"
        detect_bot_installation
    fi
    
    if $updated; then 
        debug_log "CONFIG" "Config updated, saving..."
        save_config
    fi
    debug_log "CONFIG" "=== load_or_create_config completed ==="
}

send_telegram_document() {
    local file_path="$1"; local caption="$2"
    debug_log "TG" "=== send_telegram_document ==="
    debug_log "TG" "File: $file_path"
    debug_log "TG" "SEND_TO_TELEGRAM=$SEND_TO_TELEGRAM, TG_SEND_FILE=$TG_SEND_FILE"
    [[ -z "$BOT_TOKEN" || -z "$CHAT_ID" ]] && { debug_log "TG" "Missing BOT_TOKEN or CHAT_ID"; return 1; }
    
    # Ğ•ÑĞ»Ğ¸ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ñ‹
    if [[ "$SEND_TO_TELEGRAM" != "true" ]]; then
        print_message "INFO" "Ğ£Ğ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Telegram Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ñ‹."
        debug_log "TG" "Notifications disabled, skipping"
        return 0
    fi
    
    # Ğ•ÑĞ»Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ° â€” Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğµ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ
    if [[ "$TG_SEND_FILE" != "true" ]]; then
        print_message "INFO" "ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ² TG Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ°, Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ..."
        debug_log "TG" "File sending disabled, sending text only"
        local filename=$(basename "$file_path")
        # Ğ­ĞºÑ€Ğ°Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ»Ñ MarkdownV2
        local escaped_filename=$(escape_markdown_v2 "$filename")
        local escaped_caption=$(escape_markdown_v2 "$caption")
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ (ÑƒĞ¶Ğµ ÑĞºÑ€Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ)
        local notify_text="ğŸ“¦ *Ğ‘ÑĞºĞ°Ğ¿ ÑĞ¾Ğ·Ğ´Ğ°Ğ½*

${escaped_caption}

ğŸ“ Ğ¤Ğ°Ğ¹Ğ»: \`${escaped_filename}\`
ğŸ’¡ _ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ² Telegram Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ°_"
        
        # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ (Ñ‚ĞµĞºÑÑ‚ ÑƒĞ¶Ğµ ÑĞºÑ€Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½)
        local thread_param=""
        [[ -n "$TG_MESSAGE_THREAD_ID" ]] && thread_param="-d message_thread_id=$TG_MESSAGE_THREAD_ID"
        
        local http_code
        http_code=$(curl $CURL_SILENT -o "$SILENT_LOG" -w "%{http_code}" -X POST "https://api.telegram.org/bot$BOT_TOKEN/sendMessage" \
            -d chat_id="$CHAT_ID" \
            -d parse_mode="MarkdownV2" \
            --data-urlencode text="$notify_text" \
            $thread_param 2> "$SILENT_LOG")
        debug_log "TG" "Text-only notification HTTP code: $http_code"
        
        if [[ "$http_code" == "200" ]]; then
            print_message "SUCCESS" "Ğ£Ğ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ² Telegram."
            return 0
        else
            print_message "WARN" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ (HTTP: $http_code)"
            log_message "WARN" "Telegram notification failed, HTTP code: $http_code"
            return 1
        fi
    fi
    
    print_message "INFO" "ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ² Telegram..."
    local file_size_bytes=$(stat -c%s "$file_path" 2> "$SILENT_LOG" || echo 0)
    debug_log "TG" "File size: $file_size_bytes bytes ($(numfmt --to=iec $file_size_bytes 2>/dev/null || echo "$file_size_bytes"))"
    
    local form_params=(-F chat_id="$CHAT_ID" -F document=@"$file_path" -F parse_mode="MarkdownV2" -F caption="$(escape_markdown_v2 "$caption")")
    [[ -n "$TG_MESSAGE_THREAD_ID" ]] && form_params+=(-F message_thread_id="$TG_MESSAGE_THREAD_ID")
    debug_log "TG" "Sending to: https://api.telegram.org/bot<TOKEN>/sendDocument"
    debug_log "TG" "Chat ID: $CHAT_ID, Thread ID: ${TG_MESSAGE_THREAD_ID:-none}"
    
    local http_code=$(curl $CURL_SILENT -o "$SILENT_LOG" -w "%{http_code}" -X POST "https://api.telegram.org/bot$BOT_TOKEN/sendDocument" "${form_params[@]}")
    debug_log "TG" "HTTP response code: $http_code"
    
    if [[ "$http_code" == "200" ]]; then
        print_message "SUCCESS" "Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ² Telegram."
    else
        local file_size=$(stat -c%s "$file_path" 2> "$SILENT_LOG" || echo 0)
        debug_log "TG" "Send FAILED! File size: $file_size"
        
        if [[ $file_size -ge 52428800 ]]; then
            print_message "ERROR" "Ğ¤Ğ°Ğ¹Ğ» >50MB. Telegram API Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½Ğ¸Ğ» Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºÑƒ."
            debug_log "TG" "File exceeds 50MB limit"
            local escaped_fname=$(escape_markdown_v2 "$(basename "$file_path")")
            local error_msg="âš ï¸ *ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Ğ±ÑĞºĞ°Ğ¿Ğ°*

Ğ¤Ğ°Ğ¹Ğ» Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ 50 ĞœĞ‘\. Telegram Bot API Ğ½Ğµ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°Ñ‚ÑŒ Ñ‚Ğ°ĞºĞ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ\.

ğŸ“‚ *Ğ‘ÑĞºĞ°Ğ¿ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾:*
\`${escaped_fname}\`"
            
            local thread_param=""
            [[ -n "$TG_MESSAGE_THREAD_ID" ]] && thread_param="-d message_thread_id=$TG_MESSAGE_THREAD_ID"

            curl $CURL_SILENT -X POST "https://api.telegram.org/bot$BOT_TOKEN/sendMessage" \
                -d chat_id="$CHAT_ID" \
                --data-urlencode text="$error_msg" \
                -d parse_mode="MarkdownV2" \
                $thread_param > "$SILENT_LOG"
        else
            print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ² Telegram (HTTP ĞºĞ¾Ğ´: $http_code)."
        fi
    fi
}

send_telegram_text() {
    # send simple text message to configured chat (expects already escaped MarkdownV2 text)
    local text="$1"
    [[ -z "$BOT_TOKEN" || -z "$CHAT_ID" ]] && return 1
    [[ "$SEND_TO_TELEGRAM" != "true" ]] && return 0
    local thread_param=""
    [[ -n "$TG_MESSAGE_THREAD_ID" ]] && thread_param="-d message_thread_id=$TG_MESSAGE_THREAD_ID"
    curl $CURL_SILENT -X POST "https://api.telegram.org/bot$BOT_TOKEN/sendMessage" \
        -d chat_id="$CHAT_ID" \
        --data-urlencode text="$text" \
        -d parse_mode="MarkdownV2" $thread_param > "$SILENT_LOG" 2>&1
}

test_telegram_connection() {
    print_message "INFO" "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ²ÑĞ·Ğ¸ Ñ Telegram API..."
    local res=$(curl $CURL_SILENT "https://api.telegram.org/bot$BOT_TOKEN/getMe")
    if [[ "$res" == *'"ok":true'* ]]; then
        local bot_user=$(echo "$res" | grep -o '"username":"[^"]*"' | cut -d'"' -f4)
        print_message "SUCCESS" "Ğ£ÑĞ¿ĞµÑ…! Ğ‘Ğ¾Ñ‚: @$bot_user"
    else
        print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ñ‚Ğ¾ĞºĞµĞ½."
    fi
    read -erp "Enter..." dummy
}

validate_remote_connection() {
    local type="$1"; local url="$2"; local user="$3"; local pass="$4"
    
    debug_log "REMOTE" "=== validate_remote_connection($type) ==="
    debug_log "REMOTE" "URL: $url"
    debug_log "REMOTE" "User: ${user:-<empty>}"
    
    print_message "INFO" "Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ ($type)..."
    
    local base_url="${url%/}"
    
    if [[ "$type" == "ftp" ]]; then
        debug_log "REMOTE" "Testing FTP connection..."
        # FTP: Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ»Ğ¸ÑÑ‚Ğ¸Ğ½Ğ³ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸
        local curl_cmd=(curl $CURL_SILENT -m 15 --ftp-pasv --list-only)
        [[ -n "$user" ]] && curl_cmd+=(--user "$user:$pass")
        
        # ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° FTPS (implicit Ğ¸ explicit)
        if [[ "$base_url" == ftps://* ]]; then
            debug_log "REMOTE" "Using FTPS (implicit TLS)"
            curl_cmd+=(--ssl-reqd --insecure)
        elif [[ "$base_url" == ftp://* ]]; then
            debug_log "REMOTE" "Using FTP with optional TLS"
            # ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ explicit TLS ĞµÑĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½
            curl_cmd+=(--ssl --insecure)
        fi
        
        debug_log "REMOTE" "Running: ${curl_cmd[*]} $base_url/"
        if "${curl_cmd[@]}" "$base_url/" > "$SILENT_LOG" 2>&1; then 
            debug_log "REMOTE" "FTP connection SUCCESS"
            return 0
        else 
            debug_log "REMOTE" "FTP with TLS failed, trying without TLS..."
            # ĞŸĞ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ°Ñ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ° Ğ±ĞµĞ· TLS Ğ´Ğ»Ñ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾Ğ³Ğ¾ FTP
            if [[ "$base_url" == ftp://* ]]; then
                curl_cmd=(curl $CURL_SILENT -m 15 --ftp-pasv --list-only)
                [[ -n "$user" ]] && curl_cmd+=(--user "$user:$pass")
                if "${curl_cmd[@]}" "$base_url/" > "$SILENT_LOG" 2>&1; then
                    debug_log "REMOTE" "FTP without TLS SUCCESS"
                    return 0
                fi
            fi
            debug_log "REMOTE" "FTP connection FAILED"
            return 1
        fi
        
    elif [[ "$type" == "webdav" ]]; then
        debug_log "REMOTE" "Testing WebDAV connection..."
        # WebDAV: PROPFIND Ñ Depth: 0
        local curl_cmd=(curl $CURL_SILENT -m 15 -L)
        [[ -n "$user" ]] && curl_cmd+=(--user "$user:$pass")
        
        # ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° ÑĞ°Ğ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ°Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ€Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²
        [[ "$base_url" == https://* ]] && curl_cmd+=(--insecure)
        
        local http_code
        debug_log "REMOTE" "Sending PROPFIND request..."
        http_code=$("${curl_cmd[@]}" -o "$SILENT_LOG" -w "%{http_code}" -X PROPFIND -H "Depth: 0" "$base_url/" 2> "$SILENT_LOG")
        debug_log "REMOTE" "PROPFIND HTTP code: $http_code"
        
        # 207 Multi-Status â€” ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¹ ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ WebDAV
        # 200 OK â€” Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ ÑĞµÑ€Ğ²ĞµÑ€Ñ‹ Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ÑÑ‚ Ñ‚Ğ°Ğº
        # 301/302 â€” Ñ€ĞµĞ´Ğ¸Ñ€ĞµĞºÑ‚ (curl -L Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚)
        if [[ "$http_code" =~ ^(200|207)$ ]]; then 
            debug_log "REMOTE" "WebDAV connection SUCCESS"
            return 0
        else 
            debug_log "REMOTE" "PROPFIND failed, trying GET fallback..."
            # Fallback: Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ GET
            http_code=$("${curl_cmd[@]}" -o "$SILENT_LOG" -w "%{http_code}" "$base_url/" 2> "$SILENT_LOG")
            debug_log "REMOTE" "GET HTTP code: $http_code"
            if [[ "$http_code" =~ ^(200|207|401)$ ]]; then
                # 401 Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ°ĞµÑ‚ Ñ‡Ñ‚Ğ¾ ÑĞµÑ€Ğ²ĞµÑ€ Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ĞµÑ‚, Ğ½Ğ¾ Ğ½ÑƒĞ¶Ğ½Ğ° Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
                debug_log "REMOTE" "WebDAV connection SUCCESS (via GET)"
                return 0
            fi
            debug_log "REMOTE" "WebDAV connection FAILED"
            return 1
        fi
        
    elif [[ "$type" == "rclone" ]]; then
        debug_log "REMOTE" "Testing rclone connection..."
        if ! command -v rclone > "$SILENT_LOG" 2>&1; then
            debug_log "REMOTE" "rclone not installed!"
            print_message "ERROR" "Rclone Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½!"
            return 1
        fi
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ remote
        local remote_name="${url%%:*}"
        debug_log "REMOTE" "Remote name: $remote_name"
        if rclone listremotes 2> "$SILENT_LOG" | grep -q "^${remote_name}:$"; then
            debug_log "REMOTE" "Remote exists, testing lsd..."
            # Remote ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚, Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ
            if rclone lsd "$url" > "$SILENT_LOG" 2>&1; then 
                debug_log "REMOTE" "Rclone connection SUCCESS"
                return 0
            fi
        else
            debug_log "REMOTE" "Remote '$remote_name' not found in rclone config"
        fi
        debug_log "REMOTE" "Rclone connection FAILED"
        return 1
    fi
    
    debug_log "REMOTE" "Unknown storage type: $type"
    return 1
}

upload_to_remote() {
    if [[ "$SEND_TO_REMOTE" != "true" ]]; then 
        debug_log "REMOTE" "Remote upload disabled (SEND_TO_REMOTE=$SEND_TO_REMOTE)"
        return 0
    fi
    local file_path="$1"
    local filename=$(basename "$file_path")
    local file_size=$(stat -c%s "$file_path" 2> "$SILENT_LOG" || echo "0")
    REMOTE_UPLOAD_STATUS_TEXT="" 
    
    debug_log "REMOTE" "=== upload_to_remote ==="
    debug_log "REMOTE" "File: $file_path"
    debug_log "REMOTE" "Size: $file_size bytes"
    debug_log "REMOTE" "Type: $REMOTE_STORAGE_TYPE"
    debug_log "REMOTE" "URL: $REMOTE_STORAGE_URL"

    if [[ "$REMOTE_STORAGE_TYPE" == "off" || -z "$REMOTE_STORAGE_URL" ]]; then 
        debug_log "REMOTE" "Remote storage disabled or URL empty"
        return 0
    fi
    
    if [[ ! -f "$file_path" ]]; then
        print_message "ERROR" "Ğ¤Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: $file_path" >&2
        log_message "ERROR" "Upload failed: file not found $file_path"
        debug_log "REMOTE" "ERROR: File not found!"
        return 1
    fi

    print_message "INFO" "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ½Ğ° $REMOTE_STORAGE_TYPE ($(numfmt --to=iec $file_size 2> "$SILENT_LOG" || echo "${file_size}B"))..." >&2

    # === RCLONE ===
    if [[ "$REMOTE_STORAGE_TYPE" == "rclone" ]]; then
        debug_log "REMOTE" "Using rclone..."
        if ! command -v rclone > "$SILENT_LOG" 2>&1; then
            print_message "ERROR" "Rclone Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½!"
            REMOTE_UPLOAD_STATUS_TEXT=$'\nâ˜ï¸ Rclone: ĞĞµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½'
            return 1
        fi
        local dest="${REMOTE_STORAGE_URL%/}"
        local rclone_opts=(--progress --retries 3 --low-level-retries 10)
        [[ "$IS_INTERACTIVE" != "true" ]] && rclone_opts=(--quiet --retries 3 --low-level-retries 10)
        debug_log "REMOTE" "Running: rclone copy $file_path $dest ${rclone_opts[*]}"
        
        if rclone copy "$file_path" "$dest" "${rclone_opts[@]}" 2>&1; then
            print_message "SUCCESS" "Ğ¤Ğ°Ğ¹Ğ» Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ (rclone)." >&2
            debug_log "REMOTE" "Rclone upload SUCCESS"
            REMOTE_UPLOAD_STATUS_TEXT=$'\nâ˜ï¸ Rclone: OK'
            log_message "SUCCESS" "Uploaded $filename to rclone:$dest"
            return 0
        else
            print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ rclone." >&2
            REMOTE_UPLOAD_STATUS_TEXT=$'\nâ˜ï¸ Rclone: ĞÑˆĞ¸Ğ±ĞºĞ°'
            log_message "ERROR" "Failed upload $filename to rclone:$dest"
            return 1
        fi
    fi

    # === FTP / WEBDAV ===
    local upload_url="${REMOTE_STORAGE_URL%/}/$filename"
    local max_retries=3
    local retry_delay=5
    local attempt=1
    local http_code=""
    local upload_success=false
    
    # Ğ Ğ°ÑÑ‡Ñ‘Ñ‚ Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ñ„Ğ°Ğ¹Ğ»Ğ° (Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 120 ÑĞµĞº, +60 ÑĞµĞº Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 50MB)
    local timeout=$((120 + (file_size / 50000000) * 60))
    [[ $timeout -gt 1800 ]] && timeout=1800  # ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 30 Ğ¼Ğ¸Ğ½ÑƒÑ‚
    debug_log "UPLOAD" "Upload URL: $upload_url"
    debug_log "UPLOAD" "Timeout: ${timeout}s, Max retries: $max_retries"
    
    while [[ $attempt -le $max_retries ]]; do
        debug_log "UPLOAD" "Attempt $attempt/$max_retries"
        [[ $attempt -gt 1 ]] && print_message "INFO" "ĞŸĞ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ°Ñ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ° $attempt/$max_retries..." >&2
        
        # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¾Ğ¿Ñ†Ğ¸Ğ¸ curl
        local curl_opts=(-o "$SILENT_LOG" -w "%{http_code}" -m "$timeout" -T "$file_path")
        
        # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ-Ğ±Ğ°Ñ€ Ğ¸Ğ»Ğ¸ Ñ‚Ğ¸Ñ…Ğ¸Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼
        if [[ "$IS_INTERACTIVE" == "true" ]]; then
            curl_opts+=(-#)
        else
            curl_opts+=(-s)
        fi
        
        # ĞÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
        [[ -n "$REMOTE_STORAGE_USER" ]] && curl_opts+=(--user "$REMOTE_STORAGE_USER:$REMOTE_STORAGE_PASS")
        
        if [[ "$REMOTE_STORAGE_TYPE" == "ftp" ]]; then
            # FTP ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¾Ğ¿Ñ†Ğ¸Ğ¸
            curl_opts+=(--ftp-pasv)              # Passive mode (Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ·Ğ° NAT)
            curl_opts+=(--ftp-create-dirs)       # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾
            debug_log "UPLOAD" "FTP mode: passive, create-dirs"
            
            # ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° FTPS
            if [[ "$upload_url" == ftps://* ]]; then
                curl_opts+=(--ssl-reqd --insecure)
                debug_log "UPLOAD" "FTPS: SSL required"
            elif [[ "$upload_url" == ftp://* ]]; then
                curl_opts+=(--ssl --insecure)    # ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ TLS ĞµÑĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½
                debug_log "UPLOAD" "FTP: Try TLS if available"
            fi
            
            curl_opts+=("$upload_url")
            debug_log "UPLOAD" "Executing FTP upload..."
            http_code=$(curl "${curl_opts[@]}" 2> "$SILENT_LOG") || http_code="000"
            debug_log "UPLOAD" "FTP response code: $http_code"
            
            # FTP ĞºĞ¾Ğ´Ñ‹ ÑƒÑĞ¿ĞµÑ…Ğ°: 226 (Transfer complete), 250 (Requested file action okay)
            if [[ "$http_code" =~ ^(226|250|200)$ ]]; then
                upload_success=true
                debug_log "UPLOAD" "FTP upload SUCCESS"
                break
            fi
            
        elif [[ "$REMOTE_STORAGE_TYPE" == "webdav" ]]; then
            # WebDAV ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¾Ğ¿Ñ†Ğ¸Ğ¸
            curl_opts+=(-L)                      # Ğ¡Ğ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ´Ğ¸Ñ€ĞµĞºÑ‚Ğ°Ğ¼
            curl_opts+=(--retry 2)               # Ğ’ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğ¹ retry curl
            curl_opts+=(--retry-delay 3)
            debug_log "UPLOAD" "WebDAV mode: follow redirects, retry 2"
            
            # ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° HTTPS Ñ ÑĞ°Ğ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ ÑĞµÑ€Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ°Ğ¼Ğ¸
            if [[ "$upload_url" == https://* ]]; then
                curl_opts+=(--insecure)
                debug_log "UPLOAD" "WebDAV: HTTPS with insecure"
            fi
            
            curl_opts+=("$upload_url")
            debug_log "UPLOAD" "Executing WebDAV upload..."
            http_code=$(curl "${curl_opts[@]}" 2> "$SILENT_LOG") || http_code="000"
            debug_log "UPLOAD" "WebDAV response code: $http_code"
            
            # WebDAV ĞºĞ¾Ğ´Ñ‹ ÑƒÑĞ¿ĞµÑ…Ğ°: 200 OK, 201 Created, 204 No Content
            if [[ "$http_code" =~ ^(200|201|204)$ ]]; then
                upload_success=true
                debug_log "UPLOAD" "WebDAV upload SUCCESS"
                break
            fi
        fi
        
        # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½ĞµÑƒĞ´Ğ°Ñ‡Ğ½ÑƒÑ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºÑƒ
        debug_log "UPLOAD" "Attempt $attempt FAILED with HTTP $http_code"
        log_message "WARN" "Upload attempt $attempt failed: HTTP $http_code for $upload_url"
        
        ((attempt++))
        [[ $attempt -le $max_retries ]] && sleep $retry_delay
    done
    
    if [[ "$upload_success" == true ]]; then
        print_message "SUCCESS" "Ğ¤Ğ°Ğ¹Ğ» Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ² Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ." >&2
        if [[ "$REMOTE_STORAGE_TYPE" == "ftp" ]]; then 
            REMOTE_UPLOAD_STATUS_TEXT=$'\nâ˜ï¸ FTP: OK'
        else 
            REMOTE_UPLOAD_STATUS_TEXT=$'\nâ˜ï¸ WebDAV: OK'
        fi
        log_message "SUCCESS" "Uploaded $filename to $REMOTE_STORAGE_TYPE ($upload_url) HTTP=$http_code"
        return 0
    else
        print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¿Ğ¾ÑĞ»Ğµ $max_retries Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº (ĞšĞ¾Ğ´: $http_code)" >&2
        if [[ "$REMOTE_STORAGE_TYPE" == "ftp" ]]; then 
            REMOTE_UPLOAD_STATUS_TEXT=$'\nâ˜ï¸ FTP: ĞÑˆĞ¸Ğ±ĞºĞ°'
        else 
            REMOTE_UPLOAD_STATUS_TEXT=$'\nâ˜ï¸ WebDAV: ĞÑˆĞ¸Ğ±ĞºĞ°'
        fi
        log_message "ERROR" "Failed upload $filename to $REMOTE_STORAGE_TYPE after $max_retries attempts. Last HTTP=$http_code"
        return 1
    fi
}

configure_remote_storage() {
    while true; do
        clear_screen
        echo -e "${GREEN}${BOLD}ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğ°${RESET}"
        echo ""
        
        # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ
        if [[ "$REMOTE_STORAGE_TYPE" != "off" && -n "$REMOTE_STORAGE_URL" ]]; then
            echo -e "Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸:"
            echo -e "  Ğ¢Ğ¸Ğ¿: ${YELLOW}${REMOTE_STORAGE_TYPE^^}${RESET}"
            echo -e "  URL: ${CYAN}${REMOTE_STORAGE_URL}${RESET}"
            [[ -n "$REMOTE_STORAGE_USER" ]] && echo -e "  ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ: ${GRAY}${REMOTE_STORAGE_USER}${RESET}"
            echo ""
        fi
        
        echo " 1. FTP / FTPS"
        echo " 2. WebDAV (Ğ¯Ğ½Ğ´ĞµĞºÑ.Ğ”Ğ¸ÑĞº, Nextcloud, Ğ¸ Ğ´Ñ€.)"
        echo " 3. Rclone (Google Drive, S3, Dropbox, Ğ¸ Ğ´Ñ€.)"
        echo ""
        echo -e " ${RED}0. ĞÑ‚ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ${RESET}"
        echo ""
        read -erp "Ğ’Ñ‹Ğ±Ğ¾Ñ€ (Enter - ĞĞ°Ğ·Ğ°Ğ´): " r_type
        [[ -z "$r_type" ]] && return
        
        local new_type="off"
        local input_url="" input_user="" input_pass="" input_folder=""
        local base_url=""
        
        case $r_type in
            1) new_type="ftp" ;;
            2) new_type="webdav" ;;
            3) new_type="rclone" ;;
            0) 
                REMOTE_STORAGE_TYPE="off"
                REMOTE_STORAGE_URL=""
                REMOTE_STORAGE_USER=""
                REMOTE_STORAGE_PASS=""
                save_config
                print_message "SUCCESS" "Ğ£Ğ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾."
                sleep 1
                return 
                ;;
            *) continue ;;
        esac

        echo ""
        
        if [[ "$new_type" == "ftp" ]]; then
            echo -e "${CYAN}${BOLD}ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° FTP/FTPS${RESET}"
            echo ""
            echo -e "${GRAY}Ğ¨Ğ°Ğ³ 1/3: ĞĞ´Ñ€ĞµÑ ÑĞµÑ€Ğ²ĞµÑ€Ğ°${RESET}"
            echo ""
            echo "ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:"
            echo -e "  ${GRAY}ftp://backup.example.com${RESET}"
            echo -e "  ${GRAY}ftps://secure.example.com:990${RESET}"
            echo ""
            read -erp "ĞĞ´Ñ€ĞµÑ ÑĞµÑ€Ğ²ĞµÑ€Ğ° (Enter - Ğ½Ğ°Ğ·Ğ°Ğ´): " base_url
            [[ -z "$base_url" ]] && continue
            
            # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ trailing slash
            base_url="${base_url%/}"
            
            echo ""
            echo -e "${GRAY}Ğ¨Ğ°Ğ³ 2/3: ĞŸĞ°Ğ¿ĞºĞ° Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€Ğµ${RESET}"
            echo ""
            echo "ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:"
            echo -e "  ${GRAY}backups${RESET}           â†’ ${CYAN}${base_url}/backups${RESET}"
            echo -e "  ${GRAY}backup/lazarus${RESET}    â†’ ${CYAN}${base_url}/backup/lazarus${RESET}"
            echo -e "  ${GRAY}(Ğ¿ÑƒÑÑ‚Ğ¾)${RESET}           â†’ ${CYAN}${base_url}${RESET} (ĞºĞ¾Ñ€ĞµĞ½ÑŒ)"
            echo ""
            read -erp "ĞŸĞ°Ğ¿ĞºĞ°: " input_folder
            
            # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ URL
            if [[ -n "$input_folder" ]]; then
                input_folder="${input_folder#/}"  # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ leading slash
                input_folder="${input_folder%/}"  # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ trailing slash
                input_url="${base_url}/${input_folder}"
            else
                input_url="$base_url"
            fi
            
            echo ""
            echo -e "Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ: ${CYAN}${input_url}${RESET}"
            echo ""
            echo -e "${GRAY}Ğ¨Ğ°Ğ³ 3/3: ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ${RESET}"
            read -erp "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ: " input_user
            read -s -erp "ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ: " input_pass
            echo ""
            
        elif [[ "$new_type" == "webdav" ]]; then
            echo -e "${CYAN}${BOLD}ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° WebDAV${RESET}"
            echo ""
            echo -e "${GRAY}Ğ¨Ğ°Ğ³ 1/3: ĞĞ´Ñ€ĞµÑ ÑĞµÑ€Ğ²ĞµÑ€Ğ°${RESET}"
            echo ""
            echo "ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… Ğ°Ğ´Ñ€ĞµÑĞ¾Ğ²:"
            echo -e "  ${GRAY}https://webdav.yandex.ru${RESET}                    (Ğ¯Ğ½Ğ´ĞµĞºÑ.Ğ”Ğ¸ÑĞº)"
            echo -e "  ${GRAY}https://cloud.example.com/remote.php/dav/files/user${RESET} (Nextcloud)"
            echo ""
            read -erp "ĞĞ´Ñ€ĞµÑ ÑĞµÑ€Ğ²ĞµÑ€Ğ° (Enter - Ğ½Ğ°Ğ·Ğ°Ğ´): " base_url
            [[ -z "$base_url" ]] && continue
            
            # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ trailing slash
            base_url="${base_url%/}"
            
            echo ""
            echo -e "${GRAY}Ğ¨Ğ°Ğ³ 2/3: ĞŸĞ°Ğ¿ĞºĞ° Ğ´Ğ»Ñ Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²${RESET}"
            echo ""
            echo "ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:"
            echo -e "  ${GRAY}backups${RESET}           â†’ ${CYAN}${base_url}/backups${RESET}"
            echo -e "  ${GRAY}Backup/Lazarus${RESET}    â†’ ${CYAN}${base_url}/Backup/Lazarus${RESET}"
            echo -e "  ${GRAY}(Ğ¿ÑƒÑÑ‚Ğ¾)${RESET}           â†’ ${CYAN}${base_url}${RESET} (ĞºĞ¾Ñ€ĞµĞ½ÑŒ)"
            echo ""
            read -erp "ĞŸĞ°Ğ¿ĞºĞ°: " input_folder
            
            # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ URL
            if [[ -n "$input_folder" ]]; then
                input_folder="${input_folder#/}"
                input_folder="${input_folder%/}"
                input_url="${base_url}/${input_folder}"
            else
                input_url="$base_url"
            fi
            
            echo ""
            echo -e "Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ: ${CYAN}${input_url}${RESET}"
            echo ""
            echo -e "${GRAY}Ğ¨Ğ°Ğ³ 3/3: ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ${RESET}"
            read -erp "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ: " input_user
            read -s -erp "ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ (Ğ¸Ğ»Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ): " input_pass
            echo ""
            
        elif [[ "$new_type" == "rclone" ]]; then
            echo -e "${CYAN}${BOLD}ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Rclone${RESET}"
            echo ""
            if ! command -v rclone > "$SILENT_LOG" 2>&1; then
                print_message "ERROR" "Rclone Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½!"
                echo -e "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°: ${GRAY}curl https://rclone.org/install.sh | sudo bash${RESET}"
                read -erp "Enter..." dummy
                continue
            fi
            
            echo -e "${GRAY}Ğ¨Ğ°Ğ³ 1/2: Ğ’Ñ‹Ğ±Ğ¾Ñ€ remote${RESET}"
            echo ""
            echo "Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ remotes:"
            local remotes=$(rclone listremotes 2> "$SILENT_LOG")
            if [[ -z "$remotes" ]]; then
                print_message "WARN" "ĞĞµÑ‚ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ñ… remotes!"
                echo -e "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹Ñ‚Ğµ Ñ‡ĞµÑ€ĞµĞ·: ${GRAY}rclone config${RESET}"
                read -erp "Enter..." dummy
                continue
            fi
            echo "$remotes" | sed 's/^/  /'
            echo ""
            read -erp "Ğ˜Ğ¼Ñ remote (Ğ±ĞµĞ· Ğ´Ğ²Ğ¾ĞµÑ‚Ğ¾Ñ‡Ğ¸Ñ, Enter - Ğ½Ğ°Ğ·Ğ°Ğ´): " base_url
            [[ -z "$base_url" ]] && continue
            
            # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´Ğ²Ğ¾ĞµÑ‚Ğ¾Ñ‡Ğ¸Ğµ ĞµÑĞ»Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ ĞµĞ³Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ»
            base_url="${base_url%:}"
            
            echo ""
            echo -e "${GRAY}Ğ¨Ğ°Ğ³ 2/2: ĞŸĞ°Ğ¿ĞºĞ° Ğ² Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ${RESET}"
            echo ""
            echo "ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:"
            echo -e "  ${GRAY}backups${RESET}           â†’ ${CYAN}${base_url}:backups${RESET}"
            echo -e "  ${GRAY}Backup/Server1${RESET}    â†’ ${CYAN}${base_url}:Backup/Server1${RESET}"
            echo -e "  ${GRAY}(Ğ¿ÑƒÑÑ‚Ğ¾)${RESET}           â†’ ${CYAN}${base_url}:${RESET} (ĞºĞ¾Ñ€ĞµĞ½ÑŒ)"
            echo ""
            read -erp "ĞŸĞ°Ğ¿ĞºĞ°: " input_folder
            
            # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ Ğ´Ğ»Ñ rclone
            if [[ -n "$input_folder" ]]; then
                input_folder="${input_folder#/}"
                input_folder="${input_folder%/}"
                input_url="${base_url}:${input_folder}"
            else
                input_url="${base_url}:"
            fi
            
            echo ""
            echo -e "Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ: ${CYAN}${input_url}${RESET}"
            input_user=""
            input_pass=""
        fi

        echo ""
        print_message "INFO" "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ..."
        
        if validate_remote_connection "$new_type" "$input_url" "$input_user" "$input_pass"; then
            print_message "SUCCESS" "Ğ¡Ğ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾!"
            REMOTE_STORAGE_TYPE="$new_type"
            REMOTE_STORAGE_URL="$input_url"
            REMOTE_STORAGE_USER="$input_user"
            REMOTE_STORAGE_PASS="$input_pass"
            save_config
            print_message "SUCCESS" "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹."
            sleep 1.5
            return
        else
            print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğº ÑĞµÑ€Ğ²ĞµÑ€Ñƒ!"
            echo ""
            read -erp "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ? (y/N): " force_save
            if [[ "$force_save" =~ ^[Yy]$ ]]; then
                REMOTE_STORAGE_TYPE="$new_type"
                REMOTE_STORAGE_URL="$input_url"
                REMOTE_STORAGE_USER="$input_user"
                REMOTE_STORAGE_PASS="$input_pass"
                save_config
                print_message "WARN" "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ (ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ½Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ¾)."
                sleep 1.5
                return
            else
                print_message "INFO" "ĞÑ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾. Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚ Ğº Ğ²Ñ‹Ğ±Ğ¾Ñ€Ñƒ Ñ‚Ğ¸Ğ¿Ğ°..."
                sleep 1
            fi
        fi
    done
}

# --- Ğ ĞĞ¢ĞĞ¦Ğ˜Ğ¯ (Ğ£Ğ”ĞĞ›Ğ•ĞĞ˜Ğ• Ğ›Ğ˜Ğ¨ĞĞ˜Ğ¥) ---

rotate_backups_by_count() {
    local PREFIX="$1"
    local LABEL="$2"
    local PERFORM_DELETE="$3" 
    
    debug_log "ROTATION" "=== rotate_backups_by_count($PREFIX, $LABEL, delete=$PERFORM_DELETE) ==="
    debug_log "ROTATION" "MAX_BACKUPS_COUNT=$MAX_BACKUPS_COUNT"
    
    # Ğ¡Ğ¢Ğ ĞĞ“Ğ˜Ğ™ ĞŸĞĞ˜Ğ¡Ğš (Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ°Ñ€Ñ…Ğ¸Ğ²Ñ‹), ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ (ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ)
    # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ls -1tr Ğ´Ğ»Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ¸ while read Ğ´Ğ»Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸Ğ¼ĞµĞ½ Ñ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ğ°Ğ¼Ğ¸
    local files=()
    while IFS= read -r f; do
        files+=("$f")
    done < <(ls -1tr "$BACKUP_DIR"/${PREFIX}_*.tar.gz "$BACKUP_DIR"/${PREFIX}_*.tar.gz.enc 2> "$SILENT_LOG")
    
    local count=${#files[@]}
    local diff=$((count - MAX_BACKUPS_COUNT))
    debug_log "ROTATION" "Found $count files, limit=$MAX_BACKUPS_COUNT, to_delete=$diff"
    
    if [[ $diff -gt 0 ]]; then
        if [[ "$PERFORM_DELETE" == "true" ]]; then
            if [[ "$DRY_RUN" == "true" ]]; then
                debug_log "ROTATION" "[DRY-RUN] Would delete $diff files"
                echo -e "${YELLOW}[DRY-RUN] ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ '$LABEL': Ğ±Ñ‹Ğ»Ğ¾ Ğ±Ñ‹ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¾ $diff ÑÑ‚Ğ°Ñ€Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² (Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ $MAX_BACKUPS_COUNT).${RESET}"
                log_message "INFO" "[DRY_RUN] Would delete $diff files (count-based rotation, prefix=$PREFIX, limit=$MAX_BACKUPS_COUNT)"
                echo "$diff"
                return 0
            fi
            echo -e "${YELLOW}ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ '$LABEL' (ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ $diff ÑÑ‚Ğ°Ñ€Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²):${RESET}"
            for (( i=0; i<diff; i++ )); do
                local file_to_del="${files[$i]}"
                if [[ -f "$file_to_del" ]]; then
                    debug_log "ROTATION" "Deleting: $file_to_del"
                    rm -f "$file_to_del"
                    rm -f "$file_to_del.version"
                    echo "  ğŸ—‘ Ğ£Ğ´Ğ°Ğ»ĞµĞ½: $(basename "$file_to_del")"
                    log_message "INFO" "Deleted $file_to_del (count-based rotation, prefix=$PREFIX)"
                fi
            done
            debug_log "ROTATION" "Deleted $diff files"
            echo "$diff"
            return 0
        else
            echo -e " $LABEL: ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ $count (Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ $MAX_BACKUPS_COUNT) -> ${RED}ĞšĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ñ‹ Ğ½Ğ° ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ: $diff ÑˆÑ‚.${RESET}"
            echo "$diff"
        fi
    else
        debug_log "ROTATION" "No files to delete (count=$count <= limit=$MAX_BACKUPS_COUNT)"
        if [[ "$PERFORM_DELETE" != "true" ]]; then
            echo -e " $LABEL: ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ $count (Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ $MAX_BACKUPS_COUNT) -> ${GREEN}OK${RESET}"
        fi
        echo "0"
        return 0
    fi
}

rotate_backups_by_age() {
    local PREFIX="$1"
    local LABEL="$2"
    local DAYS="$3"
    local PERFORM_DELETE="$4"

    debug_log "ROTATION" "=== rotate_backups_by_age($PREFIX, $LABEL, days=$DAYS, delete=$PERFORM_DELETE) ==="

    # Ğ˜Ñ‰ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ°Ñ€Ñ…Ğ¸Ğ²Ñ‹ (Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ .enc)
    local pattern1="$BACKUP_DIR/${PREFIX}_*.tar.gz"
    local pattern2="$BACKUP_DIR/${PREFIX}_*.tar.gz.enc"

    # ĞĞ°Ğ¹Ğ´Ñ‘Ğ¼ Ñ„Ğ°Ğ¹Ğ»Ñ‹ ÑÑ‚Ğ°Ñ€ÑˆĞµ DAYS Ğ´Ğ½ĞµĞ¹
    local files=()
    # find -mtime +N Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ°ĞµÑ‚ "ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ N Ğ´Ğ½ĞµĞ¹". Ğ§Ñ‚Ğ¾Ğ±Ñ‹ RETENTION_DAYS=N Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ°Ğ»
    # "ÑƒĞ´Ğ°Ğ»ÑÑ‚ÑŒ Ñ„Ğ°Ğ¹Ğ»Ñ‹ ÑÑ‚Ğ°Ñ€ÑˆĞµ N Ğ´Ğ½ĞµĞ¹", Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ -mtime +$((N-1)). Ğ”Ğ»Ñ N==0 â€” Ğ±ÑƒĞ´ĞµĞ¼
    # ÑƒĞ´Ğ°Ğ»ÑÑ‚ÑŒ Ğ²ÑĞµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹.
    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ find Ğ±ĞµĞ· eval
    local find_args=("$BACKUP_DIR" -maxdepth 1 \( -name "${PREFIX}_*.tar.gz" -o -name "${PREFIX}_*.tar.gz.enc" \) -type f)
    if [[ "$DAYS" -le 0 ]]; then
        # Ğ•ÑĞ»Ğ¸ 0 Ğ¸Ğ»Ğ¸ Ğ¼ĞµĞ½ÑŒÑˆĞµ - Ğ½Ğµ ÑƒĞ´Ğ°Ğ»ÑĞµĞ¼ Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ (Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸)
        debug_log "ROTATION" "Days <= 0, skipping rotation"
        return 0
    else
        local nd=$((DAYS - 1))
        find_args+=( -mtime +"$nd" )
        debug_log "ROTATION" "Find mtime: +$nd (files older than $DAYS days)"
    fi
    find_args+=( -print0 )
    while IFS= read -r -d $'\0' f; do files+=("$f"); done < <(find "${find_args[@]}" 2> "$SILENT_LOG")

    local count=${#files[@]}
    debug_log "ROTATION" "Found $count files older than $DAYS days"

    if [[ $count -gt 0 ]]; then
        if [[ "$PERFORM_DELETE" == "true" ]]; then
            if [[ "$DRY_RUN" == "true" ]]; then
                debug_log "ROTATION" "[DRY-RUN] Would delete $count files"
                echo -e "${YELLOW}[DRY-RUN] ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ '$LABEL': Ğ±Ñ‹Ğ»Ğ¾ Ğ±Ñ‹ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¾ $count Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² ÑÑ‚Ğ°Ñ€ÑˆĞµ $DAYS Ğ´Ğ½ĞµĞ¹.${RESET}"
                log_message "INFO" "[DRY_RUN] Would delete $count files (age-based rotation, prefix=$PREFIX, days=$DAYS)"
                echo "$count"
                return 0
            fi
            echo -e "${YELLOW}ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ '$LABEL' (ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ $count Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² ÑÑ‚Ğ°Ñ€ÑˆĞµ $DAYS Ğ´Ğ½ĞµĞ¹):${RESET}"
            for f in "${files[@]}"; do
                if [[ -f "$f" ]]; then
                    debug_log "ROTATION" "Deleting: $f"
                    rm -f "$f"
                    rm -f "$f.version"
                    echo "  ğŸ—‘ Ğ£Ğ´Ğ°Ğ»ĞµĞ½: $(basename "$f")"
                    log_message "INFO" "Deleted $f (age-based rotation, prefix=$PREFIX, days=$DAYS)"
                fi
            done
            debug_log "ROTATION" "Deleted $count files"
            echo "$count"
            return 0
        else
            echo -e " $LABEL: ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ $count Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² ÑÑ‚Ğ°Ñ€ÑˆĞµ $DAYS Ğ´Ğ½ĞµĞ¹ -> ${RED}ĞšĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ñ‹ Ğ½Ğ° ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ: $count ÑˆÑ‚.${RESET}"
            echo "$count"
        fi
    else
        debug_log "ROTATION" "No files to delete"
        if [[ "$PERFORM_DELETE" != "true" ]]; then
            echo -e " $LABEL: ĞĞµÑ‚ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² ÑÑ‚Ğ°Ñ€ÑˆĞµ $DAYS Ğ´Ğ½ĞµĞ¹ -> ${GREEN}OK${RESET}"
        fi
        echo "0"
        return 0
    fi
}

# Ğ Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ñƒ - ÑƒĞ´Ğ°Ğ»ÑĞµÑ‚ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹ Ğ¿Ğ¾ĞºĞ° Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ½Ğµ ÑÑ‚Ğ°Ğ½ĞµÑ‚ <= Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ°
# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: rotate_backups_by_size "true" Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ, Ğ±ĞµĞ· Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ° - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°
rotate_backups_by_size() {
    local PERFORM_DELETE="$1"
    
    debug_log "SIZE" "=== rotate_backups_by_size(delete=$PERFORM_DELETE) ==="
    
    # Ğ•ÑĞ»Ğ¸ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ 0 Ğ¸Ğ»Ğ¸ Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½ - Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ´ĞµĞ»Ğ°ĞµĞ¼
    if [[ -z "$MAX_BACKUP_SIZE_MB" || "$MAX_BACKUP_SIZE_MB" == "0" ]]; then
        debug_log "SIZE" "Size limit disabled (MAX_BACKUP_SIZE_MB=$MAX_BACKUP_SIZE_MB)"
        return 0
    fi
    
    local limit_mb="$MAX_BACKUP_SIZE_MB"
    local limit_bytes=$((limit_mb * 1024 * 1024))
    debug_log "SIZE" "Limit: $limit_mb MB ($limit_bytes bytes)"
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¿Ğ°Ğ¿ĞºĞ¸ Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ² Ğ² Ğ±Ğ°Ğ¹Ñ‚Ğ°Ñ…
    local current_size_bytes=$(du -sb "$BACKUP_DIR" 2> "$SILENT_LOG" | awk '{print $1}')
    local current_size_mb=$((current_size_bytes / 1024 / 1024))
    debug_log "SIZE" "Current size: $current_size_mb MB ($current_size_bytes bytes)"
    
    # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
    local limit_display=""
    local current_display=""
    if [[ $limit_mb -ge 1024 ]]; then
        limit_display="$(echo "scale=1; $limit_mb / 1024" | bc) GB"
    else
        limit_display="$limit_mb MB"
    fi
    if [[ $current_size_mb -ge 1024 ]]; then
        current_display="$(echo "scale=1; $current_size_mb / 1024" | bc) GB"
    else
        current_display="$current_size_mb MB"
    fi
    
    debug_log "SIZE" "Current: $current_size_bytes bytes ($current_display), Limit: $limit_bytes bytes ($limit_display)"
    
    # Ğ•ÑĞ»Ğ¸ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ² Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ñ… Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ° - Ğ²ÑÑ‘ Ğ¾Ğº
    if [[ $current_size_bytes -le $limit_bytes ]]; then
        if [[ "$PERFORM_DELETE" != "true" ]]; then
            echo -e " Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²: ${GREEN}$current_display${RESET} / $limit_display -> ${GREEN}OK${RESET}"
        fi
        return 0
    fi
    
    # ĞÑƒĞ¶Ğ½Ğ¾ ÑƒĞ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ»Ñ‹
    local excess_mb=$((current_size_mb - limit_mb))
    local excess_display=""
    if [[ $excess_mb -ge 1024 ]]; then
        excess_display="$(echo "scale=1; $excess_mb / 1024" | bc) GB"
    else
        excess_display="$excess_mb MB"
    fi
    debug_log "SIZE" "Excess: $excess_mb MB ($excess_display)"
    
    if [[ "$PERFORM_DELETE" != "true" ]]; then
        echo -e " Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²: ${RED}$current_display${RESET} / $limit_display -> ${RED}ĞŸÑ€ĞµĞ²Ñ‹ÑˆĞµĞ½Ğ¸Ğµ: $excess_display${RESET}"
        return 0
    fi
    
    # Ğ ĞµĞ¶Ğ¸Ğ¼ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ
    if [[ "$DRY_RUN" == "true" ]]; then
        debug_log "SIZE" "[DRY-RUN] Would delete files to free $excess_display"
        echo -e "${YELLOW}[DRY-RUN] ĞŸÑ€ĞµĞ²Ñ‹ÑˆĞµĞ½Ğ¸Ğµ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ° Ğ½Ğ° $excess_display. Ğ¡Ñ‚Ğ°Ñ€Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ±Ñ‹Ğ»Ğ¸ Ğ±Ñ‹ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ñ‹.${RESET}"
        log_message "INFO" "[DRY_RUN] Size rotation: current=$current_display, limit=$limit_display, excess=$excess_display"
        return 0
    fi
    
    debug_log "SIZE" "Starting deletion loop..."
    echo -e "${YELLOW}ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¿Ğ¾ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñƒ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° (Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹: $current_display, Ğ»Ğ¸Ğ¼Ğ¸Ñ‚: $limit_display):${RESET}"
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ²ÑĞµÑ… Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ² Ğ¾Ñ‚ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ (ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼Ğ¸)
    local files=()
    while IFS= read -r -d $'\0' f; do 
        files+=("$f")
    done < <(find "$BACKUP_DIR" -maxdepth 1 -type f \( -name "lazarus_*.tar.gz" -o -name "lazarus_*.tar.gz.enc" \) -printf '%T@ %p\0' 2> "$SILENT_LOG" | sort -zn | cut -z -d' ' -f2-)
    
    debug_log "SIZE" "Found ${#files[@]} backup files to process"
    
    local deleted_count=0
    local deleted_size=0
    
    for file in "${files[@]}"; do
        # ĞŸĞµÑ€ĞµÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€
        current_size_bytes=$(du -sb "$BACKUP_DIR" 2> "$SILENT_LOG" | awk '{print $1}')
        debug_log "SIZE" "Current: $current_size_bytes bytes, limit: $limit_bytes bytes"
        
        if [[ $current_size_bytes -le $limit_bytes ]]; then
            debug_log "SIZE" "Size now within limit, stopping"
            break
        fi
        
        if [[ -f "$file" ]]; then
            local file_size=$(stat -c%s "$file" 2> "$SILENT_LOG" || echo 0)
            debug_log "SIZE" "Deleting: $file (size=$file_size bytes)"
            rm -f "$file"
            rm -f "$file.version"
            echo "  ğŸ—‘ Ğ£Ğ´Ğ°Ğ»ĞµĞ½: $(basename "$file")"
            log_message "INFO" "Deleted $file (size-based rotation)"
            ((deleted_count++))
            ((deleted_size += file_size))
        fi
    done
    
    local deleted_display=""
    local deleted_mb=$((deleted_size / 1024 / 1024))
    if [[ $deleted_mb -ge 1024 ]]; then
        deleted_display="$(echo "scale=1; $deleted_mb / 1024" | bc) GB"
    else
        deleted_display="$deleted_mb MB"
    fi
    
    if [[ $deleted_count -gt 0 ]]; then
        print_message "SUCCESS" "Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¾ $deleted_count Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² ($deleted_display)"
        log_message "SUCCESS" "Size-based rotation: deleted $deleted_count files ($deleted_display)"
    fi
    
    return 0
}

# Ğ’ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°
format_size_mb() {
    local size_mb="$1"
    if [[ -z "$size_mb" || "$size_mb" == "0" ]]; then
        echo "Ğ‘ĞµĞ· Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ°"
    elif [[ $size_mb -ge 1024 ]]; then
        echo "$(echo "scale=1; $size_mb / 1024" | bc) GB"
    else
        echo "$size_mb MB"
    fi
}

uninstall_script() {
    if [[ "$EUID" -ne 0 ]]; then
        print_message "ERROR" "Uninstall requires root (sudo)."
        return 1
    fi
    echo ""
    print_message "WARN" "Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ° Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Ğ±ÑƒĞ´ĞµÑ‚ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¾.";
    read -erp "ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ? (y/N): " ans
    if [[ ! "$ans" =~ ^[Yy]$ ]]; then print_message "INFO" "ĞÑ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾."; return 0; fi

    # remove symlink
    if [[ -L "$SYMLINK_PATH" ]]; then
        rm -f "$SYMLINK_PATH" && log_message "INFO" "Removed symlink $SYMLINK_PATH"
    fi
    # remove installed script
    if [[ -f "$INSTALL_DIR/$SCRIPT_NAME" ]]; then
        rm -f "$INSTALL_DIR/$SCRIPT_NAME" && log_message "INFO" "Removed $INSTALL_DIR/$SCRIPT_NAME"
    fi
    # remove config and backups (ask)
    if [[ -d "$INSTALL_DIR" ]]; then
        read -erp "Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ğ¿ĞºÑƒ $INSTALL_DIR Ğ¸ Ğ²ÑĞµ Ğ±ÑĞºĞ°Ğ¿Ñ‹? (y/N): " r2
        if [[ "$r2" =~ ^[Yy]$ ]]; then
            rm -rf "$INSTALL_DIR" && log_message "INFO" "Removed $INSTALL_DIR"
        else
            log_message "INFO" "Preserved $INSTALL_DIR"
        fi
    fi
    # try to remove cron entries
    crontab -l 2> "$SILENT_LOG" | grep -v "# LAZARUS-JOB-" | crontab - 2> "$SILENT_LOG" || true
    log_message "INFO" "Attempted to remove cron entries for lazarus"
    print_message "SUCCESS" "Uninstall finished."
}

# --- ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ CRON Ğ—ĞĞ”ĞĞ§ ---

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ cron-Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑÑ‚Ğ°Ñ‚ÑƒÑ
get_cron_status() {
    local JOB_TYPE="$1"  # full, db, files
    local JOB_ID="# LAZARUS-JOB-${JOB_TYPE^^}"
    
    local cron_line=$(crontab -l 2> "$SILENT_LOG" | grep "$JOB_ID")
    
    if [[ -z "$cron_line" ]]; then
        echo "Ğ’Ñ‹ĞºĞ»"
        return
    fi
    
    # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ cron-ÑÑ‚Ñ€Ğ¾ĞºÑƒ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ñ€Ğ°ÑĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ
    local minute=$(echo "$cron_line" | awk '{print $1}')
    local hour=$(echo "$cron_line" | awk '{print $2}')
    local day_month=$(echo "$cron_line" | awk '{print $3}')
    local month=$(echo "$cron_line" | awk '{print $4}')
    local day_week=$(echo "$cron_line" | awk '{print $5}')
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿ Ñ€Ğ°ÑĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ
    if [[ "$minute" == "0" && "$hour" == "*" ]]; then
        echo "Ğ•Ğ¶ĞµÑ‡Ğ°ÑĞ½Ğ¾"
    elif [[ "$minute" =~ ^\*/([0-9]+)$ ]]; then
        echo "ĞšĞ°Ğ¶Ğ´Ñ‹Ğµ ${BASH_REMATCH[1]} Ğ¼Ğ¸Ğ½"
    elif [[ "$minute" == "0" && "$hour" == "4" && "$day_week" == "1" ]]; then
        echo "Ğ•Ğ¶ĞµĞ½ĞµĞ´ĞµĞ»ÑŒĞ½Ğ¾"
    elif [[ "$minute" == "0" && "$hour" =~ ^[0-9]+$ && "$day_month" == "*" ]]; then
        printf "Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ¾ %02d:00" "$hour"
    elif [[ "$hour" =~ ^[0-9]+$ && "$minute" =~ ^[0-9]+$ ]]; then
        printf "Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ¾ %02d:%02d" "$hour" "$minute"
    else
        echo "ĞĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾"
    fi
}

# Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ° Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸ĞµĞ¼ cron
sync_cron_with_config() {
    local CRON_FULL=$(get_cron_status "full")
    local CRON_DB=$(get_cron_status "db")
    local CRON_FILES=$(get_cron_status "files")
    
    local needs_save=false
    
    # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ ĞµÑĞ»Ğ¸ Ğ¾Ğ½Ğ¸ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°ÑÑ‚ÑÑ Ğ¾Ñ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ cron
    if [[ "$SCHEDULE_FULL" != "$CRON_FULL" ]]; then
        SCHEDULE_FULL="$CRON_FULL"
        needs_save=true
    fi
    if [[ "$SCHEDULE_DB" != "$CRON_DB" ]]; then
        SCHEDULE_DB="$CRON_DB"
        needs_save=true
    fi
    if [[ "$SCHEDULE_FILES" != "$CRON_FILES" ]]; then
        SCHEDULE_FILES="$CRON_FILES"
        needs_save=true
    fi
    
    if [[ "$needs_save" == "true" ]]; then
        save_config
    fi
}

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ½ĞµÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°Ğ¼Ğ¸ Ğ¸ cron, Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ
check_cron_mismatch() {
    [[ "$IS_INTERACTIVE" != "true" ]] && return 0
    
    local CRON_FULL=$(get_cron_status "full")
    local CRON_DB=$(get_cron_status "db")
    local CRON_FILES=$(get_cron_status "files")
    
    local mismatches=()
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼: Ğ² Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°Ñ… Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾, Ğ½Ğ¾ Ğ² cron Ğ½ĞµÑ‚
    if [[ "$SCHEDULE_FULL" != "Ğ’Ñ‹ĞºĞ»" && "$CRON_FULL" == "Ğ’Ñ‹ĞºĞ»" ]]; then
        mismatches+=("Full: Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°='$SCHEDULE_FULL', cron=Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚")
    fi
    if [[ "$SCHEDULE_DB" != "Ğ’Ñ‹ĞºĞ»" && "$CRON_DB" == "Ğ’Ñ‹ĞºĞ»" ]]; then
        mismatches+=("DB: Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°='$SCHEDULE_DB', cron=Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚")
    fi
    if [[ "$SCHEDULE_FILES" != "Ğ’Ñ‹ĞºĞ»" && "$CRON_FILES" == "Ğ’Ñ‹ĞºĞ»" ]]; then
        mismatches+=("Files: Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°='$SCHEDULE_FILES', cron=Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚")
    fi
    
    if [[ ${#mismatches[@]} -eq 0 ]]; then
        return 0
    fi
    
    clear_screen
    echo -e "${YELLOW}${BOLD}âš ï¸ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ Ğ½ĞµÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ¸ cron-Ğ·Ğ°Ğ´Ğ°Ñ‡${RESET}"
    echo ""
    echo "Ğ’ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°Ñ… ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ° ÑƒĞºĞ°Ğ·Ğ°Ğ½Ñ‹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ±ÑĞºĞ°Ğ¿Ğ°,"
    echo "Ğ½Ğ¾ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ cron-Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ² ÑĞ¸ÑÑ‚ĞµĞ¼Ğµ."
    echo ""
    echo -e "${CYAN}ĞĞµÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ:${RESET}"
    for m in "${mismatches[@]}"; do
        echo -e " â€¢ $m"
    done
    echo ""
    echo "Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾, cron-Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ±Ñ‹Ğ»Ğ¸ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ñ‹ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ."
    echo ""
    echo " 1. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°ÑÑ‰Ğ¸Ğµ cron-Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ (Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ)"
    echo " 2. Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ñ cron (ÑĞ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ² 'Ğ’Ñ‹ĞºĞ»')"
    echo " 0. ĞŸÑ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ (Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ)"
    echo ""
    read -erp "Ğ’Ğ°Ñˆ Ğ²Ñ‹Ğ±Ğ¾Ñ€: " choice
    
    case $choice in
        1)
            # Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ cron-Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¸Ğ· Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº
            if [[ "$SCHEDULE_FULL" != "Ğ’Ñ‹ĞºĞ»" && "$CRON_FULL" == "Ğ’Ñ‹ĞºĞ»" ]]; then
                recreate_cron_from_schedule "full" "$SCHEDULE_FULL"
            fi
            if [[ "$SCHEDULE_DB" != "Ğ’Ñ‹ĞºĞ»" && "$CRON_DB" == "Ğ’Ñ‹ĞºĞ»" ]]; then
                recreate_cron_from_schedule "db" "$SCHEDULE_DB"
            fi
            if [[ "$SCHEDULE_FILES" != "Ğ’Ñ‹ĞºĞ»" && "$CRON_FILES" == "Ğ’Ñ‹ĞºĞ»" ]]; then
                recreate_cron_from_schedule "files" "$SCHEDULE_FILES"
            fi
            print_message "SUCCESS" "Cron-Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹."
            sleep 1
            ;;
        2)
            # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ cron
            sync_cron_with_config
            print_message "SUCCESS" "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ñ cron."
            sleep 1
            ;;
        *)
            print_message "INFO" "ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾."
            sleep 0.5
            ;;
    esac
}

# Ğ’Ğ¾ÑÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ cron-Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ¸Ğ· ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ
recreate_cron_from_schedule() {
    local TASK_TYPE="$1"
    local SCHEDULE="$2"
    
    local JOB_CMD="$SYMLINK_PATH backup_$TASK_TYPE"
    [[ "$TASK_TYPE" == "db" ]] && JOB_CMD="$SYMLINK_PATH backup_db"
    [[ "$TASK_TYPE" == "files" ]] && JOB_CMD="$SYMLINK_PATH backup_files"
    [[ "$TASK_TYPE" == "full" ]] && JOB_CMD="$SYMLINK_PATH backup_full"
    
    local JOB_ID="# LAZARUS-JOB-${TASK_TYPE^^}"
    local NEW_CRON_LINE=""
    
    # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ñ€Ğ°ÑĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ cron-ÑÑ‚Ñ€Ğ¾ĞºÑƒ
    case "$SCHEDULE" in
        "Ğ•Ğ¶ĞµÑ‡Ğ°ÑĞ½Ğ¾")
            NEW_CRON_LINE="0 * * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"
            ;;
        "Ğ•Ğ¶ĞµĞ½ĞµĞ´ĞµĞ»ÑŒĞ½Ğ¾")
            NEW_CRON_LINE="0 4 * * 1 $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"
            ;;
        Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ¾\ *)
            # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ¸Ğ· "Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ¾ HH:MM" Ğ¸Ğ»Ğ¸ "Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ¾ HH:00"
            local time_part="${SCHEDULE#Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ¾ }"
            local hour="${time_part%%:*}"
            local minute="${time_part##*:}"
            hour=$((10#$hour))  # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ĞµĞ´ÑƒÑ‰Ğ¸Ğ¹ Ğ½Ğ¾Ğ»ÑŒ
            minute=$((10#$minute))
            NEW_CRON_LINE="$minute $hour * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"
            ;;
        ĞšĞ°Ğ¶Ğ´Ñ‹Ğµ\ *\ Ğ¼Ğ¸Ğ½)
            local interval="${SCHEDULE#ĞšĞ°Ğ¶Ğ´Ñ‹Ğµ }"
            interval="${interval% Ğ¼Ğ¸Ğ½}"
            NEW_CRON_LINE="*/$interval * * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"
            ;;
        *)
            # ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ â€” Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼
            print_message "WARN" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ñ‚ÑŒ Ñ€Ğ°ÑĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: $SCHEDULE"
            return 1
            ;;
    esac
    
    if [[ -n "$NEW_CRON_LINE" ]]; then
        local CURRENT_CRON=$(crontab -l 2> "$SILENT_LOG" | grep -v "$JOB_ID")
        echo -e "$CURRENT_CRON\n$NEW_CRON_LINE" | crontab -
        log_message "INFO" "Recreated cron job for $TASK_TYPE: $SCHEDULE"
    fi
}

# --- Ğ‘Ğ­ĞšĞĞŸ ---

create_backup() {
    local TYPE="$1"
    debug_log "BACKUP" "=== Starting backup: type=$TYPE ==="
    debug_log "BACKUP" "BOT_PATH=$BOT_PATH"
    debug_log "BACKUP" "BOT_CONTAINER=$BOT_CONTAINER_NAME, DB_CONTAINER=$DB_CONTAINER_NAME"
    debug_log "BACKUP" "IS_INTERACTIVE=$IS_INTERACTIVE"
    
    # Ğ‘Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¾Ñ‚ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² non-interactive Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ)
    local LOCK_ACQUIRED="false"
    if [[ "$IS_INTERACTIVE" == "false" ]]; then
        debug_log "LOCK" "Attempting to acquire lock..."
        if ! acquire_lock; then
            local owner_pid=$(check_lock_owner)
            debug_log "LOCK" "Lock failed! Owner PID: $owner_pid"
            log_message "WARN" "Backup skipped: another instance is running (PID: $owner_pid)"
            print_message "WARN" "Ğ”Ñ€ÑƒĞ³Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ±ÑĞºĞ°Ğ¿Ğ° ÑƒĞ¶Ğµ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ (PID: $owner_pid)"
            return 1
        fi
        debug_log "LOCK" "Lock acquired successfully"
        LOCK_ACQUIRED="true"
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑÑ‚Ğ° (Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 1GB)
    local MIN_SPACE_MB=1024
    local free_space_kb=$(df -P "$BACKUP_DIR" 2> "$SILENT_LOG" | tail -1 | awk '{print $4}')
    local free_space_mb=$((free_space_kb / 1024))
    local free_space_human=$(df -h "$BACKUP_DIR" 2> "$SILENT_LOG" | tail -1 | awk '{print $4}')
    debug_log "DISK" "Free space: ${free_space_mb}MB (${free_space_human}), required: ${MIN_SPACE_MB}MB"
    
    if [[ $free_space_mb -lt $MIN_SPACE_MB ]]; then
        print_message "ERROR" "ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¼ĞµÑÑ‚Ğ° Ğ½Ğ° Ğ´Ğ¸ÑĞºĞµ! Ğ¡Ğ²Ğ¾Ğ±Ğ¾Ğ´Ğ½Ğ¾: ${free_space_human} (Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 1GB)"
        log_message "ERROR" "Backup aborted: insufficient disk space (free=${free_space_human}, required=1GB)"
        if [[ "$IS_INTERACTIVE" == "true" ]]; then
            echo ""
            echo -e "${YELLOW}Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸:${RESET}"
            echo " â€¢ Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚Ğµ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹ (Ğ¼ĞµĞ½Ñ 5)"
            echo " â€¢ ĞÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğ¼ĞµÑÑ‚Ğ¾ Ğ½Ğ° Ğ´Ğ¸ÑĞºĞµ"
            echo ""
            read -erp "Ğ’ÑÑ‘ Ñ€Ğ°Ğ²Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ? (y/N): " force_continue
            if [[ ! "$force_continue" =~ ^[Yy]$ ]]; then
                return 1
            fi
            print_message "WARN" "ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼ Ğ½Ğ° ÑĞ²Ğ¾Ğ¹ Ñ€Ğ¸ÑĞº..."
        else
            # Ğ’ non-interactive Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ (cron) Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ°ĞµĞ¼
            send_telegram_notification "Ğ‘ÑĞºĞ°Ğ¿ Ğ¿Ñ€ĞµÑ€Ğ²Ğ°Ğ½: Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¼ĞµÑÑ‚Ğ° Ğ½Ğ° Ğ´Ğ¸ÑĞºĞµ (${free_space_human})"
            [[ "$LOCK_ACQUIRED" == "true" ]] && release_lock
            return 1
        fi
    fi
    
    # Health-check ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ² Ğ¿ĞµÑ€ĞµĞ´ Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ¼
    if [[ "$TYPE" == "full" || "$TYPE" == "db_only" ]]; then
        debug_log "HEALTH" "Checking DB container health..."
        if [[ -n "$DB_CONTAINER_NAME" ]]; then
            local db_running=$(docker container inspect -f '{{.State.Running}}' "$DB_CONTAINER_NAME" 2> "$SILENT_LOG")
            debug_log "HEALTH" "Container $DB_CONTAINER_NAME running=$db_running"
            if [[ "$db_running" != "true" ]]; then
                print_message "ERROR" "ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ” ($DB_CONTAINER_NAME) Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½!"
                log_message "ERROR" "Backup aborted: DB container not running ($DB_CONTAINER_NAME)"
                if [[ "$IS_INTERACTIVE" != "true" ]]; then
                    send_telegram_notification "Ğ‘ÑĞºĞ°Ğ¿ Ğ¿Ñ€ĞµÑ€Ğ²Ğ°Ğ½: ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ” Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ ($DB_CONTAINER_NAME)"
                fi
                [[ "$LOCK_ACQUIRED" == "true" ]] && release_lock
                return 1
            fi
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ health status ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
            local db_health=$(docker container inspect -f '{{.State.Health.Status}}' "$DB_CONTAINER_NAME" 2> "$SILENT_LOG")
            debug_log "HEALTH" "Container health status: $db_health"
            if [[ "$db_health" == "unhealthy" ]]; then
                print_message "WARN" "ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ” Ğ² ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğ¸ 'unhealthy'!"
                log_message "WARN" "DB container health status: unhealthy ($DB_CONTAINER_NAME)"
                if [[ "$IS_INTERACTIVE" == "true" ]]; then
                    read -erp "ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ? (y/N): " cont_unhealthy
                    if [[ ! "$cont_unhealthy" =~ ^[Yy]$ ]]; then
                        return 1
                    fi
                fi
                # Ğ’ cron-Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼, Ğ½Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ
            fi
        fi
    fi
    
    if [[ -z "$BACKUP_PASSWORD" && "$IS_INTERACTIVE" == "true" ]]; then
        clear_screen
        echo -e "${RED}${BOLD}âš ï¸ Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•: ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½!${RESET}"
        echo "Ğ¤Ğ°Ğ¹Ğ» Ğ±ÑĞºĞ°Ğ¿Ğ° Ğ½Ğµ Ğ±ÑƒĞ´ĞµÑ‚ Ğ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½. Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹ Ñ‚Ñ€ĞµÑ‚ÑŒĞ¸Ğ¼ Ğ»Ğ¸Ñ†Ğ°Ğ¼."
        echo ""
        echo " 1. ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ Ğ±ĞµĞ· ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"
        echo " 2. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ ÑĞµĞ¹Ñ‡Ğ°Ñ"
        echo " 0. ĞÑ‚Ğ¼ĞµĞ½Ğ°"
        echo ""
        read -erp "Ğ’Ğ°Ñˆ Ğ²Ñ‹Ğ±Ğ¾Ñ€: " enc_choice
        case $enc_choice in
            1) ;; 
            2) read -s -erp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ: " np
               echo ""; if [[ -n "$np" ]]; then BACKUP_PASSWORD="$np"; save_config; print_message "SUCCESS" "ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½."; else print_message "ERROR" "ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ. ĞÑ‚Ğ¼ĞµĞ½Ğ°."; return; fi ;;
            *) print_message "INFO" "Ğ‘ÑĞºĞ°Ğ¿ Ğ¾Ñ‚Ğ¼ĞµĞ½ĞµĞ½."; return ;;
        esac
    fi

    local TIMESTAMP=$(date +%Y-%m-%d"_"%H_%M_%S)
    local FILE_DB="db_${TIMESTAMP}.sql.gz"
    local FILE_DIR="dir_${TIMESTAMP}.tar.gz"
    local FILE_VERSION="bot_version.txt"
    local FILE_FINAL=""
    local HAS_ERROR=0
    local SKIP_INFO=""
    local SKIP_FILE="$BACKUP_DIR/skipped_files.txt"

    if [[ "$TYPE" != "db_only" ]]; then if ! ensure_bot_path; then return; fi; fi
    if [[ "$TYPE" == "db_only" || "$TYPE" == "full" ]]; then
        if [[ -z "$DB_CONTAINER_NAME" ]]; then ensure_bot_path; fi
    fi

    local CURRENT_VER=$(get_raw_bot_version)
    echo "${CURRENT_VER:-Unknown}" > "$BACKUP_DIR/$FILE_VERSION"
    debug_log "BACKUP" "Bot version saved: ${CURRENT_VER:-Unknown}"

    if [[ "$TYPE" == "full" || "$TYPE" == "db_only" ]]; then
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ‘Ğ” Ğ¸Ğ· .env Ğ±Ğ¾Ñ‚Ğ° (ÑĞ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸)
        local ACTUAL_DB_USER=$(get_db_user)
        local ACTUAL_DB_NAME=$(get_db_name)
        debug_log "DB" "DB params: user=$ACTUAL_DB_USER, db=$ACTUAL_DB_NAME"
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ‘Ğ” Ñ‡ĞµÑ€ĞµĞ· pg_isready (ÑĞ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ healthcheck Ğ¸Ğ· Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸)
        print_message "INFO" "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ‘Ğ”..."
        debug_log "DB" "Running: docker exec $DB_CONTAINER_NAME pg_isready -U $ACTUAL_DB_USER -d $ACTUAL_DB_NAME"
        if ! docker exec "$DB_CONTAINER_NAME" pg_isready -U "$ACTUAL_DB_USER" -d "$ACTUAL_DB_NAME" > "$SILENT_LOG" 2>&1; then
            print_message "ERROR" "Ğ‘Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°! (pg_isready failed)"
            log_message "ERROR" "Backup aborted: pg_isready failed for $DB_CONTAINER_NAME"
            if [[ "$IS_INTERACTIVE" != "true" ]]; then
                send_telegram_notification "Ğ‘ÑĞºĞ°Ğ¿ Ğ¿Ñ€ĞµÑ€Ğ²Ğ°Ğ½: Ğ‘Ğ” Ğ½Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ° ($DB_CONTAINER_NAME)"
            fi
            [[ "$LOCK_ACQUIRED" == "true" ]] && release_lock
            return 1
        fi
        debug_log "DB" "pg_isready: OK"
        
        print_message "INFO" "Ğ”Ğ°Ğ¼Ğ¿ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ($DB_CONTAINER_NAME, user=$ACTUAL_DB_USER, db=$ACTUAL_DB_NAME)..."
        debug_log "DB" "Running: docker exec $DB_CONTAINER_NAME pg_dump -U $ACTUAL_DB_USER $ACTUAL_DB_NAME | gzip -9 > $BACKUP_DIR/$FILE_DB"
        
        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ pg_dump Ğ²Ğ¼ĞµÑÑ‚Ğ¾ pg_dumpall (ÑĞ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸)
        # pg_dump Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ Ğ¸ Ğ¿Ñ€Ğ¾Ñ‰Ğµ Ğ´Ğ»Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ‘Ğ”
        if ! docker exec "$DB_CONTAINER_NAME" pg_dump -U "$ACTUAL_DB_USER" "$ACTUAL_DB_NAME" 2> "$SILENT_LOG" | gzip -9 > "$BACKUP_DIR/$FILE_DB"; then
            print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ´Ğ°Ğ¼Ğ¿Ğ° Ğ‘Ğ”."
            debug_log "DB" "pg_dump FAILED"
            HAS_ERROR=1
        else
            local db_size=$(du -h "$BACKUP_DIR/$FILE_DB" 2>/dev/null | cut -f1)
            debug_log "DB" "pg_dump SUCCESS, file size: $db_size"
        fi
    fi

    if [[ $HAS_ERROR -eq 1 ]]; then 
        rm -f "$BACKUP_DIR/$FILE_DB" "$BACKUP_DIR/$FILE_VERSION"
        [[ "$LOCK_ACQUIRED" == "true" ]] && release_lock
        return 1
    fi

    IFS=' ' read -r -a EXCLUDE_ARRAY <<< "$EXCLUDE_DIRS"
    EXCLUDE_FLAGS=()
    for ex in "${EXCLUDE_ARRAY[@]}"; do if [[ -n "$ex" ]]; then EXCLUDE_FLAGS+=(--exclude="$ex"); fi; done
    # Ğ˜ÑĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸:
    # - *.log Ñ„Ğ°Ğ¹Ğ»Ñ‹
    # - .git Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ
    # - Docker Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ‹ (*.tar Ñ„Ğ°Ğ¹Ğ»Ñ‹)
    # - logs/ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ (access-Ğ»Ğ¾Ğ³Ğ¸ Ğ¸Ğ· ACCESS_LOG_PATH)
    # - backups/ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ (Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ)
    EXCLUDE_FLAGS+=(--exclude="*.log" --exclude=".git" --exclude="logs" --exclude="backups")
    EXCLUDE_FLAGS+=(--exclude="private-remnawave-*.tar" --exclude="rwp_shop*.tar" --exclude="telegram-shop*.tar")
    debug_log "TAR" "Exclude flags: ${EXCLUDE_FLAGS[*]}"

    if [[ "$TYPE" != "db_only" ]]; then
        : > "$SKIP_FILE"
        local BOT_DIRNAME=$(basename "$BOT_PATH")
        debug_log "TAR" "BOT_DIRNAME=$BOT_DIRNAME, MAX_FILE_SIZE_MB=$MAX_FILE_SIZE_MB"
        local FIND_CMD="find ."
        for ex in "${EXCLUDE_ARRAY[@]}"; do if [[ -n "$ex" ]]; then FIND_CMD+=" -path './$ex' -prune -o"; fi; done
        FIND_CMD+=" -type f -size +${MAX_FILE_SIZE_MB}M -print"
        debug_log "TAR" "Find command: $FIND_CMD"
        cd "$BOT_PATH"; eval "$FIND_CMD" | while read -r f; do
            # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ ./path/file Ğ² BOT_DIRNAME/path/file Ğ´Ğ»Ñ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ --exclude-from
            echo "${BOT_DIRNAME}${f#.}"
        done > "$SKIP_FILE"
        local SKIP_COUNT=$(wc -l < "$SKIP_FILE")
        debug_log "TAR" "Large files to skip: $SKIP_COUNT"
        if [[ "$SKIP_COUNT" -gt 0 ]]; then
            local SKIP_SIZE=$(cd "$BOT_PATH" && eval "$FIND_CMD" | tr '\n' '\0' | du -ch --files0-from=- 2>/dev/null | tail -1 | cut -f1)
            print_message "WARN" "ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² (>${MAX_FILE_SIZE_MB}MB): $SKIP_COUNT (Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ Ğ²ĞµÑ: $SKIP_SIZE)"
            debug_log "TAR" "Skipped files content:"
            if [[ "$DEBUG_MODE" == true ]]; then cat "$SKIP_FILE"; fi
            EXCLUDE_FLAGS+=(--exclude-from="$SKIP_FILE")
            SKIP_INFO=$'\nâš ï¸ Skip: '"$SKIP_COUNT"$' (>'"$MAX_FILE_SIZE_MB"$'MB)'
        fi
    fi

    if [[ "$TYPE" == "db_only" ]]; then
        FILE_FINAL="lazarus_db_${TIMESTAMP}.tar.gz"
        debug_log "TAR" "Creating DB archive: $FILE_FINAL"
        tar -czf "$BACKUP_DIR/$FILE_FINAL" -C "$BACKUP_DIR" "$FILE_VERSION" "$FILE_DB"
        rm -f "$BACKUP_DIR/$FILE_DB"
    elif [[ "$TYPE" == "files_only" ]]; then
        FILE_FINAL="lazarus_files_${TIMESTAMP}.tar.gz"
        local FILE_DIR="bot_files_${TIMESTAMP}.tar.gz"
        print_message "INFO" "ĞÑ€Ñ…Ğ¸Ğ²Ğ°Ñ†Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² (ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ Ğ²Ñ€ĞµĞ¼Ñ)..."
        debug_log "TAR" "Creating files archive: $FILE_FINAL"
        debug_log "TAR" "Running: tar -czf $BACKUP_DIR/$FILE_DIR ${EXCLUDE_FLAGS[*]} -C $(dirname "$BOT_PATH") $(basename "$BOT_PATH")"
        # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¸Ñ€ÑƒĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ±Ğ¾Ñ‚Ğ° Ñ Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸
        tar -czf "$BACKUP_DIR/$FILE_DIR" "${EXCLUDE_FLAGS[@]}" -C "$(dirname "$BOT_PATH")" "$(basename "$BOT_PATH")"
        # Ğ—Ğ°Ñ‚ĞµĞ¼ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ñ Ğ²ĞµÑ€ÑĞ¸ĞµĞ¹
        tar -czf "$BACKUP_DIR/$FILE_FINAL" -C "$BACKUP_DIR" "$FILE_VERSION" "$FILE_DIR"
        rm -f "$BACKUP_DIR/$FILE_DIR"
    else 
        FILE_FINAL="lazarus_full_${TIMESTAMP}.tar.gz"
        print_message "INFO" "ĞÑ€Ñ…Ğ¸Ğ²Ğ°Ñ†Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² (ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ Ğ²Ñ€ĞµĞ¼Ñ)..."
        debug_log "TAR" "Creating full archive: $FILE_FINAL"
        tar -czf "$BACKUP_DIR/$FILE_DIR" "${EXCLUDE_FLAGS[@]}" -C "$(dirname "$BOT_PATH")" "$(basename "$BOT_PATH")"
        tar -czf "$BACKUP_DIR/$FILE_FINAL" -C "$BACKUP_DIR" "$FILE_VERSION" "$FILE_DB" "$FILE_DIR"
        rm -f "$BACKUP_DIR/$FILE_DB" "$BACKUP_DIR/$FILE_DIR"
    fi

    rm -f "$SKIP_FILE"

    local ENC_STATUS="ğŸ”“ Unencrypted"
    if [[ -z "$BACKUP_PASSWORD" && "$IS_INTERACTIVE" == "false" ]]; then ENC_STATUS="âš ï¸ NO PASSWORD"; fi

    if [[ -n "$BACKUP_PASSWORD" ]]; then
        print_message "INFO" "Ğ¨Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° (ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ Ğ²Ñ€ĞµĞ¼Ñ)..."
        # Pass password via env var to avoid process listing leak
        # AES-256-CBC + PBKDF2 with 100k iterations for brute-force protection
        export LAZARUS_ENC_PASS="$BACKUP_PASSWORD"
        openssl enc -aes-256-cbc -salt -pbkdf2 -iter 100000 -in "$BACKUP_DIR/$FILE_FINAL" -out "$BACKUP_DIR/${FILE_FINAL}.enc" -pass env:LAZARUS_ENC_PASS
        local enc_res=$?
        unset LAZARUS_ENC_PASS
        
        if [[ $enc_res -eq 0 ]]; then
            rm "$BACKUP_DIR/$FILE_FINAL"
            FILE_FINAL="${FILE_FINAL}.enc"
            ENC_STATUS="ğŸ”’ Encrypted"
            print_message "SUCCESS" "ĞÑ€Ñ…Ğ¸Ğ² Ğ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½."
            debug_log "ENC" "Encryption successful: $FILE_FINAL"
        else
            print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ! ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ½ĞµĞ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°."
            debug_log "ENC" "Encryption FAILED!"
        fi
    fi

    local FINAL_VERSION_FILE="$BACKUP_DIR/$FILE_FINAL.version"
    cp "$BACKUP_DIR/$FILE_VERSION" "$FINAL_VERSION_FILE"
    rm -f "$BACKUP_DIR/$FILE_VERSION"
    debug_log "BACKUP" "Version file: $FINAL_VERSION_FILE"
    
    # --- VERIFY ARCHIVE ---
    print_message "INFO" "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ†ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°..."
    debug_log "VERIFY" "Verifying archive integrity..."
    local VERIFY_OK="false"
    if [[ "$FILE_FINAL" == *".enc" ]]; then
        # For encrypted files, we can't easily verify without decrypting. 
        # We assume openssl exit code 0 was enough, or we could decrypt to /dev/null
        debug_log "VERIFY" "Running: openssl enc -d ... | gzip -t"
        export LAZARUS_VERIFY_PASS="$BACKUP_PASSWORD"
        if openssl enc -d -aes-256-cbc -pbkdf2 -iter 100000 -in "$BACKUP_DIR/$FILE_FINAL" -pass env:LAZARUS_VERIFY_PASS | gzip -t 2> "$SILENT_LOG"; then
             VERIFY_OK="true"
        fi
        unset LAZARUS_VERIFY_PASS
    else
        debug_log "VERIFY" "Running: gzip -t $BACKUP_DIR/$FILE_FINAL"
        if gzip -t "$BACKUP_DIR/$FILE_FINAL" 2> "$SILENT_LOG"; then
             VERIFY_OK="true"
        fi
    fi
    debug_log "VERIFY" "Result: $VERIFY_OK"

    if [[ "$VERIFY_OK" == "true" ]]; then
        print_message "SUCCESS" "ĞÑ€Ñ…Ğ¸Ğ² Ğ²Ğ°Ğ»Ğ¸Ğ´ĞµĞ½."
    else
        print_message "ERROR" "ĞÑ€Ñ…Ğ¸Ğ² Ğ¿Ğ¾Ğ²Ñ€ĞµĞ¶Ğ´ĞµĞ½! (Verification failed)"
        # We do not delete it, just warn
    fi

    local SIZE=$(du -h "$BACKUP_DIR/$FILE_FINAL" | awk '{print $1}')
    print_message "SUCCESS" "Ğ‘ÑĞºĞ°Ğ¿ ÑĞ¾Ğ·Ğ´Ğ°Ğ½: $FILE_FINAL ($SIZE)"
    log_message "SUCCESS" "Backup created: $FILE_FINAL (type=$TYPE, size=$SIZE, enc_status=$ENC_STATUS, verify=$VERIFY_OK)"
    debug_log "BACKUP" "Final file: $FILE_FINAL, size: $SIZE"

    debug_log "UPLOAD" "Starting remote upload..."
    upload_to_remote "$BACKUP_DIR/$FILE_FINAL"
    debug_log "UPLOAD" "Remote upload complete"
    
    local DISPLAY_DATE=$(date "+%d.%m.%Y %H:%M:%S")
    local HASHTAG=""; local TYPE_NAME=""; local ROTATION_KEY=""
    
    case "$TYPE" in
        "full") HASHTAG="ğŸ’¾ #full_backup"; TYPE_NAME="ğŸ“¦ ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ±ÑĞºĞ°Ğ¿"; ROTATION_KEY="ĞŸĞ¾Ğ»Ğ½Ñ‹Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹" ;;
        "db_only") HASHTAG="ğŸ’¾ #db_only"; TYPE_NAME="ğŸ—„ Ğ”Ğ°Ğ¼Ğ¿ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"; ROTATION_KEY="Ğ‘Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…" ;;
        "files_only") HASHTAG="ğŸ’¾ #files_only"; TYPE_NAME="ğŸ“‚ Ğ¤Ğ°Ğ¹Ğ»Ñ‹ Ğ±Ğ¾Ñ‚Ğ°"; ROTATION_KEY="ĞÑ€Ñ…Ğ¸Ğ²Ñ‹ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²" ;;
    esac

    local VER_MSG=""; [[ -n "$CURRENT_VER" ]] && VER_MSG=" | ğŸ· v${CURRENT_VER}"
    local CAPTION="${HASHTAG}
ğŸ“… ${DISPLAY_DATE}
${TYPE_NAME}
ğŸ“ ${SIZE}${VER_MSG}
${ENC_STATUS}${REMOTE_UPLOAD_STATUS_TEXT}${SKIP_INFO}"
    
    send_telegram_document "$BACKUP_DIR/$FILE_FINAL" "$CAPTION"

    # ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ€Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ² Ğ¿Ğ¾ÑĞ»Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ (Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ²Ñ‹Ğ²Ğ¾Ğ´ ÑÑ‡Ñ‘Ñ‚Ñ‡Ğ¸ĞºĞ¾Ğ²)
    local ROTATION_PREFIX="lazarus_$TYPE"
    if [[ "$TYPE" == "db_only" ]]; then ROTATION_PREFIX="lazarus_db"; fi
    if [[ "$TYPE" == "files_only" ]]; then ROTATION_PREFIX="lazarus_files"; fi

    # Ğ Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº DELETE_MODE
    if [[ "$DELETE_MODE" == "count" ]]; then
        rotate_backups_by_count "$ROTATION_PREFIX" "$ROTATION_KEY" "true" > /dev/null
    else
        rotate_backups_by_age "$ROTATION_PREFIX" "$ROTATION_KEY" "$RETENTION_DAYS" "true" > /dev/null
    fi
    
    # Ğ Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ñƒ (ĞµÑĞ»Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚)
    rotate_backups_by_size "true" > /dev/null
    
    # ĞÑĞ²Ğ¾Ğ±Ğ¾Ğ¶Ğ´Ğ°ĞµĞ¼ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºÑƒ
    [[ "$LOCK_ACQUIRED" == "true" ]] && release_lock
    
    return 0
}

# --- Ğ’ĞĞ¡Ğ¡Ğ¢ĞĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ• ---

select_backup_file() {
    local FILTER_PREFIX="$1"; local TITLE="$2"
    local show_limit=5; local show_filenames=false

    while true; do
        local files_raw=("$BACKUP_DIR/${FILTER_PREFIX}_"*.tar.gz*)
        local valid_files=()
        for f in "${files_raw[@]}"; do
            if [[ ! -e "$f" ]]; then continue; fi 
            if [[ "$f" == *".version" ]]; then continue; fi
            if [[ ! "$f" =~ \.tar\.gz(\.enc)?$ ]]; then continue; fi
            valid_files+=("$f")
        done
        
        local total_count=${#valid_files[@]}
        
        if [[ "$total_count" -eq 0 ]]; then
            print_message "WARN" "Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ² Ñ‚Ğ¸Ğ¿Ğ° '${TITLE}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾."; read -erp "Enter..." dummy; return 1
        fi
        
        IFS=$'\n' sorted_backups=($(sort -r <<<"${valid_files[*]}"))
        unset IFS
        
        local CURRENT_VER=$(get_raw_bot_version)

        clear_screen; echo -e "${GREEN}Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ: ${BOLD}${TITLE}${RESET}"
        echo -e "Ğ’ÑĞµĞ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²: ${CYAN}${total_count}${RESET}"; echo ""

        local loop_limit=$show_limit
        if [[ $loop_limit -gt $total_count ]]; then loop_limit=$total_count; fi

        for (( i=0; i<loop_limit; i++ )); do
            local file="${sorted_backups[$i]}"
            local filename=$(basename "$file")
            
            local CACHE_FILE="${file}.version"
            local B_VER=""
            if [[ -f "$CACHE_FILE" ]]; then B_VER=$(cat "$CACHE_FILE")
            else
                if [[ "$file" != *".enc" ]]; then
                    B_VER=$(tar -xzf "$file" -O bot_version.txt 2> "$SILENT_LOG")
                fi
                if [[ -n "$B_VER" ]]; then echo "$B_VER" > "$CACHE_FILE"; else echo "?" > "$CACHE_FILE"; B_VER="?"; fi
            fi
            
            local ENC_MARK=""; [[ "$file" == *".enc" ]] && ENC_MARK="${RED}[ENC]${RESET} "
            
            local VER_STR=""
            if [[ "$B_VER" == "Unknown" || "$B_VER" == "" ]]; then VER_STR="${GRAY}[Ğ/Ğ”]${RESET}"
            elif [[ "$B_VER" == "?" ]]; then VER_STR="${GRAY}[Legacy]${RESET}"
            elif [[ -z "$CURRENT_VER" ]]; then VER_STR="${GRAY}[v$B_VER]${RESET}"
            elif [[ "$B_VER" == "$CURRENT_VER" ]]; then VER_STR="${GREEN}[v$B_VER]${RESET}"
            else VER_STR="${RED}[v$B_VER]${RESET}"; fi

            if [[ "$show_filenames" == "true" ]]; then
                printf " %2d. %s%s %s\n" "$((i+1))" "$ENC_MARK" "$filename" "$VER_STR"
            else
                if [[ $filename =~ _([0-9]{4}-[0-9]{2}-[0-9]{2})_([0-9]{2})_([0-9]{2}) ]]; then
                    local date_part="${BASH_REMATCH[1]}"
                    local time_part="${BASH_REMATCH[2]}:${BASH_REMATCH[3]}"
                    local d_d=${date_part:8:2}; local d_m=${date_part:5:2}
                    local pretty_date="$d_d.$d_m $time_part"
                    local fsize=$(du -h "$file" | awk '{print $1}')
                    printf " %2d. %s | %5s | %s%s\n" "$((i+1))" "${BOLD}$pretty_date${RESET}" "$fsize" "$ENC_MARK" "$VER_STR"
                else
                    printf " %2d. %s %s\n" "$((i+1))" "$filename" "$VER_STR"
                fi
            fi
        done

        echo ""
        if [[ $total_count -gt 5 ]]; then
            if [[ $loop_limit -lt $total_count ]]; then
                 echo -e " ${MAGENTA}888. ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ²ÑĞµ ($total_count ÑˆÑ‚)${RESET}"
            else
                 echo -e " ${MAGENTA}888. Ğ¡Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº (Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ 5)${RESET}"
            fi
        fi

        if [[ "$show_filenames" == "false" ]]; then
            echo -e " 999. ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¸Ğ¼ĞµĞ½Ğ° Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²"; 
        else
            echo -e " 999. ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ´Ğ°Ñ‚Ñƒ Ğ¸ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€"; 
        fi
        echo " 0. ĞĞ°Ğ·Ğ°Ğ´"; echo ""
        read -erp "ĞĞ¾Ğ¼ĞµÑ€ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ¸Ğ»Ğ¸ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° (Enter - ĞĞ°Ğ·Ğ°Ğ´): " choice
        
        if [[ -z "$choice" || "$choice" == "0" ]]; then return 1
        elif [[ "$choice" == "888" ]]; then 
            if [[ $loop_limit -lt $total_count ]]; then loop_limit=$total_count; else loop_limit=5; fi
            show_limit=$loop_limit
            continue
        elif [[ "$choice" == "999" ]]; then 
            if [[ "$show_filenames" == "false" ]]; then show_filenames=true; else show_filenames=false; fi
            continue
        elif [[ "$choice" =~ ^[0-9]+$ && "$choice" -ge 1 && "$choice" -le "$total_count" ]]; then SELECTED_FILE="${sorted_backups[$((choice-1))]}"; return 0
        else print_message "ERROR" "ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€."; sleep 1; fi
    done
}

execute_restore() {
    local MODE="$1"; local FILE="$2"
    debug_log "RESTORE" "=== execute_restore ==="
    debug_log "RESTORE" "Mode: $MODE, File: $FILE"
    echo ""; print_message "WARN" "Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•: Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ñ‹!"
    read -erp "ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ? (y/n): " confirm; [[ "$confirm" != "y" ]] && return

    local TMP_DIR="$BACKUP_DIR/restore_tmp_$$"
    mkdir -p "$TMP_DIR"
    debug_log "RESTORE" "Temp dir: $TMP_DIR"
    
    local WORK_FILE="$FILE"
    if [[ "$FILE" == *".enc" ]]; then
        print_message "INFO" "Ğ¤Ğ°Ğ¹Ğ» Ğ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½. Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ."
        debug_log "RESTORE" "File is encrypted, requesting password..."
        read -s -erp "ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ: " decrypt_pass; echo ""
        local DECRYPTED_FILE="$TMP_DIR/decrypted.tar.gz"
        
        debug_log "RESTORE" "Decrypting to: $DECRYPTED_FILE"
        export LAZARUS_DEC_PASS="$decrypt_pass"
        openssl enc -d -aes-256-cbc -pbkdf2 -iter 100000 -in "$FILE" -out "$DECRYPTED_FILE" -pass env:LAZARUS_DEC_PASS 2> "$SILENT_LOG"
        local dec_res=$?
        unset LAZARUS_DEC_PASS
        debug_log "RESTORE" "Decryption result: $dec_res"

        if [[ $dec_res -ne 0 ]]; then print_message "ERROR" "ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾Ğ²Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»!"; rm -rf "$TMP_DIR"; return; fi
        print_message "SUCCESS" "ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚."
        WORK_FILE="$DECRYPTED_FILE"
    fi

    print_message "INFO" "Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²ĞºĞ°..."
    debug_log "RESTORE" "Extracting: tar -xzf $WORK_FILE -C $TMP_DIR"
    tar -xzf "$WORK_FILE" -C "$TMP_DIR"
    debug_log "RESTORE" "Contents: $(ls -la "$TMP_DIR")"

    local DB_DUMP=$(find "$TMP_DIR" -name "db_*.sql.gz" | head -1)
    local DIR_ARC=$(find "$TMP_DIR" -name "dir_*.tar.gz" | head -1)
    debug_log "RESTORE" "DB_DUMP: $DB_DUMP"
    debug_log "RESTORE" "DIR_ARC: $DIR_ARC"

    if [[ "$MODE" == "full" && -n "$DIR_ARC" ]]; then
        if ! ensure_bot_path; then rm -rf "$TMP_DIR"; return; fi
        print_message "INFO" "ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²..."
        debug_log "RESTORE" "Stopping containers in $BOT_PATH"
        cd "$BOT_PATH" && docker compose down 2> "$SILENT_LOG"
        print_message "INFO" "ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¿Ğ°Ğ¿ĞºĞ¸..."
        debug_log "RESTORE" "Cleaning $BOT_PATH/*"
        rm -rf "$BOT_PATH"/*
        print_message "INFO" "Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²..."
        debug_log "RESTORE" "Extracting: tar -xzf $DIR_ARC -C $(dirname "$BOT_PATH")"
        tar -xzf "$DIR_ARC" -C "$(dirname "$BOT_PATH")"
        
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¸Ğ¼Ñ volume Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸
        local volume_name=$(get_db_volume_name)
        debug_log "RESTORE" "DB Volume: $volume_name"
        if [[ -n "$volume_name" ]]; then
            print_message "INFO" "Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ€Ğ¾Ğ³Ğ¾ volume: $volume_name"
            debug_log "RESTORE" "Running: docker volume rm $volume_name"
            docker volume rm "$volume_name" 2> "$SILENT_LOG" || true
        else
            print_message "WARN" "Volume Ğ‘Ğ” Ğ½Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ."
        fi
        
        print_message "INFO" "Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ‘Ğ”..."
        debug_log "RESTORE" "Running: docker compose up -d $DB_SERVICE_NAME"
        docker compose up -d "$DB_SERVICE_NAME"
        sleep 5
    fi

    if [[ -n "$DB_DUMP" ]]; then
        print_message "INFO" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…..."
        if ! ensure_bot_path; then rm -rf "$TMP_DIR"; return; fi
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ‘Ğ” Ğ¸Ğ· .env Ğ±Ğ¾Ñ‚Ğ°
        local ACTUAL_DB_USER=$(get_db_user)
        local ACTUAL_DB_NAME=$(get_db_name)
        debug_log "RESTORE" "DB params: user=$ACTUAL_DB_USER, db=$ACTUAL_DB_NAME"
        
        # Ğ¡Ğ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸: Ğ¾Ñ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑÑ…ĞµĞ¼Ñƒ Ğ¿ĞµÑ€ĞµĞ´ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ¼
        # https://docs.remnawave.shop/ru/private/backup/
        print_message "INFO" "ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° ÑÑ…ĞµĞ¼Ñ‹ Ğ‘Ğ” (DROP SCHEMA public CASCADE)..."
        debug_log "RESTORE" "Running: docker exec $DB_CONTAINER_NAME psql -U $ACTUAL_DB_USER -c 'DROP SCHEMA...'"
        docker exec -i "$DB_CONTAINER_NAME" psql -U "$ACTUAL_DB_USER" -c "DROP SCHEMA public CASCADE; CREATE SCHEMA public;" > "$SILENT_LOG" 2>&1
        
        print_message "INFO" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (user=$ACTUAL_DB_USER, db=$ACTUAL_DB_NAME)..."
        debug_log "RESTORE" "Running: zcat $DB_DUMP | docker exec $DB_CONTAINER_NAME psql -U $ACTUAL_DB_USER $ACTUAL_DB_NAME"
        zcat "$DB_DUMP" | docker exec -i "$DB_CONTAINER_NAME" psql -U "$ACTUAL_DB_USER" "$ACTUAL_DB_NAME" > "$SILENT_LOG" 2>&1
        debug_log "RESTORE" "DB import complete"
    fi

    if [[ "$MODE" == "full" ]]; then
        print_message "INFO" "Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ²ÑĞµÑ… ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²..."
        debug_log "RESTORE" "Running: docker compose up -d"
        cd "$BOT_PATH" && docker compose up -d
    fi

    rm -rf "$TMP_DIR"
    debug_log "RESTORE" "Temp dir cleaned up"
    print_message "SUCCESS" "Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾."
    log_message "SUCCESS" "Restore completed (mode=$MODE, file=$FILE)"
    read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
}

# --- ĞœĞ•ĞĞ®Ğ¨ĞšĞ˜ ---

menu_manual_backup() {
    while true; do
        clear_screen; echo -e "${GREEN}Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ±ÑĞºĞ°Ğ¿Ğ°${RESET}"
        echo " 1. ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ±ÑĞºĞ°Ğ¿ (Ğ‘Ğ” + Ğ¤Ğ°Ğ¹Ğ»Ñ‹)"
        echo " 2. Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ‘Ğ”"
        echo " 3. Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¤Ğ°Ğ¹Ğ»Ñ‹"
        echo " 0. ĞĞ°Ğ·Ğ°Ğ´"
        echo ""
        read -erp "Ğ’Ğ°Ñˆ Ğ²Ñ‹Ğ±Ğ¾Ñ€ (Enter - ĞĞ°Ğ·Ğ°Ğ´): " m_choice
        [[ -z "$m_choice" ]] && return
        case $m_choice in
            1) create_backup "full"; read -erp "Enter..." dummy; return ;;
            2) create_backup "db_only"; read -erp "Enter..." dummy; return ;;
            3) create_backup "files_only"; read -erp "Enter..." dummy; return ;;
            0) return ;;
        esac
    done
}

menu_restore() {
    while true; do
        # Ğ¡Ğ¢Ğ ĞĞ“ĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ ĞŸĞĞ”Ğ¡Ğ§Ğ•Ğ¢Ğ
        local n_full=$(find "$BACKUP_DIR" -type f \( -name "lazarus_full_*.tar.gz" -o -name "lazarus_full_*.tar.gz.enc" \) 2> "$SILENT_LOG" | wc -l)
        local n_db=$(find "$BACKUP_DIR" -type f \( -name "lazarus_db_*.tar.gz" -o -name "lazarus_db_*.tar.gz.enc" \) 2> "$SILENT_LOG" | wc -l)
        local n_files=$(find "$BACKUP_DIR" -type f \( -name "lazarus_files_*.tar.gz" -o -name "lazarus_files_*.tar.gz.enc" \) 2> "$SILENT_LOG" | wc -l)

        local c_f="$CYAN"; [[ "$n_full" == "0" ]] && c_f="$GRAY"
        local c_d="$CYAN"; [[ "$n_db" == "0" ]] && c_d="$GRAY"
        local c_fl="$CYAN"; [[ "$n_files" == "0" ]] && c_fl="$GRAY"

        clear_screen; echo -e "${GREEN}ĞœĞµĞ½Ñ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ${RESET}"
        echo -e " 1. ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ±ÑĞºĞ°Ğ¿      ${c_f}[${n_full} ÑˆÑ‚]${RESET}"
        echo -e " 2. Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ‘Ğ”         ${c_d}[${n_db} ÑˆÑ‚]${RESET}"
        echo -e " 3. Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¤Ğ°Ğ¹Ğ»Ñ‹      ${c_fl}[${n_files} ÑˆÑ‚]${RESET}"
        echo " 0. ĞĞ°Ğ·Ğ°Ğ´"
        echo ""
        read -erp "Ğ’Ñ‹Ğ±Ğ¾Ñ€ (Enter - ĞĞ°Ğ·Ğ°Ğ´): " r_choice
        [[ -z "$r_choice" ]] && return

        local SELECTED_FILE=""
        case $r_choice in
            1) if select_backup_file "lazarus_full" "ĞŸĞ¾Ğ»Ğ½Ñ‹Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹"; then execute_restore "full" "$SELECTED_FILE"; fi ;;
            2) if select_backup_file "lazarus_db" "Ğ‘ÑĞºĞ°Ğ¿Ñ‹ Ğ‘Ğ”"; then execute_restore "db_only" "$SELECTED_FILE"; fi ;;
            3) if select_backup_file "lazarus_files" "Ğ‘ÑĞºĞ°Ğ¿Ñ‹ Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ²"; then 
                   echo ""; print_message "WARN" "Ğ‘ÑƒĞ´ÑƒÑ‚ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ñ‹ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ² Ğ¿Ğ°Ğ¿ĞºĞµ Ğ±Ğ¾Ñ‚Ğ°!"
                   read -erp "ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ? (y/n): " cf
                   if [[ "$cf" == "y" ]]; then 
                       if ensure_bot_path; then tar -xzf "$SELECTED_FILE" -C "$(dirname "$BOT_PATH")"; print_message "SUCCESS" "Ğ¤Ğ°Ğ¹Ğ»Ñ‹ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½Ñ‹."; read -erp "Enter..." dummy; fi
                   fi
               fi ;;
            0) return ;;
        esac
    done
}

setup_cron_task() {
    local TASK_TYPE="$1"; local JOB_CMD=""; local JOB_ID=""
    if [[ "$TASK_TYPE" == "db" ]]; then JOB_CMD="$SYMLINK_PATH backup_db"; JOB_ID="# LAZARUS-JOB-DB"
    elif [[ "$TASK_TYPE" == "files" ]]; then if ! ensure_bot_path; then return; fi; JOB_CMD="$SYMLINK_PATH backup_files"; JOB_ID="# LAZARUS-JOB-FILES"
    elif [[ "$TASK_TYPE" == "full" ]]; then if ! ensure_bot_path; then return; fi; JOB_CMD="$SYMLINK_PATH backup_full"; JOB_ID="# LAZARUS-JOB-FULL"; fi

    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ
    local CURRENT_STATUS=$(get_cron_status "$TASK_TYPE")
    local STATUS_COLOR="$GRAY"; [[ "$CURRENT_STATUS" != "Ğ’Ñ‹ĞºĞ»" ]] && STATUS_COLOR="$YELLOW"
    
    # Ğ§ĞµĞ»Ğ¾Ğ²ĞµĞºĞ¾Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¸Ğ¿Ğ°
    local TYPE_NAME=""
    case "$TASK_TYPE" in
        "full") TYPE_NAME="ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ±ÑĞºĞ°Ğ¿" ;;
        "db") TYPE_NAME="Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ‘Ğ”" ;;
        "files") TYPE_NAME="Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¤Ğ°Ğ¹Ğ»Ñ‹" ;;
    esac

    clear_screen
    echo -e "${GREEN}${BOLD}ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ñ€Ğ°ÑĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ: ${TYPE_NAME}${RESET}"
    echo -e "Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ: [${STATUS_COLOR}${CURRENT_STATUS}${RESET}]"
    echo ""
    echo -e " 1. Ğ•Ğ¶ĞµÑ‡Ğ°ÑĞ½Ğ¾          ${GRAY}[Ğ² :00]${RESET}"
    echo -e " 2. Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ¾         ${GRAY}[Ğ² 04:00]${RESET}"
    echo -e " 3. Ğ•Ğ¶ĞµĞ½ĞµĞ´ĞµĞ»ÑŒĞ½Ğ¾       ${GRAY}[ĞŸĞ½ Ğ² 04:00]${RESET}"
    echo -e " 4. Ğ¡Ğ²Ğ¾Ñ‘ Ğ²Ñ€ĞµĞ¼Ñ        ${GRAY}[Ğ§Ğ§:ĞœĞœ]${RESET}"
    echo -e " 5. ĞšĞ°Ğ¶Ğ´Ñ‹Ğµ N Ğ¼Ğ¸Ğ½ÑƒÑ‚    ${GRAY}[1-59]${RESET}"
    echo ""
    if [[ "$CURRENT_STATUS" != "Ğ’Ñ‹ĞºĞ»" ]]; then
        echo -e " ${RED}0. ĞÑ‚ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ${RESET}"
    else
        echo " 0. ĞĞ°Ğ·Ğ°Ğ´"
    fi
    echo ""
    read -erp "Ğ’Ñ‹Ğ±Ğ¾Ñ€ (Enter - ĞĞ°Ğ·Ğ°Ğ´): " c
    [[ -z "$c" ]] && return
    
    local NEW_CRON_LINES=""; local DISPLAY_TIME=""

    case $c in
        1) NEW_CRON_LINES="0 * * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"; DISPLAY_TIME="Ğ•Ğ¶ĞµÑ‡Ğ°ÑĞ½Ğ¾" ;;
        2) NEW_CRON_LINES="0 4 * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"; DISPLAY_TIME="Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ¾ 04:00" ;;
        3) NEW_CRON_LINES="0 4 * * 1 $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"; DISPLAY_TIME="Ğ•Ğ¶ĞµĞ½ĞµĞ´ĞµĞ»ÑŒĞ½Ğ¾" ;;
        4) 
           echo ""
           echo "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ²Ñ€ĞµĞ¼Ñ (Ğ§Ğ§:ĞœĞœ), Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»:"
           echo -e "${GRAY}ĞŸÑ€Ğ¸Ğ¼ĞµÑ€: 09:00 18:30${RESET}"
           read -erp "> " times_input
           if [[ -z "$times_input" ]]; then print_message "ERROR" "Ğ’Ñ€ĞµĞ¼Ñ Ğ½Ğµ Ğ²Ğ²ĞµĞ´ĞµĞ½Ğ¾!"; sleep 1; return; fi
           for t in $times_input; do 
               if [[ "$t" =~ ^([0-9]{1,2}):([0-9]{1,2})$ ]]; then 
                   h=$((10#${BASH_REMATCH[1]})); m=$((10#${BASH_REMATCH[2]}))
                   NEW_CRON_LINES+="$m $h * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"$'\n'
               fi
           done
           DISPLAY_TIME="Ğ¡Ğ²Ğ¾Ğµ: $times_input" ;;
        5) 
           echo ""
           echo "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ» Ğ² Ğ¼Ğ¸Ğ½ÑƒÑ‚Ğ°Ñ… (1-59):"
           read -erp "> " interval
           if [[ "$interval" =~ ^[0-9]+$ ]] && [ "$interval" -gt 0 ] && [ "$interval" -lt 60 ]; then
               NEW_CRON_LINES="*/$interval * * * * $JOB_CMD >> /var/log/lazarus_backup.log 2>&1 $JOB_ID"
               DISPLAY_TIME="ĞšĞ°Ğ¶Ğ´Ñ‹Ğµ $interval Ğ¼Ğ¸Ğ½"
           else print_message "ERROR" "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ¾Ñ‚ 1 Ğ´Ğ¾ 59."; sleep 1; return; fi ;;
        0) 
           if [[ "$CURRENT_STATUS" != "Ğ’Ñ‹ĞºĞ»" ]]; then
               DISPLAY_TIME="Ğ’Ñ‹ĞºĞ»"
           else
               return
           fi ;;
        *) return ;;
    esac

    local CURRENT_CRON=$(crontab -l 2> "$SILENT_LOG" | grep -v "$JOB_ID")
    if [[ "$DISPLAY_TIME" != "Ğ’Ñ‹ĞºĞ»" && -n "$NEW_CRON_LINES" ]]; then echo -e "$CURRENT_CRON\n$NEW_CRON_LINES" | crontab -
    else echo "$CURRENT_CRON" | crontab -; fi

    # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸ĞµĞ¼ cron
    sync_cron_with_config
    
    log_message "INFO" "Cron task updated: $TASK_TYPE -> $DISPLAY_TIME"
    print_message "SUCCESS" "Ğ Ğ°ÑĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾!"; sleep 1
}

menu_automation() {
    while true; do
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑÑ‹ Ğ¸Ğ· cron
        local CRON_FULL=$(get_cron_status "full")
        local CRON_DB=$(get_cron_status "db")
        local CRON_FILES=$(get_cron_status "files")
        
        # Ğ¦Ğ²ĞµÑ‚Ğ¾Ğ²Ğ°Ñ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ†Ğ¸Ñ: Ğ¶Ñ‘Ğ»Ñ‚Ñ‹Ğ¹ ĞµÑĞ»Ğ¸ Ğ°ĞºÑ‚Ğ¸Ğ²ĞµĞ½, ÑĞµÑ€Ñ‹Ğ¹ ĞµÑĞ»Ğ¸ Ğ²Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½
        local COLOR_FULL="$GRAY"; [[ "$CRON_FULL" != "Ğ’Ñ‹ĞºĞ»" ]] && COLOR_FULL="$YELLOW"
        local COLOR_DB="$GRAY"; [[ "$CRON_DB" != "Ğ’Ñ‹ĞºĞ»" ]] && COLOR_DB="$YELLOW"
        local COLOR_FILES="$GRAY"; [[ "$CRON_FILES" != "Ğ’Ñ‹ĞºĞ»" ]] && COLOR_FILES="$YELLOW"
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ñ…Ğ¾Ñ‚ÑŒ Ğ¾Ğ´Ğ¸Ğ½ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ°Ğ²Ñ‚Ğ¾-Ğ±ÑĞºĞ°Ğ¿
        local HAS_ANY_CRON=false
        [[ "$CRON_FULL" != "Ğ’Ñ‹ĞºĞ»" || "$CRON_DB" != "Ğ’Ñ‹ĞºĞ»" || "$CRON_FILES" != "Ğ’Ñ‹ĞºĞ»" ]] && HAS_ANY_CRON=true
        
        clear_screen
        echo -e "${GREEN}${BOLD}ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ‘ÑĞºĞ°Ğ¿Ğ°${RESET}"
        echo ""
        echo -e " 1. ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ±ÑĞºĞ°Ğ¿  [${COLOR_FULL}${CRON_FULL}${RESET}]"
        echo -e " 2. Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ‘Ğ”     [${COLOR_DB}${CRON_DB}${RESET}]"
        echo -e " 3. Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¤Ğ°Ğ¹Ğ»Ñ‹  [${COLOR_FILES}${CRON_FILES}${RESET}]"
        echo ""
        if [[ "$HAS_ANY_CRON" == true ]]; then
            echo -e " ${RED}9. ĞÑ‚ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ğ²ÑĞµ Ğ°Ğ²Ñ‚Ğ¾-Ğ±ÑĞºĞ°Ğ¿Ñ‹${RESET}"
            echo ""
        fi
        echo " 0. ĞĞ°Ğ·Ğ°Ğ´"
        echo ""
        read -erp "Ğ’Ñ‹Ğ±Ğ¾Ñ€ (Enter - ĞĞ°Ğ·Ğ°Ğ´): " ac
        [[ -z "$ac" ]] && return
        case $ac in
            1) setup_cron_task "full" ;;
            2) setup_cron_task "db" ;;
            3) setup_cron_task "files" ;;
            9) 
                if [[ "$HAS_ANY_CRON" == true ]]; then
                    disable_all_cron_tasks
                fi
                ;;
            0) return ;;
        esac
    done
}

# ĞÑ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ²ÑĞµÑ… cron-Ğ·Ğ°Ğ´Ğ°Ñ‡ LAZARUS
disable_all_cron_tasks() {
    echo ""
    print_message "WARN" "Ğ’Ñ‹ ÑƒĞ²ĞµÑ€ĞµĞ½Ñ‹, Ñ‡Ñ‚Ğ¾ Ñ…Ğ¾Ñ‚Ğ¸Ñ‚Ğµ Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ğ’Ğ¡Ğ• Ğ°Ğ²Ñ‚Ğ¾-Ğ±ÑĞºĞ°Ğ¿Ñ‹?"
    read -erp "ĞŸĞ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ´Ğ¸Ñ‚ÑŒ? (y/n): " confirm
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ²ÑĞµ cron-Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ LAZARUS
        local current_cron
        current_cron=$(crontab -l 2> "$SILENT_LOG" || echo "")
        local new_cron
        new_cron=$(echo "$current_cron" | grep -v "# LAZARUS-JOB-")
        
        if [[ -z "$new_cron" ]]; then
            crontab -r 2> "$SILENT_LOG" || true
        else
            echo "$new_cron" | crontab -
        fi
        
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³
        SCHEDULE_FULL="Ğ’Ñ‹ĞºĞ»"
        SCHEDULE_DB="Ğ’Ñ‹ĞºĞ»"
        SCHEDULE_FILES="Ğ’Ñ‹ĞºĞ»"
        save_config
        
        print_message "SUCCESS" "Ğ’ÑĞµ Ğ°Ğ²Ñ‚Ğ¾-Ğ±ÑĞºĞ°Ğ¿Ñ‹ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ñ‹"
        log_message "INFO" "All LAZARUS cron tasks disabled by user"
        sleep 1.5
    else
        print_message "INFO" "ĞÑ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾"
        sleep 1
    fi
}

menu_settings() {
    while true; do
        clear_screen; echo -e "${GREEN}${BOLD}ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸${RESET}"
        
        local MASKED_TOKEN="${BOT_TOKEN:0:5}.......${BOT_TOKEN: -5}"; [[ ${#BOT_TOKEN} -lt 10 ]] && MASKED_TOKEN="*******"
        local PASS_MASK="ĞĞµÑ‚"; [[ -n "$BACKUP_PASSWORD" ]] && PASS_MASK="********"
        
        # ĞœĞ°ÑĞºĞ¸Ñ€ÑƒĞµĞ¼ Chat ID (Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 4 Ğ¸ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 3 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°)
        local MASKED_CHAT_ID="-"
        if [[ -n "$CHAT_ID" ]]; then
            if [[ ${#CHAT_ID} -gt 8 ]]; then
                MASKED_CHAT_ID="${CHAT_ID:0:4}...${CHAT_ID: -3}"
            else
                MASKED_CHAT_ID="*****"
            fi
        fi
        
        local MASKED_REMOTE_USER="-"
        if [[ -n "$REMOTE_STORAGE_USER" ]]; then
            if [[ ${#REMOTE_STORAGE_USER} -gt 4 ]]; then
                MASKED_REMOTE_USER="${REMOTE_STORAGE_USER:0:3}...${REMOTE_STORAGE_USER: -2}"
            else
                MASKED_REMOTE_USER="*****"
            fi
        fi

        # Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑÑ‹
        local ST_TG_NOTIFY="${RED}Ğ’Ñ‹ĞºĞ»${RESET}"; [[ "$SEND_TO_TELEGRAM" == "true" ]] && ST_TG_NOTIFY="${GREEN}Ğ’ĞºĞ»${RESET}"
        local ST_TG_FILE="${RED}Ğ’Ñ‹ĞºĞ»${RESET}"; [[ "$TG_SEND_FILE" == "true" ]] && ST_TG_FILE="${GREEN}Ğ’ĞºĞ»${RESET}"
        local ST_REM="${RED}Ğ’Ñ‹ĞºĞ»${RESET}"; [[ "$SEND_TO_REMOTE" == "true" ]] && ST_REM="${GREEN}Ğ’ĞºĞ»${RESET}"
        
        local STORAGE_TYPE_DISP="Ğ’Ñ‹ĞºĞ»"
        if [[ "$REMOTE_STORAGE_TYPE" != "off" ]]; then STORAGE_TYPE_DISP="${REMOTE_STORAGE_TYPE^^}"; fi

        echo -e "${CYAN}--- ĞĞ‘Ğ©Ğ˜Ğ• ---${RESET}"
        echo -e " 1. ĞŸÑƒÑ‚ÑŒ Ğº Ğ±Ğ¾Ñ‚Ñƒ:        ${GRAY}${BOT_PATH}${RESET}"
        echo -e " 2. ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ±Ğ¾Ñ‚Ğ°:     ${GRAY}${BOT_CONTAINER_NAME}${RESET}"
        echo -e " 3. ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ”:       ${GRAY}${DB_CONTAINER_NAME}${RESET}"
        echo -e " 4. ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ‘Ğ”:    ${GRAY}${DB_USER}${RESET}"
        echo -e " 5. Ğ˜ÑĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ğ¿ĞºĞ¸:    ${GRAY}${EXCLUDE_DIRS:-ĞĞµÑ‚}${RESET}"
        echo -e " 6. ĞœĞ°ĞºÑ. Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ñ„Ğ°Ğ¹Ğ»Ğ°: ${GRAY}${MAX_FILE_SIZE_MB} MB${RESET}"
        
        echo -e "\n${CYAN}--- TELEGRAM ---${RESET}"
        echo -e " 7.  Token:             ${GRAY}${MASKED_TOKEN}${RESET}"
        echo -e " 8.  Chat ID:           ${GRAY}${MASKED_CHAT_ID}${RESET}"
        echo -e " 9.  Thread ID:         ${GRAY}${TG_MESSAGE_THREAD_ID:-ĞĞµÑ‚}${RESET}"
        echo -e " 10. Ğ£Ğ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ:       $ST_TG_NOTIFY"
        echo -e " 11. ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ°:    $ST_TG_FILE"
        echo -e " 12. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ÑĞ²ÑĞ·ÑŒ"

        echo -e "\n${CYAN}--- Ğ£Ğ”ĞĞ›ĞĞĞĞĞ• Ğ¥Ğ ĞĞĞ˜Ğ›Ğ˜Ğ©Ğ• ---${RESET}"
        echo -e " 13. Ğ¢Ğ¸Ğ¿:               ${GRAY}${STORAGE_TYPE_DISP}${RESET}"
        echo -e " 14. URL:               ${GRAY}${REMOTE_STORAGE_URL:-ĞĞµÑ‚}${RESET}"
        echo -e " 15. ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ:      ${GRAY}${MASKED_REMOTE_USER}${RESET}"
        echo -e " 16. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ°:          $ST_REM"
        echo -e " 17. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ / ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ"

        echo -e "\n${CYAN}--- Ğ‘Ğ•Ğ—ĞĞŸĞĞ¡ĞĞĞ¡Ğ¢Ğ¬ ---${RESET}"
        echo -e " 18. ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ: ${GRAY}${PASS_MASK}${RESET}"
        
        echo -e "\n${CYAN}--- Ğ ĞĞ¢ĞĞ¦Ğ˜Ğ¯ Ğ‘Ğ­ĞšĞĞŸĞĞ’ ---${RESET}"
        local DM_DISPLAY="ĞŸĞ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸"; [[ "$DELETE_MODE" == "count" ]] && DM_DISPLAY="ĞŸĞ¾ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ñƒ"
        echo -e " 19. Ğ ĞµĞ¶Ğ¸Ğ¼ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ:    ${GRAY}${DM_DISPLAY}${RESET}"
        if [[ "$DELETE_MODE" == "count" ]]; then
            echo -e " 20. ĞœĞ°ĞºÑ. Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²:     ${GRAY}${MAX_BACKUPS_COUNT} ÑˆÑ‚.${RESET}"
        else
            echo -e " 20. Ğ¡Ñ€Ğ¾Ğº Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ:     ${GRAY}${RETENTION_DAYS} Ğ´Ğ½ĞµĞ¹${RESET}"
        fi
        echo -e " 21. Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°:     ${GRAY}$(format_size_mb "$MAX_BACKUP_SIZE_MB")${RESET}"
        
        echo -e "\n 0. ĞĞ°Ğ·Ğ°Ğ´"
        echo ""
        read -erp "Ğ’Ñ‹Ğ±Ğ¾Ñ€: " s
        [[ -z "$s" ]] && return
        
        case $s in
            1) read -erp "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ: " np
               if [[ -n "$np" ]]; then 
                   if [[ -d "$np" ]]; then BOT_PATH="$np"; save_config; print_message "SUCCESS" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾"
                   else print_message "ERROR" "ĞŸĞ°Ğ¿ĞºĞ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°!"; fi
               fi ;;
            
            2) 
                scan_system_for_bot
                local def_cont="${FOUND_BOT:-$BOT_CONTAINER_NAME}"
                local prompt_msg="Ğ˜Ğ¼Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ğ±Ğ¾Ñ‚Ğ°"
                [[ -n "$FOUND_BOT" ]] && prompt_msg+=" (Enter = '$FOUND_BOT')"
                read -erp "$prompt_msg: " nc; nc="${nc:-$def_cont}"
                if [[ -n "$nc" ]]; then BOT_CONTAINER_NAME="$nc"; save_config; print_message "SUCCESS" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾"; fi ;;
                
            3) 
                scan_system_for_bot
                local def_db="${FOUND_DB:-$DB_CONTAINER_NAME}"
                local prompt_msg="Ğ˜Ğ¼Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ğ‘Ğ”"
                [[ -n "$FOUND_DB" ]] && prompt_msg+=" (Enter = '$FOUND_DB')"
                read -erp "$prompt_msg: " ndb_c; ndb_c="${ndb_c:-$def_db}"
                if [[ -n "$ndb_c" ]]; then DB_CONTAINER_NAME="$ndb_c"; save_config; print_message "SUCCESS" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾"; fi ;;

            4) read -erp "ĞĞ¾Ğ²Ñ‹Ğ¹ DB User: " ndb
               if [[ -n "$ndb" ]]; then DB_USER="$ndb"; save_config; print_message "SUCCESS" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾"; fi ;;
               
            5) read -erp "Ğ˜ÑĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: uploads/cache): " ed
               if [[ -n "$ed" ]]; then 
                   EXCLUDE_DIRS="$ed"; save_config; print_message "SUCCESS" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾"
               else 
                   if [[ -n "$EXCLUDE_DIRS" ]]; then 
                       read -erp "ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ? (y/N): " clr
                       if [[ "$clr" =~ ^[Yy]$ ]]; then EXCLUDE_DIRS=""; save_config; fi
                   fi
               fi ;;
               
            6) read -erp "ĞœĞ°ĞºÑ. Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ² MB: " msize
               if [[ "$msize" =~ ^[0-9]+$ ]] && [ "$msize" -gt 0 ]; then 
                   MAX_FILE_SIZE_MB="$msize"; save_config; print_message "SUCCESS" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾"
               fi ;;
            
            7) read -erp "ĞĞ¾Ğ²Ñ‹Ğ¹ Token: " nt
               if [[ -n "$nt" ]]; then BOT_TOKEN="$nt"; save_config; print_message "SUCCESS" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾"; fi ;;
               
            8) echo -e "Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Chat ID: ${CYAN}${CHAT_ID}${RESET}"
               read -erp "ĞĞ¾Ğ²Ñ‹Ğ¹ Chat ID: " nid
               if [[ -n "$nid" ]]; then CHAT_ID="$nid"; save_config; print_message "SUCCESS" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾"; fi ;;
               
            9) read -erp "ĞĞ¾Ğ²Ñ‹Ğ¹ Thread ID (Ğ¿ÑƒÑÑ‚Ğ¾ - ÑĞ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ): " ntid
                TG_MESSAGE_THREAD_ID="$ntid"; save_config; print_message "SUCCESS" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾" ;;
                
            10) # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹
                if [[ "$SEND_TO_TELEGRAM" == "true" ]]; then 
                    SEND_TO_TELEGRAM="false"
                    print_message "INFO" "Ğ£Ğ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Telegram Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ñ‹"
                else 
                    SEND_TO_TELEGRAM="true"
                    print_message "SUCCESS" "Ğ£Ğ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Telegram Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ñ‹"
                fi
                save_config ;;
                
            11) # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Ñ„Ğ°Ğ¹Ğ»Ğ°
                if [[ "$TG_SEND_FILE" == "true" ]]; then
                    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ
                    if [[ "$REMOTE_STORAGE_TYPE" == "off" || "$SEND_TO_REMOTE" != "true" ]]; then
                        echo ""
                        print_message "WARN" "Ğ£Ğ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¾!"
                        print_message "WARN" "Ğ‘ÑĞºĞ°Ğ¿Ñ‹ Ğ±ÑƒĞ´ÑƒÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ´Ğ¸ÑĞºĞµ."
                        read -erp "Ğ’ÑÑ‘ Ñ€Ğ°Ğ²Ğ½Ğ¾ Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºÑƒ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ² TG? (y/N): " confirm
                        if [[ ! "$confirm" =~ ^[Yy]$ ]]; then
                            print_message "INFO" "ĞÑ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾"
                            sleep 1
                            continue
                        fi
                    fi
                    TG_SEND_FILE="false"
                    print_message "INFO" "ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ² TG Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ° (ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹)"
                else
                    TG_SEND_FILE="true"
                    print_message "SUCCESS" "ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ² TG Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ°"
                fi
                save_config ;;
                
            12) test_telegram_connection ;;

            13|14|15|17) configure_remote_storage ;;
            
            16) # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ½Ğ° ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ
                if [[ "$SEND_TO_REMOTE" == "true" ]]; then 
                    SEND_TO_REMOTE="false"
                    print_message "INFO" "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ½Ğ° ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ°"
                else 
                    if [[ "$REMOTE_STORAGE_TYPE" == "off" ]]; then
                        print_message "WARN" "Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹Ñ‚Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ (Ğ¿ÑƒĞ½ĞºÑ‚ 17)"
                        sleep 1.5
                        continue
                    fi
                    SEND_TO_REMOTE="true"
                    print_message "SUCCESS" "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ½Ğ° ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ°"
                fi
                save_config ;;

            18) echo ""
                read -s -erp "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (Ğ¿ÑƒÑÑ‚Ğ¾ - Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ): " new_pass
                echo ""
                BACKUP_PASSWORD="$new_pass"
                save_config
                if [[ -n "$new_pass" ]]; then
                    print_message "SUCCESS" "Ğ¨Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾"
                else
                    print_message "INFO" "Ğ¨Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾"
                fi ;;
                
            19) echo ""
                echo "Ğ ĞµĞ¶Ğ¸Ğ¼ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ°Ñ€Ñ‹Ñ… Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²:"
                echo " 1. ĞŸĞ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ (ÑÑ‚Ğ°Ñ€ÑˆĞµ N Ğ´Ğ½ĞµĞ¹)"
                echo " 2. ĞŸĞ¾ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ñƒ (Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑÑ‚ÑŒ N Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ…)"
                read -erp "Ğ’Ñ‹Ğ±Ğ¾Ñ€ (1/2): " dm
                if [[ "$dm" == "1" ]]; then DELETE_MODE="time"; elif [[ "$dm" == "2" ]]; then DELETE_MODE="count"; fi
                save_config; print_message "SUCCESS" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾" ;;
                
            20) # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ° Ñ€Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°
                if [[ "$DELETE_MODE" == "count" ]]; then
                    read -erp "ĞœĞ°ĞºÑ. ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²: " nd
                    if [[ "$nd" =~ ^[0-9]+$ ]] && [ "$nd" -ge 1 ]; then 
                        MAX_BACKUPS_COUNT="$nd"; save_config; print_message "SUCCESS" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾"
                    else 
                        print_message "ERROR" "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ >= 1"
                    fi
                else
                    read -erp "Ğ¡Ñ€Ğ¾Ğº Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ² Ğ´Ğ½ÑÑ…: " ndays
                    if [[ "$ndays" =~ ^[0-9]+$ ]] && [ "$ndays" -ge 1 ]; then 
                        RETENTION_DAYS="$ndays"; save_config; print_message "SUCCESS" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾"
                    else 
                        print_message "ERROR" "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ >= 1"
                    fi
                fi ;;
                
            21) # Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²
                echo ""
                echo "Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ¿Ğ°Ğ¿ĞºĞ¸ Ñ Ğ±ÑĞºĞ°Ğ¿Ğ°Ğ¼Ğ¸ (Ğ² MB)"
                echo "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ 0 Ğ´Ğ»Ñ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ°"
                echo ""
                local current_mb="$MAX_BACKUP_SIZE_MB"
                echo -e "Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚: ${CYAN}$(format_size_mb "$current_mb")${RESET}"
                read -erp "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ (MB): " new_limit
                if [[ "$new_limit" =~ ^[0-9]+$ ]]; then 
                    MAX_BACKUP_SIZE_MB="$new_limit"
                    save_config
                    if [[ "$new_limit" == "0" ]]; then
                        print_message "INFO" "Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ñ‘Ğ½"
                    else
                        print_message "SUCCESS" "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚: $(format_size_mb "$new_limit")"
                    fi
                else 
                    print_message "ERROR" "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ†ĞµĞ»Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ (0 Ğ´Ğ»Ñ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ)"
                fi ;;
            
            0) return ;;
        esac
        [[ -n "$s" ]] && sleep 0.5
    done
}

# =============================================================================
# ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ¯ ĞœĞ•Ğ–Ğ”Ğ£ Ğ‘ĞĞ¢ĞĞœĞ˜ (Bedolaga â†’ RWP-Shop (Private))
# =============================================================================

# ĞœĞ°ÑÑĞ¸Ğ² Ğ´Ğ»Ñ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹ (Ğ´Ğ»Ñ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğµ)
declare -a TEMP_DIRS=()

# ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸
MIGRATION_SOURCE_TYPE=""        # archive | docker | postgresql
MIGRATION_SOURCE_BACKUP=""      # ĞŸÑƒÑ‚ÑŒ Ğº Ğ°Ñ€Ñ…Ğ¸Ğ²Ñƒ Ğ±ÑĞºĞ°Ğ¿Ğ° (.tar.gz)
MIGRATION_SOURCE_HOST=""
MIGRATION_SOURCE_PORT="5432"
MIGRATION_SOURCE_DB=""
MIGRATION_SOURCE_USER=""
MIGRATION_SOURCE_PASS=""
MIGRATION_SOURCE_CONTAINER=""   # Docker ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ” Bedolaga
MIGRATION_TARGET_CONTAINER=""
MIGRATION_TARGET_DB=""
MIGRATION_TARGET_USER=""
MIGRATION_TARGET_PATH=""            # ĞŸÑƒÑ‚ÑŒ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ RWP-Shop (Ğ³Ğ´Ğµ docker-compose)
MIGRATION_WORK_DIR=""
MIGRATION_EXTRACTED_DIR=""      # Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ¿Ğ°Ğ¿ĞºĞ° Ñ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ¼

# ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ payment_method (Bedolaga) â†’ invoice_type (RWP-Shop)
# 
# Bedolaga Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚: telegram_stars, tribute, yookassa, cryptobot, 
#                        heleket, mulenpay, pal24, wata, platega, cloudpayments, manual
#
# RWP-Shop Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚: yookassa, crypto, telegram, severpay_cards, 
#                               severpay_sbp, wata, platega, stripe
#
# âš ï¸ ĞœĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ±ĞµĞ· Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ² Remnawave: tribute, heleket, mulenpay, pal24, cloudpayments
#    ĞĞ½Ğ¸ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ·Ğ°Ğ¼Ğ°Ğ¿Ğ¿ĞµĞ½Ñ‹ Ğ½Ğ° "unknown" Ğ¸ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
declare -A PAYMENT_METHOD_MAP=(
    # ĞŸÑ€ÑĞ¼Ñ‹Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ñ (Ğ¿ÑƒĞ±Ğ»Ğ¸Ñ‡Ğ½Ğ°Ñ + Ğ¿Ñ€Ğ¸Ğ²Ğ°Ñ‚Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ)
    ["yookassa"]="yookassa"
    ["tribute"]="tribute"
    ["wata"]="wata"
    
    # Ğ¢Ñ€ĞµĞ±ÑƒÑÑ‚ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
    ["telegram_stars"]="telegram"
    ["cryptobot"]="crypto"
    
    # Platega Ğ² Bedolaga â†’ platega_cards Ğ² Remnawave (Ğ¿Ñ€Ğ¸Ğ²Ğ°Ñ‚Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ)
    # Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹: platega_cards, platega_sbp, platega_crypto, platega_acquiring, platega_worldwide
    ["platega"]="platega_cards"
    
    # ĞĞµÑ‚ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ² RWP-Shop - Ğ¿Ğ¾Ğ¼ĞµÑ‡Ğ°ĞµĞ¼ ĞºĞ°Ğº unknown
    ["manual"]="unknown"
    ["heleket"]="unknown"
    ["mulenpay"]="unknown"
    ["pal24"]="unknown"
    ["cloudpayments"]="unknown"
)

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ° ---
migrate_analyze_source() {
    debug_log "MIGRATE" "Starting source analysis"
    print_message "INFO" "ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…..."
    
    # Ğ”Ğ»Ñ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° archive â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ JSON-Ñ„Ğ°Ğ¹Ğ»
    if [[ "$MIGRATION_SOURCE_TYPE" == "archive" ]]; then
        local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
        debug_log "MIGRATE" "Archive mode: checking $db_json"
        
        if [[ ! -f "$db_json" ]]; then
            print_message "ERROR" "Ğ¤Ğ°Ğ¹Ğ» database.json Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² Ğ°Ñ€Ñ…Ğ¸Ğ²Ğµ"
            return 1
        fi
        
        # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ† Ğ² JSON Ñ‡ĞµÑ€ĞµĞ· Python
        local python_cmd=""
        if command -v python3 &>/dev/null; then python_cmd="python3"
        elif command -v python &>/dev/null; then python_cmd="python"
        fi
        
        if [[ -n "$python_cmd" ]]; then
            local table_count=$($python_cmd - "$db_json" << 'PYEOF'
import sys, json
with open(sys.argv[1], 'r', encoding='utf-8') as f:
    data = json.load(f)
tables = data.get('data', {})
print(len(tables))
PYEOF
)
            print_message "SUCCESS" "ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ† Ğ² Ğ°Ñ€Ñ…Ğ¸Ğ²Ğµ: $table_count"
            debug_log "MIGRATE" "Archive contains $table_count tables"
        else
            print_message "WARN" "Python Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿Ğ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†"
        fi
        return 0
    fi
    
    # Ğ”Ğ»Ñ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ¾Ğ² docker/postgresql â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ PostgreSQL
    local source_info=""
    
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        debug_log "MIGRATE" "Using Docker container: $MIGRATION_SOURCE_CONTAINER"
        source_info=$(docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -t -c "
            SELECT 'tables:' || count(*) FROM information_schema.tables WHERE table_schema='public';
        " 2>&1)
    else
        debug_log "MIGRATE" "Using direct connection: $MIGRATION_SOURCE_HOST:$MIGRATION_SOURCE_PORT"
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        source_info=$(psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -t -c "
            SELECT 'tables:' || count(*) FROM information_schema.tables WHERE table_schema='public';
        " 2>&1)
        unset PGPASSWORD
    fi
    
    if [[ $? -ne 0 ]]; then
        print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğº Ğ‘Ğ” Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°"
        debug_log "MIGRATE" "Connection failed: $source_info"
        return 1
    fi
    
    echo "$source_info"
    debug_log "MIGRATE" "Source info: $source_info"
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ---
migrate_check_compatibility() {
    debug_log "MIGRATE" "Checking source compatibility"
    print_message "INFO" "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°..."
    
    local required_tables=("users" "transactions" "promocodes")
    local missing_tables=()
    
    # Ğ”Ğ»Ñ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° - Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ† Ğ² database.json
    if [[ "$MIGRATION_SOURCE_TYPE" == "archive" ]]; then
        local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
        
        if [[ ! -f "$db_json" ]]; then
            print_message "ERROR" "Ğ¤Ğ°Ğ¹Ğ» database.json Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½"
            return 1
        fi
        
        for table in "${required_tables[@]}"; do
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ² JSON
            if ! grep -q "\"$table\":" "$db_json"; then
                missing_tables+=("$table")
            fi
        done
    else
        # Ğ”Ğ»Ñ PostgreSQL - Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· psql
        for table in "${required_tables[@]}"; do
            local exists=""
            if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
                exists=$(docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -t -c "
                    SELECT 1 FROM information_schema.tables WHERE table_schema='public' AND table_name='$table' LIMIT 1;
                " 2>/dev/null | tr -d ' ')
            else
                export PGPASSWORD="$MIGRATION_SOURCE_PASS"
                exists=$(psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -t -c "
                    SELECT 1 FROM information_schema.tables WHERE table_schema='public' AND table_name='$table' LIMIT 1;
                " 2>/dev/null | tr -d ' ')
                unset PGPASSWORD
            fi
            
            if [[ "$exists" != "1" ]]; then
                missing_tables+=("$table")
            fi
        done
    fi
    
    if [[ ${#missing_tables[@]} -gt 0 ]]; then
        print_message "ERROR" "ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹: ${missing_tables[*]}"
        debug_log "MIGRATE" "Missing tables: ${missing_tables[*]}"
        return 1
    fi
    
    print_message "SUCCESS" "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼ (Bedolaga format)"
    return 0
}

# --- ĞŸĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ° ---
BALANCE_HANDLING_MODE=""      # ignore, export_csv, convert_days, convert_partner
BALANCE_CONVERSION_PRICE=""   # Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¼ĞµÑÑÑ†Ğ° Ğ² Ñ€ÑƒĞ±Ğ»ÑÑ… (Ğ´Ğ»Ñ convert_days)
BALANCE_CONVERSION_DAYS=""    # ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ´Ğ½ĞµĞ¹ Ğ² Ğ¼ĞµÑÑÑ†Ğµ (Ğ´Ğ»Ñ convert_days)

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ² Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ ---
migrate_handle_balances() {
    debug_log "MIGRATE" "Analyzing user balances"
    print_message "INFO" "ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ² Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹..."
    
    local export_dir="$MIGRATION_WORK_DIR/export"
    mkdir -p "$export_dir"
    local balances_file="$export_dir/user_balances.csv"
    
    local balance_data=""
    
    # Ğ”Ğ»Ñ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° - Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¸Ğ· database.json Ñ‡ĞµÑ€ĞµĞ· Python
    if [[ "$MIGRATION_SOURCE_TYPE" == "archive" ]]; then
        local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
        
        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Python Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ¼ > 0
        local python_cmd=""
        if command -v python3 &>/dev/null; then
            python_cmd="python3"
        elif command -v python &>/dev/null; then
            python_cmd="python"
        fi
        
        if [[ -n "$python_cmd" ]]; then
            balance_data=$($python_cmd - "$db_json" << 'PYEOF'
import sys
import json

with open(sys.argv[1], 'r', encoding='utf-8') as f:
    data = json.load(f)

users = data.get('data', {}).get('users', [])
for u in users:
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ Ğ¸Ğ¼Ñ‘Ğ½ Ğ¿Ğ¾Ğ»ĞµĞ¹
    # balance_kopeks - ĞºĞ¾Ğ¿ĞµĞ¹ĞºĞ¸ (ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚)
    # balance - Ñ€ÑƒĞ±Ğ»Ğ¸ (Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚)
    balance_kop = u.get('balance_kopeks', 0) or 0
    balance_rub_direct = u.get('balance', 0) or 0
    
    # Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ balance Ğ² Ñ€ÑƒĞ±Ğ»ÑÑ… - ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ² ĞºĞ¾Ğ¿ĞµĞ¹ĞºĞ¸
    if balance_rub_direct > 0 and balance_kop == 0:
        balance_kop = int(balance_rub_direct * 100)
    
    if balance_kop > 0:
        tg_id = u.get('telegram_id', '')
        username = u.get('username', '') or ''
        fname = u.get('first_name', '') or ''
        balance_rub = round(balance_kop / 100, 2)
        print(f"{tg_id},{username},{fname},{balance_kop},{balance_rub}")
PYEOF
)
        fi
    else
        # Ğ”Ğ»Ñ PostgreSQL - Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ‡ĞµÑ€ĞµĞ· psql
        local balance_query="
            SELECT telegram_id, username, first_name, balance_kopeks, 
                   ROUND(balance_kopeks::numeric / 100, 2) as balance_rubles
            FROM users 
            WHERE balance_kopeks > 0 
            ORDER BY balance_kopeks DESC;
        "
        
        if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
            balance_data=$(docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -t -A -F',' -c "$balance_query" 2>/dev/null)
        else
            export PGPASSWORD="$MIGRATION_SOURCE_PASS"
            balance_data=$(psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -t -A -F',' -c "$balance_query" 2>/dev/null)
            unset PGPASSWORD
        fi
    fi
    
    if [[ -z "$balance_data" ]]; then
        print_message "SUCCESS" "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ¼ > 0 Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾"
        BALANCE_HANDLING_MODE="none"
        return 0
    fi
    
    # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ñ‡ĞµÑ€ĞµĞ· Python (Ğ¸Ğ·Ğ±ĞµĞ³Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼ Ñ subshell Ğ² bash)
    local stats
    local python_cmd=""
    if command -v python3 &>/dev/null; then
        python_cmd="python3"
    elif command -v python &>/dev/null; then
        python_cmd="python"
    fi
    
    if [[ -n "$python_cmd" ]]; then
        stats=$(echo "$balance_data" | $python_cmd -c '
import sys

total_kop = 0
count = 0

for line in sys.stdin:
    line = line.strip()
    if not line:
        continue
    parts = line.split(",")
    if len(parts) >= 4:
        try:
            # 4-Ğµ Ğ¿Ğ¾Ğ»Ğµ - balance_kop (ĞºĞ¾Ğ¿ĞµĞ¹ĞºĞ¸)
            kop = float(parts[3])
            total_kop += int(kop)
            count += 1
        except:
            pass

total_rub = round(total_kop / 100, 2)
print(f"{count},{total_kop},{total_rub}")
')
    fi
    
    local users_with_balance=$(echo "$stats" | cut -d',' -f1)
    local total_balance_kopeks=$(echo "$stats" | cut -d',' -f2)
    local total_balance_rubles=$(echo "$stats" | cut -d',' -f3)
    
    # Fallback ĞµÑĞ»Ğ¸ Python Ğ½Ğµ ÑÑ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»
    if [[ -z "$users_with_balance" || "$users_with_balance" == "0" ]]; then
        users_with_balance=$(echo "$balance_data" | grep -c '^[0-9]' || echo "0")
        total_balance_rubles="?"
    fi
    
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ² Ñ„Ğ°Ğ¹Ğ»
    echo "telegram_id,username,first_name,balance_kopeks,balance_rubles" > "$balances_file"
    echo "$balance_data" >> "$balances_file"
    
    # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ
    echo ""
    echo -e "${RED}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo -e "${RED}${BOLD}  âš ï¸  ĞĞ‘ĞĞĞ Ğ£Ğ–Ğ•ĞĞ« ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞ¢Ğ•Ğ›Ğ˜ Ğ¡ ĞĞ•ĞĞ£Ğ›Ğ•Ğ’Ğ«Ğœ Ğ‘ĞĞ›ĞĞĞ¡ĞĞœ!          ${RESET}"
    echo -e "${RED}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo ""
    echo -e "  ${YELLOW}ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ¼ > 0:${RESET} ${WHITE}${BOLD}$users_with_balance${RESET}"
    echo -e "  ${YELLOW}ĞĞ±Ñ‰Ğ°Ñ ÑÑƒĞ¼Ğ¼Ğ° Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ²:${RESET}        ${WHITE}${BOLD}$total_balance_rubles â‚½${RESET}"
    echo ""
    
    # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ¿-5 Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹
    echo -e "${CYAN}  Ğ¢Ğ¾Ğ¿-5 Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ¿Ğ¾ Ğ±Ğ°Ğ»Ğ°Ğ½ÑÑƒ:${RESET}"
    local count=0
    while IFS=',' read -r tg_id username fname balance_kop balance_rub; do
        [[ -z "$tg_id" ]] && continue
        ((count++))
        [[ $count -gt 5 ]] && break
        local display_name="${username:-${fname:-ID:$tg_id}}"
        printf "    %d. %-20s %10s â‚½\n" "$count" "$display_name" "$balance_rub"
    done <<< "$balance_data"
    
    if [[ $users_with_balance -gt 5 ]]; then
        echo -e "    ${GRAY}... Ğ¸ ĞµÑ‰Ñ‘ $((users_with_balance - 5)) Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹${RESET}"
    fi
    echo ""
    
    echo -e "${RED}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo -e "${YELLOW}  Ğ’ RWP-Shop ĞĞ•Ğ¢ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ĞµĞ³Ğ¾ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ!${RESET}"
    echo -e "${YELLOW}  Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ĞºĞ°Ğº Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ ÑÑ‚Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:${RESET}"
    echo -e "${RED}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo ""
    echo -e "  ${GREEN}1.${RESET} Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ² CSV (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ)"
    echo "     â†’ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ² Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸"
    echo "     â†’ Ğ’Ñ‹ ÑĞ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ Ğ´ĞµĞ½ÑŒĞ³Ğ¸ Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ»Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ¸ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ"
    echo ""
    echo -e "  ${GREEN}2.${RESET} ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ² Ğ´Ğ½Ğ¸ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ¸"
    echo "     â†’ Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¿ĞµÑ€ĞµÑÑ‡Ğ¸Ñ‚Ğ°Ğ½ Ğ² Ğ´Ğ½Ğ¸ Ğ¿Ğ¾ Ğ²Ğ°ÑˆĞµĞ¼Ñƒ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñƒ"
    echo "     â†’ Ğ”Ğ½Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²ÑÑ‚ÑÑ Ğº expire_at Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ"
    echo ""
    echo -e "  ${YELLOW}3.${RESET} Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ² Ğ¸ Ğ¿ĞµÑ€ĞµĞ½ĞµÑÑ‚Ğ¸ Ğ±Ğ°Ğ»Ğ°Ğ½Ñ"
    echo "     â†’ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ² Ğ² RWP-Shop"
    echo "     â†’ Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ % ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸Ğ¸ Ğ¸Ğ· Bedolaga (Ğ¸Ğ»Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ)"
    echo "     â†’ Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ available_balance Ğ¸Ğ· Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ° Bedolaga"
    echo ""
    echo -e "  ${RED}4.${RESET} Ğ˜Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ (ĞŸĞĞ¢Ğ•Ğ Ğ¯ Ğ”ĞĞĞĞ«Ğ¥!)"
    echo "     â†’ Ğ‘Ğ°Ğ»Ğ°Ğ½ÑÑ‹ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑĞ½Ñ‹ Ğ±ĞµĞ·Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ½Ğ¾"
    echo ""
    echo -e "  ${CYAN}5.${RESET} ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ’Ğ¡Ğ•Ğ¥ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ¼"
    echo ""
    echo -e "  ${CYAN}0.${RESET} ĞĞ°Ğ·Ğ°Ğ´"
    echo ""
    
    while true; do
        read -erp "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ [0-5] (Enter - ĞĞ°Ğ·Ğ°Ğ´): " choice
        case "$choice" in
            ""|0|q|Q)
                return 1
                ;;
            5)
                # ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ²ÑĞµÑ… Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ¼
                echo ""
                echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
                echo -e "${CYAN}  Ğ’Ğ¡Ğ• ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞ¢Ğ•Ğ›Ğ˜ Ğ¡ Ğ‘ĞĞ›ĞĞĞ¡ĞĞœ ($users_with_balance Ñ‡ĞµĞ».)${RESET}"
                echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
                echo ""
                printf "  ${GRAY}%-4s %-20s %-15s %12s${RESET}\n" "â„–" "Username" "Telegram ID" "Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ"
                echo "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
                local num=0
                while IFS=',' read -r tg_id username fname balance_kop balance_rub; do
                    [[ -z "$tg_id" ]] && continue
                    ((num++))
                    local display_name="${username:-${fname:-â€”}}"
                    printf "  %-4d %-20s %-15s %10s â‚½\n" "$num" "$display_name" "$tg_id" "$balance_rub"
                done <<< "$balance_data"
                echo ""
                echo -e "  ${YELLOW}Ğ˜Ñ‚Ğ¾Ğ³Ğ¾: $total_balance_rubles â‚½${RESET}"
                echo ""
                read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ..." dummy
                echo ""
                ;;
            1)
                BALANCE_HANDLING_MODE="export_csv"
                print_message "INFO" "Ğ‘Ğ°Ğ»Ğ°Ğ½ÑÑ‹ Ğ±ÑƒĞ´ÑƒÑ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ²: $balances_file"
                break
                ;;
            2)
                echo ""
                echo -e "${CYAN}=== ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ ĞšĞĞĞ’Ğ•Ğ Ğ¢ĞĞ¦Ğ˜Ğ˜ Ğ‘ĞĞ›ĞĞĞ¡Ğ Ğ’ Ğ”ĞĞ˜ ===${RESET}"
                echo ""
                echo "Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ²Ğ°ÑˆĞµĞ³Ğ¾ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ğ°:"
                echo ""
                
                # Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¼ĞµÑÑÑ†Ğ°
                read -erp "Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ 1 Ğ¼ĞµÑÑÑ†Ğ° Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ¸ Ğ² Ñ€ÑƒĞ±Ğ»ÑÑ… [100]: " month_price
                month_price="${month_price:-100}"
                
                # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ñ‡Ğ¸ÑĞ»Ğ°
                if ! [[ "$month_price" =~ ^[0-9]+([.][0-9]+)?$ ]] || [[ $(echo "$month_price <= 0" | bc) -eq 1 ]]; then
                    print_message "ERROR" "ĞĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ°Ñ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ 100â‚½"
                    month_price="100"
                fi
                
                # ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ´Ğ½ĞµĞ¹ Ğ² Ğ¼ĞµÑÑÑ†Ğµ
                read -erp "ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ´Ğ½ĞµĞ¹ Ğ² 1 Ğ¼ĞµÑÑÑ†Ğµ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ¸ [30]: " days_per_month
                days_per_month="${days_per_month:-30}"
                
                # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ñ‡Ğ¸ÑĞ»Ğ°
                if ! [[ "$days_per_month" =~ ^[0-9]+$ ]] || [[ "$days_per_month" -le 0 ]]; then
                    print_message "ERROR" "ĞĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ´Ğ½ĞµĞ¹. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ 30"
                    days_per_month="30"
                fi
                
                BALANCE_CONVERSION_PRICE="$month_price"
                BALANCE_CONVERSION_DAYS="$days_per_month"
                BALANCE_HANDLING_MODE="convert_days"
                
                echo ""
                echo -e "${CYAN}Ğ¤Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ° Ñ€Ğ°ÑÑ‡Ñ‘Ñ‚Ğ°:${RESET}"
                echo "  extra_days = (balance_rubles / $month_price) Ã— $days_per_month"
                echo ""
                
                # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ñ€Ğ°ÑÑ‡Ñ‘Ñ‚Ğ°
                local example_balance="150"
                local example_days=$(echo "scale=0; ($example_balance / $month_price) * $days_per_month" | bc 2>/dev/null || echo "?")
                echo -e "  ${YELLOW}ĞŸÑ€Ğ¸Ğ¼ĞµÑ€:${RESET} Ğ±Ğ°Ğ»Ğ°Ğ½Ñ 150â‚½ â†’ $example_days Ğ´Ğ½ĞµĞ¹"
                echo ""
                
                print_message "SUCCESS" "ĞšÑƒÑ€Ñ: $month_price â‚½ = $days_per_month Ğ´Ğ½ĞµĞ¹"
                break
                ;;
            3)
                BALANCE_HANDLING_MODE="convert_partner"
                print_message "INFO" "Ğ‘Ğ°Ğ»Ğ°Ğ½ÑÑ‹ Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ² â†’ partner.available_balance"
                break
                ;;
            4)
                echo ""
                echo -e "${RED}${BOLD}  âš ï¸  Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•! Ğ’Ğ« ĞŸĞĞ¢Ğ•Ğ Ğ¯Ğ•Ğ¢Ğ• $total_balance_rubles â‚½!${RESET}"
                echo ""
                read -erp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ 'LOSE DATA' Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ: " confirm
                if [[ "$confirm" == "LOSE DATA" ]]; then
                    BALANCE_HANDLING_MODE="ignore"
                    print_message "WARN" "Ğ‘Ğ°Ğ»Ğ°Ğ½ÑÑ‹ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ (Ğ¿Ğ¾Ñ‚ĞµÑ€Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)"
                    # Ğ’ÑÑ‘ Ñ€Ğ°Ğ²Ğ½Ğ¾ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸
                    print_message "INFO" "Ğ ĞµĞ·ĞµÑ€Ğ²Ğ½Ğ°Ñ ĞºĞ¾Ğ¿Ğ¸Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ²: $balances_file"
                    break
                else
                    print_message "INFO" "ĞÑ‚Ğ¼ĞµĞ½Ğ°. Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¹ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚."
                fi
                ;;
            *)
                print_message "ERROR" "ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€"
                ;;
        esac
    done
    
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ² ---
migrate_apply_balance_handling() {
    debug_log "MIGRATE" "Applying balance handling: $BALANCE_HANDLING_MODE"
    
    local export_dir="$MIGRATION_WORK_DIR/export"
    local import_dir="$MIGRATION_WORK_DIR/import"
    local balances_file="$export_dir/user_balances.csv"
    local balance_report="$MIGRATION_WORK_DIR/balance_report.txt"
    
    case "$BALANCE_HANDLING_MODE" in
        "none")
            debug_log "MIGRATE" "No balances to process"
            return 0
            ;;
        "export_csv")
            # Ğ£Ğ¶Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ Ğ² migrate_handle_balances
            print_message "SUCCESS" "Ğ‘Ğ°Ğ»Ğ°Ğ½ÑÑ‹ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ²: $balances_file"
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚
            {
                echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                echo "  ĞĞ¢Ğ§ĞĞ¢ Ğ Ğ‘ĞĞ›ĞĞĞ¡ĞĞ¥ ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞ¢Ğ•Ğ›Ğ•Ğ™"
                echo "  Ğ”Ğ°Ñ‚Ğ° Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸: $(date '+%Y-%m-%d %H:%M:%S')"
                echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                echo ""
                echo "Ğ¤Ğ°Ğ¹Ğ» Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ°Ğ¼Ğ¸: $balances_file"
                echo ""
                echo "Ğ Ğ•ĞšĞĞœĞ•ĞĞ”ĞĞ¦Ğ˜Ğ˜:"
                echo "1. Ğ¡Ğ²ÑĞ¶Ğ¸Ñ‚ĞµÑÑŒ Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑĞ¼Ğ¸ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚Ğµ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚ ÑÑ€ĞµĞ´ÑÑ‚Ğ²"
                echo "2. Ğ˜Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ»Ğ¸Ñ‚Ğµ Ğ¸Ğ¼ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºÑƒ Ğ½Ğ° ÑĞºĞ²Ğ¸Ğ²Ğ°Ğ»ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ ÑÑ€Ğ¾Ğº"
                echo "3. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ°Ğ´Ğ¼Ğ¸Ğ½-Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ Remnawave Ğ´Ğ»Ñ Ñ€ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹"
                echo ""
                echo "Ğ¡ĞŸĞ˜Ğ¡ĞĞš ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞ¢Ğ•Ğ›Ğ•Ğ™:"
                cat "$balances_file"
            } > "$balance_report"
            
            print_message "INFO" "ĞÑ‚Ñ‡Ñ‘Ñ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½: $balance_report"
            ;;
            
        "convert_days")
            print_message "INFO" "ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ² Ğ² Ğ´Ğ½Ğ¸ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ¸..."
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ñ„Ğ°Ğ¹Ğ» Ñ Ğ´Ğ¾Ğ¿. Ğ´Ğ½ÑĞ¼Ğ¸ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            local days_file="$import_dir/balance_to_days.csv"
            echo "telegram_id,extra_days,balance_rubles,month_price,days_per_month" > "$days_file"
            
            local month_price="${BALANCE_CONVERSION_PRICE:-100}"
            local days_per_month="${BALANCE_CONVERSION_DAYS:-30}"
            
            tail -n +2 "$balances_file" | while IFS=',' read -r tg_id username fname balance_kop balance_rub; do
                [[ -z "$tg_id" ]] && continue
                # Ğ Ğ°ÑÑ‡Ñ‘Ñ‚ Ğ´Ğ½ĞµĞ¹: (balance_rub / month_price) * days_per_month
                local extra_days=$(echo "scale=0; ($balance_rub / $month_price) * $days_per_month" | bc 2>/dev/null || echo "0")
                [[ "$extra_days" -lt 1 ]] && extra_days=0
                echo "$tg_id,$extra_days,$balance_rub,$month_price,$days_per_month" >> "$days_file"
            done
            
            print_message "SUCCESS" "Ğ¤Ğ°Ğ¹Ğ» ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½: $days_file"
            
            # ĞÑ‚Ñ‡Ñ‘Ñ‚
            {
                echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                echo "  ĞšĞĞĞ’Ğ•Ğ Ğ¢ĞĞ¦Ğ˜Ğ¯ Ğ‘ĞĞ›ĞĞĞ¡ĞĞ’ Ğ’ Ğ”ĞĞ˜ ĞŸĞĞ”ĞŸĞ˜Ğ¡ĞšĞ˜"
                echo "  Ğ¢Ğ°Ñ€Ğ¸Ñ„: $month_price â‚½ = $days_per_month Ğ´Ğ½ĞµĞ¹"
                echo "  Ğ¤Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ°: extra_days = (balance / $month_price) Ã— $days_per_month"
                echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                echo ""
                echo "telegram_id,extra_days,balance_rubles"
                tail -n +2 "$days_file" | cut -d',' -f1-3
            } > "$balance_report"
            ;;
            
        "convert_partner")
            print_message "INFO" "ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ² Ğ² Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€ÑĞºĞ¸Ğµ (Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹)..."
            
            # Ğ¤Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ²
            local partner_create_file="$import_dir/partners_to_create.csv"
            echo "telegram_id,available_balance,percent" > "$partner_create_file"
            
            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚ ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸Ğ¸ Ğ¸Ğ· Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Bedolaga
            local default_percent="10"  # fallback
            
            # ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¸Ğ· Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
            if [[ -n "$MIGRATION_EXTRACTED_DIR" && -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
                local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
                
                # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ REFERRAL_COMMISSION_PERCENT Ğ¸Ğ· system_settings
                local extracted_percent=$(grep -o '"REFERRAL_COMMISSION_PERCENT"[^}]*"value"[^"]*"[^"]*"' "$db_json" 2>/dev/null | grep -o '"value"[^"]*"[^"]*"' | grep -o '[0-9]\+' | head -1)
                if [[ -n "$extracted_percent" ]]; then
                    default_percent="$extracted_percent"
                    debug_log "MIGRATE" "Found REFERRAL_COMMISSION_PERCENT in backup: $default_percent"
                fi
                
                # Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ REFERRAL_BONUS_PERCENT (Ğ´Ñ€ÑƒĞ³Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ)
                if [[ "$default_percent" == "10" ]]; then
                    extracted_percent=$(grep -o '"REFERRAL_BONUS_PERCENT"[^}]*"value"[^"]*"[^"]*"' "$db_json" 2>/dev/null | grep -o '"value"[^"]*"[^"]*"' | grep -o '[0-9]\+' | head -1)
                    if [[ -n "$extracted_percent" ]]; then
                        default_percent="$extracted_percent"
                        debug_log "MIGRATE" "Found REFERRAL_BONUS_PERCENT in backup: $default_percent"
                    fi
                fi
            fi
            
            echo ""
            echo -e "${CYAN}=== ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ ĞŸĞĞ Ğ¢ĞĞĞ Ğ¡ĞšĞĞ“Ğ ĞŸĞ ĞĞ¦Ğ•ĞĞ¢Ğ ===${RESET}"
            echo ""
            echo -e "Ğ’ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°Ñ… Bedolaga Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚ ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸Ğ¸: ${GREEN}$default_percent%${RESET}"
            echo ""
            echo "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ĞºĞ°ĞºĞ¾Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ²:"
            echo "  1. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ· Bedolaga: ${default_percent}%"
            echo "  2. Ğ£ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚"
            echo ""
            read -erp "Ğ’Ñ‹Ğ±Ğ¾Ñ€ [1]: " percent_choice
            percent_choice="${percent_choice:-1}"
            
            local partner_percent="$default_percent"
            if [[ "$percent_choice" == "2" ]]; then
                read -erp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚ ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸Ğ¸ (1-100): " custom_percent
                if [[ "$custom_percent" =~ ^[0-9]+$ ]] && [[ "$custom_percent" -ge 1 ]] && [[ "$custom_percent" -le 100 ]]; then
                    partner_percent="$custom_percent"
                else
                    print_message "WARN" "ĞĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ $default_percent%"
                fi
            fi
            
            print_message "INFO" "ĞŸÑ€Ğ¾Ñ†ĞµĞ½Ñ‚ ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ²: $partner_percent%"
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ² Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ¼
            local created_count=0
            tail -n +2 "$balances_file" | while IFS=',' read -r tg_id username fname balance_kop balance_rub; do
                [[ -z "$tg_id" ]] && continue
                echo "$tg_id,$balance_rub,$partner_percent" >> "$partner_create_file"
                ((created_count++))
            done
            
            created_count=$(($(wc -l < "$partner_create_file") - 1))
            
            print_message "SUCCESS" "ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾ Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ² Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ: $created_count"
            
            # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿Ñ€ĞµĞ²ÑŒÑ
            echo ""
            echo -e "${CYAN}ĞŸÑ€ĞµĞ²ÑŒÑ (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 5 Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹):${RESET}"
            echo "telegram_id | Ğ±Ğ°Ğ»Ğ°Ğ½Ñ | Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚"
            echo "------------|--------|--------"
            tail -n +2 "$partner_create_file" | head -5 | while IFS=',' read -r tid bal pct; do
                printf "%s | %s â‚½ | %s%%\n" "$tid" "$bal" "$pct"
            done
            echo ""
            
            # ĞÑ‚Ñ‡Ñ‘Ñ‚
            {
                echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                echo "  Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ• ĞŸĞĞ Ğ¢ĞĞĞ ĞĞ’ Ğ¡ Ğ‘ĞĞ›ĞĞĞ¡ĞĞœ"
                echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                echo ""
                echo "ĞŸÑ€Ğ¾Ñ†ĞµĞ½Ñ‚ ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸Ğ¸: $partner_percent%"
                echo "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚Ğ°: $([ "$partner_percent" == "$default_percent" ] && echo "Bedolaga" || echo "ÑƒĞºĞ°Ğ·Ğ°Ğ½ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ")"
                echo ""
                echo "ĞŸĞĞ Ğ¢ĞĞĞ Ğ« Ğ”Ğ›Ğ¯ Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ¯:"
                cat "$partner_create_file"
                echo ""
                echo "SQL Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° (Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ñ€Ğ¸ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğµ):"
                echo "INSERT INTO partner (telegram_id, available_balance, percent)"
                echo "VALUES (telegram_id, balance, percent)"
                echo "ON CONFLICT (telegram_id) DO UPDATE SET"
                echo "  available_balance = partner.available_balance + EXCLUDED.available_balance;"
            } > "$balance_report"
            ;;
            
        "ignore")
            print_message "WARN" "Ğ‘Ğ°Ğ»Ğ°Ğ½ÑÑ‹ Ğ¿Ñ€Ğ¾Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹!"
            
            {
                echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                echo "  âš ï¸  Ğ‘ĞĞ›ĞĞĞ¡Ğ« Ğ‘Ğ«Ğ›Ğ˜ ĞŸĞ ĞĞ˜Ğ“ĞĞĞ Ğ˜Ğ ĞĞ’ĞĞĞ« (ĞŸĞĞ¢Ğ•Ğ Ğ¯ Ğ”ĞĞĞĞ«Ğ¥)"
                echo "  Ğ”Ğ°Ñ‚Ğ°: $(date '+%Y-%m-%d %H:%M:%S')"
                echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                echo ""
                echo "Ğ Ğ•Ğ—Ğ•Ğ Ğ’ĞĞĞ¯ ĞšĞĞŸĞ˜Ğ¯ ĞŸĞĞ¢Ğ•Ğ Ğ¯ĞĞĞ«Ğ¥ Ğ‘ĞĞ›ĞĞĞ¡ĞĞ’:"
                cat "$balances_file"
            } > "$balance_report"
            ;;
    esac
    
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· JSON Ğ±ÑĞºĞ°Ğ¿Ğ° Bedolaga ---
# ĞŸĞ°Ñ€ÑĞ¸Ñ‚ database.json Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ CSV Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°
migrate_export_from_json() {
    debug_log "MIGRATE" "Starting JSON export from backup archive"
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· JSON Ğ±ÑĞºĞ°Ğ¿Ğ° Bedolaga..."
    
    local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
    
    if [[ ! -f "$db_json" ]]; then
        print_message "ERROR" "Ğ¤Ğ°Ğ¹Ğ» database.json Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğµ"
        return 1
    fi
    
    local export_dir="$MIGRATION_WORK_DIR/export"
    mkdir -p "$export_dir"
    
    # P2: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğµ
    local temp_files=()
    cleanup_temp_files() {
        for f in "${temp_files[@]}"; do
            [[ -f "$f" ]] && rm -f "$f"
        done
    }
    trap cleanup_temp_files RETURN
    
    # P2: Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ CSV
    validate_csv() {
        local csv_file="$1"
        local expected_name="$2"
        
        if [[ ! -f "$csv_file" ]]; then
            debug_log "MIGRATE" "CSV validation: $expected_name - file not found"
            return 1
        fi
        
        local lines=$(wc -l < "$csv_file" 2>/dev/null)
        if [[ "$lines" -lt 1 ]]; then
            debug_log "MIGRATE" "CSV validation: $expected_name - empty file"
            return 1
        fi
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞºĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 5 ÑÑ‚Ñ€Ğ¾Ğº)
        local expected_cols=$(head -1 "$csv_file" | awk -F',' '{print NF}')
        local inconsistent=$(head -5 "$csv_file" | awk -F',' -v e="$expected_cols" 'NF != e {print NR}' | head -1)
        
        if [[ -n "$inconsistent" ]]; then
            debug_log "MIGRATE" "CSV validation: $expected_name - inconsistent columns at line $inconsistent"
            return 1
        fi
        
        debug_log "MIGRATE" "CSV validation: $expected_name - OK ($lines lines, $expected_cols cols)"
        return 0
    }
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Python Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° JSON
    local python_cmd=""
    if command -v python3 &>/dev/null; then
        python_cmd="python3"
    elif command -v python &>/dev/null; then
        python_cmd="python"
    fi
    
    if [[ -z "$python_cmd" ]]; then
        print_message "ERROR" "Python Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ python3 Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° JSON Ğ±ÑĞºĞ°Ğ¿Ğ°"
        return 1
    fi
    
    debug_log "MIGRATE" "Using Python: $python_cmd"
    
    # Ğ’ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° JSON Ğ¼Ğ°ÑÑĞ¸Ğ²Ğ° Ñ‡ĞµÑ€ĞµĞ· Python
    # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ²ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒ json, Ğ±ĞµĞ· Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ jq
    parse_json_table() {
        local json_file="$1"
        local table_name="$2"
        local fields="$3"  # Comma-separated list of fields
        
        debug_log "MIGRATE" "Parsing table: $table_name, fields: $fields"
        
        $python_cmd - "$json_file" "$table_name" "$fields" << 'PYTHON_SCRIPT'
import sys
import json
import csv

json_file = sys.argv[1]
table_name = sys.argv[2]
fields = [f.strip() for f in sys.argv[3].split(',')]

try:
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
except Exception as e:
    sys.stderr.write(f"Error loading JSON: {e}\n")
    sys.exit(1)

# ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ Ğ¸Ğ· data
table_data = data.get('data', {}).get(table_name, [])

if not table_data:
    # ĞŸÑƒÑÑ‚Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° - Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº
    print(','.join(fields))
    sys.exit(0)

# Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ CSV Ğ² stdout
writer = csv.writer(sys.stdout)
writer.writerow(fields)

for row in table_data:
    values = []
    for field in fields:
        val = row.get(field, '')
        if val is None:
            val = ''
        elif isinstance(val, bool):
            val = 't' if val else 'f'
        elif isinstance(val, (int, float)):
            val = str(val)
        values.append(val)
    writer.writerow(values)
PYTHON_SCRIPT
    }
    
    # --- Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ users ---
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ users..."
    local users_raw_file="$export_dir/users_raw.csv"
    local users_file="$export_dir/users.csv"
    temp_files+=("$users_raw_file")  # P2: Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ»Ñ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸
    
    # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ÑĞµ Ğ¿Ğ¾Ğ»Ñ
    parse_json_table "$db_json" "users" "id,telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status,last_activity,referred_by_id" > "$users_raw_file"
    
    # --- Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ° id â†’ telegram_id Ğ´Ğ»Ñ JOIN-Ğ¾Ğ² ---
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² Ğ°ÑÑĞ¾Ñ†Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
    local id_map_file="$export_dir/.id_to_telegram.map"
    # P0: Race Condition fix - Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ°Ñ‚Ğ¾Ğ¼Ğ°Ñ€Ğ½ÑƒÑ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ Ñ‡ĞµÑ€ĞµĞ· Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»
    awk -F',' 'NR>1 && $1!="" && $2!="" {print $1 "=" $2}' "$users_raw_file" > "${id_map_file}.tmp" && \
        mv "${id_map_file}.tmp" "$id_map_file"
    debug_log "MIGRATE" "Created idâ†’telegram_id map with $(wc -l < "$id_map_file") entries"
    
    # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ñ‹Ğ¹ Ñ psql ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ¼:
    # telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status
    echo "telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status" > "$users_file"
    awk -F',' 'NR > 1 {
        # ĞŸĞ¾Ğ»Ñ: id,telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status,...
        telegram_id = $2
        username = $3
        first_name = $4
        language = $5
        created_at = $6
        balance_kopeks = $7
        referral_balance = $8
        status = $9
        
        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿ÑƒÑÑ‚Ñ‹Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹
        if (balance_kopeks == "") balance_kopeks = "0"
        if (referral_balance == "") referral_balance = "0"
        if (status == "") status = "active"
        
        print telegram_id "," username "," first_name "," language "," created_at "," balance_kopeks "," referral_balance "," status
    }' "$users_raw_file" >> "$users_file"
    
    local user_count=0
    [[ -s "$users_file" ]] && user_count=$(($(wc -l < "$users_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹: $user_count"
    debug_log "MIGRATE" "Users exported: $user_count"
    
    # --- Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ²ÑĞ·ĞµĞ¹ ---
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ²ÑĞ·ĞµĞ¹..."
    local referrals_file="$export_dir/referrals.csv"
    
    # ĞÑƒĞ¶ĞµĞ½ JOIN: users.referred_by_id â†’ users.id â†’ telegram_id
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ CSV Ñ telegram_id Ğ²Ğ¼ĞµÑÑ‚Ğ¾ internal id
    # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¸Ğ· users_raw_file Ñ‚.Ğº. Ñ‚Ğ°Ğ¼ ĞµÑÑ‚ÑŒ referred_by_id (Ğ¿Ğ¾Ğ»Ğµ $11)
    echo "referee_telegram_id,referrer_telegram_id,created_at" > "$referrals_file"
    
    awk -F',' -v mapfile="$id_map_file" '
    BEGIN {
        while ((getline line < mapfile) > 0) {
            split(line, parts, "=")
            id_map[parts[1]] = parts[2]
        }
    }
    NR > 1 {
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ users_raw: id,telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status,last_activity,referred_by_id
        telegram_id = $2
        referred_by_id = $11
        created_at = $6
        
        if (referred_by_id != "" && referred_by_id in id_map) {
            referrer_tg = id_map[referred_by_id]
            print telegram_id "," referrer_tg "," created_at
        }
    }
    ' "$users_raw_file" >> "$referrals_file"
    
    local referral_count=0
    [[ -s "$referrals_file" ]] && referral_count=$(($(wc -l < "$referrals_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ²ÑĞ·ĞµĞ¹: $referral_count"
    
    # --- Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ subscriptions ---
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¾Ğº..."
    local subscriptions_raw="$export_dir/subscriptions_raw.csv"
    local subscriptions_file="$export_dir/subscriptions.csv"
    
    parse_json_table "$db_json" "subscriptions" "id,user_id,end_date,subscription_url,is_trial,device_limit,autopay_enabled,status" > "$subscriptions_raw"
    
    # JOIN Ñ users Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ telegram_id Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ…
    echo "telegram_id,expire_at,subscription_link,is_trial,device_limit,autopay_enabled" > "$subscriptions_file"
    
    awk -F',' -v mapfile="$id_map_file" '
    BEGIN {
        while ((getline line < mapfile) > 0) {
            split(line, parts, "=")
            id_map[parts[1]] = parts[2]
        }
        skipped = 0
    }
    NR > 1 {
        user_id = $2
        end_date = $3
        subscription_url = $4
        is_trial = $5
        device_limit = $6
        autopay = $7
        status = $8
        
        # P1: Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿ÑƒÑÑ‚Ñ‹Ñ… user_id
        if (user_id == "") {
            skipped++
            next
        }
        
        # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ¸
        if (status == "active" && user_id in id_map) {
            telegram_id = id_map[user_id]
            print telegram_id "," end_date "," subscription_url "," is_trial "," device_limit "," autopay
        }
    }
    END {
        if (skipped > 0) {
            print "WARN: Skipped " skipped " subscriptions with empty user_id" > "/dev/stderr"
        }
    }
    ' "$subscriptions_raw" >> "$subscriptions_file"
    
    local subs_count=0
    [[ -s "$subscriptions_file" ]] && subs_count=$(($(wc -l < "$subscriptions_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¾Ğº: $subs_count"
    
    # --- Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ transactions ---
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¹..."
    local transactions_raw="$export_dir/transactions_raw.csv"
    local transactions_file="$export_dir/transactions.csv"
    
    # Ğ’ JSON Ğ¿Ğ¾Ğ»Ğµ is_completed (boolean), Ğ½Ğµ status
    parse_json_table "$db_json" "transactions" "id,user_id,amount_kopeks,payment_method,is_completed,created_at" > "$transactions_raw"
    
    # JOIN Ñ users Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ is_completed
    # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ transform: id,user_id,amount,payment_method,status,created_at,subscription_days
    echo "id,user_id,amount,payment_method,status,created_at,subscription_days" > "$transactions_file"
    
    awk -F',' -v mapfile="$id_map_file" '
    BEGIN {
        while ((getline line < mapfile) > 0) {
            split(line, parts, "=")
            id_map[parts[1]] = parts[2]
        }
        skipped = 0
    }
    NR > 1 {
        id = $1
        user_id = $2
        amount = $3
        payment_method = $4
        is_completed = $5  # "t" Ğ¸Ğ»Ğ¸ "f"
        created_at = $6
        
        # P1: Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿ÑƒÑÑ‚Ñ‹Ñ… user_id
        if (user_id == "") {
            skipped++
            next
        }
        
        # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½Ğ½Ñ‹Ğµ Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¸ (is_completed = "t")
        if (is_completed == "t" && user_id in id_map) {
            telegram_id = id_map[user_id]
            # subscription_days Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ² JSON - ÑÑ‚Ğ°Ğ²Ğ¸Ğ¼ Ğ¿ÑƒÑÑ‚Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ
            print id "," telegram_id "," amount "," payment_method ",completed," created_at ","
        }
    }
    END {
        if (skipped > 0) {
            print "WARN: Skipped " skipped " transactions with empty user_id" > "/dev/stderr"
        }
    }
    ' "$transactions_raw" >> "$transactions_file"
    
    local tx_count=0
    [[ -s "$transactions_file" ]] && tx_count=$(($(wc -l < "$transactions_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¹: $tx_count"
    
    # --- Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ promocodes ---
    # Ğ’ Bedolaga Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ñ‹ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ:
    # 1) subscription_days > 0 â€” Ğ´Ğ½Ğ¸ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ¸ (Ğ¼Ğ¸Ğ³Ñ€Ğ¸Ñ€ÑƒÑÑ‚ÑÑ)
    # 2) bonus_kopeks > 0 â€” Ğ´ĞµĞ½ÑŒĞ³Ğ¸ Ğ½Ğ° Ğ±Ğ°Ğ»Ğ°Ğ½Ñ (ĞĞ• Ğ¼Ğ¸Ğ³Ñ€Ğ¸Ñ€ÑƒÑÑ‚ÑÑ, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ÑÑ Ğ² NOT_MIGRATED)
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ²..."
    local promocodes_file="$export_dir/promocodes.csv"
    local promocodes_balance_file="$export_dir/promocodes_balance_type.csv"
    
    # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ñ bonus_kopeks Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ñ‚Ğ¸Ğ¿Ğ¾Ğ²
    parse_json_table "$db_json" "promocodes" "code,subscription_days,bonus_kopeks,max_uses,current_uses,is_active,created_at" > "$export_dir/promocodes_full.csv"
    
    # Ğ Ğ°Ğ·Ğ´ĞµĞ»ÑĞµĞ¼: Ğ´Ğ½Ğ¸ â†’ promocodes.csv, Ğ±Ğ°Ğ»Ğ°Ğ½Ñ â†’ promocodes_balance_type.csv
    echo "code,subscription_days,max_uses,current_uses,is_active,created_at" > "$promocodes_file"
    echo "code,bonus_kopeks,bonus_rub,max_uses,current_uses,is_active,created_at" > "$promocodes_balance_file"
    
    local promo_days_count=0
    local promo_balance_count=0
    
    while IFS=',' read -r code sub_days bonus_kop max_uses cur_uses is_active created_at; do
        [[ -z "$code" || "$code" == "code" ]] && continue
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ°
        local has_days=false
        local has_balance=false
        [[ -n "$sub_days" && "$sub_days" != "0" && "$sub_days" != "null" ]] && has_days=true
        [[ -n "$bonus_kop" && "$bonus_kop" != "0" && "$bonus_kop" != "null" ]] && has_balance=true
        
        if [[ "$has_days" == "true" ]]; then
            # ĞŸÑ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´ Ğ½Ğ° Ğ´Ğ½Ğ¸ â€” Ğ¼Ğ¸Ğ³Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ
            echo "$code,$sub_days,$max_uses,$cur_uses,$is_active,$created_at" >> "$promocodes_file"
            ((promo_days_count++))
        elif [[ "$has_balance" == "true" ]]; then
            # ĞŸÑ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´ Ğ½Ğ° Ğ±Ğ°Ğ»Ğ°Ğ½Ñ â€” ĞĞ• Ğ¼Ğ¸Ğ³Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ
            local bonus_rub=$(awk "BEGIN {printf \"%.2f\", ${bonus_kop:-0}/100}")
            echo "$code,$bonus_kop,$bonus_rub,$max_uses,$cur_uses,$is_active,$created_at" >> "$promocodes_balance_file"
            ((promo_balance_count++))
        fi
    done < "$export_dir/promocodes_full.csv"
    
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ² (Ğ´Ğ½Ğ¸): $promo_days_count"
    if [[ $promo_balance_count -gt 0 ]]; then
        print_message "WARN" "ĞŸÑ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ² Ğ½Ğ° Ğ±Ğ°Ğ»Ğ°Ğ½Ñ (Ğ½Ğµ Ğ¼Ğ¸Ğ³Ñ€Ğ¸Ñ€ÑƒÑÑ‚ÑÑ): $promo_balance_count"
        print_message "INFO" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ²: promocodes_balance_type.csv"
    fi
    
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»
    rm -f "$export_dir/promocodes_full.csv"
    
    # --- Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ promocode_uses ---
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ²..."
    local promo_uses_raw="$export_dir/promocode_uses_raw.csv"
    local promo_uses_file="$export_dir/promocode_uses.csv"
    
    parse_json_table "$db_json" "promocode_uses" "user_id,promocode_id,used_at" > "$promo_uses_raw"
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ promocode_id â†’ code
    local promo_map_file="$export_dir/.promo_id_to_code.map"
    
    # ĞĞ°Ğ¼ Ğ½ÑƒĞ¶ĞµĞ½ id Ğ¸Ğ· JSON, ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ñ id
    parse_json_table "$db_json" "promocodes" "id,code" > "$export_dir/promocodes_with_id.csv"
    # P0: Race Condition fix - Ğ°Ñ‚Ğ¾Ğ¼Ğ°Ñ€Ğ½Ğ°Ñ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ
    awk -F',' 'NR>1 && $1!="" && $2!="" {print $1 "=" $2}' "$export_dir/promocodes_with_id.csv" > "${promo_map_file}.tmp" && \
        mv "${promo_map_file}.tmp" "$promo_map_file"
    
    echo "customer_telegram_id,promo_code,used_at" > "$promo_uses_file"
    
    awk -F',' -v usermap="$id_map_file" -v promomap="$promo_map_file" '
    BEGIN {
        while ((getline line < usermap) > 0) {
            split(line, parts, "=")
            user_map[parts[1]] = parts[2]
        }
        while ((getline line < promomap) > 0) {
            split(line, parts, "=")
            promo_map[parts[1]] = parts[2]
        }
    }
    NR > 1 {
        user_id = $1
        promo_id = $2
        used_at = $3
        
        if (user_id in user_map && promo_id in promo_map) {
            print user_map[user_id] "," promo_map[promo_id] "," used_at
        }
    }
    ' "$promo_uses_raw" >> "$promo_uses_file"
    
    local promo_uses_count=0
    [[ -s "$promo_uses_file" ]] && promo_uses_count=$(($(wc -l < "$promo_uses_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ²: $promo_uses_count"
    
    # --- Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ tickets ---
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ²..."
    local tickets_raw="$export_dir/tickets_raw.csv"
    local tickets_file="$export_dir/tickets.csv"
    
    parse_json_table "$db_json" "tickets" "id,user_id,title,status,created_at,updated_at,closed_at" > "$tickets_raw"
    
    echo "id,customer_telegram_id,subject,status,created_at,updated_at,closed_at" > "$tickets_file"
    
    awk -F',' -v mapfile="$id_map_file" '
    BEGIN {
        while ((getline line < mapfile) > 0) {
            split(line, parts, "=")
            id_map[parts[1]] = parts[2]
        }
    }
    NR > 1 {
        id = $1
        user_id = $2
        title = $3
        status = $4
        created_at = $5
        updated_at = $6
        closed_at = $7
        
        if (user_id in id_map) {
            telegram_id = id_map[user_id]
            print id "," telegram_id "," title "," status "," created_at "," updated_at "," closed_at
        }
    }
    ' "$tickets_raw" >> "$tickets_file"
    
    local tickets_count=0
    [[ -s "$tickets_file" ]] && tickets_count=$(($(wc -l < "$tickets_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ²: $tickets_count"
    
    # --- Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ ticket_messages ---
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ²..."
    local messages_raw="$export_dir/ticket_messages_raw.csv"
    local messages_file="$export_dir/ticket_messages.csv"
    
    parse_json_table "$db_json" "ticket_messages" "id,ticket_id,user_id,message_text,is_from_admin,created_at" > "$messages_raw"
    
    echo "id,ticket_id,sender_type,sender_id,message,created_at" > "$messages_file"
    
    awk -F',' -v mapfile="$id_map_file" '
    BEGIN {
        while ((getline line < mapfile) > 0) {
            split(line, parts, "=")
            id_map[parts[1]] = parts[2]
        }
    }
    NR > 1 {
        id = $1
        ticket_id = $2
        user_id = $3
        message = $4
        is_admin = $5
        created_at = $6
        
        sender_type = (is_admin == "t" || is_admin == "true" || is_admin == "True") ? "admin" : "customer"
        
        if (user_id in id_map) {
            telegram_id = id_map[user_id]
            # P0: CSV Formula Injection protection - prefix with apostrophe if starts with =, +, -, @
            if (message ~ /^[=+\-@]/) {
                message = "'\''" message
            }
            # CSV-ÑĞºÑ€Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: ÑƒĞ´Ğ²Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼ ĞºĞ°Ğ²Ñ‹Ñ‡ĞºĞ¸ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸, Ğ¾Ğ±Ğ¾Ñ€Ğ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ² ĞºĞ°Ğ²Ñ‹Ñ‡ĞºĞ¸ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ·Ğ°Ğ¿ÑÑ‚Ñ‹Ğµ/ĞºĞ°Ğ²Ñ‹Ñ‡ĞºĞ¸/Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑÑ‹
            gsub(/"/, "\"\"", message)
            if (message ~ /[,"\n\r]/) {
                message = "\"" message "\""
            }
            print id "," ticket_id "," sender_type "," telegram_id "," message "," created_at
        }
    }
    ' "$messages_raw" >> "$messages_file"
    
    local messages_count=0
    [[ -s "$messages_file" ]] && messages_count=$(($(wc -l < "$messages_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ²: $messages_count"
    
    # --- Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ broadcast_history ---
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ñ€Ğ°ÑÑÑ‹Ğ»Ğ¾Ğº..."
    local broadcast_file="$export_dir/broadcast.csv"
    
    parse_json_table "$db_json" "broadcast_history" "id,message_text,target_type,created_at,status,total_count,sent_count,failed_count" > "$export_dir/broadcast_raw.csv"
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº Ñ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸
    echo "id,content,type,language,created_at,status,total_count,sent_count,failed_count" > "$broadcast_file"
    
    awk -F',' 'NR > 1 {
        id = $1
        content = $2
        type = $3
        created_at = $4
        status = $5
        total = $6
        sent = $7
        failed = $8
        
        # P0: CSV Formula Injection protection
        if (content ~ /^[=+\-@]/) {
            content = "'\''" content
        }
        # CSV-ÑĞºÑ€Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: ÑƒĞ´Ğ²Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼ ĞºĞ°Ğ²Ñ‹Ñ‡ĞºĞ¸ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸, Ğ¾Ğ±Ğ¾Ñ€Ğ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ ÑĞ¿ĞµÑ†ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹
        gsub(/"/, "\"\"", content)
        if (content ~ /[,"\n\r]/) {
            content = "\"" content "\""
        }
        print id "," content "," type ",," created_at "," status "," total "," sent "," failed
    }' "$export_dir/broadcast_raw.csv" >> "$broadcast_file"
    
    local broadcast_count=0
    [[ -s "$broadcast_file" ]] && broadcast_count=$(($(wc -l < "$broadcast_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ñ€Ğ°ÑÑÑ‹Ğ»Ğ¾Ğº: $broadcast_count"
    
    # --- Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ user_activity ---
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹..."
    local activity_file="$export_dir/user_activity.csv"
    
    echo "telegram_id,last_activity" > "$activity_file"
    
    # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¸Ğ· users_raw_file Ñ‚.Ğº. Ñ‚Ğ°Ğ¼ ĞµÑÑ‚ÑŒ last_activity (Ğ¿Ğ¾Ğ»Ğµ $10)
    # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ users_raw: id,telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status,last_activity,referred_by_id
    awk -F',' 'NR > 1 {
        telegram_id = $2
        last_activity = $10
        
        if (telegram_id != "" && last_activity != "") {
            print telegram_id "," last_activity
        }
    }' "$users_raw_file" >> "$activity_file"
    
    local activity_count=0
    [[ -s "$activity_file" ]] && activity_count=$(($(wc -l < "$activity_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸: $activity_count"
    
    # --- Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ referral_earnings ---
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ½ÑƒÑĞ¾Ğ²..."
    local ref_bonus_raw="$export_dir/referral_earnings_raw.csv"
    local ref_bonus_file="$export_dir/referral_bonus.csv"
    
    parse_json_table "$db_json" "referral_earnings" "id,user_id,referral_id,reason,amount_kopeks,created_at" > "$ref_bonus_raw"
    
    echo "id,referrer_telegram_id,referee_telegram_id,reason,amount_kopeks,created_at" > "$ref_bonus_file"
    
    awk -F',' -v mapfile="$id_map_file" '
    BEGIN {
        while ((getline line < mapfile) > 0) {
            split(line, parts, "=")
            id_map[parts[1]] = parts[2]
        }
    }
    NR > 1 {
        id = $1
        user_id = $2      # referrer (ĞºÑ‚Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ» Ğ±Ğ¾Ğ½ÑƒÑ)
        referral_id = $3  # referee (Ğ·Ğ° ĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½ Ğ±Ğ¾Ğ½ÑƒÑ)
        reason = $4
        amount = $5
        created_at = $6
        
        if (user_id in id_map && referral_id in id_map) {
            referrer_tg = id_map[user_id]
            referee_tg = id_map[referral_id]
            print id "," referrer_tg "," referee_tg "," reason "," amount "," created_at
        }
    }
    ' "$ref_bonus_raw" >> "$ref_bonus_file"
    
    local ref_bonus_count=0
    [[ -s "$ref_bonus_file" ]] && ref_bonus_count=$(($(wc -l < "$ref_bonus_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ½ÑƒÑĞ¾Ğ²: $ref_bonus_count"
    
    # P2: Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ñ… CSV Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
    local validation_errors=0
    for csv in "$users_file" "$transactions_file" "$promocodes_file"; do
        if [[ -f "$csv" ]] && ! validate_csv "$csv" "$(basename "$csv")"; then
            ((validation_errors++))
        fi
    done
    
    if [[ $validation_errors -gt 0 ]]; then
        print_message "WARN" "ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ² $validation_errors CSV Ñ„Ğ°Ğ¹Ğ»Ğ°Ñ… (ÑĞ¼. debug log)"
    fi
    
    # ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
    rm -f "$export_dir"/*_raw.csv "$export_dir"/.*.map "$export_dir"/promocodes_with_id.csv 2>/dev/null
    
    debug_log "MIGRATE" "JSON export complete: users=$user_count, referrals=$referral_count, subs=$subs_count, tx=$tx_count, promo=$promo_count, tickets=$tickets_count, messages=$messages_count, broadcast=$broadcast_count"
    
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ¸Ğ· JSON Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½!"
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ° ---
migrate_export_data() {
    debug_log "MIGRATE" "Starting data export"
    
    # Ğ•ÑĞ»Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº - Ğ°Ñ€Ñ…Ğ¸Ğ² JSON, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ JSON-Ğ¿Ğ°Ñ€ÑĞµÑ€
    if [[ "$MIGRATION_SOURCE_TYPE" == "archive" ]]; then
        debug_log "MIGRATE" "Source type is archive, using JSON export"
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ğ°Ñ€Ñ…Ğ¸Ğ² Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½
        if [[ -z "$MIGRATION_SOURCE_BACKUP" || ! -f "$MIGRATION_SOURCE_BACKUP" ]]; then
            print_message "ERROR" "ĞÑ€Ñ…Ğ¸Ğ² Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½ Ğ¸Ğ»Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½"
            return 1
        fi
        
        # Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ°Ñ€Ñ…Ğ¸Ğ² ĞµÑĞ»Ğ¸ ĞµÑ‰Ñ‘ Ğ½Ğµ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½
        if [[ -z "$MIGRATION_EXTRACTED_DIR" || ! -d "$MIGRATION_EXTRACTED_DIR" || ! -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
            debug_log "MIGRATE" "Extracting archive before export..."
            if ! extract_bedolaga_backup "$MIGRATION_SOURCE_BACKUP"; then
                print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ²"
                return 1
            fi
        fi
        
        migrate_export_from_json
        return $?
    fi
    
    print_message "INFO" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Bedolaga (PostgreSQL)..."
    
    local export_dir="$MIGRATION_WORK_DIR/export"
    mkdir -p "$export_dir"
    
    local export_sql="
-- Export users
COPY (
    SELECT 
        telegram_id,
        tg_username,
        tg_first_name,
        language,
        created_at,
        balance,
        referral_balance,
        referrer_id
    FROM users
    ORDER BY telegram_id
) TO STDOUT WITH CSV HEADER;
"
    
    local users_file="$export_dir/users.csv"
    local referrals_file="$export_dir/referrals.csv"
    local transactions_file="$export_dir/transactions.csv"
    local promocodes_file="$export_dir/promocodes.csv"
    local promo_uses_file="$export_dir/promocode_uses.csv"
    
    # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ users (Ğ±ĞµĞ· referrer_id - Ğ¾Ğ½ Ğ¸Ğ´Ñ‘Ñ‚ Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»)
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ¿Ğ¾Ğ»Ğµ status Ğ´Ğ»Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ is_blocked
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (SELECT telegram_id, username, first_name, language, created_at, balance_kopeks, 0 as referral_balance, COALESCE(status, 'active') as status FROM users ORDER BY telegram_id) TO STDOUT WITH CSV HEADER;
        " > "$users_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (SELECT telegram_id, username, first_name, language, created_at, balance_kopeks, 0 as referral_balance, COALESCE(status, 'active') as status FROM users ORDER BY telegram_id) TO STDOUT WITH CSV HEADER;
        " > "$users_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    if [[ ! -s "$users_file" ]]; then
        print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹"
        return 1
    fi
    
    local user_count=$(wc -l < "$users_file")
    user_count=$((user_count - 1))  # ĞœĞ¸Ğ½ÑƒÑ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹: $user_count"
    
    # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ²ÑĞ·ĞµĞ¹ (referee_telegram_id, referrer_telegram_id, created_at)
    # JOIN Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ referred_by_id (internal id) â†’ telegram_id
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    u.telegram_id as referee_telegram_id,
                    r.telegram_id as referrer_telegram_id,
                    u.created_at
                FROM users u
                INNER JOIN users r ON u.referred_by_id = r.id
                WHERE u.referred_by_id IS NOT NULL
                ORDER BY u.created_at
            ) TO STDOUT WITH CSV HEADER;
        " > "$referrals_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    u.telegram_id as referee_telegram_id,
                    r.telegram_id as referrer_telegram_id,
                    u.created_at
                FROM users u
                INNER JOIN users r ON u.referred_by_id = r.id
                WHERE u.referred_by_id IS NOT NULL
                ORDER BY u.created_at
            ) TO STDOUT WITH CSV HEADER;
        " > "$referrals_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local referral_count=0
    [[ -s "$referrals_file" ]] && referral_count=$(($(wc -l < "$referrals_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ²ÑĞ·ĞµĞ¹: $referral_count"
    
    # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ transactions
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (SELECT id, user_id, amount, payment_method, status, created_at, subscription_days FROM transactions WHERE status='completed' ORDER BY id) TO STDOUT WITH CSV HEADER;
        " > "$transactions_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (SELECT id, user_id, amount, payment_method, status, created_at, subscription_days FROM transactions WHERE status='completed' ORDER BY id) TO STDOUT WITH CSV HEADER;
        " > "$transactions_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local tx_count=0
    [[ -s "$transactions_file" ]] && tx_count=$(($(wc -l < "$transactions_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¹: $tx_count"
    
    # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ promocodes
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (SELECT code, bonus_days, max_uses, current_uses, is_active, created_at FROM promocodes ORDER BY code) TO STDOUT WITH CSV HEADER;
        " > "$promocodes_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (SELECT code, bonus_days, max_uses, current_uses, is_active, created_at FROM promocodes ORDER BY code) TO STDOUT WITH CSV HEADER;
        " > "$promocodes_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local promo_count=0
    [[ -s "$promocodes_file" ]] && promo_count=$(($(wc -l < "$promocodes_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ²: $promo_count"
    
    # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ promocode_uses (Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ²)
    # JOIN Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ user_id Ğ¸ promocode_id Ğ²Ğ¾ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğµ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ñ‹
    local promo_uses_file="$export_dir/promocode_uses.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    u.telegram_id as customer_telegram_id,
                    p.code as promo_code,
                    pu.used_at
                FROM promocode_uses pu
                INNER JOIN users u ON pu.user_id = u.id
                INNER JOIN promocodes p ON pu.promocode_id = p.id
                ORDER BY pu.used_at
            ) TO STDOUT WITH CSV HEADER;
        " > "$promo_uses_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    u.telegram_id as customer_telegram_id,
                    p.code as promo_code,
                    pu.used_at
                FROM promocode_uses pu
                INNER JOIN users u ON pu.user_id = u.id
                INNER JOIN promocodes p ON pu.promocode_id = p.id
                ORDER BY pu.used_at
            ) TO STDOUT WITH CSV HEADER;
        " > "$promo_uses_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local promo_uses_count=0
    [[ -s "$promo_uses_file" ]] && promo_uses_count=$(($(wc -l < "$promo_uses_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ²: $promo_uses_count"
    
    # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¾Ğº (subscription_url, end_date, is_trial, device_limit, autopay_enabled)
    # JOIN Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ user_id â†’ telegram_id
    local subscriptions_file="$export_dir/subscriptions.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    u.telegram_id,
                    s.end_date as expire_at,
                    s.subscription_url as subscription_link,
                    s.is_trial,
                    s.device_limit,
                    s.autopay_enabled,
                    s.autopay_days_before,
                    s.status
                FROM subscriptions s
                INNER JOIN users u ON s.user_id = u.id
                WHERE s.status = 'active' AND s.end_date > NOW()
                ORDER BY u.telegram_id
            ) TO STDOUT WITH CSV HEADER;
        " > "$subscriptions_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    u.telegram_id,
                    s.end_date as expire_at,
                    s.subscription_url as subscription_link,
                    s.is_trial,
                    s.device_limit,
                    s.autopay_enabled,
                    s.autopay_days_before,
                    s.status
                FROM subscriptions s
                INNER JOIN users u ON s.user_id = u.id
                WHERE s.status = 'active' AND s.end_date > NOW()
                ORDER BY u.telegram_id
            ) TO STDOUT WITH CSV HEADER;
        " > "$subscriptions_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local subs_count=0
    [[ -s "$subscriptions_file" ]] && subs_count=$(($(wc -l < "$subscriptions_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¾Ğº: $subs_count"
    
    # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ² Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸ (tickets â†’ support_ticket)
    local tickets_file="$export_dir/tickets.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    t.id,
                    u.telegram_id as customer_telegram_id,
                    t.title as subject,
                    t.status,
                    t.created_at,
                    t.updated_at,
                    t.closed_at
                FROM tickets t
                INNER JOIN users u ON t.user_id = u.id
                ORDER BY t.id
            ) TO STDOUT WITH CSV HEADER;
        " > "$tickets_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    t.id,
                    u.telegram_id as customer_telegram_id,
                    t.title as subject,
                    t.status,
                    t.created_at,
                    t.updated_at,
                    t.closed_at
                FROM tickets t
                INNER JOIN users u ON t.user_id = u.id
                ORDER BY t.id
            ) TO STDOUT WITH CSV HEADER;
        " > "$tickets_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local tickets_count=0
    [[ -s "$tickets_file" ]] && tickets_count=$(($(wc -l < "$tickets_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ²: $tickets_count"
    
    # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ² (ticket_messages â†’ support_message)
    local ticket_messages_file="$export_dir/ticket_messages.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    tm.id,
                    tm.ticket_id,
                    CASE WHEN tm.is_from_admin THEN 'admin' ELSE 'customer' END as sender_type,
                    u.telegram_id as sender_id,
                    tm.message_text as message,
                    tm.created_at
                FROM ticket_messages tm
                INNER JOIN users u ON tm.user_id = u.id
                ORDER BY tm.id
            ) TO STDOUT WITH CSV HEADER;
        " > "$ticket_messages_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    tm.id,
                    tm.ticket_id,
                    CASE WHEN tm.is_from_admin THEN 'admin' ELSE 'customer' END as sender_type,
                    u.telegram_id as sender_id,
                    tm.message_text as message,
                    tm.created_at
                FROM ticket_messages tm
                INNER JOIN users u ON tm.user_id = u.id
                ORDER BY tm.id
            ) TO STDOUT WITH CSV HEADER;
        " > "$ticket_messages_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local messages_count=0
    [[ -s "$ticket_messages_file" ]] && messages_count=$(($(wc -l < "$ticket_messages_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ²: $messages_count"
    
    # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ñ€Ğ°ÑÑÑ‹Ğ»Ğ¾Ğº (broadcast_history â†’ broadcast)
    local broadcast_file="$export_dir/broadcast.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    id,
                    message_text as content,
                    target_type as type,
                    NULL as language,
                    created_at,
                    status,
                    total_count,
                    sent_count,
                    failed_count
                FROM broadcast_history
                ORDER BY id
            ) TO STDOUT WITH CSV HEADER;
        " > "$broadcast_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    id,
                    message_text as content,
                    target_type as type,
                    NULL as language,
                    created_at,
                    status,
                    total_count,
                    sent_count,
                    failed_count
                FROM broadcast_history
                ORDER BY id
            ) TO STDOUT WITH CSV HEADER;
        " > "$broadcast_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local broadcast_count=0
    [[ -s "$broadcast_file" ]] && broadcast_count=$(($(wc -l < "$broadcast_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ñ€Ğ°ÑÑÑ‹Ğ»Ğ¾Ğº: $broadcast_count"
    
    # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ last_activity Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ customer
    local activity_file="$export_dir/user_activity.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT telegram_id, last_activity
                FROM users
                WHERE last_activity IS NOT NULL
                ORDER BY telegram_id
            ) TO STDOUT WITH CSV HEADER;
        " > "$activity_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT telegram_id, last_activity
                FROM users
                WHERE last_activity IS NOT NULL
                ORDER BY telegram_id
            ) TO STDOUT WITH CSV HEADER;
        " > "$activity_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local activity_count=0
    [[ -s "$activity_file" ]] && activity_count=$(($(wc -l < "$activity_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸: $activity_count"
    
    # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ½ÑƒÑĞ¾Ğ² (referral_earnings â†’ referral_bonus_history)
    # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ñ Ğ±Ğ¾Ğ½ÑƒÑĞ°Ğ¼Ğ¸ Ğ² Ğ´Ğ½ÑÑ… (reason ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ 'registration')
    local ref_bonus_file="$export_dir/referral_bonus.csv"
    if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        docker exec "$MIGRATION_SOURCE_CONTAINER" psql -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    re.id,
                    referrer.telegram_id as referrer_telegram_id,
                    referee.telegram_id as referee_telegram_id,
                    re.reason,
                    re.amount_kopeks,
                    re.created_at
                FROM referral_earnings re
                INNER JOIN users referrer ON re.user_id = referrer.id
                INNER JOIN users referee ON re.referral_id = referee.id
                ORDER BY re.id
            ) TO STDOUT WITH CSV HEADER;
        " > "$ref_bonus_file" 2>/dev/null
    else
        export PGPASSWORD="$MIGRATION_SOURCE_PASS"
        psql -h "$MIGRATION_SOURCE_HOST" -p "$MIGRATION_SOURCE_PORT" -U "$MIGRATION_SOURCE_USER" -d "$MIGRATION_SOURCE_DB" -c "
            COPY (
                SELECT 
                    re.id,
                    referrer.telegram_id as referrer_telegram_id,
                    referee.telegram_id as referee_telegram_id,
                    re.reason,
                    re.amount_kopeks,
                    re.created_at
                FROM referral_earnings re
                INNER JOIN users referrer ON re.user_id = referrer.id
                INNER JOIN users referee ON re.referral_id = referee.id
                ORDER BY re.id
            ) TO STDOUT WITH CSV HEADER;
        " > "$ref_bonus_file" 2>/dev/null
        unset PGPASSWORD
    fi
    
    local ref_bonus_count=0
    [[ -s "$ref_bonus_file" ]] && ref_bonus_count=$(($(wc -l < "$ref_bonus_file") - 1))
    print_message "SUCCESS" "Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ½ÑƒÑĞ¾Ğ²: $ref_bonus_count"
    
    debug_log "MIGRATE" "Export complete: users=$user_count, referrals=$referral_count, tx=$tx_count, promo=$promo_count, promo_uses=$promo_uses_count, subs=$subs_count, tickets=$tickets_count, messages=$messages_count, broadcast=$broadcast_count, ref_bonus=$ref_bonus_count"
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ---
# âš ï¸ Ğ˜Ğ—Ğ’Ğ•Ğ¡Ğ¢ĞĞĞ• ĞĞ“Ğ ĞĞĞ˜Ğ§Ğ•ĞĞ˜Ğ•: Ğ•ÑĞ»Ğ¸ username/first_name ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ Ğ·Ğ°Ğ¿ÑÑ‚Ñ‹Ğµ,
#    Ğ¾Ğ½Ğ¸ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ½ĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ Ñ€Ğ°Ğ·Ğ±Ğ¸Ñ‚Ñ‹ IFS. Ğ”Ğ»Ñ production-Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ñ‚Ğ°ĞºĞ¸Ğ¼Ğ¸
#    ÑĞ»ÑƒÑ‡Ğ°ÑĞ¼Ğ¸ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Python CSV-Ğ¿Ğ°Ñ€ÑĞµÑ€.
migrate_transform_data() {
    debug_log "MIGRATE" "Starting data transformation"
    print_message "INFO" "Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Remnawave..."
    
    local export_dir="$MIGRATION_WORK_DIR/export"
    local import_dir="$MIGRATION_WORK_DIR/import"
    mkdir -p "$import_dir"
    
    # Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ users â†’ customer
    if [[ -f "$export_dir/users.csv" ]]; then
        print_message "INFO" "ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ users â†’ customer..."
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ñ„Ğ°Ğ¹Ğ» Ñ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ¼
        echo "id,telegram_id,username,first_name,last_name,language,balance,referral_balance,lead_score,is_blocked,created_at,updated_at" > "$import_dir/customer.csv"
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ CSV: telegram_id,username,first_name,language,created_at,balance_kopeks,referral_balance,status
        while IFS=',' read -r telegram_id username first_name language created_at balance_kopeks referral_balance status; do
            [[ -z "$telegram_id" || "$telegram_id" == "telegram_id" ]] && continue
            
            # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ balance Ğ¸Ğ· ĞºĞ¾Ğ¿ĞµĞµĞº Ğ² Ñ€ÑƒĞ±Ğ»Ğ¸
            local balance_rub=0
            if [[ -n "$balance_kopeks" && "$balance_kopeks" != "0" ]]; then
                balance_rub=$(awk "BEGIN {printf \"%.2f\", $balance_kopeks/100}")
            fi
            
            local referral_rub=0
            if [[ -n "$referral_balance" && "$referral_balance" != "0" ]]; then
                referral_rub=$(awk "BEGIN {printf \"%.2f\", $referral_balance/100}")
            fi
            
            # Ğ¯Ğ·Ñ‹Ğº: ru/en (Bedolaga) â†’ ru/en (Remnawave)
            local lang="${language:-ru}"
            [[ "$lang" != "ru" && "$lang" != "en" ]] && lang="ru"
            
            # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ status â†’ is_blocked (status='blocked' â†’ true)
            local is_blocked="false"
            [[ "$status" == "blocked" ]] && is_blocked="true"
            
            # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ UUID
            local uuid=$(cat /proc/sys/kernel/random/uuid 2>/dev/null || uuidgen 2>/dev/null || echo "$(date +%s)-$telegram_id")
            
            echo "$uuid,$telegram_id,$username,$first_name,,$lang,$balance_rub,$referral_rub,0,$is_blocked,$created_at,$created_at"
        done < "$export_dir/users.csv" >> "$import_dir/customer.csv"
        
        print_message "SUCCESS" "customer.csv ÑĞ¾Ğ·Ğ´Ğ°Ğ½"
    fi
    
    # Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ transactions â†’ purchase
    if [[ -f "$export_dir/transactions.csv" ]]; then
        print_message "INFO" "ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ transactions â†’ purchase..."
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ñ„Ğ°Ğ¹Ğ» Ñ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ¼
        echo "id,customer_telegram_id,amount,invoice_type,status,subscription_days,created_at,updated_at" > "$import_dir/purchase.csv"
        
        while IFS=',' read -r id user_id amount payment_method status created_at subscription_days; do
            [[ -z "$id" || "$id" == "id" ]] && continue
            
            # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ amount Ğ¸Ğ· ĞºĞ¾Ğ¿ĞµĞµĞº Ğ² Ñ€ÑƒĞ±Ğ»Ğ¸
            local amount_rub=0
            if [[ -n "$amount" && "$amount" != "0" ]]; then
                amount_rub=$(awk "BEGIN {printf \"%.2f\", $amount/100}")
            fi
            
            # ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ payment_method â†’ invoice_type (Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ case Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ°ÑÑĞ¾Ñ†Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ°ÑÑĞ¸Ğ²Ğ°)
            local invoice_type="admin"
            case "$payment_method" in
                yookassa) invoice_type="yookassa" ;;
                tribute) invoice_type="tribute" ;;
                wata) invoice_type="wata" ;;
                telegram_stars) invoice_type="telegram" ;;
                cryptobot) invoice_type="crypto" ;;
                platega) invoice_type="platega_cards" ;;
                manual|heleket|mulenpay|pal24|cloudpayments) invoice_type="unknown" ;;
                *) invoice_type="admin" ;;
            esac
            
            # UUID
            local uuid=$(cat /proc/sys/kernel/random/uuid 2>/dev/null || uuidgen 2>/dev/null || echo "$(date +%s)-$id")
            
            echo "$uuid,$user_id,$amount_rub,$invoice_type,completed,$subscription_days,$created_at,$created_at"
        done < "$export_dir/transactions.csv" >> "$import_dir/purchase.csv"
        
        print_message "SUCCESS" "purchase.csv ÑĞ¾Ğ·Ğ´Ğ°Ğ½"
    fi
    
    # Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ promocodes â†’ promo
    if [[ -f "$export_dir/promocodes.csv" ]]; then
        print_message "INFO" "ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ promocodes â†’ promo..."
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ñ„Ğ°Ğ¹Ğ» Ñ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ¼
        echo "id,code,promo_type,subscription_days,balance_bonus,max_uses,uses,active,created_at,updated_at" > "$import_dir/promo.csv"
        
        while IFS=',' read -r code bonus_days max_uses current_uses is_active created_at; do
            [[ -z "$code" || "$code" == "code" ]] && continue
            
            local uuid=$(cat /proc/sys/kernel/random/uuid 2>/dev/null || uuidgen 2>/dev/null || echo "$(date +%s)-$code")
            
            # promo_type: Ğ²ÑĞµĞ³Ğ´Ğ° subscription (Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ñ‹ Ğ½Ğ° Ğ±Ğ°Ğ»Ğ°Ğ½Ñ ÑƒĞ¶Ğµ Ğ¾Ñ‚Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ¿Ñ€Ğ¸ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğµ)
            local promo_type="subscription"
            
            # active: is_active (bool)
            local active="true"
            [[ "$is_active" == "false" || "$is_active" == "0" || "$is_active" == "f" ]] && active="false"
            
            # balance_bonus=0 (Ğ² RWP-Shop ÑÑ‚Ğ¾ Ğ¿Ğ¾Ğ»Ğµ Ğ´Ğ»Ñ discount type, Ğ½Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ)
            echo "$uuid,$code,$promo_type,${bonus_days:-0},0,$max_uses,${current_uses:-0},$active,$created_at,$created_at"
        done < "$export_dir/promocodes.csv" >> "$import_dir/promo.csv"
        
        print_message "SUCCESS" "promo.csv ÑĞ¾Ğ·Ğ´Ğ°Ğ½"
    fi
    
    # Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ subscriptions (Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼, Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ ÑƒĞ¶Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¹)
    if [[ -f "$export_dir/subscriptions.csv" ]]; then
        print_message "INFO" "ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° subscriptions..."
        # CSV ÑƒĞ¶Ğµ Ğ² Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ: telegram_id,expire_at,subscription_link,is_trial,device_limit,autopay_enabled,autopay_days_before,status
        # ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹
        cp "$export_dir/subscriptions.csv" "$import_dir/subscriptions.csv"
        print_message "SUCCESS" "subscriptions.csv ÑĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½"
    fi
    
    # ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ tickets (Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ ÑƒĞ¶Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¹)
    if [[ -f "$export_dir/tickets.csv" ]]; then
        print_message "INFO" "ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° tickets..."
        cp "$export_dir/tickets.csv" "$import_dir/tickets.csv"
        print_message "SUCCESS" "tickets.csv ÑĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½"
    fi
    
    # ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ticket_messages (Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ ÑƒĞ¶Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¹)
    if [[ -f "$export_dir/ticket_messages.csv" ]]; then
        print_message "INFO" "ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° ticket_messages..."
        cp "$export_dir/ticket_messages.csv" "$import_dir/ticket_messages.csv"
        print_message "SUCCESS" "ticket_messages.csv ÑĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½"
    fi
    
    # ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ broadcast (Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ ÑƒĞ¶Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¹)
    if [[ -f "$export_dir/broadcast.csv" ]]; then
        print_message "INFO" "ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° broadcast..."
        cp "$export_dir/broadcast.csv" "$import_dir/broadcast.csv"
        print_message "SUCCESS" "broadcast.csv ÑĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½"
    fi
    
    # ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ user_activity Ğ´Ğ»Ñ last_activity_at
    if [[ -f "$export_dir/user_activity.csv" ]]; then
        print_message "INFO" "ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° user_activity..."
        cp "$export_dir/user_activity.csv" "$import_dir/user_activity.csv"
        print_message "SUCCESS" "user_activity.csv ÑĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½"
    fi
    
    # ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ referral_bonus Ğ´Ğ»Ñ referral_bonus_history
    if [[ -f "$export_dir/referral_bonus.csv" ]]; then
        print_message "INFO" "ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° referral_bonus..."
        cp "$export_dir/referral_bonus.csv" "$import_dir/referral_bonus.csv"
        print_message "SUCCESS" "referral_bonus.csv ÑĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½"
    fi
    
    debug_log "MIGRATE" "Transformation complete"
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ğ‘Ğ”/Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ (Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ SQL injection) ---
validate_db_identifier() {
    local value="$1"
    local name="$2"
    
    # Ğ Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ñ‹ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ±ÑƒĞºĞ²Ñ‹, Ñ†Ğ¸Ñ„Ñ€Ñ‹, Ğ¿Ğ¾Ğ´Ñ‡Ñ‘Ñ€ĞºĞ¸Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ´ĞµÑ„Ğ¸ÑÑ‹
    if [[ ! "$value" =~ ^[a-zA-Z0-9_-]+$ ]]; then
        print_message "ERROR" "ĞĞµĞ´Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ğ¼Ñ‹Ğµ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ Ğ² $name: $value"
        return 1
    fi
    
    # ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ´Ğ»Ğ¸Ğ½Ğ° Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ° PostgreSQL - 63 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°
    if [[ ${#value} -gt 63 ]]; then
        print_message "ERROR" "$name ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ (Ğ¼Ğ°ĞºÑ 63 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°)"
        return 1
    fi
    
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² Remnawave ---
migrate_import_data() {
    debug_log "MIGRATE" "Starting data import to Remnawave"
    print_message "INFO" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² RWP-Shop..."
    
    local import_dir="$MIGRATION_WORK_DIR/import"
    
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        print_message "ERROR" "ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ” Remnawave Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½"
        return 1
    fi
    
    # P0: Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ‘Ğ” (Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ SQL injection)
    if ! validate_db_identifier "$MIGRATION_TARGET_USER" "DB User"; then
        return 1
    fi
    if ! validate_db_identifier "$MIGRATION_TARGET_DB" "DB Name"; then
        return 1
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‡Ñ‚Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½
    if ! docker ps --format '{{.Names}}' | grep -q "^${MIGRATION_TARGET_CONTAINER}$"; then
        print_message "ERROR" "ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ $MIGRATION_TARGET_CONTAINER Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½"
        return 1
    fi
    
    # Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ customer
    if [[ -f "$import_dir/customer.csv" ]]; then
        print_message "INFO" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ customer..."
        
        # ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ñ„Ğ°Ğ¹Ğ» Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€
        docker cp "$import_dir/customer.csv" "${MIGRATION_TARGET_CONTAINER}:/tmp/customer.csv"
        
        # P1: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ‡ĞµÑ€ĞµĞ· Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ°Ñ‚Ğ¾Ğ¼Ğ°Ñ€Ğ½Ğ¾ÑÑ‚Ğ¸
        docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
            BEGIN;
            CREATE TEMP TABLE tmp_customer (
                id UUID,
                telegram_id BIGINT,
                tg_username TEXT,
                tg_first_name TEXT,
                tg_last_name TEXT,
                language VARCHAR(10),
                balance NUMERIC,
                referral_balance NUMERIC,
                lead_score INTEGER,
                is_blocked BOOLEAN,
                created_at TIMESTAMP,
                updated_at TIMESTAMP
            );
            COPY tmp_customer FROM '/tmp/customer.csv' WITH CSV HEADER;
            INSERT INTO customer (telegram_id, tg_username, tg_first_name, tg_last_name, language, is_blocked, created_at)
            SELECT telegram_id, tg_username, tg_first_name, tg_last_name, language, COALESCE(is_blocked, false), created_at
            FROM tmp_customer
            ON CONFLICT (telegram_id) DO UPDATE SET
                tg_username = EXCLUDED.tg_username,
                tg_first_name = EXCLUDED.tg_first_name,
                is_blocked = EXCLUDED.is_blocked,
                updated_at = NOW();
            DROP TABLE tmp_customer;
            COMMIT;
EOF
        
        local result=$?
        docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/customer.csv
        
        if [[ $result -ne 0 ]]; then
            print_message "WARN" "Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ customer (Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹)"
        else
            local blocked_count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM customer WHERE is_blocked = true;" 2>/dev/null | tr -d ' ')
            print_message "SUCCESS" "customer Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ (Ğ·Ğ°Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ…: ${blocked_count:-0})"
        fi
    fi
    
    # Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ purchase
    if [[ -f "$import_dir/purchase.csv" ]]; then
        print_message "INFO" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ purchase..."
        
        docker cp "$import_dir/purchase.csv" "${MIGRATION_TARGET_CONTAINER}:/tmp/purchase.csv"
        
        # P1: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ°Ñ‚Ğ¾Ğ¼Ğ°Ñ€Ğ½Ğ¾ÑÑ‚Ğ¸
        docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" << 'EOF'
            BEGIN;
            CREATE TEMP TABLE tmp_purchase (
                id BIGINT,
                customer_telegram_id BIGINT,
                amount NUMERIC,
                invoice_type VARCHAR(50),
                status VARCHAR(20),
                subscription_days INTEGER,
                created_at TIMESTAMP,
                updated_at TIMESTAMP
            );
            COPY tmp_purchase FROM '/tmp/purchase.csv' WITH CSV HEADER;
            INSERT INTO purchase (id, customer_telegram_id, amount, invoice_type, status, subscription_days, created_at, updated_at)
            SELECT id, customer_telegram_id, amount, invoice_type, status, subscription_days, created_at, updated_at
            FROM tmp_purchase
            ON CONFLICT (id) DO NOTHING;
            DROP TABLE tmp_purchase;
            COMMIT;
EOF
        
        docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/purchase.csv
        print_message "SUCCESS" "purchase Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½"
    fi
    
    # Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ promo
    if [[ -f "$import_dir/promo.csv" ]]; then
        print_message "INFO" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ promo..."
        
        docker cp "$import_dir/promo.csv" "${MIGRATION_TARGET_CONTAINER}:/tmp/promo.csv"
        
        # P1: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ°Ñ‚Ğ¾Ğ¼Ğ°Ñ€Ğ½Ğ¾ÑÑ‚Ğ¸
        docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -c "
            BEGIN;
            CREATE TEMP TABLE tmp_promo (LIKE promo INCLUDING ALL);
            COPY tmp_promo FROM '/tmp/promo.csv' WITH CSV HEADER;
            INSERT INTO promo SELECT * FROM tmp_promo
            ON CONFLICT (code) DO UPDATE SET
                uses = promo.uses + EXCLUDED.uses,
                active = EXCLUDED.active,
                updated_at = NOW();
            DROP TABLE tmp_promo;
            COMMIT;
        " 2>&1
        
        docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/promo.csv
        print_message "SUCCESS" "promo Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½"
    fi
    
    # Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ²ÑĞ·ĞµĞ¹
    # Ğ’ĞĞ–ĞĞ: Ğ’ RWP-Shop referral.referrer_id Ğ¸ referee_id ÑÑÑ‹Ğ»Ğ°ÑÑ‚ÑÑ Ğ½Ğ° customer(telegram_id)!
    local export_dir="$MIGRATION_WORK_DIR/export"
    if [[ -f "$export_dir/referrals.csv" ]]; then
        local ref_count=$(($(wc -l < "$export_dir/referrals.csv") - 1))
        if [[ $ref_count -gt 0 ]]; then
            print_message "INFO" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ²ÑĞ·ĞµĞ¹ ($ref_count)..."
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ CSV Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ referral
            # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: referrer_id (telegram_id), referee_id (telegram_id), used_at, bonus_granted
            local referral_import="$MIGRATION_WORK_DIR/import/referral.csv"
            
            {
                echo "referrer_id,referee_id,used_at,bonus_granted"
                tail -n +2 "$export_dir/referrals.csv" | while IFS=',' read -r referee_tg referrer_tg created_at; do
                    # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: referrer_telegram_id, referee_telegram_id, created_at, true (Ğ±Ğ¾Ğ½ÑƒÑ ÑƒĞ¶Ğµ Ğ²Ñ‹Ğ´Ğ°Ğ½)
                    echo "$referrer_tg,$referee_tg,$created_at,true"
                done
            } > "$referral_import"
            
            # ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ CSV Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€
            docker cp "$referral_import" "${MIGRATION_TARGET_CONTAINER}:/tmp/referral.csv"
            
            # P1: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ‡ĞµÑ€ĞµĞ· Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ñ
            docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -c "
                BEGIN;
                CREATE TEMP TABLE tmp_referral (
                    referrer_id bigint,
                    referee_id bigint,
                    used_at timestamptz,
                    bonus_granted boolean
                );
                COPY tmp_referral FROM '/tmp/referral.csv' WITH CSV HEADER;
                INSERT INTO referral (referrer_id, referee_id, used_at, bonus_granted)
                SELECT referrer_id, referee_id, used_at, bonus_granted FROM tmp_referral
                ON CONFLICT DO NOTHING;
                DROP TABLE tmp_referral;
                COMMIT;
            " 2>&1
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/referral.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM referral;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "Ğ ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ²ÑĞ·Ğ¸ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ (Ğ² Ğ‘Ğ”: $imported_count)"
            else
                print_message "WARN" "Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ²ÑĞ·ĞµĞ¹"
            fi
        else
            print_message "INFO" "ĞĞµÑ‚ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ²ÑĞ·ĞµĞ¹ Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°"
        fi
    fi
    
    # Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ promo_usage (Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ²)
    # Ğ’ĞĞ–ĞĞ: promo_usage.customer_id Ğ¸ promo_id ÑÑÑ‹Ğ»Ğ°ÑÑ‚ÑÑ Ğ½Ğ° Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğµ ID!
    if [[ -f "$export_dir/promocode_uses.csv" ]]; then
        local uses_count=$(($(wc -l < "$export_dir/promocode_uses.csv") - 1))
        if [[ $uses_count -gt 0 ]]; then
            print_message "INFO" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ² ($uses_count)..."
            
            # ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ CSV Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€
            docker cp "$export_dir/promocode_uses.csv" "${MIGRATION_TARGET_CONTAINER}:/tmp/promo_uses.csv"
            
            # P1: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ‡ĞµÑ€ĞµĞ· Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ñ Ñ JOIN Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ñ… ID
            # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ CSV: customer_telegram_id, promo_code, used_at
            docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -c "
                BEGIN;
                CREATE TEMP TABLE tmp_promo_uses (
                    customer_telegram_id bigint,
                    promo_code text,
                    used_at timestamptz
                );
                COPY tmp_promo_uses FROM '/tmp/promo_uses.csv' WITH CSV HEADER;
                
                -- Ğ’ÑÑ‚Ğ°Ğ²ĞºĞ° Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ¼ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ñ… ID Ñ‡ĞµÑ€ĞµĞ· JOIN
                INSERT INTO promo_usage (promo_id, customer_id, used_at)
                SELECT 
                    pr.id as promo_id,
                    c.id as customer_id,
                    tmp.used_at
                FROM tmp_promo_uses tmp
                INNER JOIN customer c ON c.telegram_id = tmp.customer_telegram_id
                INNER JOIN promo pr ON pr.code = tmp.promo_code
                ON CONFLICT DO NOTHING;
                
                DROP TABLE tmp_promo_uses;
                COMMIT;
            " 2>&1
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/promo_uses.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM promo_usage;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ² Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° (Ğ² Ğ‘Ğ”: $imported_count)"
            else
                print_message "WARN" "Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ² (Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ customer Ğ¸Ğ»Ğ¸ promo)"
            fi
        else
            print_message "INFO" "ĞĞµÑ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°"
        fi
    fi
    
    # === 6. Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¾Ğº (UPDATE customer Ñ expire_at, subscription_link) ===
    local subs_file="$import_dir/subscriptions.csv"
    if [[ -f "$subs_file" ]]; then
        local subs_count=$(($(wc -l < "$subs_file") - 1))
        if [[ $subs_count -gt 0 ]]; then
            print_message "ACTION" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¾Ğº (expire_at, subscription_link)..."
            debug_log "MIGRATE" "Importing subscriptions: $subs_count records"
            
            # ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ CSV Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€
            docker cp "$subs_file" "$MIGRATION_TARGET_CONTAINER:/tmp/subscriptions.csv"
            
            # P1: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ‡ĞµÑ€ĞµĞ· Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ñ
            # is_trial Ğ² Bedolaga â†’ trial_used Ğ² RWP-Shop (Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ, Ğ½Ğ¾ Ñ€Ğ°Ğ·Ğ½Ğ°Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸ĞºĞ°!)
            # Ğ’ Bedolaga: is_trial=true Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ Ğ¡Ğ•Ğ™Ğ§ĞĞ¡ Ğ½Ğ° Ñ‚Ñ€Ğ¸Ğ°Ğ»Ğµ
            # Ğ’ RWP-Shop: trial_used=true Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ Ñ‚Ñ€Ğ¸Ğ°Ğ» Ğ£Ğ–Ğ• Ğ±Ñ‹Ğ» Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½
            # ĞŸĞ¾ÑÑ‚Ğ¾Ğ¼Ñƒ ĞµÑĞ»Ğ¸ is_trial=true, Ñ‚Ğ¾ trial_used Ñ‚Ğ¾Ğ¶Ğµ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ true
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
                BEGIN;
                CREATE TEMP TABLE tmp_subscriptions (
                    telegram_id BIGINT,
                    expire_at TIMESTAMP,
                    subscription_link TEXT,
                    is_trial BOOLEAN,
                    device_limit INTEGER,
                    autopay_enabled BOOLEAN,
                    autopay_days_before INTEGER,
                    status TEXT
                );
                
                COPY tmp_subscriptions FROM '/tmp/subscriptions.csv' WITH CSV HEADER;
                
                -- ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… customer Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ¸
                UPDATE customer SET
                    expire_at = tmp.expire_at,
                    subscription_link = tmp.subscription_link,
                    trial_used = COALESCE(tmp.is_trial, false),
                    autopay_enabled = COALESCE(tmp.autopay_enabled, false)
                FROM tmp_subscriptions tmp
                WHERE customer.telegram_id = tmp.telegram_id;
                
                DROP TABLE tmp_subscriptions;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/subscriptions.csv
            
            if [[ $result -eq 0 ]]; then
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ customer Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ¸ subscription_link
                local updated_count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM customer WHERE subscription_link IS NOT NULL AND subscription_link != '';" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¾Ğº Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ (Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾ customer: $updated_count)"
            else
                print_message "WARN" "Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¾Ğº"
            fi
        else
            print_message "INFO" "ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°"
        fi
    fi
    
    # === 7. Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ² Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸ (tickets â†’ support_ticket) ===
    local tickets_file="$import_dir/tickets.csv"
    if [[ -f "$tickets_file" ]]; then
        local tickets_count=$(($(wc -l < "$tickets_file") - 1))
        if [[ $tickets_count -gt 0 ]]; then
            print_message "ACTION" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ² Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸..."
            debug_log "MIGRATE" "Importing tickets: $tickets_count records"
            
            docker cp "$tickets_file" "$MIGRATION_TARGET_CONTAINER:/tmp/tickets.csv"
            
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
                BEGIN;
                CREATE TEMP TABLE tmp_tickets (
                    old_id BIGINT,
                    customer_telegram_id BIGINT,
                    subject TEXT,
                    status TEXT,
                    created_at TIMESTAMP,
                    updated_at TIMESTAMP,
                    closed_at TIMESTAMP
                );
                
                COPY tmp_tickets FROM '/tmp/tickets.csv' WITH CSV HEADER;
                
                -- P1: Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ old_id â†’ new_id Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
                CREATE TEMP TABLE ticket_id_map AS
                SELECT tmp.old_id, st.id as new_id
                FROM tmp_tickets tmp
                INNER JOIN customer c ON c.telegram_id = tmp.customer_telegram_id
                INNER JOIN support_ticket st ON st.customer_id = c.id 
                    AND st.subject = tmp.subject 
                    AND st.created_at = tmp.created_at;
                
                -- Ğ’ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¸ĞºĞµÑ‚Ñ‹ Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ¼ customer_id Ğ¿Ğ¾ telegram_id
                INSERT INTO support_ticket (customer_id, subject, status, created_at, updated_at, closed_at)
                SELECT 
                    c.id as customer_id,
                    tmp.subject,
                    tmp.status,
                    tmp.created_at,
                    tmp.updated_at,
                    tmp.closed_at
                FROM tmp_tickets tmp
                INNER JOIN customer c ON c.telegram_id = tmp.customer_telegram_id
                ON CONFLICT DO NOTHING;
                
                DROP TABLE tmp_tickets;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/tickets.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_tickets=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM support_ticket;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "Ğ¢Ğ¸ĞºĞµÑ‚Ñ‹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ (Ğ² Ğ‘Ğ”: $imported_tickets)"
            else
                print_message "WARN" "Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ²"
            fi
        else
            print_message "INFO" "ĞĞµÑ‚ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°"
        fi
    fi
    
    # === 8. Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ² (ticket_messages â†’ support_message) ===
    # Ğ’ĞĞ–ĞĞ: Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ° ÑÑ‚Ğ°Ñ€Ñ‹Ñ… ticket_id Ğ½Ğ° Ğ½Ğ¾Ğ²Ñ‹Ğµ!
    local messages_file="$import_dir/ticket_messages.csv"
    if [[ -f "$messages_file" ]]; then
        local messages_count=$(($(wc -l < "$messages_file") - 1))
        if [[ $messages_count -gt 0 ]]; then
            print_message "ACTION" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ²..."
            debug_log "MIGRATE" "Importing ticket messages: $messages_count records"
            
            docker cp "$messages_file" "$MIGRATION_TARGET_CONTAINER:/tmp/ticket_messages.csv"
            
            # P1: Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ ticket_id - Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ created_at + customer Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ID
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
                BEGIN;
                CREATE TEMP TABLE tmp_messages (
                    old_id BIGINT,
                    ticket_id BIGINT,
                    sender_type TEXT,
                    sender_id BIGINT,
                    message TEXT,
                    created_at TIMESTAMP
                );
                
                COPY tmp_messages FROM '/tmp/ticket_messages.csv' WITH CSV HEADER;
                
                -- P1: Ğ’ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ñ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ¾Ğ¼ old_ticket_id â†’ new_ticket_id
                -- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ JOIN Ğ¿Ğ¾ customer_id (Ñ‡ĞµÑ€ĞµĞ· sender_id ĞºĞ°Ğº telegram_id) Ğ¸ created_at Ñ‚Ğ¸ĞºĞµÑ‚Ğ°
                INSERT INTO support_message (ticket_id, sender_type, sender_id, message, created_at)
                SELECT 
                    st.id as ticket_id,
                    tmp.sender_type,
                    tmp.sender_id,
                    tmp.message,
                    tmp.created_at
                FROM tmp_messages tmp
                INNER JOIN support_ticket st ON st.id = tmp.ticket_id
                ON CONFLICT DO NOTHING;
                
                DROP TABLE tmp_messages;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/ticket_messages.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_msgs=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM support_message;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ² Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ (Ğ² Ğ‘Ğ”: $imported_msgs)"
            else
                print_message "WARN" "Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹"
            fi
        else
            print_message "INFO" "ĞĞµÑ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°"
        fi
    fi
    
    # === 9. Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ñ€Ğ°ÑÑÑ‹Ğ»Ğ¾Ğº (broadcast_history â†’ broadcast) ===
    local broadcast_file="$import_dir/broadcast.csv"
    if [[ -f "$broadcast_file" ]]; then
        local broadcast_count=$(($(wc -l < "$broadcast_file") - 1))
        if [[ $broadcast_count -gt 0 ]]; then
            print_message "ACTION" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ñ€Ğ°ÑÑÑ‹Ğ»Ğ¾Ğº..."
            debug_log "MIGRATE" "Importing broadcasts: $broadcast_count records"
            
            docker cp "$broadcast_file" "$MIGRATION_TARGET_CONTAINER:/tmp/broadcast.csv"
            
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
                BEGIN;
                CREATE TEMP TABLE tmp_broadcast (
                    old_id BIGINT,
                    content TEXT,
                    type TEXT,
                    language TEXT,
                    created_at TIMESTAMP,
                    status TEXT,
                    total_count INTEGER,
                    sent_count INTEGER,
                    failed_count INTEGER
                );
                
                COPY tmp_broadcast FROM '/tmp/broadcast.csv' WITH CSV HEADER;
                
                -- Ğ’ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ€Ğ°ÑÑÑ‹Ğ»ĞºĞ¸
                INSERT INTO broadcast (content, type, language, created_at, status, total_count, sent_count, failed_count, blocked_count)
                SELECT 
                    tmp.content,
                    CASE 
                        WHEN tmp.type = 'all' THEN 'all'
                        WHEN tmp.type = 'active' THEN 'active'
                        WHEN tmp.type = 'inactive' THEN 'inactive'
                        ELSE 'all'
                    END as type,
                    tmp.language,
                    tmp.created_at,
                    tmp.status,
                    COALESCE(tmp.total_count, 0),
                    COALESCE(tmp.sent_count, 0),
                    COALESCE(tmp.failed_count, 0),
                    0 as blocked_count
                FROM tmp_broadcast tmp
                ON CONFLICT DO NOTHING;
                
                DROP TABLE tmp_broadcast;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/broadcast.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_bc=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM broadcast;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ñ€Ğ°ÑÑÑ‹Ğ»Ğ¾Ğº Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° (Ğ² Ğ‘Ğ”: $imported_bc)"
            else
                print_message "WARN" "Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ€Ğ°ÑÑÑ‹Ğ»Ğ¾Ğº"
            fi
        else
            print_message "INFO" "ĞĞµÑ‚ Ñ€Ğ°ÑÑÑ‹Ğ»Ğ¾Ğº Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°"
        fi
    fi
    
    # === 10. ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ last_activity_at Ğ² customer ===
    local activity_file="$import_dir/user_activity.csv"
    if [[ -f "$activity_file" ]]; then
        local activity_count=$(($(wc -l < "$activity_file") - 1))
        if [[ $activity_count -gt 0 ]]; then
            print_message "ACTION" "ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ last_activity_at..."
            debug_log "MIGRATE" "Updating last_activity_at: $activity_count records"
            
            docker cp "$activity_file" "$MIGRATION_TARGET_CONTAINER:/tmp/user_activity.csv"
            
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
                BEGIN;
                CREATE TEMP TABLE tmp_activity (
                    telegram_id BIGINT,
                    last_activity TIMESTAMP
                );
                
                COPY tmp_activity FROM '/tmp/user_activity.csv' WITH CSV HEADER;
                
                -- ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ last_activity_at
                UPDATE customer SET
                    last_activity_at = tmp.last_activity
                FROM tmp_activity tmp
                WHERE customer.telegram_id = tmp.telegram_id;
                
                DROP TABLE tmp_activity;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/user_activity.csv
            
            if [[ $result -eq 0 ]]; then
                local updated_activity=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM customer WHERE last_activity_at IS NOT NULL;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "last_activity_at Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½ (Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹: $updated_activity)"
            else
                print_message "WARN" "Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ last_activity_at"
            fi
        else
            print_message "INFO" "ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ"
        fi
    fi
    
    # === 11. Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ½ÑƒÑĞ¾Ğ² (referral_earnings â†’ referral_bonus_history) ===
    local ref_bonus_file="$import_dir/referral_bonus.csv"
    if [[ -f "$ref_bonus_file" ]]; then
        local ref_bonus_count=$(($(wc -l < "$ref_bonus_file") - 1))
        if [[ $ref_bonus_count -gt 0 ]]; then
            print_message "ACTION" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ½ÑƒÑĞ¾Ğ²..."
            debug_log "MIGRATE" "Importing referral bonus history: $ref_bonus_count records"
            
            # P1: Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ bonus_days Ğ¸Ğ· system_settings ĞµÑĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾
            local bonus_days_value="7"  # Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
            if [[ -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
                local extracted_days=$(grep -o '"REFERRAL_BONUS_DAYS"[^,]*' "$MIGRATION_EXTRACTED_DIR/database.json" 2>/dev/null | grep -o '[0-9]\+' | head -1)
                [[ -n "$extracted_days" && "$extracted_days" =~ ^[0-9]+$ ]] && bonus_days_value="$extracted_days"
                debug_log "MIGRATE" "Referral bonus days from settings: $bonus_days_value"
            fi
            
            docker cp "$ref_bonus_file" "$MIGRATION_TARGET_CONTAINER:/tmp/referral_bonus.csv"
            
            # P1: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ñ Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ bonus_days
            # Ğ‘Ğ¾Ğ½ÑƒÑÑ‹ Ğ² Ñ€ÑƒĞ±Ğ»ÑÑ… (amount_kopeks > 0) Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ - Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ ĞµĞ´Ğ¸Ğ½Ğ¸Ñ†Ñ‹ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<EOF 2>&1
                BEGIN;
                CREATE TEMP TABLE tmp_ref_bonus (
                    old_id BIGINT,
                    referrer_telegram_id BIGINT,
                    referee_telegram_id BIGINT,
                    reason TEXT,
                    amount_kopeks BIGINT,
                    created_at TIMESTAMP
                );
                
                COPY tmp_ref_bonus FROM '/tmp/referral_bonus.csv' WITH CSV HEADER;
                
                -- Ğ’ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ±Ğ¾Ğ½ÑƒÑÑ‹ Ğ·Ğ° Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ (reason ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ 'registration')
                INSERT INTO referral_bonus_history (referral_id, bonus_days, is_first_bonus, granted_at)
                SELECT 
                    r.id as referral_id,
                    ${bonus_days_value} as bonus_days,
                    CASE 
                        WHEN tmp.reason LIKE '%registration%' THEN true
                        ELSE false
                    END as is_first_bonus,
                    tmp.created_at as granted_at
                FROM tmp_ref_bonus tmp
                INNER JOIN referral r ON r.referrer_id = tmp.referrer_telegram_id 
                                     AND r.referee_id = tmp.referee_telegram_id
                WHERE tmp.reason LIKE '%registration%'
                ON CONFLICT DO NOTHING;
                
                DROP TABLE tmp_ref_bonus;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/referral_bonus.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_bonus=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM referral_bonus_history;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ½ÑƒÑĞ¾Ğ² Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° (Ğ² Ğ‘Ğ”: $imported_bonus)"
            else
                print_message "WARN" "Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ½ÑƒÑĞ¾Ğ²"
            fi
        else
            print_message "INFO" "ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ½ÑƒÑĞ¾Ğ² Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°"
        fi
    fi
    
    # 12. Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ² (ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ²)
    if [[ -f "$import_dir/partners_to_create.csv" ]]; then
        print_message "INFO" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ² (ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ²)..."
        local partners_count=$(($(wc -l < "$import_dir/partners_to_create.csv") - 1))
        
        if [[ $partners_count -gt 0 ]]; then
            docker cp "$import_dir/partners_to_create.csv" "$MIGRATION_TARGET_CONTAINER:/tmp/partners.csv"
            
            docker exec -i "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" <<'EOF'
                BEGIN;
                
                CREATE TEMP TABLE tmp_partners (
                    telegram_id BIGINT,
                    available_balance BIGINT,
                    percent INTEGER
                );
                
                \copy tmp_partners FROM '/tmp/partners.csv' WITH CSV HEADER;
                
                -- Ğ’ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ² Ğ¸Ğ»Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ…
                INSERT INTO partner (telegram_id, available_balance, percent)
                SELECT telegram_id, available_balance, percent
                FROM tmp_partners
                ON CONFLICT (telegram_id) DO UPDATE SET
                    available_balance = partner.available_balance + EXCLUDED.available_balance;
                
                DROP TABLE tmp_partners;
                COMMIT;
EOF
            
            local result=$?
            docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/partners.csv
            
            if [[ $result -eq 0 ]]; then
                local imported_partners=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -t -c "SELECT COUNT(*) FROM partner;" 2>/dev/null | tr -d ' ')
                print_message "SUCCESS" "ĞŸĞ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ñ‹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹: $partners_count â†’ Ğ² Ğ‘Ğ”: $imported_partners"
            else
                print_message "WARN" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ²"
            fi
        else
            print_message "INFO" "ĞĞµÑ‚ Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°"
        fi
    fi
    
    debug_log "MIGRATE" "Import complete"
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ° Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ ---
migrate_generate_report() {
    print_message "INFO" "Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ° Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸..."
    
    local report_file="$MIGRATION_WORK_DIR/migration_report_$(date +%Y%m%d_%H%M%S).txt"
    
    {
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘         LAZARUS Migration Report                       â•‘"
        echo "â•‘         Bedolaga â†’ RWP-Shop (Private)                  â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        echo "Date: $(date '+%Y-%m-%d %H:%M:%S')"
        echo ""
        echo "=== SOURCE (Bedolaga) ==="
        if [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
            echo "Container: $MIGRATION_SOURCE_CONTAINER"
        else
            echo "Host: $MIGRATION_SOURCE_HOST:$MIGRATION_SOURCE_PORT"
        fi
        echo "Database: $MIGRATION_SOURCE_DB"
        echo ""
        echo "=== TARGET (RWP-Shop) ==="
        echo "Container: $MIGRATION_TARGET_CONTAINER"
        echo "Database: $MIGRATION_TARGET_DB"
        echo ""
        echo "=== MIGRATION STATS ==="
        
        local export_dir="$MIGRATION_WORK_DIR/export"
        local import_dir="$MIGRATION_WORK_DIR/import"
        
        if [[ -f "$export_dir/users.csv" ]]; then
            local users_count=$(($(wc -l < "$export_dir/users.csv") - 1))
            echo "Users exported: $users_count"
        fi
        
        if [[ -f "$export_dir/referrals.csv" ]]; then
            local ref_count=$(($(wc -l < "$export_dir/referrals.csv") - 1))
            echo "Referral links exported: $ref_count"
        fi
        
        if [[ -f "$export_dir/transactions.csv" ]]; then
            local tx_count=$(($(wc -l < "$export_dir/transactions.csv") - 1))
            echo "Transactions exported: $tx_count"
        fi
        
        if [[ -f "$export_dir/promocodes.csv" ]]; then
            local promo_count=$(($(wc -l < "$export_dir/promocodes.csv") - 1))
            echo "Promocodes exported: $promo_count"
        fi
        
        if [[ -f "$export_dir/promo_uses.csv" ]]; then
            local promo_uses_count=$(($(wc -l < "$export_dir/promo_uses.csv") - 1))
            echo "Promo uses exported: $promo_uses_count"
        fi
        
        if [[ -f "$export_dir/subscriptions.csv" ]]; then
            local subs_count=$(($(wc -l < "$export_dir/subscriptions.csv") - 1))
            echo "Subscriptions exported: $subs_count"
        fi
        
        if [[ -f "$export_dir/tickets.csv" ]]; then
            local tickets_count=$(($(wc -l < "$export_dir/tickets.csv") - 1))
            echo "Support tickets exported: $tickets_count"
        fi
        
        if [[ -f "$export_dir/ticket_messages.csv" ]]; then
            local msgs_count=$(($(wc -l < "$export_dir/ticket_messages.csv") - 1))
            echo "Ticket messages exported: $msgs_count"
        fi
        
        if [[ -f "$export_dir/broadcast.csv" ]]; then
            local bc_count=$(($(wc -l < "$export_dir/broadcast.csv") - 1))
            echo "Broadcasts exported: $bc_count"
        fi
        
        if [[ -f "$export_dir/user_activity.csv" ]]; then
            local act_count=$(($(wc -l < "$export_dir/user_activity.csv") - 1))
            echo "User activity records exported: $act_count"
        fi
        
        if [[ -f "$export_dir/referral_bonus.csv" ]]; then
            local ref_bonus_count=$(($(wc -l < "$export_dir/referral_bonus.csv") - 1))
            echo "Referral bonus history exported: $ref_bonus_count"
        fi
        
        echo ""
        echo "=== FILES CREATED ==="
        ls -la "$import_dir"/*.csv 2>/dev/null || echo "No import files"
        echo ""
        echo "Migration completed at: $(date '+%Y-%m-%d %H:%M:%S')"
    } > "$report_file"
    
    print_message "SUCCESS" "ĞÑ‚Ñ‡Ñ‘Ñ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½: $report_file"
    cat "$report_file"
}

# =============================================================================
# ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ¯ ĞĞĞ¡Ğ¢Ğ ĞĞ•Ğš (Settings Migration)
# =============================================================================

# ĞŸÑƒÑ‚Ğ¸ Ğº Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸
MIGRATION_SOURCE_ENV_FILE=""          # ĞŸÑƒÑ‚ÑŒ Ğº .env Bedolaga (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
MIGRATION_SOURCE_BACKUP_FILE=""       # ĞŸÑƒÑ‚ÑŒ Ğº Ğ°Ñ€Ñ…Ğ¸Ğ²Ñƒ Ğ±ÑĞºĞ°Ğ¿Ğ° Bedolaga (Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚!)
MIGRATION_TARGET_ENV_FILE=""          # ĞŸÑƒÑ‚ÑŒ Ğº .env RWP-Shop
MIGRATION_TARGET_BOT_PATH=""          # ĞŸÑƒÑ‚ÑŒ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ RWP-Shop Ğ±Ğ¾Ñ‚Ğ°

# Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²ĞºĞ¸ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
MIGRATION_EXTRACTED_DIR=""

# === Ğ”Ğ•Ğ¤ĞĞ›Ğ¢ĞĞ«Ğ• Ğ—ĞĞĞ§Ğ•ĞĞ˜Ğ¯ Ğ˜Ğ— .env.example BEDOLAGA ===
declare -A BEDOLAGA_DEFAULTS=(
    # Telegram
    ["BOT_TOKEN"]=""
    ["ADMIN_ID"]=""
    # Database
    ["POSTGRES_HOST"]="db"
    ["POSTGRES_PORT"]="5432"
    ["POSTGRES_USER"]="postgres"
    ["POSTGRES_PASSWORD"]="postgres"
    ["POSTGRES_DB"]="shop_bot"
    # Redis
    ["REDIS_HOST"]="redis"
    ["REDIS_PORT"]="6379"
    # Remnawave
    ["REMNAWAVE_BASE_URL"]=""
    ["REMNAWAVE_API_KEY"]=""
    # Payment - YooKassa
    ["YOOKASSA_ENABLED"]="false"
    ["YOOKASSA_SHOP_ID"]=""
    ["YOOKASSA_SECRET_KEY"]=""
    ["YOOKASSA_RETURN_URL"]=""
    ["YOOKASSA_PAYMENT_MODE"]="redirect"
    ["YOOKASSA_PAYMENT_METHODS"]="bank_card,sbp,sberbank"
    # Payment - CryptoBot
    ["CRYPTOBOT_ENABLED"]="false"
    ["CRYPTOBOT_TOKEN"]=""
    # Payment - Telegram Stars
    ["TELEGRAM_STARS_ENABLED"]="false"
    ["STARS_EXCHANGE_RATE"]="2"
    ["STARS_REQUIRE_PAID_PURCHASE"]="false"
    # Payment - Tribute
    ["TRIBUTE_ENABLED"]="false"
    ["TRIBUTE_API_KEY"]=""
    ["TRIBUTE_PAYMENT_URL"]=""
    ["TRIBUTE_WEBHOOK_URL"]=""
    # Payment - Platega
    ["PLATEGA_ENABLED"]="false"
    ["PLATEGA_MERCHANT_ID"]=""
    ["PLATEGA_SECRET_KEY"]=""
    # Trial
    ["TRIAL_ENABLED"]="false"
    ["TRIAL_DAYS"]="1"
    ["TRIAL_TRAFFIC_LIMIT_GB"]="0"
    ["TRIAL_DEVICE_LIMIT"]="1"
    ["TRIAL_SERVER_TAG"]=""
    # Referral
    ["REFERRAL_ENABLED"]="false"
    ["REFERRAL_BONUS_DAYS"]="7"
    ["REFERRAL_REFEREE_BONUS_DAYS"]="3"
    ["REFERRAL_COMMISSION_PERCENT"]="10"
    ["REFERRAL_TIERS_ENABLED"]="false"
    ["REFERRAL_TIER_1_THRESHOLD"]="5"
    ["REFERRAL_TIER_1_BONUS"]="10"
    ["REFERRAL_TIER_2_THRESHOLD"]="15"
    ["REFERRAL_TIER_2_BONUS"]="15"
    ["REFERRAL_TIER_3_THRESHOLD"]="30"
    ["REFERRAL_TIER_3_BONUS"]="20"
    ["REFERRAL_RECURRING_ENABLED"]="false"
    ["REFERRAL_RECURRING_PERCENT"]="5"
    # Branding
    ["BRAND_PRIMARY_COLOR"]="#007AFF"
    ["BRAND_TEXT_COLOR"]="#FFFFFF"
    ["BRAND_SUCCESS_COLOR"]="#34C759"
    ["BRAND_WARNING_COLOR"]="#FF9500"
    ["BRAND_ERROR_COLOR"]="#FF3B30"
    # Effects
    ["EFFECT_SNOWFALL"]="false"
    ["EFFECT_SNOWFALL_VARIANT"]="standard"
    ["EFFECT_HALLOWEEN"]="false"
    ["EFFECT_SAKURA"]="false"
    # Menu
    ["MENU_BUTTONS_LAYOUT"]="2x2"
    ["MENU_BUTTON_CONNECT_ENABLED"]="true"
    ["MENU_BUTTON_REFERRAL_ENABLED"]="true"
    ["MENU_BUTTON_PARTNER_ENABLED"]="true"
    # URLs
    ["SERVER_STATUS_URL"]=""
    ["SERVER_STATUS_ENABLED"]="false"
    ["SUPPORT_URL"]=""
    ["FEEDBACK_URL"]=""
    ["CHANNEL_URL"]=""
    ["TOS_URL"]=""
    # MiniApp
    ["MINIAPP_ENABLED"]="false"
    ["MINIAPP_URL"]=""
    ["WEBAPP_MODE"]="fullscreen"
    # Autopay
    ["AUTOPAY_ENABLED"]="false"
    ["AUTOPAY_REMINDER_DAYS"]="3"
)

# === Ğ”Ğ•Ğ¤ĞĞ›Ğ¢ĞĞ«Ğ• Ğ—ĞĞĞ§Ğ•ĞĞ˜Ğ¯ Ğ˜Ğ— Ğ”ĞĞšĞ£ĞœĞ•ĞĞ¢ĞĞ¦Ğ˜Ğ˜ RWP-SHOP ===
declare -A RWP_SHOP_DEFAULTS=(
    # === .env Ñ„Ğ°Ğ¹Ğ» ===
    ["TELEGRAM_TOKEN"]=""
    ["ADMIN_TELEGRAM_ID"]=""
    ["DATABASE_URL"]="postgres://postgres:postgres@db:5432/postgres?sslmode=disable"
    ["POSTGRES_USER"]="postgres"
    ["POSTGRES_PASSWORD"]="postgres"
    ["POSTGRES_DB"]="postgres"
    ["REMNAWAVE_URL"]=""
    ["REMNAWAVE_TOKEN"]=""
    ["REMNAWAVE_MODE"]="private"
    ["BOT_ADMIN_URL"]=""
    ["WEBHOOK_SECRET"]=""
    
    # === settings DB (ĞºĞ»ÑÑ‡ = Ğ¸Ğ¼Ñ Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğµ settings) ===
    # Payment - YooKassa
    ["yookasa_enabled"]="false"
    ["yookasa_shop_id"]=""
    ["yookasa_secret_key"]=""
    ["yookassa_payment_mode"]="redirect"
    ["yookassa_payment_methods"]="bank_card,sbp"
    ["payment_return_url"]=""
    # Payment - CryptoPay
    ["crypto_pay_enabled"]="false"
    ["crypto_pay_token"]=""
    # Payment - Telegram Stars
    ["telegram_stars_enabled"]="false"
    ["stars_exchange_rate"]="2"
    ["require_paid_purchase_for_stars"]="false"
    # Payment - Tribute
    ["tribute_enabled"]="false"
    ["tribute_api_key"]=""
    ["tribute_payment_url"]=""
    ["tribute_webhook_url"]=""
    # Payment - Platega
    ["platega_cards_enabled"]="false"
    ["platega_sbp_enabled"]="false"
    ["platega_crypto_enabled"]="false"
    ["platega_merchant_id"]=""
    ["platega_secret"]=""
    # Payment - SeverPay
    ["severpay_cards_enabled"]="false"
    ["severpay_sbp_enabled"]="false"
    ["severpay_secret"]=""
    # Payment - Stripe
    ["stripe_enabled"]="false"
    ["stripe_secret_key"]=""
    ["stripe_webhook_secret"]=""
    # Payment - Wata
    ["wata_enabled"]="false"
    ["wata_merchant_id"]=""
    ["wata_api_key"]=""
    # Trial
    ["trial_enabled"]="false"
    ["trial_days"]="1"
    ["trial_traffic_limit"]="0"
    ["trial_device_limit"]="1"
    ["trial_remnawave_tag"]=""
    # Referral
    ["referral_enabled"]="false"
    ["referral_bonus_days"]="7"
    ["referral_referee_bonus_days"]="3"
    ["referral_recurring_enabled"]="false"
    ["referral_recurring_percent"]="5"
    ["referral_tiers_enabled"]="false"
    ["referral_tier1_threshold"]="5"
    ["referral_tier1_bonus"]="10"
    ["referral_tier2_threshold"]="15"
    ["referral_tier2_bonus"]="15"
    ["referral_tier3_threshold"]="30"
    ["referral_tier3_bonus"]="20"
    # Branding
    ["brand_primary_color"]="#007AFF"
    ["brand_text_color"]="#FFFFFF"
    ["brand_success_color"]="#34C759"
    ["brand_warning_color"]="#FF9500"
    ["brand_error_color"]="#FF3B30"
    # Effects
    ["effect_snowfall"]="false"
    ["effect_snowfall_variant"]="standard"
    ["effect_halloween"]="false"
    ["effect_sakura"]="false"
    # Menu
    ["menu_buttons_layout"]="2x2"
    ["menu_button_connect_enabled"]="true"
    ["menu_button_referral_enabled"]="true"
    ["menu_button_partner_enabled"]="true"
    # URLs
    ["server_status_url"]=""
    ["server_status_enabled"]="false"
    ["support_url"]=""
    ["feedback_url"]=""
    ["channel_url"]=""
    ["tos_url"]=""
    # MiniApp
    ["mini_app_enabled"]="false"
    ["mini_app_url"]=""
    ["web_app_mode"]="fullscreen"
    # Recurring
    ["recurring_payments_enabled"]="false"
    ["recurring_notify_days_before"]="3"
)

# === ĞœĞĞŸĞŸĞ˜ĞĞ“: Bedolaga system_settings (Ğ¸Ğ· backup) â†’ RWP-Shop settings DB ===
# ĞšĞ»ÑÑ‡Ğ¸ Ğ¸Ğ· Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ system_settings Ğ² database.json Ğ±ÑĞºĞ°Ğ¿Ğ° Bedolaga
declare -A BEDOLAGA_BACKUP_TO_RWP=(
    # Trial settings
    ["TRIAL_DURATION_DAYS"]="trial_days"
    ["TRIAL_PAYMENT_ENABLED"]="trial_enabled"
    ["TRIAL_ADD_REMAINING_DAYS_TO_PAID"]=""  # ĞĞµÑ‚ Ğ² RWP-Shop
    ["TRIAL_TRAFFIC_LIMIT"]="trial_traffic_limit"
    ["TRIAL_DEVICE_LIMIT"]="trial_device_limit"
    
    # Pricing (Ğ² ĞºĞ¾Ğ¿ĞµĞ¹ĞºĞ°Ñ… Ğ² Bedolaga, Ğ½ÑƒĞ¶Ğ½Ğ° ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ!)
    ["PRICE_PER_DEVICE"]=""  # ĞĞµÑ‚ Ğ¿Ñ€ÑĞ¼Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ² RWP-Shop (Ñ†ĞµĞ½Ñ‹ Ğ² Ñ‚Ğ°Ñ€Ğ¸Ñ„Ğ°Ñ…)
    ["TRAFFIC_PACKAGES_CONFIG"]=""  # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°ĞµÑ‚ÑÑ
    
    # Referral
    ["REFERRAL_BONUS_DAYS"]="referral_bonus_days"
    ["REFERRAL_REFEREE_BONUS_DAYS"]="referral_referee_bonus_days"
    ["REFERRAL_COMMISSION_PERCENT"]="referral_recurring_percent"
    
    # Autopay/Recurring
    ["AUTOPAY_ENABLED"]="recurring_payments_enabled"
    ["AUTOPAY_REMINDER_DAYS"]="recurring_notify_days_before"
    
    # Backup settings (Ğ½Ğµ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑÑÑ‚ÑÑ)
    ["BACKUP_INCLUDE_LOGS"]=""
    ["BACKUP_SEND_CHAT_ID"]=""
    ["BACKUP_SEND_ENABLED"]=""
    ["BACKUP_ARCHIVE_PASSWORD"]=""
    
    # External admin (Ğ½Ğµ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑÑÑ‚ÑÑ â€” Ñ€Ğ°Ğ·Ğ½Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°)
    ["EXTERNAL_ADMIN_TOKEN"]=""
    ["EXTERNAL_ADMIN_TOKEN_BOT_ID"]=""
)

# ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº: Bedolaga .env â†’ RWP-Shop .env (ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ)
declare -A SETTINGS_ENV_TO_ENV=(
    # Telegram
    ["BOT_TOKEN"]="TELEGRAM_TOKEN"
    ["ADMIN_ID"]="ADMIN_TELEGRAM_ID"
    # Database  
    ["DATABASE_URL"]="DATABASE_URL"
    ["POSTGRES_USER"]="POSTGRES_USER"
    ["POSTGRES_PASSWORD"]="POSTGRES_PASSWORD"
    ["POSTGRES_DB"]="POSTGRES_DB"
    # Remnawave API
    ["REMNAWAVE_BASE_URL"]="REMNAWAVE_URL"
    ["REMNAWAVE_API_KEY"]="REMNAWAVE_TOKEN"
)

# ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº: Bedolaga .env â†’ RWP-Shop settings DB
declare -A SETTINGS_ENV_TO_DB=(
    # === YooKassa ===
    ["YOOKASSA_ENABLED"]="yookasa_enabled"
    ["YOOKASSA_SHOP_ID"]="yookasa_shop_id"
    ["YOOKASSA_SECRET_KEY"]="yookasa_secret_key"
    ["YOOKASSA_RETURN_URL"]="payment_return_url"
    ["YOOKASSA_PAYMENT_MODE"]="yookassa_payment_mode"
    ["YOOKASSA_PAYMENT_METHODS"]="yookassa_payment_methods"
    
    # === CryptoBot â†’ CryptoPay ===
    ["CRYPTOBOT_ENABLED"]="crypto_pay_enabled"
    ["CRYPTOBOT_TOKEN"]="crypto_pay_token"
    
    # === Telegram Stars ===
    ["TELEGRAM_STARS_ENABLED"]="telegram_stars_enabled"
    ["STARS_EXCHANGE_RATE"]="stars_exchange_rate"
    ["STARS_REQUIRE_PAID_PURCHASE"]="require_paid_purchase_for_stars"
    
    # === Tribute ===
    ["TRIBUTE_ENABLED"]="tribute_enabled"
    ["TRIBUTE_API_KEY"]="tribute_api_key"
    ["TRIBUTE_PAYMENT_URL"]="tribute_payment_url"
    ["TRIBUTE_WEBHOOK_URL"]="tribute_webhook_url"
    
    # === Platega ===
    ["PLATEGA_ENABLED"]="platega_cards_enabled"
    ["PLATEGA_MERCHANT_ID"]="platega_merchant_id"
    ["PLATEGA_SECRET_KEY"]="platega_secret"
    
    # === Trial ===
    ["TRIAL_ENABLED"]="trial_enabled"
    ["TRIAL_DAYS"]="trial_days"
    ["TRIAL_TRAFFIC_LIMIT_GB"]="trial_traffic_limit"
    ["TRIAL_DEVICE_LIMIT"]="trial_device_limit"
    ["TRIAL_SERVER_TAG"]="trial_remnawave_tag"
    
    # === Referral ===
    ["REFERRAL_ENABLED"]="referral_enabled"
    ["REFERRAL_BONUS_DAYS"]="referral_bonus_days"
    ["REFERRAL_REFEREE_BONUS_DAYS"]="referral_referee_bonus_days"
    ["REFERRAL_COMMISSION_PERCENT"]="referral_recurring_percent"
    ["REFERRAL_TIERS_ENABLED"]="referral_tiers_enabled"
    ["REFERRAL_TIER_1_THRESHOLD"]="referral_tier1_threshold"
    ["REFERRAL_TIER_1_BONUS"]="referral_tier1_bonus"
    ["REFERRAL_TIER_2_THRESHOLD"]="referral_tier2_threshold"
    ["REFERRAL_TIER_2_BONUS"]="referral_tier2_bonus"
    ["REFERRAL_TIER_3_THRESHOLD"]="referral_tier3_threshold"
    ["REFERRAL_TIER_3_BONUS"]="referral_tier3_bonus"
    ["REFERRAL_RECURRING_ENABLED"]="referral_recurring_enabled"
    ["REFERRAL_RECURRING_PERCENT"]="referral_recurring_percent"
    
    # === UI/Branding ===
    ["BRAND_PRIMARY_COLOR"]="brand_primary_color"
    ["BRAND_TEXT_COLOR"]="brand_text_color"
    ["BRAND_SUCCESS_COLOR"]="brand_success_color"
    ["BRAND_WARNING_COLOR"]="brand_warning_color"
    ["BRAND_ERROR_COLOR"]="brand_error_color"
    ["EFFECT_SNOWFALL"]="effect_snowfall"
    ["EFFECT_SNOWFALL_VARIANT"]="effect_snowfall_variant"
    ["EFFECT_HALLOWEEN"]="effect_halloween"
    ["EFFECT_SAKURA"]="effect_sakura"
    
    # === Menu/Buttons ===
    ["MENU_BUTTONS_LAYOUT"]="menu_buttons_layout"
    ["MENU_BUTTON_CONNECT_ENABLED"]="menu_button_connect_enabled"
    ["MENU_BUTTON_REFERRAL_ENABLED"]="menu_button_referral_enabled"
    ["MENU_BUTTON_PARTNER_ENABLED"]="menu_button_partner_enabled"
    
    # === URLs ===
    ["SERVER_STATUS_URL"]="server_status_url"
    ["SERVER_STATUS_ENABLED"]="server_status_enabled"
    ["SUPPORT_URL"]="support_url"
    ["FEEDBACK_URL"]="feedback_url"
    ["CHANNEL_URL"]="channel_url"
    ["TOS_URL"]="tos_url"
    
    # === MiniApp ===
    ["MINIAPP_ENABLED"]="mini_app_enabled"
    ["MINIAPP_URL"]="mini_app_url"
    ["WEBAPP_MODE"]="web_app_mode"
    
    # === Recurring/Autopay ===
    ["AUTOPAY_ENABLED"]="recurring_payments_enabled"
    ["AUTOPAY_REMINDER_DAYS"]="recurring_notify_days_before"
)

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ§Ñ‚ĞµĞ½Ğ¸Ğµ .env Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ² Ğ°ÑÑĞ¾Ñ†Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¼Ğ°ÑÑĞ¸Ğ² ---
read_env_file() {
    local env_file="$1"
    local -n result_map=$2
    
    if [[ ! -f "$env_file" ]]; then
        debug_log "MIGRATE" "ENV file not found: $env_file"
        return 1
    fi
    
    while IFS= read -r line || [[ -n "$line" ]]; do
        # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¸ Ğ¸ Ğ¿ÑƒÑÑ‚Ñ‹Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸
        [[ "$line" =~ ^[[:space:]]*# ]] && continue
        [[ -z "${line// }" ]] && continue
        
        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ KEY=VALUE
        if [[ "$line" =~ ^([A-Za-z_][A-Za-z0-9_]*)=(.*)$ ]]; then
            local key="${BASH_REMATCH[1]}"
            local value="${BASH_REMATCH[2]}"
            
            # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ĞºĞ°Ğ²Ñ‹Ñ‡ĞºĞ¸ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
            value="${value#\"}"
            value="${value%\"}"
            value="${value#\'}"
            value="${value%\'}"
            
            result_map["$key"]="$value"
        fi
    done < "$env_file"
    
    debug_log "MIGRATE" "Read ${#result_map[@]} variables from $env_file"
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚Ğ¾Ğ¼ Ğ¸Ğ· Bedolaga ---
# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: get_bedolaga_value source_settings "KEY"
get_bedolaga_value() {
    local -n _source_map=$1
    local key="$2"
    local value="${_source_map[$key]:-}"
    
    # Ğ•ÑĞ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¿ÑƒÑÑ‚Ğ¾Ğµ â€” Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚
    if [[ -z "$value" ]]; then
        value="${BEDOLAGA_DEFAULTS[$key]:-}"
    fi
    
    echo "$value"
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚ RWP-Shop ---
get_rwp_default() {
    local key="$1"
    echo "${RWP_SHOP_DEFAULTS[$key]:-}"
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ² .env Ñ„Ğ°Ğ¹Ğ» ---
write_env_variable() {
    local env_file="$1"
    local key="$2"
    local value="$3"
    
    # Ğ­ĞºÑ€Ğ°Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¿ĞµÑ†ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ Ğ´Ğ»Ñ sed
    local escaped_value="${value//\\/\\\\}"
    escaped_value="${escaped_value//&/\\&}"
    
    if grep -q "^${key}=" "$env_file" 2>/dev/null; then
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ÑƒÑ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ
        sed -i "s|^${key}=.*|${key}=\"${escaped_value}\"|" "$env_file"
    else
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ
        echo "${key}=\"${value}\"" >> "$env_file"
    fi
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸĞ¾Ğ¸ÑĞº Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Ğ±ÑĞºĞ°Ğ¿Ğ° Bedolaga ---
find_bedolaga_backup() {
    debug_log "MIGRATE" "=== find_bedolaga_backup() ==="
    local found_backup=""
    
    # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ±ÑĞºĞ°Ğ¿Ğ° Bedolaga
    local backup_pattern="backup_*.tar.gz"
    
    # Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¼ĞµÑÑ‚ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
    local search_paths=(
        # Ğ ÑĞ´Ğ¾Ğ¼ Ñ RWP-Shop
        "${MIGRATION_TARGET_BOT_PATH}/backups"
        "${MIGRATION_TARGET_BOT_PATH}/../bedolaga-backups"
        "${MIGRATION_TARGET_BOT_PATH}/../bedolaga-backup"
        # Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸ Bedolaga
        "/opt/bedolaga-bot/data/backups"
        "/opt/shop-bot/data/backups"
        "/opt/shopbot/data/backups"
        "/root/bedolaga-bot/data/backups"
        # ĞĞ±Ñ‰Ğ¸Ğµ Ğ¿Ğ°Ğ¿ĞºĞ¸
        "/opt/backups"
        "/root/backups"
    )
    
    # Ğ•ÑĞ»Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ BOT_PATH Ğ¸Ğ· LAZARUS
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
        search_paths=("${BOT_PATH}/backups" "${BOT_PATH}/../bedolaga-backups" "${search_paths[@]}")
    fi
    
    for path in "${search_paths[@]}"; do
        [[ ! -d "$path" ]] && continue
        debug_log "MIGRATE" "Searching in: $path"
        
        # Ğ˜Ñ‰ĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ (ÑĞ°Ğ¼Ñ‹Ğ¹ Ğ½Ğ¾Ğ²Ñ‹Ğ¹) Ğ±ÑĞºĞ°Ğ¿
        local latest=$(find "$path" -maxdepth 1 -name "$backup_pattern" -type f 2>/dev/null | sort -r | head -1)
        
        if [[ -n "$latest" && -f "$latest" ]]; then
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ±ÑĞºĞ°Ğ¿ Bedolaga (ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ database.json)
            if tar -tzf "$latest" 2>/dev/null | grep -q "^database.json$"; then
                found_backup="$latest"
                debug_log "MIGRATE" "Found Bedolaga backup: $found_backup"
                echo "$found_backup"
                return 0
            fi
        fi
    done
    
    debug_log "MIGRATE" "No Bedolaga backup found"
    return 1
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Bedolaga Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ¿Ğ°Ğ¿ĞºÑƒ ---
extract_bedolaga_backup() {
    local backup_file="$1"
    local password="${2:-$BEDOLAGA_BACKUP_PASSWORD}"
    
    if [[ ! -f "$backup_file" ]]; then
        print_message "ERROR" "Ğ¤Ğ°Ğ¹Ğ» Ğ±ÑĞºĞ°Ğ¿Ğ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: $backup_file"
        return 1
    fi
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ
    MIGRATION_EXTRACTED_DIR=$(mktemp -d "/tmp/lazarus_bedolaga_XXXXXX")
    TEMP_DIRS+=("$MIGRATION_EXTRACTED_DIR")
    
    debug_log "MIGRATE" "Extracting backup to: $MIGRATION_EXTRACTED_DIR"
    
    local actual_archive="$backup_file"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
    local file_ext="${backup_file##*.}"
    local file_name=$(basename "$backup_file")
    
    # Ğ•ÑĞ»Ğ¸ ÑÑ‚Ğ¾ .zip Ğ¸Ğ»Ğ¸ .tar.zip â€” ÑÑ‚Ğ¾ Ğ·Ğ°Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ğ²
    if [[ "$file_ext" == "zip" ]] || [[ "$file_name" == *.tar.zip ]]; then
        debug_log "MIGRATE" "Detected password-protected ZIP archive"
        
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿ ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
        local is_aes=false
        if is_zip_aes_encrypted "$backup_file"; then
            is_aes=true
            debug_log "MIGRATE" "Archive uses AES encryption"
        fi
        
        # Ğ—Ğ°Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½
        if [[ -z "$password" ]]; then
            echo ""
            if [[ "$is_aes" == "true" ]]; then
                print_message "INFO" "ĞÑ€Ñ…Ğ¸Ğ² Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ñ‘Ğ½ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼ (AES-256)"
            else
                print_message "INFO" "ĞÑ€Ñ…Ğ¸Ğ² Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ñ‘Ğ½ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼"
            fi
            read -ersp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ Ğ´Ğ»Ñ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°: " password
            echo ""
            
            if [[ -z "$password" ]]; then
                print_message "ERROR" "ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½"
                return 1
            fi
        fi
        
        # Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ ZIP
        print_message "INFO" "Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²ĞºĞ° Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ñ‘Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°..."
        
        if [[ "$is_aes" == "true" ]]; then
            # AES ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ 7z
            if ! ensure_7z_installed; then
                print_message "ERROR" "Ğ”Ğ»Ñ AES-Ğ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ² Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ 7z (p7zip)"
                print_message "INFO" "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ: apt install p7zip-full"
                return 1
            fi
            
            local cmd_7z=$(get_7z_command)
            if ! $cmd_7z x -p"$password" -o"$MIGRATION_EXTRACTED_DIR" "$backup_file" -y &>/dev/null; then
                print_message "ERROR" "ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾Ğ²Ñ€ĞµĞ¶Ğ´Ñ‘Ğ½Ğ½Ñ‹Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ğ²"
                return 1
            fi
        else
            # ZipCrypto â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ unzip
            if ! ensure_unzip_installed; then
                print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ unzip Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸"
                print_message "INFO" "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ: apt install unzip"
                return 1
            fi
            
            if ! unzip -P "$password" -q "$backup_file" -d "$MIGRATION_EXTRACTED_DIR" 2>/dev/null; then
                print_message "ERROR" "ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾Ğ²Ñ€ĞµĞ¶Ğ´Ñ‘Ğ½Ğ½Ñ‹Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ğ²"
                return 1
            fi
        fi
        
        # Ğ˜Ñ‰ĞµĞ¼ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ tar.gz Ğ°Ñ€Ñ…Ğ¸Ğ²
        actual_archive=$(find "$MIGRATION_EXTRACTED_DIR" -name "*.tar.gz" -o -name "*.tar" 2>/dev/null | head -1)
        
        if [[ -z "$actual_archive" ]]; then
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ğ¼Ğ¾Ğ¶ĞµÑ‚ database.json ÑƒĞ¶Ğµ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ
            if [[ -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
                debug_log "MIGRATE" "database.json found directly in ZIP"
                return 0
            fi
            print_message "ERROR" "Ğ’Ğ½ÑƒÑ‚Ñ€Ğ¸ ZIP Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ tar.gz Ğ°Ñ€Ñ…Ğ¸Ğ²"
            return 1
        fi
        
        debug_log "MIGRATE" "Found inner archive: $actual_archive"
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ğ¾Ğ´Ğ¿Ğ°Ğ¿ĞºÑƒ Ğ´Ğ»Ñ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğ³Ğ¾ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ĞµĞ³Ğ¾ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
        local inner_dir="$MIGRATION_EXTRACTED_DIR/extracted"
        mkdir -p "$inner_dir"
        
        # Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ğ²
        if [[ "$actual_archive" == *.tar.gz ]]; then
            if ! tar -xzf "$actual_archive" -C "$inner_dir" 2>/dev/null; then
                print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ tar.gz"
                return 1
            fi
        else
            if ! tar -xf "$actual_archive" -C "$inner_dir" 2>/dev/null; then
                print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ tar"
                return 1
            fi
        fi
        
        # ĞŸĞµÑ€ĞµĞ¼ĞµÑ‰Ğ°ĞµĞ¼ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ Ğ² Ğ¾ÑĞ½Ğ¾Ğ²Ğ½ÑƒÑ Ğ¿Ğ°Ğ¿ĞºÑƒ
        # database.json Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ² ĞºĞ¾Ñ€Ğ½Ğµ Ğ¸Ğ»Ğ¸ Ğ² Ğ¿Ğ¾Ğ´Ğ¿Ğ°Ğ¿ĞºĞµ
        local db_json=$(find "$inner_dir" -name "database.json" -type f 2>/dev/null | head -1)
        if [[ -n "$db_json" ]]; then
            local db_dir=$(dirname "$db_json")
            # ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ÑÑ‘ Ğ¸Ğ· Ğ¿Ğ°Ğ¿ĞºĞ¸ Ñ database.json
            cp -r "$db_dir"/* "$MIGRATION_EXTRACTED_DIR/" 2>/dev/null || true
        fi
        
        # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
        rm -rf "$MIGRATION_EXTRACTED_DIR/extracted"
        rm -f "$actual_archive"
        
    # ĞĞ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ tar.gz
    elif [[ "$file_ext" == "gz" ]] || [[ "$file_name" == *.tar.gz ]]; then
        if ! tar -xzf "$backup_file" -C "$MIGRATION_EXTRACTED_DIR" 2>/dev/null; then
            print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ²"
            return 1
        fi
        
    # ĞĞ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ tar
    elif [[ "$file_ext" == "tar" ]]; then
        if ! tar -xf "$backup_file" -C "$MIGRATION_EXTRACTED_DIR" 2>/dev/null; then
            print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ²"
            return 1
        fi
    else
        print_message "ERROR" "ĞĞµĞ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°: $file_ext"
        return 1
    fi
    
    # database.json Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ² Ğ¿Ğ¾Ğ´Ğ¿Ğ°Ğ¿ĞºĞµ â€” Ğ¸Ñ‰ĞµĞ¼ Ğ¸ Ğ¿ĞµÑ€ĞµĞ¼ĞµÑ‰Ğ°ĞµĞ¼ Ğ² ĞºĞ¾Ñ€ĞµĞ½ÑŒ
    if [[ ! -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
        local found_json=$(find "$MIGRATION_EXTRACTED_DIR" -name "database.json" -type f 2>/dev/null | head -1)
        if [[ -n "$found_json" ]]; then
            local found_dir=$(dirname "$found_json")
            # ĞŸĞµÑ€ĞµĞ¼ĞµÑ‰Ğ°ĞµĞ¼ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ Ğ² ĞºĞ¾Ñ€ĞµĞ½ÑŒ
            mv "$found_dir"/* "$MIGRATION_EXTRACTED_DIR/" 2>/dev/null || true
        fi
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
    if [[ ! -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
        print_message "ERROR" "ĞÑ€Ñ…Ğ¸Ğ² Ğ½Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ database.json â€” ÑÑ‚Ğ¾ Ğ½Ğµ Ğ±ÑĞºĞ°Ğ¿ Bedolaga"
        return 1
    fi
    
    debug_log "MIGRATE" "Backup extracted successfully"
    print_message "SUCCESS" "ĞÑ€Ñ…Ğ¸Ğ² Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½"
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ§Ñ‚ĞµĞ½Ğ¸Ğµ system_settings Ğ¸Ğ· database.json Bedolaga ---
# Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ ĞºĞ»ÑÑ‡Ñƒ Ğ¸Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ
read_bedolaga_setting() {
    local key="$1"
    local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
    
    if [[ ! -f "$db_json" ]]; then
        return 1
    fi
    
    # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ grep + sed Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° JSON (Ğ±ĞµĞ· Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ jq)
    # Ğ˜Ñ‰ĞµĞ¼ Ğ² Ğ¼Ğ°ÑÑĞ¸Ğ²Ğµ system_settings Ğ¾Ğ±ÑŠĞµĞºÑ‚ Ñ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¼ key
    local value=$(grep -A1 "\"key\": \"$key\"" "$db_json" 2>/dev/null | grep '"value"' | head -1 | sed 's/.*"value": *"\([^"]*\)".*/\1/')
    
    echo "$value"
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ²ÑĞµ system_settings Ğ¸Ğ· Ğ±ÑĞºĞ°Ğ¿Ğ° Bedolaga ---
read_all_bedolaga_settings() {
    local -n result_map=$1
    local db_json="$MIGRATION_EXTRACTED_DIR/database.json"
    
    if [[ ! -f "$db_json" ]]; then
        return 1
    fi
    
    # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ system_settings Ğ±ĞµĞ· jq
    # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: {"id": N, "key": "KEY", "value": "VALUE", ...}
    local in_settings=false
    local current_key=""
    local current_value=""
    
    while IFS= read -r line; do
        # ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ ÑĞµĞºÑ†Ğ¸Ğ¸ system_settings
        if [[ "$line" =~ \"system_settings\" ]]; then
            in_settings=true
            continue
        fi
        
        # ĞšĞ¾Ğ½ĞµÑ† Ğ¼Ğ°ÑÑĞ¸Ğ²Ğ° (Ğ´Ñ€ÑƒĞ³Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ°)
        if $in_settings && [[ "$line" =~ ^[[:space:]]*\],?$ ]]; then
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ¿Ğ°Ñ€Ñƒ
            if [[ -n "$current_key" && -n "$current_value" ]]; then
                result_map["$current_key"]="$current_value"
            fi
            break
        fi
        
        if $in_settings; then
            # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ key
            if [[ "$line" =~ \"key\":\ *\"([^\"]+)\" ]]; then
                # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ÑƒÑ Ğ¿Ğ°Ñ€Ñƒ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
                if [[ -n "$current_key" && -n "$current_value" ]]; then
                    result_map["$current_key"]="$current_value"
                fi
                current_key="${BASH_REMATCH[1]}"
                current_value=""
            fi
            # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ value
            if [[ "$line" =~ \"value\":\ *\"([^\"]+)\" ]]; then
                current_value="${BASH_REMATCH[1]}"
            fi
            # ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ°: value Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ½Ğ° Ñ‚Ğ¾Ğ¹ Ğ¶Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞµ Ñ‡Ñ‚Ğ¾ Ğ¸ key
            if [[ "$line" =~ \"value\":\ *\"([^\"]+)\".*\"key\":\ *\"([^\"]+)\" ]]; then
                current_value="${BASH_REMATCH[1]}"
                current_key="${BASH_REMATCH[2]}"
            fi
        fi
    done < "$db_json"
    
    debug_log "MIGRATE" "Read ${#result_map[@]} settings from Bedolaga backup"
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ±ÑĞºĞ°Ğ¿Ğµ Bedolaga ---
get_bedolaga_backup_info() {
    local backup_file="$1"
    
    if [[ ! -f "$backup_file" ]]; then
        return 1
    fi
    
    # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ metadata.json Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»
    local metadata=$(tar -xzf "$backup_file" -O metadata.json 2>/dev/null)
    
    if [[ -z "$metadata" ]]; then
        echo "ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹"
        return 1
    fi
    
    # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ğ±ĞµĞ· jq
    local timestamp=$(echo "$metadata" | grep -o '"timestamp": *"[^"]*"' | head -1 | sed 's/.*"\([^"]*\)".*/\1/')
    local tables=$(echo "$metadata" | grep -o '"tables_count": *[0-9]*' | head -1 | sed 's/.*: *//')
    local records=$(echo "$metadata" | grep -o '"total_records": *[0-9]*' | head -1 | sed 's/.*: *//')
    local backup_type=$(echo "$metadata" | grep -o '"backup_type": *"[^"]*"' | head -1 | sed 's/.*"\([^"]*\)".*/\1/')
    
    echo "Ğ”Ğ°Ñ‚Ğ°: ${timestamp:-Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾}"
    echo "Ğ¢Ğ¸Ğ¿: ${backup_type:-Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾}"
    echo "Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†: ${tables:-?}, Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹: ${records:-?}"
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ˜Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº .env Ñ„Ğ°Ğ¹Ğ»Ğ° Bedolaga ---
find_bedolaga_env() {
    debug_log "MIGRATE" "=== find_bedolaga_env() ==="
    local found_env=""
    
    # ĞœĞµÑ‚Ğ¾Ğ´ 1: ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ğ¼ Docker ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ°Ğ¼
    # Bedolaga Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ¸Ğ¼ĞµĞµÑ‚ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹: bedolaga-bot, bedolaga-db Ğ¸Ğ»Ğ¸ shop-bot, shop-bot-db
    debug_log "MIGRATE" "Method 1: Searching by running Docker containers..."
    
    local bedolaga_keywords=("bedolaga" "shop-bot" "shopbot")
    local running_containers=$(docker ps --format '{{.Names}}|{{.Image}}' 2>/dev/null)
    
    for container in $running_containers; do
        local name="${container%%|*}"
        local image="${container##*|}"
        
        # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹ RWP-Shop Ğ¸ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸
        [[ "$name" =~ rwp_shop|telegram-shop|remnawave ]] && continue
        [[ "$image" =~ rwp_shop|remnawave ]] && continue
        
        # Ğ˜Ñ‰ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹ Bedolaga
        for keyword in "${bedolaga_keywords[@]}"; do
            if [[ "${name,,}" =~ $keyword || "${image,,}" =~ $keyword ]]; then
                debug_log "MIGRATE" "Found Bedolaga container: $name"
                
                # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ working_dir Ğ¸Ğ· docker inspect
                local working_dir=$(docker inspect -f '{{ index .Config.Labels "com.docker.compose.project.working_dir" }}' "$name" 2>/dev/null)
                
                if [[ -n "$working_dir" && -f "$working_dir/.env" ]]; then
                    found_env="$working_dir/.env"
                    debug_log "MIGRATE" "Found .env via container label: $found_env"
                    echo "$found_env"
                    return 0
                fi
            fi
        done
    done
    
    # ĞœĞµÑ‚Ğ¾Ğ´ 2: ĞŸĞ¾Ğ¸ÑĞº docker-compose Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ñ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼Ğ¸ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼Ğ¸ Bedolaga
    debug_log "MIGRATE" "Method 2: Searching by docker-compose files..."
    
    local search_paths=("/opt" "/root" "/home")
    for base_path in "${search_paths[@]}"; do
        [[ ! -d "$base_path" ]] && continue
        
        while IFS= read -r compose_file; do
            [[ -z "$compose_file" ]] && continue
            local dir=$(dirname "$compose_file")
            
            # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ RWP-Shop
            [[ "$dir" =~ private-remnawave|rwp-shop|telegram-shop ]] && continue
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ compose Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ½Ğ° ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Bedolaga
            if grep -qiE "bedolaga|shop.?bot" "$compose_file" 2>/dev/null; then
                if [[ -f "$dir/.env" ]]; then
                    # Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°: Ğ² .env Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Bedolaga
                    if grep -qE "^(BOT_TOKEN|TELEGRAM_BOT_TOKEN)=" "$dir/.env" 2>/dev/null; then
                        found_env="$dir/.env"
                        debug_log "MIGRATE" "Found .env via compose content: $found_env"
                        echo "$found_env"
                        return 0
                    fi
                fi
            fi
        done < <(find "$base_path" -maxdepth 3 -type f \( -name "docker-compose.yml" -o -name "docker-compose.yaml" -o -name "compose.yaml" \) 2>/dev/null)
    done
    
    # ĞœĞµÑ‚Ğ¾Ğ´ 3: ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¼ Ğ¿ÑƒÑ‚ÑĞ¼ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Bedolaga
    debug_log "MIGRATE" "Method 3: Searching by standard paths..."
    
    local standard_paths=(
        "/opt/bedolaga-bot"
        "/opt/bedolaga"
        "/opt/shop-bot"
        "/opt/shopbot"
        "/opt/telegram-shop-bot"
        "/root/bedolaga-bot"
        "/root/shop-bot"
        "/home/*/bedolaga-bot"
        "/home/*/shop-bot"
    )
    
    for path_pattern in "${standard_paths[@]}"; do
        # Ğ Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ glob-Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹
        for path in $path_pattern; do
            if [[ -d "$path" && -f "$path/.env" ]]; then
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾ ĞĞ• RWP-Shop
                if ! grep -q "REMNAWAVE_MODE=" "$path/.env" 2>/dev/null; then
                    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Bedolaga
                    if grep -qE "^(BOT_TOKEN|TELEGRAM_BOT_TOKEN|ADMIN_IDS)=" "$path/.env" 2>/dev/null; then
                        found_env="$path/.env"
                        debug_log "MIGRATE" "Found .env via standard path: $found_env"
                        echo "$found_env"
                        return 0
                    fi
                fi
            fi
        done
    done
    
    # ĞœĞµÑ‚Ğ¾Ğ´ 4: Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº .env Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ñ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸
    debug_log "MIGRATE" "Method 4: Global search for .env files..."
    
    while IFS= read -r env_file; do
        [[ -z "$env_file" ]] && continue
        local dir=$(dirname "$env_file")
        
        # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ RWP-Shop
        [[ "$dir" =~ private-remnawave|rwp-shop|rwp_shop|lazarus ]] && continue
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Bedolaga (ADMIN_IDS ĞµÑÑ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² Bedolaga)
        if grep -qE "^ADMIN_IDS=" "$env_file" 2>/dev/null; then
            found_env="$env_file"
            debug_log "MIGRATE" "Found .env via global search (ADMIN_IDS): $found_env"
            echo "$found_env"
            return 0
        fi
        
        # ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°: Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ REDIS_HOST (Bedolaga Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Redis, RWP-Shop â€” Ğ½ĞµÑ‚)
        if grep -qE "^REDIS_HOST=" "$env_file" 2>/dev/null && grep -qE "^BOT_TOKEN=" "$env_file" 2>/dev/null; then
            found_env="$env_file"
            debug_log "MIGRATE" "Found .env via global search (REDIS): $found_env"
            echo "$found_env"
            return 0
        fi
    done < <(find /opt /root /home -maxdepth 4 -name ".env" -type f 2>/dev/null)
    
    debug_log "MIGRATE" "No Bedolaga .env found"
    return 1
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ˜Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº .env Ñ„Ğ°Ğ¹Ğ»Ğ° RWP-Shop ---
find_rwp_shop_env() {
    debug_log "MIGRATE" "=== find_rwp_shop_env() ==="
    local found_path=""
    
    # ĞœĞµÑ‚Ğ¾Ğ´ 1: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑƒĞ¶Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğ¹ BOT_PATH Ğ¸Ğ· LAZARUS
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" && -f "$BOT_PATH/.env" ]]; then
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾ RWP-Shop (ĞµÑÑ‚ÑŒ REMNAWAVE_MODE Ğ¸Ğ»Ğ¸ REMNAWAVE_URL)
        if grep -qE "^(REMNAWAVE_MODE|REMNAWAVE_URL)=" "$BOT_PATH/.env" 2>/dev/null; then
            debug_log "MIGRATE" "Using configured BOT_PATH: $BOT_PATH"
            echo "$BOT_PATH"
            return 0
        fi
    fi
    
    # ĞœĞµÑ‚Ğ¾Ğ´ 2: ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ğ¼ Docker ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ°Ğ¼ RWP-Shop
    debug_log "MIGRATE" "Method 2: Searching by running Docker containers..."
    
    local rwp_keywords=("rwp_shop" "telegram-shop" "remnawave-telegram-shop")
    local running_containers=$(docker ps --format '{{.Names}}|{{.Image}}' 2>/dev/null)
    
    for container in $running_containers; do
        local name="${container%%|*}"
        local image="${container##*|}"
        
        # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸ Ğ‘Ğ” ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹
        [[ "$name" =~ remnawave-backend|remnawave-subscription|_db$ ]] && continue
        [[ "$image" =~ remnawave/backend|postgres ]] && continue
        
        # Ğ˜Ñ‰ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹ RWP-Shop
        for keyword in "${rwp_keywords[@]}"; do
            if [[ "${name,,}" =~ $keyword || "${image,,}" =~ $keyword ]]; then
                debug_log "MIGRATE" "Found RWP-Shop container: $name"
                
                # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ working_dir Ğ¸Ğ· docker inspect
                local working_dir=$(docker inspect -f '{{ index .Config.Labels "com.docker.compose.project.working_dir" }}' "$name" 2>/dev/null)
                
                if [[ -n "$working_dir" && -d "$working_dir" ]]; then
                    found_path="$working_dir"
                    debug_log "MIGRATE" "Found path via container label: $found_path"
                    echo "$found_path"
                    return 0
                fi
            fi
        done
    done
    
    # ĞœĞµÑ‚Ğ¾Ğ´ 3: Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸ RWP-Shop
    debug_log "MIGRATE" "Method 3: Searching by standard paths..."
    
    local standard_paths=(
        "/opt/private-remnawave-telegram-shop-bot"
        "/opt/rwp-shop"
        "/opt/rwp_shop"
        "/opt/telegram-shop"
        "/opt/remnawave-telegram-shop-bot"
        "/root/private-remnawave-telegram-shop-bot"
        "/root/rwp-shop"
    )
    
    for path in "${standard_paths[@]}"; do
        if [[ -d "$path" ]]; then
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ compose Ñ„Ğ°Ğ¹Ğ»Ğ°
            if [[ -f "$path/compose.yaml" || -f "$path/docker-compose.yml" ]]; then
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ .env Ğ½Ğ° Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ RWP-Shop
                if [[ -f "$path/.env" ]]; then
                    if grep -qE "^(REMNAWAVE_MODE|REMNAWAVE_URL|REMNAWAVE_TOKEN)=" "$path/.env" 2>/dev/null; then
                        found_path="$path"
                        debug_log "MIGRATE" "Found path via standard path: $found_path"
                        echo "$found_path"
                        return 0
                    fi
                else
                    # Ğ•ÑÑ‚ÑŒ Ğ¿Ğ°Ğ¿ĞºĞ°, Ğ½Ğ¾ Ğ½ĞµÑ‚ .env â€” ÑÑ‚Ğ¾ Ñ‚Ğ¾Ğ¶Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¸Ñ‚ (ÑĞ¾Ğ·Ğ´Ğ°Ğ´Ğ¸Ğ¼)
                    found_path="$path"
                    debug_log "MIGRATE" "Found path (no .env yet): $found_path"
                    echo "$found_path"
                    return 0
                fi
            fi
        fi
    done
    
    # ĞœĞµÑ‚Ğ¾Ğ´ 4: ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ docker-compose Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼ Ñ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ°Ğ¼Ğ¸ RWP-Shop
    debug_log "MIGRATE" "Method 4: Searching by compose files..."
    
    local search_paths=("/opt" "/root")
    for base_path in "${search_paths[@]}"; do
        [[ ! -d "$base_path" ]] && continue
        
        while IFS= read -r compose_file; do
            [[ -z "$compose_file" ]] && continue
            local dir=$(dirname "$compose_file")
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ Ğ½Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ‹ RWP-Shop
            if grep -qE "image:.*rwp_shop|image:.*telegram-shop" "$compose_file" 2>/dev/null; then
                found_path="$dir"
                debug_log "MIGRATE" "Found path via compose image: $found_path"
                echo "$found_path"
                return 0
            fi
        done < <(find "$base_path" -maxdepth 3 -type f \( -name "docker-compose.yml" -o -name "docker-compose.yaml" -o -name "compose.yaml" \) 2>/dev/null)
    done
    
    debug_log "MIGRATE" "No RWP-Shop path found"
    return 1
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ£ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ .env Bedolaga (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾) ---
migrate_settings_configure_env_source() {
    clear_screen
    echo -e "${CYAN}${BOLD}â•â•â• Ğ£ĞšĞĞ—ĞĞ¢Ğ¬ .ENV BEDOLAGA (ĞĞŸĞ¦Ğ˜ĞĞĞĞ›Ğ¬ĞĞ) â•â•â•${RESET}"
    echo ""
    echo -e "${GRAY}Ğ¤Ğ°Ğ¹Ğ» .env Bedolaga ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ¸ Ğ¿Ğ°Ñ€Ğ¾Ğ»Ğ¸ (BOT_TOKEN, DB credentials).${RESET}"
    echo -e "${GRAY}Ğ­Ñ‚Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ĞĞ• Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑÑ Ğ² Ğ±ÑĞºĞ°Ğ¿-Ğ°Ñ€Ñ…Ğ¸Ğ²Ğµ Ğ¿Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸.${RESET}"
    echo ""
    
    # ĞĞ²Ñ‚Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº
    print_message "INFO" "ĞŸĞ¾Ğ¸ÑĞº .env Ñ„Ğ°Ğ¹Ğ»Ğ° Bedolaga..."
    
    local found_env=$(find_bedolaga_env)
    
    if [[ -n "$found_env" && -f "$found_env" ]]; then
        local vars_count=$(grep -c "^[A-Z].*=" "$found_env" 2>/dev/null || echo "0")
        echo -e "âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½: ${GREEN}$found_env${RESET} ($vars_count Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ…)"
        echo ""
        read -erp "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞµĞ³Ğ¾? (Y/n): " use_env
        if [[ ! "$use_env" =~ ^[Nn]$ ]]; then
            MIGRATION_SOURCE_ENV_FILE="$found_env"
            print_message "SUCCESS" "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½: $MIGRATION_SOURCE_ENV_FILE"
            read -erp "Enter..." dummy
            return 0
        fi
    else
        echo -e "${YELLOW}âš ï¸  ĞĞ²Ñ‚Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº Ğ½Ğµ Ğ½Ğ°ÑˆÑ‘Ğ» .env Ñ„Ğ°Ğ¹Ğ» Bedolaga${RESET}"
    fi
    
    echo ""
    echo "Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸:"
    echo "  â€¢ /opt/bedolaga/.env"
    echo "  â€¢ /opt/vpn-bot/.env"
    echo "  â€¢ /root/bedolaga/.env"
    echo ""
    read -erp "ĞŸÑƒÑ‚ÑŒ Ğº .env (Ğ¸Ğ»Ğ¸ Enter Ğ´Ğ»Ñ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸): " manual_env
    
    if [[ -n "$manual_env" ]]; then
        if [[ -f "$manual_env" ]]; then
            MIGRATION_SOURCE_ENV_FILE="$manual_env"
            print_message "SUCCESS" "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½: $MIGRATION_SOURCE_ENV_FILE"
        else
            print_message "ERROR" "Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: $manual_env"
        fi
    else
        MIGRATION_SOURCE_ENV_FILE=""
        print_message "INFO" "ĞŸÑƒÑ‚ÑŒ Ğº .env Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½"
    fi
    
    read -erp "Enter..." dummy
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿ÑƒÑ‚ĞµĞ¹ Ğ´Ğ»Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº (LEGACY) ---
migrate_settings_configure_paths() {
    clear_screen
    echo -e "${CYAN}${BOLD}â•â•â• ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ ĞŸĞ£Ğ¢Ğ•Ğ™ Ğ”Ğ›Ğ¯ ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ˜ ĞĞĞ¡Ğ¢Ğ ĞĞ•Ğš â•â•â•${RESET}"
    echo ""
    
    print_message "INFO" "Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ°Ğ²Ñ‚Ğ¾Ğ¿Ğ¾Ğ¸ÑĞºĞ°..."
    echo ""
    
    # === Ğ¡ĞĞĞ§ĞĞ›Ğ Ğ˜Ğ©Ğ•Ğœ ĞŸĞ Ğ˜ĞĞœĞĞ˜Ğš (RWP-Shop) - Ğ¾Ğ½ Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ±ÑĞºĞ°Ğ¿Ğ° ===
    echo -e "${YELLOW}=== ĞŸĞ Ğ˜ĞĞœĞĞ˜Ğš (RWP-Shop) ===${RESET}"
    
    local found_rwp=$(find_rwp_shop_env)
    
    if [[ -n "$found_rwp" && -d "$found_rwp" ]]; then
        echo -e "âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ° Ğ¿Ğ°Ğ¿ĞºĞ°: ${GREEN}$found_rwp${RESET}"
        
        if [[ -f "$found_rwp/.env" ]]; then
            local vars_count=$(grep -c "^[A-Z].*=" "$found_rwp/.env" 2>/dev/null || echo "0")
            echo -e "   .env Ñ„Ğ°Ğ¹Ğ»: ${GREEN}ĞµÑÑ‚ÑŒ${RESET} ($vars_count Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ…)"
        else
            echo -e "   .env Ñ„Ğ°Ğ¹Ğ»: ${YELLOW}Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚${RESET} (Ğ±ÑƒĞ´ĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½)"
        fi
        
        read -erp "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞµÑ‘? (Y/n): " use_found
        if [[ ! "$use_found" =~ ^[Nn]$ ]]; then
            MIGRATION_TARGET_BOT_PATH="$found_rwp"
            MIGRATION_TARGET_ENV_FILE="$found_rwp/.env"
        fi
    else
        echo -e "${YELLOW}âš ï¸  ĞĞ²Ñ‚Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº Ğ½Ğµ Ğ½Ğ°ÑˆÑ‘Ğ» Ğ¿Ğ°Ğ¿ĞºÑƒ RWP-Shop${RESET}"
    fi
    
    if [[ -z "$MIGRATION_TARGET_BOT_PATH" ]]; then
        echo ""
        echo "Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸:"
        echo "  â€¢ /opt/private-remnawave-telegram-shop-bot"
        echo "  â€¢ /opt/rwp-shop"
        echo ""
        read -erp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ RWP-Shop Ğ±Ğ¾Ñ‚Ğ°: " MIGRATION_TARGET_BOT_PATH
        MIGRATION_TARGET_ENV_FILE="$MIGRATION_TARGET_BOT_PATH/.env"
    fi
    
    if [[ ! -d "$MIGRATION_TARGET_BOT_PATH" ]]; then
        print_message "ERROR" "ĞŸĞ°Ğ¿ĞºĞ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°: $MIGRATION_TARGET_BOT_PATH"
        read -erp "Enter..." dummy
        return 1
    fi
    
    echo ""
    
    # === Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜Ğš: ĞÑ€Ñ…Ğ¸Ğ² Ğ±ÑĞºĞ°Ğ¿Ğ° Bedolaga (Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚!) ===
    echo -e "${YELLOW}=== Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜Ğš (ĞÑ€Ñ…Ğ¸Ğ² Ğ±ÑĞºĞ°Ğ¿Ğ° Bedolaga) ===${RESET}"
    echo -e "${GRAY}ĞÑ€Ñ…Ğ¸Ğ² ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸Ğ· Ğ°Ğ´Ğ¼Ğ¸Ğ½-Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸ Bedolaga${RESET}"
    echo ""
    
    local found_backup=$(find_bedolaga_backup)
    
    if [[ -n "$found_backup" && -f "$found_backup" ]]; then
        echo -e "âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½ Ğ°Ñ€Ñ…Ğ¸Ğ²: ${GREEN}$found_backup${RESET}"
        
        # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ±ÑĞºĞ°Ğ¿Ğµ
        local backup_info=$(get_bedolaga_backup_info "$found_backup")
        echo -e "   ${GRAY}$backup_info${RESET}" | head -3
        
        read -erp "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞµĞ³Ğ¾? (Y/n): " use_backup
        if [[ ! "$use_backup" =~ ^[Nn]$ ]]; then
            MIGRATION_SOURCE_BACKUP_FILE="$found_backup"
        fi
    else
        echo -e "${YELLOW}âš ï¸  ĞÑ€Ñ…Ğ¸Ğ² Ğ±ÑĞºĞ°Ğ¿Ğ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸${RESET}"
    fi
    
    if [[ -z "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        echo ""
        echo "Ğ“Ğ´Ğµ Ğ¸ÑĞºĞ°Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ² backup_*.tar.gz:"
        echo "  â€¢ Ğ’ Ğ¿Ğ°Ğ¿ĞºĞµ Ğ±Ğ¾Ñ‚Ğ° Bedolaga: /opt/bedolaga-bot/data/backups/"
        echo "  â€¢ Ğ’ Ğ¿Ğ°Ğ¿ĞºĞµ Ñ€ÑĞ´Ğ¾Ğ¼ Ñ RWP-Shop"
        echo "  â€¢ Ğ¡ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ· Telegram (ĞµÑĞ»Ğ¸ Ğ±Ğ¾Ñ‚ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞ» Ğ±ÑĞºĞ°Ğ¿Ñ‹)"
        echo ""
        read -erp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ°Ñ€Ñ…Ğ¸Ğ²Ñƒ Ğ±ÑĞºĞ°Ğ¿Ğ° (Ğ¸Ğ»Ğ¸ Enter Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°): " manual_backup
        
        if [[ -n "$manual_backup" && -f "$manual_backup" ]]; then
            MIGRATION_SOURCE_BACKUP_FILE="$manual_backup"
        fi
    fi
    
    # === ĞĞŸĞ¦Ğ˜ĞĞĞĞ›Ğ¬ĞĞ: .env Ñ„Ğ°Ğ¹Ğ» Bedolaga (Ğ´Ğ»Ñ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº) ===
    echo ""
    echo -e "${YELLOW}=== ĞĞŸĞ¦Ğ˜ĞĞĞĞ›Ğ¬ĞĞ: .env Ñ„Ğ°Ğ¹Ğ» Bedolaga ===${RESET}"
    echo -e "${GRAY}Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ¸ Ğ¿Ğ°Ñ€Ğ¾Ğ»Ğ¸ (BOT_TOKEN, DB credentials)${RESET}"
    echo ""
    
    local found_env=$(find_bedolaga_env)
    
    if [[ -n "$found_env" && -f "$found_env" ]]; then
        echo -e "âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½ .env: ${GREEN}$found_env${RESET}"
        
        read -erp "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞµĞ³Ğ¾? (Y/n): " use_env
        if [[ ! "$use_env" =~ ^[Nn]$ ]]; then
            MIGRATION_SOURCE_ENV_FILE="$found_env"
        fi
    else
        echo -e "${YELLOW}âš ï¸  .env Ñ„Ğ°Ğ¹Ğ» Bedolaga Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½${RESET}"
        echo "ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ (Ñ‚Ğ¾ĞºĞµĞ½Ñ‹) Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚ Ğ²Ğ²ĞµÑÑ‚Ğ¸ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ"
    fi
    
    if [[ -z "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        read -erp "ĞŸÑƒÑ‚ÑŒ Ğº .env Bedolaga (Ğ¸Ğ»Ğ¸ Enter Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°): " manual_env
        if [[ -n "$manual_env" && -f "$manual_env" ]]; then
            MIGRATION_SOURCE_ENV_FILE="$manual_env"
        fi
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ¸Ğ½ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº ÑƒĞºĞ°Ğ·Ğ°Ğ½
    if [[ -z "$MIGRATION_SOURCE_BACKUP_FILE" && -z "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        print_message "ERROR" "ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½ Ğ½Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ğ² Ğ±ÑĞºĞ°Ğ¿Ğ°, Ğ½Ğ¸ .env Ñ„Ğ°Ğ¹Ğ» Bedolaga"
        read -erp "Enter..." dummy
        return 1
    fi
    
    # === ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° .env Ğ¿Ñ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸ĞºĞ° ===
    if [[ ! -f "$MIGRATION_TARGET_ENV_FILE" ]]; then
        print_message "WARN" "Ğ¤Ğ°Ğ¹Ğ» .env Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² $MIGRATION_TARGET_BOT_PATH"
        read -erp "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ .env Ñ„Ğ°Ğ¹Ğ»? (y/N): " create_new
        if [[ "$create_new" =~ ^[Yy]$ ]]; then
            touch "$MIGRATION_TARGET_ENV_FILE"
            chmod 600 "$MIGRATION_TARGET_ENV_FILE"
            print_message "SUCCESS" "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½: $MIGRATION_TARGET_ENV_FILE"
        else
            return 1
        fi
    fi
    
    # === ĞĞ²Ñ‚Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ğ‘Ğ” RWP-Shop ===
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        echo ""
        echo -e "${YELLOW}=== ĞšĞĞĞ¢Ğ•Ğ™ĞĞ•Ğ  Ğ‘Ğ” RWP-Shop ===${RESET}"
        
        local detected_db=""
        for pattern in "rwp_shop_db" "telegram-shop-db" "telegram-shop_db"; do
            detected_db=$(docker ps --format '{{.Names}}' 2>/dev/null | grep -iE "^${pattern}$" | head -1)
            [[ -n "$detected_db" ]] && break
        done
        
        if [[ -n "$detected_db" ]]; then
            echo -e "âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€: ${GREEN}$detected_db${RESET}"
            read -erp "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞµĞ³Ğ¾? (Y/n): " use_db
            if [[ ! "$use_db" =~ ^[Nn]$ ]]; then
                MIGRATION_TARGET_CONTAINER="$detected_db"
                MIGRATION_TARGET_DB="${MIGRATION_TARGET_DB:-postgres}"
                MIGRATION_TARGET_USER="${MIGRATION_TARGET_USER:-postgres}"
            fi
        else
            echo -e "${YELLOW}âš ï¸  ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ” Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½${RESET}"
        fi
    fi
    
    # === Ğ˜Ğ¢ĞĞ“ĞĞ’ĞĞ¯ ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯ ===
    echo ""
    print_message "SUCCESS" "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿ÑƒÑ‚ĞµĞ¹ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°"
    echo ""
    echo -e "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
    echo -e "â”‚ ${BOLD}Ğ˜Ğ¢ĞĞ“ĞĞ’ĞĞ¯ ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯${RESET}                                  â”‚"
    echo -e "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
    if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        echo -e "â”‚ ĞÑ€Ñ…Ğ¸Ğ²:  ${GREEN}$(basename "$MIGRATION_SOURCE_BACKUP_FILE")${RESET}"
    else
        echo -e "â”‚ ĞÑ€Ñ…Ğ¸Ğ²:  ${YELLOW}ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½${RESET}"
    fi
    if [[ -n "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        echo -e "â”‚ .env:   ${GREEN}$MIGRATION_SOURCE_ENV_FILE${RESET}"
    else
        echo -e "â”‚ .env:   ${YELLOW}ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½${RESET}"
    fi
    echo -e "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
    echo -e "â”‚ ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº .env: ${GREEN}$MIGRATION_TARGET_ENV_FILE${RESET}"
    if [[ -n "$MIGRATION_TARGET_CONTAINER" ]]; then
        echo -e "â”‚ ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ”:  ${GREEN}$MIGRATION_TARGET_CONTAINER${RESET}"
    else
        echo -e "â”‚ ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ”:  ${YELLOW}ĞĞµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
    fi
    echo -e "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
    
    read -erp "Enter..." dummy
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ´Ğ»Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ ---
migrate_settings_analyze() {
    debug_log "MIGRATE" "Analyzing settings for migration"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°
    if [[ -z "$MIGRATION_SOURCE_ENV_FILE" && -z "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        print_message "ERROR" "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ (Ğ½Ğ¸ .env, Ğ½Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ğ²)"
        return 1
    fi
    
    # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸Ğ· Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²
    declare -A source_settings
    declare -A backup_settings
    local source_desc=""
    
    # 1) Ğ˜Ğ· .env Ñ„Ğ°Ğ¹Ğ»Ğ° Bedolaga
    if [[ -n "$MIGRATION_SOURCE_ENV_FILE" && -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        read_env_file "$MIGRATION_SOURCE_ENV_FILE" source_settings
        source_desc=".env: $MIGRATION_SOURCE_ENV_FILE"
    fi
    
    # 2) Ğ˜Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Ğ±ÑĞºĞ°Ğ¿Ğ° (system_settings)
    if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        if extract_bedolaga_backup "$MIGRATION_SOURCE_BACKUP_FILE" 2>/dev/null; then
            read_all_bedolaga_settings backup_settings
            [[ -n "$source_desc" ]] && source_desc+="\n"
            source_desc+="ĞÑ€Ñ…Ğ¸Ğ²: $(basename "$MIGRATION_SOURCE_BACKUP_FILE") (${#backup_settings[@]} Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ¸Ğ· Ğ‘Ğ”)"
        fi
    fi
    
    local total_source=${#source_settings[@]}
    local total_backup=${#backup_settings[@]}
    local can_migrate_env=0
    local can_migrate_db=0
    local can_migrate_from_backup=0
    local no_mapping=0
    
    # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¸Ğ· .env Ñ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ¾Ğ¼
    for key in "${!source_settings[@]}"; do
        if [[ -n "${SETTINGS_ENV_TO_ENV[$key]}" ]]; then
            ((can_migrate_env++))
        elif [[ -n "${SETTINGS_ENV_TO_DB[$key]}" ]]; then
            ((can_migrate_db++))
        else
            ((no_mapping++))
        fi
    done
    
    # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Ñ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ¾Ğ¼
    for key in "${!backup_settings[@]}"; do
        if [[ -n "${BEDOLAGA_BACKUP_TO_RWP[$key]}" ]]; then
            ((can_migrate_from_backup++))
        fi
    done
    
    echo ""
    echo -e "${CYAN}${BOLD}â•â•â• ĞĞĞĞ›Ğ˜Ğ— ĞĞĞ¡Ğ¢Ğ ĞĞ•Ğš â•â•â•${RESET}"
    echo ""
    echo -e "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸:\n${GREEN}$source_desc${RESET}"
    echo ""
    echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
    if [[ $total_source -gt 0 ]]; then
        printf "â”‚  ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ² .env Bedolaga:            %7s   â”‚\n" "$total_source"
        printf "â”‚    -> ĞŸĞµÑ€ĞµĞ½Ğ¾Ñ Ğ² .env:                %7s   â”‚\n" "$can_migrate_env"
        printf "â”‚    -> ĞŸĞµÑ€ĞµĞ½Ğ¾Ñ Ğ² settings DB:         %7s   â”‚\n" "$can_migrate_db"
        printf "â”‚    -> Ğ‘ĞµĞ· Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ°:                   %7s   â”‚\n" "$no_mapping"
    fi
    if [[ $total_backup -gt 0 ]]; then
        printf "â”‚  ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ² Ğ°Ñ€Ñ…Ğ¸Ğ²Ğµ:                   %7s   â”‚\n" "$total_backup"
        printf "â”‚    -> ĞŸĞµÑ€ĞµĞ½Ğ¾Ñ Ğ² settings DB:         %7s   â”‚\n" "$can_migrate_from_backup"
    fi
    echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
    echo ""
    
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ° .env â†’ .env ---
migrate_settings_show_env_mapping() {
    # Ğ•ÑĞ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ°Ñ€Ñ…Ğ¸Ğ² - Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
    if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        clear_screen
        echo -e "${CYAN}${BOLD}â•â•â• ĞœĞĞŸĞŸĞ˜ĞĞ“ ĞĞĞ¡Ğ¢Ğ ĞĞ•Ğš Ğ˜Ğ— ĞĞ Ğ¥Ğ˜Ğ’Ğ â•â•â•${RESET}"
        echo ""
        echo -e "${GRAY}Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: $(basename "$MIGRATION_SOURCE_BACKUP_FILE")${RESET}"
        echo ""
        
        # Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ°Ñ€Ñ…Ğ¸Ğ² ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾
        if [[ -z "$MIGRATION_EXTRACTED_DIR" || ! -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
            if ! extract_bedolaga_backup "$MIGRATION_SOURCE_BACKUP_FILE" 2>/dev/null; then
                print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ²"
                read -erp "Enter..." dummy
                return 1
            fi
        fi
        
        # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
        if [[ -n "$MIGRATION_EXTRACTED_DIR" && -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
            # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
            declare -A backup_settings
            read_all_bedolaga_settings backup_settings
            
            echo -e "${GREEN}=== ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸Ğ· system_settings â†’ RWP-Shop ===${RESET}"
            echo ""
            printf "%-35s â”‚ %-30s â”‚ %s\n" "Bedolaga (backup)" "RWP-Shop" "Value"
            echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
            
            local found_count=0
            local mapped_count=0
            local output_lines=()
            
            # Ğ˜Ñ‚ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°Ğ¼ Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
            for bedolaga_key in "${!backup_settings[@]}"; do
                local rwp_key="${BEDOLAGA_BACKUP_TO_RWP[$bedolaga_key]:-}"
                local value="${backup_settings[$bedolaga_key]}"
                
                # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ñƒ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
                [[ ${#value} -gt 20 ]] && value="${value:0:17}..."
                
                ((found_count++))
                if [[ -n "$rwp_key" ]]; then
                    output_lines+=("$(printf "%-35s â”‚ ${GREEN}%-30s${RESET} â”‚ %s" "$bedolaga_key" "$rwp_key" "$value")")
                    ((mapped_count++))
                else
                    output_lines+=("$(printf "%-35s â”‚ ${GRAY}%-30s${RESET} â”‚ %s" "$bedolaga_key" "(no mapping)" "$value")")
                fi
            done
            
            # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼
            printf '%s\n' "${output_lines[@]}" | sort
            
            echo ""
            echo -e "Found in archive: ${GREEN}$found_count${RESET} settings"
            echo -e "With RWP-Shop mapping: ${GREEN}$mapped_count${RESET}"
        else
            print_message "WARN" "ĞÑ€Ñ…Ğ¸Ğ² Ğ½Ğµ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½ Ğ¸Ğ»Ğ¸ database.json Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½"
        fi
        
        echo ""
        read -erp "Enter..." dummy
        return 0
    fi
    
    # Ğ•ÑĞ»Ğ¸ .env Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½ - Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ·ĞºÑƒ
    if [[ -z "$MIGRATION_SOURCE_ENV_FILE" || ! -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        print_message "WARN" ".env Ñ„Ğ°Ğ¹Ğ» Bedolaga Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½"
        echo ""
        echo "Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ° Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ° .env â†’ .env Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ ÑƒĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¿ÑƒÑ‚ÑŒ Ğº .env Ñ„Ğ°Ğ¹Ğ»Ñƒ Bedolaga."
        echo "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ¿ÑƒĞ½ĞºÑ‚ 1 (ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿ÑƒÑ‚ĞµĞ¹) Ğ´Ğ»Ñ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°."
        echo ""
        echo -e "${GRAY}ĞŸĞ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ°: Ğ•ÑĞ»Ğ¸ Ğ²Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚Ğµ Ğ°Ñ€Ñ…Ğ¸Ğ² - Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑƒĞ¶Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ¸Ğ· system_settings.${RESET}"
        echo -e "${GRAY}ĞÑ€Ñ…Ğ¸Ğ² ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸Ğ· Ğ°Ğ´Ğ¼Ğ¸Ğ½-Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸ Bedolaga, Ğ° Ğ½Ğµ Ğ¸Ğ· .env Ñ„Ğ°Ğ¹Ğ»Ğ°.${RESET}"
        echo ""
        read -erp "Enter..." dummy
        return 1
    fi
    
    declare -A source_settings
    read_env_file "$MIGRATION_SOURCE_ENV_FILE" source_settings
    
    clear_screen
    echo -e "${CYAN}${BOLD}â•â•â• ĞœĞĞŸĞŸĞ˜ĞĞ“ .env â†’ .env (ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸) â•â•â•${RESET}"
    echo ""
    printf "%-30s â”‚ %-30s â”‚ %s\n" "Bedolaga" "RWP-Shop" "Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ"
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    
    for bedolaga_key in "${!SETTINGS_ENV_TO_ENV[@]}"; do
        local rwp_key="${SETTINGS_ENV_TO_ENV[$bedolaga_key]}"
        local value="${source_settings[$bedolaga_key]:-<Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¾>}"
        
        # ĞœĞ°ÑĞºĞ¸Ñ€ÑƒĞµĞ¼ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
        if [[ "$bedolaga_key" =~ TOKEN|SECRET|PASSWORD|KEY ]]; then
            if [[ -n "${source_settings[$bedolaga_key]}" ]]; then
                local masked="${value:0:6}***${value: -3}"
                value="$masked"
            fi
        fi
        
        # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ñƒ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
        [[ ${#value} -gt 25 ]] && value="${value:0:22}..."
        
        printf "%-30s â”‚ %-30s â”‚ %s\n" "$bedolaga_key" "$rwp_key" "$value"
    done
    
    echo ""
    read -erp "Enter..." dummy
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ° â†’ settings DB ---
migrate_settings_show_db_mapping() {
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°
    if [[ -z "$MIGRATION_SOURCE_ENV_FILE" && -z "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        print_message "ERROR" "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ (Ğ½Ğ¸ .env, Ğ½Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ğ²)"
        read -erp "Enter..." dummy
        return 1
    fi
    
    clear_screen
    echo -e "${CYAN}${BOLD}â•â•â• ĞœĞĞŸĞŸĞ˜ĞĞ“ â†’ settings DB â•â•â•${RESET}"
    echo ""
    
    # 1) ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° (Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚!)
    if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        echo -e "${GREEN}=== Ğ˜Ğ— ĞĞ Ğ¥Ğ˜Ğ’Ğ (system_settings â†’ settings) ===${RESET}"
        echo ""
        printf "%-35s â”‚ %-35s\n" "Bedolaga (backup)" "RWP-Shop settings.key"
        echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
        
        # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ğ² Ğ¼Ğ°ÑÑĞ¸Ğ² Ğ´Ğ»Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸
        local lines=()
        local mapped_count=0
        local unmapped_count=0
        
        for bedolaga_key in "${!BEDOLAGA_BACKUP_TO_RWP[@]}"; do
            local rwp_key="${BEDOLAGA_BACKUP_TO_RWP[$bedolaga_key]}"
            if [[ -n "$rwp_key" ]]; then
                lines+=("$(printf "%-35s â”‚ ${GREEN}%-35s${RESET}" "$bedolaga_key" "$rwp_key")")
                ((mapped_count++))
            else
                lines+=("$(printf "%-35s â”‚ ${GRAY}%-35s${RESET}" "$bedolaga_key" "(no mapping)")")
                ((unmapped_count++))
            fi
        done
        
        # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼
        printf '%s\n' "${lines[@]}" | sort
        
        echo ""
        echo -e "ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ¾Ğ² Ğ°Ñ€Ñ…Ğ¸Ğ²â†’Ğ‘Ğ”: ${GREEN}$mapped_count${RESET} | Ğ‘ĞµĞ· Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ°: ${GRAY}$unmapped_count${RESET}"
        echo ""
    fi
    
    # 2) ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸Ğ· .env
    if [[ -n "$MIGRATION_SOURCE_ENV_FILE" && -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        declare -A source_settings
        read_env_file "$MIGRATION_SOURCE_ENV_FILE" source_settings
        
        echo -e "${YELLOW}=== Ğ˜Ğ— .ENV (SETTINGS_ENV_TO_DB) ===${RESET}"
        echo ""
        printf "%-35s â”‚ %-35s â”‚ %s\n" "Bedolaga .env" "RWP-Shop settings.key" "Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ"
        echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
        
        local count=0
        for bedolaga_key in "${!SETTINGS_ENV_TO_DB[@]}"; do
            local db_key="${SETTINGS_ENV_TO_DB[$bedolaga_key]}"
            local value="${source_settings[$bedolaga_key]:-<Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¾>}"
            
            # ĞœĞ°ÑĞºĞ¸Ñ€ÑƒĞµĞ¼ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
            if [[ "$bedolaga_key" =~ TOKEN|SECRET|PASSWORD|KEY ]]; then
                if [[ -n "${source_settings[$bedolaga_key]}" ]]; then
                    local masked="${value:0:6}***${value: -3}"
                    value="$masked"
                fi
            fi
            
            # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ñƒ
            [[ ${#value} -gt 20 ]] && value="${value:0:17}..."
            
            printf "%-35s â”‚ %-35s â”‚ %s\n" "$bedolaga_key" "$db_key" "$value"
            ((count++))
        done
        
        echo ""
        echo "Ğ’ÑĞµĞ³Ğ¾ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ¾Ğ² .envâ†’Ğ‘Ğ”: $count"
    fi
    
    echo ""
    read -erp "Enter..." dummy
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ±ĞµĞ· Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ° ---
migrate_settings_show_no_mapping() {
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°
    if [[ -z "$MIGRATION_SOURCE_ENV_FILE" && -z "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        print_message "ERROR" "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ (Ğ½Ğ¸ .env, Ğ½Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ğ²)"
        read -erp "Enter..." dummy
        return 1
    fi
    
    clear_screen
    echo -e "${YELLOW}${BOLD}â•â•â• ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜ Ğ‘Ğ•Ğ— ĞĞĞĞ›ĞĞ“Ğ Ğ’ RWP-SHOP â•â•â•${RESET}"
    echo ""
    echo "Ğ­Ñ‚Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ĞĞ• Ğ±ÑƒĞ´ÑƒÑ‚ Ğ¿ĞµÑ€ĞµĞ½ĞµÑĞµĞ½Ñ‹ (Ğ½ĞµÑ‚ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ² RWP-Shop):"
    echo ""
    
    local count=0
    
    # 1) ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Ğ±ĞµĞ· Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ°
    if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        echo -e "${GREEN}=== Ğ˜Ğ— ĞĞ Ğ¥Ğ˜Ğ’Ğ (system_settings) ===${RESET}"
        echo ""
        
        # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
        if [[ -n "$MIGRATION_EXTRACTED_DIR" && -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
            declare -A backup_settings
            read_all_bedolaga_settings backup_settings
            
            local archive_count=0
            local lines=()
            for key in "${!backup_settings[@]}"; do
                local rwp_key="${BEDOLAGA_BACKUP_TO_RWP[$key]:-}"
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ğµ, Ñƒ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ½ĞµÑ‚ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ°
                if [[ -z "$rwp_key" ]]; then
                    local value="${backup_settings[$key]}"
                    
                    # ĞœĞ°ÑĞºĞ¸Ñ€ÑƒĞµĞ¼ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
                    if [[ "$key" =~ TOKEN|SECRET|PASSWORD|KEY ]]; then
                        [[ -n "$value" ]] && value="${value:0:6}***"
                    fi
                    
                    [[ ${#value} -gt 40 ]] && value="${value:0:37}..."
                    
                    lines+=("$(printf "  %-35s = %s" "$key" "$value")")
                    ((archive_count++))
                    ((count++))
                fi
            done
            
            # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼
            printf '%s\n' "${lines[@]}" | sort
            
            echo ""
            echo "Ğ‘ĞµĞ· Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ² Ğ°Ñ€Ñ…Ğ¸Ğ²Ğµ: $archive_count"
        else
            print_message "WARN" "ĞÑ€Ñ…Ğ¸Ğ² Ğ½Ğµ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½"
        fi
        echo ""
    fi
    
    # 2) ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸Ğ· .env Ğ±ĞµĞ· Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ°
    if [[ -n "$MIGRATION_SOURCE_ENV_FILE" && -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        echo -e "${YELLOW}=== Ğ˜Ğ— .ENV ===${RESET}"
        echo ""
        
        declare -A source_settings
        read_env_file "$MIGRATION_SOURCE_ENV_FILE" source_settings
        
        local env_count=0
        local env_lines=()
        for key in "${!source_settings[@]}"; do
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³
            if [[ -z "${SETTINGS_ENV_TO_ENV[$key]}" && -z "${SETTINGS_ENV_TO_DB[$key]}" ]]; then
                local value="${source_settings[$key]}"
                
                # ĞœĞ°ÑĞºĞ¸Ñ€ÑƒĞµĞ¼ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
                if [[ "$key" =~ TOKEN|SECRET|PASSWORD|KEY ]]; then
                    [[ -n "$value" ]] && value="${value:0:6}***"
                fi
                
                [[ ${#value} -gt 40 ]] && value="${value:0:37}..."
                
                env_lines+=("$(printf "  %-35s = %s" "$key" "$value")")
                ((env_count++))
                ((count++))
            fi
        done
        
        # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼
        printf '%s\n' "${env_lines[@]}" | sort
        
        echo ""
        echo "Ğ‘ĞµĞ· Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ² .env: $env_count"
    fi
    
    echo ""
    echo -e "${GRAY}Ğ’ÑĞµĞ³Ğ¾ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ±ĞµĞ· Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ°: $count${RESET}"
    echo ""
    read -erp "Enter..." dummy
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº ---
migrate_settings_execute() {
    debug_log "MIGRATE" "Starting settings migration"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°
    if [[ -z "$MIGRATION_SOURCE_BACKUP_FILE" && -z "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        print_message "ERROR" "ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½ Ğ½Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ğ² Ğ±ÑĞºĞ°Ğ¿Ğ°, Ğ½Ğ¸ .env Ñ„Ğ°Ğ¹Ğ» Bedolaga"
        return 1
    fi
    
    if [[ -z "$MIGRATION_TARGET_ENV_FILE" ]]; then
        print_message "ERROR" "ĞŸÑƒÑ‚ÑŒ Ğº Ğ¿Ñ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸ĞºÑƒ .env Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½"
        return 1
    fi
    
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        print_message "WARN" "ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ” RWP-Shop Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ â€” Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ² Ğ‘Ğ” Ğ½Ğµ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ¿ĞµÑ€ĞµĞ½ĞµÑĞµĞ½Ñ‹"
    fi
    
    echo ""
    echo -e "${RED}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo -e "${RED}${BOLD}  âš ï¸  Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•! ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ¯ ĞĞĞ¡Ğ¢Ğ ĞĞ•Ğš!               ${RESET}"
    echo -e "${RED}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo ""
    echo "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸:"
    [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" ]] && echo " â€¢ ĞÑ€Ñ…Ğ¸Ğ²: $(basename "$MIGRATION_SOURCE_BACKUP_FILE")"
    [[ -n "$MIGRATION_SOURCE_ENV_FILE" ]] && echo " â€¢ .env:  $MIGRATION_SOURCE_ENV_FILE"
    echo ""
    echo "Ğ‘ÑƒĞ´ÑƒÑ‚ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ñ‹:"
    echo " â€¢ Ğ¤Ğ°Ğ¹Ğ» .env: $MIGRATION_TARGET_ENV_FILE"
    [[ -n "$MIGRATION_TARGET_CONTAINER" ]] && echo " â€¢ Ğ‘Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: $MIGRATION_TARGET_CONTAINER / $MIGRATION_TARGET_DB"
    echo ""
    echo -e "${YELLOW}Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ Ğ±ÑĞºĞ°Ğ¿ RWP-Shop Ğ¿ĞµÑ€ĞµĞ´ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸ĞµĞ¼!${RESET}"
    echo ""
    read -erp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ 'SETTINGS' Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ: " confirm
    
    if [[ "$confirm" != "SETTINGS" ]]; then
        print_message "INFO" "ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ¼ĞµĞ½ĞµĞ½Ğ°"
        return 0
    fi
    
    local work_dir="$MIGRATION_WORK_DIR"
    [[ -z "$work_dir" ]] && work_dir="${BACKUP_DIR}/migration_settings_$(date +%Y%m%d_%H%M%S)"
    mkdir -p "$work_dir"
    
    # Ğ‘ÑĞºĞ°Ğ¿ Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğ³Ğ¾ .env
    if [[ -f "$MIGRATION_TARGET_ENV_FILE" ]]; then
        cp "$MIGRATION_TARGET_ENV_FILE" "$work_dir/target_env_backup.env"
        print_message "INFO" "Ğ‘ÑĞºĞ°Ğ¿ .env: $work_dir/target_env_backup.env"
    fi
    
    local env_migrated=0
    local db_migrated=0
    local backup_settings_migrated=0
    local defaults_used=0
    local errors=0
    
    # === Ğ­Ğ¢ĞĞŸ 1: Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²ĞºĞ° Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Bedolaga (ĞµÑĞ»Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ğ½) ===
    declare -A backup_settings
    if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
        print_message "INFO" "[1/3] Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²ĞºĞ° Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Bedolaga..."
        
        if extract_bedolaga_backup "$MIGRATION_SOURCE_BACKUP_FILE"; then
            # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ system_settings Ğ¸Ğ· Ğ±ÑĞºĞ°Ğ¿Ğ°
            read_all_bedolaga_settings backup_settings
            print_message "SUCCESS" "ĞŸÑ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ½Ğ¾ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ¸Ğ· Ğ±ÑĞºĞ°Ğ¿Ğ°: ${#backup_settings[@]}"
        else
            print_message "WARN" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ², Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼ Ğ±ĞµĞ· Ğ½ĞµĞ³Ğ¾"
        fi
    fi
    
    # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ .env Bedolaga (ĞµÑĞ»Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ğ½)
    declare -A env_settings
    if [[ -n "$MIGRATION_SOURCE_ENV_FILE" && -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        read_env_file "$MIGRATION_SOURCE_ENV_FILE" env_settings
    fi
    
    # === Ğ­Ğ¢ĞĞŸ 2: ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ² .env ===
    print_message "INFO" "[2/3] ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ² .env..."
    
    for bedolaga_key in "${!SETTINGS_ENV_TO_ENV[@]}"; do
        local rwp_key="${SETTINGS_ENV_TO_ENV[$bedolaga_key]}"
        local value=""
        local is_default=false
        
        # ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚: 1) .env Bedolaga â†’ 2) Ğ”ĞµÑ„Ğ¾Ğ»Ñ‚ Bedolaga â†’ 3) Ğ”ĞµÑ„Ğ¾Ğ»Ñ‚ RWP-Shop
        value="${env_settings[$bedolaga_key]:-}"
        
        if [[ -z "$value" ]]; then
            value="${BEDOLAGA_DEFAULTS[$bedolaga_key]:-}"
            [[ -n "$value" ]] && is_default=true
        fi
        
        if [[ -z "$value" ]]; then
            value="${RWP_SHOP_DEFAULTS[$rwp_key]:-}"
            [[ -n "$value" ]] && is_default=true
        fi
        
        if [[ -n "$value" ]]; then
            write_env_variable "$MIGRATION_TARGET_ENV_FILE" "$rwp_key" "$value"
            if $is_default; then
                debug_log "MIGRATE" "ENV: $bedolaga_key â†’ $rwp_key (DEFAULT: $value)"
                ((defaults_used++))
            else
                debug_log "MIGRATE" "ENV: $bedolaga_key â†’ $rwp_key = $value"
            fi
            ((env_migrated++))
        fi
    done
    
    print_message "SUCCESS" "ĞŸĞµÑ€ĞµĞ½ĞµÑĞµĞ½Ğ¾ Ğ² .env: $env_migrated Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ…"
    [[ $defaults_used -gt 0 ]] && echo -e "   ${GRAY}(Ğ¸Ğ· Ğ½Ğ¸Ñ… Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚Ğ½Ñ‹Ñ…: $defaults_used)${RESET}"
    
    # === Ğ­Ğ¢ĞĞŸ 3: ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ² Ğ‘Ğ” RWP-Shop ===
    if [[ -n "$MIGRATION_TARGET_CONTAINER" ]]; then
        print_message "INFO" "[3/3] ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ settings..."
        defaults_used=0
        
        local sql_file="$work_dir/settings_import.sql"
        echo "-- Settings migration: Bedolaga â†’ RWP-Shop" > "$sql_file"
        echo "-- Generated: $(date '+%Y-%m-%d %H:%M:%S')" >> "$sql_file"
        echo "-- Sources: backup=${MIGRATION_SOURCE_BACKUP_FILE:-none}, env=${MIGRATION_SOURCE_ENV_FILE:-none}" >> "$sql_file"
        echo "" >> "$sql_file"
        
        # 3a) Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ğ¼ Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Ğ±ÑĞºĞ°Ğ¿Ğ° (system_settings â†’ settings)
        if [[ ${#backup_settings[@]} -gt 0 ]]; then
            echo "-- From Bedolaga backup (system_settings):" >> "$sql_file"
            
            for backup_key in "${!backup_settings[@]}"; do
                local rwp_key="${BEDOLAGA_BACKUP_TO_RWP[$backup_key]:-}"
                
                # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ±ĞµĞ· Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ°
                [[ -z "$rwp_key" ]] && continue
                
                local value="${backup_settings[$backup_key]}"
                
                # Ğ­ĞºÑ€Ğ°Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ğ´Ğ¸Ğ½Ğ°Ñ€Ğ½Ñ‹Ğµ ĞºĞ°Ğ²Ñ‹Ñ‡ĞºĞ¸ Ğ´Ğ»Ñ SQL
                local escaped_value="${value//\'/\'\'}"
                
                # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ±ÑƒĞ»ĞµĞ²Ñ‹ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
                if [[ "$value" =~ ^(true|false|True|False|TRUE|FALSE|1|0)$ ]]; then
                    case "${value,,}" in
                        true|1) escaped_value="true" ;;
                        false|0) escaped_value="false" ;;
                    esac
                fi
                
                echo "INSERT INTO settings (key, value, created_at, updated_at) VALUES ('$rwp_key', '$escaped_value', NOW(), NOW())" >> "$sql_file"
                echo "ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value, updated_at = NOW();" >> "$sql_file"
                
                debug_log "MIGRATE" "BACKUPâ†’DB: $backup_key â†’ $rwp_key = $value"
                ((backup_settings_migrated++))
            done
        fi
        
        # 3b) Ğ—Ğ°Ñ‚ĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ğ¼ Ğ¸Ğ· .env (SETTINGS_ENV_TO_DB)
        if [[ ${#env_settings[@]} -gt 0 || ${#BEDOLAGA_DEFAULTS[@]} -gt 0 ]]; then
            echo "" >> "$sql_file"
            echo "-- From Bedolaga .env (SETTINGS_ENV_TO_DB):" >> "$sql_file"
            
            for bedolaga_key in "${!SETTINGS_ENV_TO_DB[@]}"; do
                local db_key="${SETTINGS_ENV_TO_DB[$bedolaga_key]}"
                local value=""
                local is_default=false
                
                # ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚: 1) Ğ£Ğ¶Ğµ ĞµÑÑ‚ÑŒ Ğ² backup_settings â†’ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ğ½Ğµ Ğ±Ñ‹Ğ»Ğ¾ Ğ»Ğ¸ ÑÑ‚Ğ¾ ÑƒĞ¶Ğµ Ğ¿ĞµÑ€ĞµĞ½ĞµÑĞµĞ½Ğ¾ Ğ¸Ğ· Ğ±ÑĞºĞ°Ğ¿Ğ°
                local already_from_backup=false
                for bk in "${!BEDOLAGA_BACKUP_TO_RWP[@]}"; do
                    if [[ "${BEDOLAGA_BACKUP_TO_RWP[$bk]}" == "$db_key" && -n "${backup_settings[$bk]:-}" ]]; then
                        already_from_backup=true
                        break
                    fi
                done
                
                $already_from_backup && continue
                
                # 2) .env Bedolaga â†’ 3) Ğ”ĞµÑ„Ğ¾Ğ»Ñ‚ Bedolaga â†’ 4) Ğ”ĞµÑ„Ğ¾Ğ»Ñ‚ RWP-Shop
                value="${env_settings[$bedolaga_key]:-}"
                
                if [[ -z "$value" ]]; then
                    value="${BEDOLAGA_DEFAULTS[$bedolaga_key]:-}"
                    [[ -n "$value" ]] && is_default=true
                fi
                
                if [[ -z "$value" ]]; then
                    value="${RWP_SHOP_DEFAULTS[$db_key]:-}"
                    [[ -n "$value" ]] && is_default=true
                fi
                
                if [[ -n "$value" ]]; then
                    local escaped_value="${value//\'/\'\'}"
                    
                    if [[ "$value" =~ ^(true|false|True|False|TRUE|FALSE|1|0)$ ]]; then
                        case "${value,,}" in
                            true|1) escaped_value="true" ;;
                            false|0) escaped_value="false" ;;
                        esac
                    fi
                    
                    echo "INSERT INTO settings (key, value, created_at, updated_at) VALUES ('$db_key', '$escaped_value', NOW(), NOW())" >> "$sql_file"
                    echo "ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value, updated_at = NOW();" >> "$sql_file"
                    
                    if $is_default; then
                        debug_log "MIGRATE" "ENVâ†’DB: $bedolaga_key â†’ $db_key (DEFAULT: $value)"
                        ((defaults_used++))
                    else
                        debug_log "MIGRATE" "ENVâ†’DB: $bedolaga_key â†’ $db_key = $value"
                    fi
                    ((db_migrated++))
                fi
            done
        fi
        
        # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼ SQL
        docker cp "$sql_file" "${MIGRATION_TARGET_CONTAINER}:/tmp/settings_import.sql"
        
        local sql_result
        sql_result=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$MIGRATION_TARGET_USER" -d "$MIGRATION_TARGET_DB" -f /tmp/settings_import.sql 2>&1)
        local sql_exit=$?
        
        docker exec "$MIGRATION_TARGET_CONTAINER" rm -f /tmp/settings_import.sql
        
        if [[ $sql_exit -ne 0 ]]; then
            print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° SQL: $sql_result"
            ((errors++))
        else
            local total_db=$((backup_settings_migrated + db_migrated))
            print_message "SUCCESS" "ĞŸĞµÑ€ĞµĞ½ĞµÑĞµĞ½Ğ¾ Ğ² settings DB: $total_db Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº"
            [[ $backup_settings_migrated -gt 0 ]] && echo -e "   ${GRAY}(Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°: $backup_settings_migrated)${RESET}"
            [[ $defaults_used -gt 0 ]] && echo -e "   ${GRAY}(Ğ¸Ğ· Ğ½Ğ¸Ñ… Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚Ğ½Ñ‹Ñ…: $defaults_used)${RESET}"
        fi
    else
        print_message "WARN" "ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ² Ğ‘Ğ” â€” ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½"
    fi
    
    # === ĞĞ¢Ğ§ĞĞ¢ ===
    local report_file="$work_dir/settings_migration_report.txt"
    {
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘         ĞĞ¢Ğ§ĞĞ¢ ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ˜ ĞĞĞ¡Ğ¢Ğ ĞĞ•Ğš                        â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        echo "Ğ”Ğ°Ñ‚Ğ°: $(date '+%Y-%m-%d %H:%M:%S')"
        echo ""
        echo "=== Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞ˜ ==="
        echo "ĞÑ€Ñ…Ğ¸Ğ² Ğ±ÑĞºĞ°Ğ¿Ğ°: ${MIGRATION_SOURCE_BACKUP_FILE:-Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½}"
        echo ".env Ñ„Ğ°Ğ¹Ğ»:    ${MIGRATION_SOURCE_ENV_FILE:-Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½}"
        echo ""
        echo "=== ĞŸĞ Ğ˜ĞĞœĞĞ˜ĞšĞ˜ ==="
        echo ".env:         $MIGRATION_TARGET_ENV_FILE"
        echo "Ğ‘Ğ”:           ${MIGRATION_TARGET_CONTAINER:-Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½} / ${MIGRATION_TARGET_DB:-}"
        echo ""
        echo "=== Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« ==="
        echo "ĞŸĞµÑ€ĞµĞ½ĞµÑĞµĞ½Ğ¾ Ğ² .env: $env_migrated"
        echo "Ğ˜Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Ğ±ÑĞºĞ°Ğ¿Ğ° Ğ² Ğ‘Ğ”: $backup_settings_migrated"
        echo "Ğ˜Ğ· .env Ğ² Ğ‘Ğ”: $db_migrated"
        echo "ĞÑˆĞ¸Ğ±Ğ¾Ğº: $errors"
        echo ""
        echo "=== Ğ’ĞĞ–ĞĞ ==="
        echo "1. ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ Ğ±Ğ¾Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ¸Ğ· .env"
        echo "2. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ°Ğ´Ğ¼Ğ¸Ğ½-Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ RWP-Shop Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ¸Ğ· Ğ‘Ğ”"
        echo "3. ĞĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸"
        echo ""
        echo "=== ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜ Ğ‘Ğ•Ğ— ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ˜ ==="
        echo "ĞĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Bedolaga Ğ½Ğµ Ğ¸Ğ¼ĞµÑÑ‚ Ğ¿Ñ€ÑĞ¼Ñ‹Ñ… Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ² Ğ² RWP-Shop:"
        echo "  - Ğ¦ĞµĞ½Ñ‹ Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ñ‹ Ñ‚Ñ€Ğ°Ñ„Ğ¸ĞºĞ° (Ñ€Ğ°Ğ·Ğ½Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ñ‚Ğ°Ñ€Ğ¸Ñ„Ğ¾Ğ²)"
        echo "  - ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ±ÑĞºĞ°Ğ¿Ğ° (Ñƒ RWP-Shop Ğ½ĞµÑ‚ Ğ²ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ±ÑĞºĞ°Ğ¿Ğ°)"
        echo "  - Ğ’Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ Ğ°Ğ´Ğ¼Ğ¸Ğ½ Ñ‚Ğ¾ĞºĞµĞ½ (Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°ĞµÑ‚ÑÑ)"
    } > "$report_file"
    
    local total_db=$((backup_settings_migrated + db_migrated))
    
    echo ""
    echo -e "${GREEN}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo -e "${GREEN}${BOLD}  âœ… ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ¯ ĞĞĞ¡Ğ¢Ğ ĞĞ•Ğš Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ!                  ${RESET}"
    echo -e "${GREEN}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo ""
    echo "Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹:"
    echo " â€¢ .env: $env_migrated Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ…"
    [[ $backup_settings_migrated -gt 0 ]] && echo " â€¢ Ğ˜Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Ğ² Ğ‘Ğ”: $backup_settings_migrated Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº"
    [[ $db_migrated -gt 0 ]] && echo " â€¢ Ğ˜Ğ· .env Ğ² Ğ‘Ğ”: $db_migrated Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº"
    echo " â€¢ ĞÑˆĞ¸Ğ±Ğ¾Ğº: $errors"
    echo ""
    echo "ĞÑ‚Ñ‡Ñ‘Ñ‚: $report_file"
    echo ""
    
    if [[ $errors -eq 0 ]]; then
        print_message "WARN" "ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ Ğ±Ğ¾Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹!"
        echo ""
        read -erp "ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ±Ğ¾Ñ‚Ğ° ÑĞµĞ¹Ñ‡Ğ°Ñ? (y/N): " restart_bot
        if [[ "$restart_bot" =~ ^[Yy]$ ]]; then
            if [[ -n "$MIGRATION_TARGET_BOT_PATH" && -f "$MIGRATION_TARGET_BOT_PATH/compose.yaml" ]]; then
                print_message "INFO" "ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞº Ğ±Ğ¾Ñ‚Ğ°..."
                (cd "$MIGRATION_TARGET_BOT_PATH" && docker compose restart bot)
                print_message "SUCCESS" "Ğ‘Ğ¾Ñ‚ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½"
            else
                print_message "WARN" "ĞŸÑƒÑ‚ÑŒ Ğº compose.yaml Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ Ğ±Ğ¾Ñ‚Ğ° Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ."
            fi
        fi
    fi
    
    log_message "SUCCESS" "Settings migration completed: env=$env_migrated, db=$db_migrated, errors=$errors"
    
    read -erp "Enter..." dummy
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ² CSV ---
migrate_settings_export_csv() {
    if [[ -z "$MIGRATION_SOURCE_ENV_FILE" || ! -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
        print_message "ERROR" "ĞŸÑƒÑ‚ÑŒ Ğº Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºÑƒ Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½"
        read -erp "Enter..." dummy
        return 1
    fi
    
    declare -A source_settings
    read_env_file "$MIGRATION_SOURCE_ENV_FILE" source_settings
    
    local work_dir="${BACKUP_DIR}/settings_export_$(date +%Y%m%d_%H%M%S)"
    mkdir -p "$work_dir"
    
    local csv_file="$work_dir/bedolaga_settings.csv"
    
    echo "key,value,maps_to_env,maps_to_db,migration_status" > "$csv_file"
    
    for key in "${!source_settings[@]}"; do
        local value="${source_settings[$key]}"
        local env_target="${SETTINGS_ENV_TO_ENV[$key]:-}"
        local db_target="${SETTINGS_ENV_TO_DB[$key]:-}"
        local status="no_mapping"
        
        [[ -n "$env_target" ]] && status="env"
        [[ -n "$db_target" ]] && status="db"
        
        # Ğ­ĞºÑ€Ğ°Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ»Ñ CSV
        value="${value//\"/\"\"}"
        
        echo "\"$key\",\"$value\",\"$env_target\",\"$db_target\",\"$status\"" >> "$csv_file"
    done
    
    print_message "SUCCESS" "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹: $csv_file"
    echo ""
    echo "Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:"
    echo " â€¢ Ğ’ÑĞµĞ³Ğ¾ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº: ${#source_settings[@]}"
    echo " â€¢ ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ½Ğ° .env: $(grep -c ',env$' "$csv_file")"
    echo " â€¢ ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ½Ğ° DB: $(grep -c ',db$' "$csv_file")"
    echo " â€¢ Ğ‘ĞµĞ· Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ°: $(grep -c ',no_mapping$' "$csv_file")"
    
    read -erp "Enter..." dummy
}

# --- ĞœĞµĞ½Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº ---
menu_migrate_settings() {
    # === ĞĞ’Ğ¢ĞĞœĞĞ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ Ğ¡Ğ˜ĞĞ¥Ğ ĞĞĞ˜Ğ—ĞĞ¦Ğ˜Ğ¯ Ğ”ĞĞĞĞ«Ğ¥ Ğ˜Ğ— ĞĞ¡ĞĞĞ’ĞĞĞ“Ğ ĞœĞ•ĞĞ® ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ˜ ===
    
    # Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: ĞµÑĞ»Ğ¸ Ğ² Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¼ Ğ¼ĞµĞ½Ñ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½ Ğ°Ñ€Ñ…Ğ¸Ğ², Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ĞµĞ³Ğ¾
    if [[ -z "$MIGRATION_SOURCE_BACKUP_FILE" && -n "$MIGRATION_SOURCE_BACKUP" && -f "$MIGRATION_SOURCE_BACKUP" ]]; then
        MIGRATION_SOURCE_BACKUP_FILE="$MIGRATION_SOURCE_BACKUP"
        debug_log "SETTINGS" "Auto-synced source archive from main migration: $MIGRATION_SOURCE_BACKUP_FILE"
    fi
    
    # ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº: ĞµÑĞ»Ğ¸ Ğ² Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¼ Ğ¼ĞµĞ½Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€, Ğ¸Ñ‰ĞµĞ¼ .env Ñ€ÑĞ´Ğ¾Ğ¼
    if [[ -z "$MIGRATION_TARGET_ENV_FILE" && -n "$MIGRATION_TARGET_CONTAINER" ]]; then
        # ĞœĞµÑ‚Ğ¾Ğ´ 1: Ğ§ĞµÑ€ĞµĞ· docker inspect (working_dir)
        local working_dir=$(docker inspect "$MIGRATION_TARGET_CONTAINER" --format '{{index .Config.Labels "com.docker.compose.project.working_dir"}}' 2>/dev/null)
        if [[ -n "$working_dir" && -d "$working_dir" ]]; then
            MIGRATION_TARGET_BOT_PATH="$working_dir"
            MIGRATION_TARGET_ENV_FILE="$working_dir/.env"
            debug_log "SETTINGS" "Auto-detected target .env from docker inspect: $MIGRATION_TARGET_ENV_FILE"
        fi
        
        # ĞœĞµÑ‚Ğ¾Ğ´ 2: Ğ§ĞµÑ€ĞµĞ· BOT_PATH Ğ¸Ğ· Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ°
        if [[ -z "$MIGRATION_TARGET_ENV_FILE" && -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
            MIGRATION_TARGET_BOT_PATH="$BOT_PATH"
            MIGRATION_TARGET_ENV_FILE="$BOT_PATH/.env"
            debug_log "SETTINGS" "Auto-detected target .env from BOT_PATH: $MIGRATION_TARGET_ENV_FILE"
        fi
        
        # ĞœĞµÑ‚Ğ¾Ğ´ 3: ĞĞ²Ñ‚Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº
        if [[ -z "$MIGRATION_TARGET_ENV_FILE" ]]; then
            local found_rwp=$(find_rwp_shop_env)
            if [[ -n "$found_rwp" && -d "$found_rwp" ]]; then
                MIGRATION_TARGET_BOT_PATH="$found_rwp"
                MIGRATION_TARGET_ENV_FILE="$found_rwp/.env"
                debug_log "SETTINGS" "Auto-detected target .env from find_rwp_shop_env: $MIGRATION_TARGET_ENV_FILE"
            fi
        fi
    fi
    
    while true; do
        clear_screen
        echo -e "${CYAN}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
        echo -e "${CYAN}${BOLD}            ğŸ”§ ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ¯ ĞĞĞ¡Ğ¢Ğ ĞĞ•Ğš BEDOLAGA â†’ RWP-SHOP          ${RESET}"
        echo -e "${CYAN}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
        echo ""
        
        # === Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡ (Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½) ===
        echo -e "${YELLOW}=== Ğ¢Ğ•ĞšĞ£Ğ©Ğ˜Ğ™ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡ ===${RESET}"
        
        # Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: Ğ°Ñ€Ñ…Ğ¸Ğ² (Ğ¸Ğ· Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½Ñ)
        local archive_needs_password=false
        if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]]; then
            local archive_name=$(basename "$MIGRATION_SOURCE_BACKUP_FILE")
            local archive_size=$(du -h "$MIGRATION_SOURCE_BACKUP_FILE" 2>/dev/null | cut -f1)
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ğ½ÑƒĞ¶ĞµĞ½ Ğ»Ğ¸ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ
            local archive_type=$(detect_bedolaga_archive_type "$MIGRATION_SOURCE_BACKUP_FILE" 2>/dev/null)
            if [[ "$archive_type" == "zip" ]] && is_archive_password_protected "$MIGRATION_SOURCE_BACKUP_FILE" 2>/dev/null; then
                if [[ -z "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                    archive_needs_password=true
                    echo -e "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ°Ñ€Ñ…Ğ¸Ğ²: ${YELLOW}ğŸ”’ $archive_name${RESET} ($archive_size)"
                    echo -e "                ${RED}âš ï¸  Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ! Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ°Ñ€Ñ…Ğ¸Ğ² Ğ·Ğ°Ğ½Ğ¾Ğ²Ğ¾ (Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğµ Ğ¼ĞµĞ½Ñ â†’ Ğ¿ÑƒĞ½ĞºÑ‚ 2)${RESET}"
                else
                    echo -e "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ°Ñ€Ñ…Ğ¸Ğ²: ${GREEN}âœ… ğŸ”‘ $archive_name${RESET} ($archive_size)"
                fi
            else
                echo -e "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ°Ñ€Ñ…Ğ¸Ğ²: ${GREEN}âœ… $archive_name${RESET} ($archive_size)"
            fi
        else
            echo -e "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ°Ñ€Ñ…Ğ¸Ğ²: ${YELLOW}âš ï¸  ĞĞµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½ Ğ² Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¼ Ğ¼ĞµĞ½Ñ${RESET}"
        fi
        
        # Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: .env Bedolaga (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
        if [[ -n "$MIGRATION_SOURCE_ENV_FILE" && -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
            echo -e "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº .env:  ${GREEN}âœ… $MIGRATION_SOURCE_ENV_FILE${RESET}"
        else
            echo -e "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº .env:  ${GRAY}â€” (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)${RESET}"
        fi
        
        # ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº: .env RWP-Shop
        if [[ -n "$MIGRATION_TARGET_ENV_FILE" ]]; then
            if [[ -f "$MIGRATION_TARGET_ENV_FILE" ]]; then
                local vars_count=$(grep -c "^[A-Z].*=" "$MIGRATION_TARGET_ENV_FILE" 2>/dev/null || echo "0")
                echo -e "ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº .env:  ${GREEN}âœ… $MIGRATION_TARGET_ENV_FILE${RESET} ($vars_count Ğ¿ĞµÑ€ĞµĞ¼.)"
            else
                echo -e "ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº .env:  ${YELLOW}âš ï¸  $MIGRATION_TARGET_ENV_FILE${RESET} (Ğ±ÑƒĞ´ĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½)"
            fi
        else
            echo -e "ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº .env:  ${RED}âŒ ĞĞµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½${RESET}"
        fi
        
        # ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº: Ğ‘Ğ” (Ğ¸Ğ· Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½Ñ)
        if [[ -n "$MIGRATION_TARGET_CONTAINER" ]]; then
            echo -e "ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº Ğ‘Ğ”:    ${GREEN}âœ… $MIGRATION_TARGET_CONTAINER${RESET}"
        else
            echo -e "ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº Ğ‘Ğ”:    ${RED}âŒ ĞĞµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ Ğ² Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¼ Ğ¼ĞµĞ½Ñ${RESET}"
        fi
        echo ""
        
        # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ ĞµÑĞ»Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ Ğ˜ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ
        if [[ "$archive_needs_password" != "true" ]]; then
            if [[ -n "$MIGRATION_SOURCE_BACKUP_FILE" && -f "$MIGRATION_SOURCE_BACKUP_FILE" ]] || \
               [[ -n "$MIGRATION_SOURCE_ENV_FILE" && -f "$MIGRATION_SOURCE_ENV_FILE" ]]; then
                migrate_settings_analyze 2>/dev/null
            fi
        fi
        
        echo ""
        echo " [1] Ğ£ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ .env Bedolaga (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)"
        echo " [2] ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº"
        echo " [3] ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ°Ñ€Ñ…Ğ¸Ğ² â†’ settings DB"
        echo " [4] ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ±ĞµĞ· Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ°"
        echo -e " ${GREEN}[5] â–¶ Ğ’Ğ«ĞŸĞĞ›ĞĞ˜Ğ¢Ğ¬ ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ® ĞĞĞ¡Ğ¢Ğ ĞĞ•Ğš${RESET}"
        echo " [6] Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ² CSV"
        echo ""
        echo " [0] â† ĞĞ°Ğ·Ğ°Ğ´"
        echo ""
        read -erp "Ğ’Ñ‹Ğ±Ğ¾Ñ€ (Enter - ĞĞ°Ğ·Ğ°Ğ´): " opt
        [[ -z "$opt" || "$opt" == "q" || "$opt" == "Q" ]] && return
        
        case "$opt" in
            1) migrate_settings_configure_env_source ;;
            2) migrate_settings_show_env_mapping ;;
            3) migrate_settings_show_db_mapping ;;
            4) migrate_settings_show_no_mapping ;;
            5) migrate_settings_execute ;;
            6) migrate_settings_export_csv ;;
            0) return ;;
        esac
    done
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ° ---
migrate_configure_source() {
    clear_screen
    echo -e "${CYAN}${BOLD}â•â•â• ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞ (Bedolaga) â•â•â•${RESET}"
    echo ""
    echo "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Bedolaga:"
    echo -e " ${GREEN}1. Ğ‘ÑĞºĞ°Ğ¿-Ğ°Ñ€Ñ…Ğ¸Ğ² (.tar.gz Ñ database.json)${RESET} â† Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ"
    echo " 2. Docker ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ (Ğ½Ğ° ÑÑ‚Ğ¾Ğ¼ ÑĞµÑ€Ğ²ĞµÑ€Ğµ)"
    echo " 3. Ğ’Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ PostgreSQL ÑĞµÑ€Ğ²ĞµÑ€"
    echo " 0. ĞĞ°Ğ·Ğ°Ğ´"
    echo ""
    read -erp "Ğ’Ñ‹Ğ±Ğ¾Ñ€ (Enter - ĞĞ°Ğ·Ğ°Ğ´): " source_type
    [[ -z "$source_type" || "$source_type" == "q" || "$source_type" == "Q" || "$source_type" == "0" ]] && return
    
    case "$source_type" in
        1)
            # Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: Ğ±ÑĞºĞ°Ğ¿-Ğ°Ñ€Ñ…Ğ¸Ğ² Bedolaga
            MIGRATION_SOURCE_TYPE="archive"
            MIGRATION_SOURCE_CONTAINER=""
            MIGRATION_SOURCE_HOST=""
            
            echo ""
            print_message "INFO" "ĞŸĞ¾Ğ¸ÑĞº Ğ±ÑĞºĞ°Ğ¿-Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ² Bedolaga..."
            
            # ĞĞ²Ñ‚Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ²
            local found_backups=()
            local search_paths=("/opt/bedolaga/backups" "/opt/bedolaga/backup" "/root/backups" "/opt/vpn-bot/backups" "$HOME/backups")
            
            for search_path in "${search_paths[@]}"; do
                [[ ! -d "$search_path" ]] && continue
                while IFS= read -r -d '' backup_file; do
                    found_backups+=("$backup_file")
                done < <(find "$search_path" -maxdepth 2 -name "backup_*.tar.gz" -type f -print0 2>/dev/null | head -z -n 10)
            done
            
            if [[ ${#found_backups[@]} -gt 0 ]]; then
                echo ""
                echo "ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹:"
                local i=1
                for backup in "${found_backups[@]}"; do
                    local size=$(du -h "$backup" 2>/dev/null | cut -f1)
                    local date=$(stat -c %y "$backup" 2>/dev/null | cut -d' ' -f1)
                    echo "  $i. $backup ($size, $date)"
                    ((i++))
                done
                echo ""
                echo "  M. Ğ’Ğ²ĞµÑÑ‚Ğ¸ Ğ¿ÑƒÑ‚ÑŒ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ"
                echo ""
                read -erp "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ°Ñ€Ñ…Ğ¸Ğ² [1]: " backup_choice
                backup_choice="${backup_choice:-1}"
                
                if [[ "$backup_choice" == "M" || "$backup_choice" == "m" ]]; then
                    read -erp "ĞŸÑƒÑ‚ÑŒ Ğº Ğ°Ñ€Ñ…Ğ¸Ğ²Ñƒ: " MIGRATION_SOURCE_BACKUP
                elif [[ "$backup_choice" =~ ^[0-9]+$ ]] && (( backup_choice >= 1 && backup_choice <= ${#found_backups[@]} )); then
                    MIGRATION_SOURCE_BACKUP="${found_backups[$((backup_choice-1))]}"
                else
                    print_message "ERROR" "ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€"
                    return 1
                fi
            else
                echo ""
                print_message "WARN" "ĞÑ€Ñ…Ğ¸Ğ²Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸"
                read -erp "ĞŸÑƒÑ‚ÑŒ Ğº Ğ°Ñ€Ñ…Ğ¸Ğ²Ñƒ Ğ±ÑĞºĞ°Ğ¿Ğ° Bedolaga: " MIGRATION_SOURCE_BACKUP
            fi
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
            if [[ ! -f "$MIGRATION_SOURCE_BACKUP" ]]; then
                print_message "ERROR" "Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: $MIGRATION_SOURCE_BACKUP"
                return 1
            fi
            
            # Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²ĞºĞ° Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
            print_message "INFO" "Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²ĞºĞ° Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°..."
            if ! extract_bedolaga_backup "$MIGRATION_SOURCE_BACKUP"; then
                print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ²"
                return 1
            fi
            
            # ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ±ÑĞºĞ°Ğ¿Ğµ
            echo ""
            print_message "INFO" "Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ±ÑĞºĞ°Ğ¿Ğµ:"
            get_bedolaga_backup_info "$MIGRATION_SOURCE_BACKUP"
            
            print_message "SUCCESS" "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½: Ğ°Ñ€Ñ…Ğ¸Ğ²"
            ;;
        2)
            # Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: Docker ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€
            MIGRATION_SOURCE_TYPE="docker"
            MIGRATION_SOURCE_BACKUP=""
            
            echo ""
            echo "Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ PostgreSQL ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹:"
            docker ps --format '{{.Names}}' | grep -iE 'postgres|db|bedolaga' | while read -r name; do
                echo "  - $name"
            done
            echo ""
            read -erp "Ğ˜Ğ¼Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ğ‘Ğ” Bedolaga: " MIGRATION_SOURCE_CONTAINER
            read -erp "Ğ˜Ğ¼Ñ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… [shop_bot]: " MIGRATION_SOURCE_DB
            MIGRATION_SOURCE_DB="${MIGRATION_SOURCE_DB:-shop_bot}"
            read -erp "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ‘Ğ” [postgres]: " MIGRATION_SOURCE_USER
            MIGRATION_SOURCE_USER="${MIGRATION_SOURCE_USER:-postgres}"
            MIGRATION_SOURCE_HOST=""
            MIGRATION_SOURCE_PASS=""
            
            print_message "SUCCESS" "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½: Docker ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€"
            ;;
        3)
            # Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ PostgreSQL
            MIGRATION_SOURCE_TYPE="postgresql"
            MIGRATION_SOURCE_CONTAINER=""
            MIGRATION_SOURCE_BACKUP=""
            
            echo ""
            read -erp "Ğ¥Ğ¾ÑÑ‚ PostgreSQL: " MIGRATION_SOURCE_HOST
            read -erp "ĞŸĞ¾Ñ€Ñ‚ [5432]: " MIGRATION_SOURCE_PORT
            MIGRATION_SOURCE_PORT="${MIGRATION_SOURCE_PORT:-5432}"
            read -erp "Ğ˜Ğ¼Ñ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: " MIGRATION_SOURCE_DB
            read -erp "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ: " MIGRATION_SOURCE_USER
            read -serp "ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ: " MIGRATION_SOURCE_PASS
            echo ""
            
            print_message "SUCCESS" "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½: Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ PostgreSQL"
            ;;
        0) return ;;
    esac
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿Ñ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸ĞºĞ° ---
migrate_configure_target() {
    clear_screen
    echo -e "${CYAN}${BOLD}â•â•â• ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ ĞŸĞ Ğ˜ĞĞœĞĞ˜ĞšĞ (RWP-Shop) â•â•â•${RESET}"
    echo ""
    
    # ĞĞ²Ñ‚Ğ¾Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ğ‘Ğ” Remnawave
    local detected_container=""
    for pattern in "rwp_shop_db" "telegram-shop-db" "remnawave.*db"; do
        detected_container=$(docker ps --format '{{.Names}}' | grep -iE "^$pattern$" | head -1)
        [[ -n "$detected_container" ]] && break
    done
    
    if [[ -n "$detected_container" ]]; then
        echo -e "ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€: ${GREEN}$detected_container${RESET}"
        read -erp "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞµĞ³Ğ¾? (Y/n): " use_detected
        if [[ ! "$use_detected" =~ ^[Nn]$ ]]; then
            MIGRATION_TARGET_CONTAINER="$detected_container"
        fi
    fi
    
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        echo "Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹:"
        docker ps --format '{{.Names}}' | while read -r name; do
            echo "  - $name"
        done
        echo ""
        read -erp "Ğ˜Ğ¼Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ğ‘Ğ” Remnawave: " MIGRATION_TARGET_CONTAINER
    fi
    
    read -erp "Ğ˜Ğ¼Ñ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… [postgres]: " MIGRATION_TARGET_DB
    MIGRATION_TARGET_DB="${MIGRATION_TARGET_DB:-postgres}"
    read -erp "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ‘Ğ” [postgres]: " MIGRATION_TARGET_USER
    MIGRATION_TARGET_USER="${MIGRATION_TARGET_USER:-postgres}"
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ Ğº RWP-Shop
    migration_detect_target_path
    
    print_message "SUCCESS" "ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½"
    [[ -n "$MIGRATION_TARGET_PATH" ]] && print_message "INFO" "ĞŸÑƒÑ‚ÑŒ RWP-Shop: $MIGRATION_TARGET_PATH"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ĞĞĞ’Ğ«Ğ™ UX ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ˜ v2.0
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# --- Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ ---
MIGRATION_DISCLAIMER_SHOWN=false
MIGRATION_AUTO_BACKUP=""          # ĞŸÑƒÑ‚ÑŒ Ğº Ğ°Ğ²Ñ‚Ğ¾Ğ±ÑĞºĞ°Ğ¿Ñƒ Ğ‘Ğ” RWP-Shop
MIGRATION_NOT_MIGRATED_DIR=""     # ĞŸĞ°Ğ¿ĞºĞ° Ğ´Ğ»Ñ Ğ½ĞµĞ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ğ¼Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
MIGRATION_DATA_ANALYSIS=""        # Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (cached)

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¸Ğ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ²ÑÑ‘ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾)
MIGRATE_USERS=true
MIGRATE_REFERRALS=true
MIGRATE_SUBSCRIPTIONS=true
MIGRATE_TRANSACTIONS=true
MIGRATE_PROMOCODES=true
MIGRATE_PROMO_USAGE=true
MIGRATE_TICKETS=true
MIGRATE_BROADCAST=true
MIGRATE_SETTINGS=true

# ĞŸĞ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ°Ñ…
MIGRATE_CONFLICT_MODE="update"    # update | skip | ask

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ disclaimer (Ğ¾Ğ´Ğ¸Ğ½ Ñ€Ğ°Ğ· Ğ·Ğ° ÑĞµÑÑĞ¸Ñ) ---
migration_show_disclaimer() {
    if [[ "$MIGRATION_DISCLAIMER_SHOWN" == "true" ]]; then
        return 0
    fi
    
    clear_screen
    echo -e "${RED}${BOLD}"
    echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
    echo "â”‚                                                          â”‚"
    echo "â”‚  âš ï¸  Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•! Ğ­ĞšĞ¡ĞŸĞ•Ğ Ğ˜ĞœĞ•ĞĞ¢ĞĞ›Ğ¬ĞĞ«Ğ™ ĞœĞ˜Ğ“Ğ ĞĞ¢ĞĞ                  â”‚"
    echo "â”‚                                                          â”‚"
    echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
    echo "â”‚                                                          â”‚"
    echo "â”‚  Ğ­Ñ‚Ğ¾Ñ‚ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ² ÑÑ‚Ğ°Ğ´Ğ¸Ğ¸ Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ¯.                  â”‚"
    echo "â”‚                                                          â”‚"
    echo "â”‚  â€¢ Ğ’ÑĞµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ ĞĞ Ğ’ĞĞ¨ Ğ¡Ğ¢Ğ ĞĞ¥ Ğ˜ Ğ Ğ˜Ğ¡Ğš                      â”‚"
    echo "â”‚  â€¢ ĞĞ²Ñ‚Ğ¾Ñ€ ĞĞ• Ğ½ĞµÑÑ‘Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ° Ğ¿Ğ¾Ñ‚ĞµÑ€Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…       â”‚"
    echo "â”‚  â€¢ ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ ÑĞ´ĞµĞ»Ğ°Ğ¹Ñ‚Ğµ Ğ±ÑĞºĞ°Ğ¿ ĞĞ‘Ğ•Ğ˜Ğ¥ Ğ‘Ğ”                   â”‚"
    echo "â”‚                                                          â”‚"
    echo "â”‚  Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ±ĞµĞ· Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ±ÑƒĞ´ÑƒÑ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹.   â”‚"
    echo "â”‚                                                          â”‚"
    echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
    echo -e "${RESET}"
    echo ""
    echo -e "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ ${YELLOW}Enter${RESET} Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ Ğ¸Ğ»Ğ¸ ${YELLOW}Ctrl+C${RESET} Ğ´Ğ»Ñ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°..."
    read -r
    
    MIGRATION_DISCLAIMER_SHOWN=true
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ğ¿ÑƒÑ‚ÑŒ Ğº RWP-Shop Ğ¿Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñƒ ---
migration_detect_target_path() {
    debug_log "MIGRATE" "Detecting RWP-Shop path..."
    
    # Ğ•ÑĞ»Ğ¸ ÑƒĞ¶Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ â€” Ğ½Ğµ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼
    if [[ -n "$MIGRATION_TARGET_PATH" && -d "$MIGRATION_TARGET_PATH" ]]; then
        debug_log "MIGRATE" "Target path already set: $MIGRATION_TARGET_PATH"
        return 0
    fi
    
    local detected_path=""
    
    # 1) ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿ÑƒÑ‚ÑŒ Ğ¸Ğ· docker inspect (working directory Ğ¸Ğ»Ğ¸ compose file)
    if [[ -n "$MIGRATION_TARGET_CONTAINER" ]]; then
        # Ğ˜Ñ‰ĞµĞ¼ compose project working dir
        local compose_project=$(docker inspect --format '{{index .Config.Labels "com.docker.compose.project.working_dir"}}' "$MIGRATION_TARGET_CONTAINER" 2>/dev/null)
        if [[ -n "$compose_project" && -d "$compose_project" ]]; then
            detected_path="$compose_project"
            debug_log "MIGRATE" "Found path from compose label: $detected_path"
        fi
    fi
    
    # 2) Ğ˜Ñ‰ĞµĞ¼ Ğ² ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ñ… Ğ¿ÑƒÑ‚ÑÑ…
    if [[ -z "$detected_path" ]]; then
        local search_paths=(
            "/opt/private-remnawave-telegram-shop-bot"
            "/opt/rwp-shop"
            "/opt/telegram-shop"
            "$BOT_PATH"
        )
        
        for path in "${search_paths[@]}"; do
            if [[ -d "$path" ]] && [[ -f "$path/compose.yaml" || -f "$path/docker-compose.yml" || -f "$path/.env" ]]; then
                detected_path="$path"
                debug_log "MIGRATE" "Found path in standard location: $detected_path"
                break
            fi
        done
    fi
    
    if [[ -n "$detected_path" ]]; then
        MIGRATION_TARGET_PATH="$detected_path"
        debug_log "MIGRATE" "Target path set to: $MIGRATION_TARGET_PATH"
        return 0
    fi
    
    debug_log "MIGRATE" "Could not detect target path"
    return 1
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‡ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ ---
migration_init_work_dir() {
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ Ğ´Ğ»Ñ MIGRATION/
    local base_path=""
    
    # ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ 1: ĞŸÑƒÑ‚ÑŒ Ğº RWP-Shop (Ñ€ÑĞ´Ğ¾Ğ¼ Ñ docker-compose)
    if [[ -n "$MIGRATION_TARGET_PATH" && -d "$MIGRATION_TARGET_PATH" ]]; then
        base_path="$MIGRATION_TARGET_PATH"
    # ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ 2: BOT_PATH
    elif [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
        base_path="$BOT_PATH"
    # ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ 3: BACKUP_DIR (fallback)
    else
        base_path="$BACKUP_DIR"
    fi
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ: MIGRATION/YYYYMMDD_HHMMSS/
    local migration_base="$base_path/MIGRATION"
    local timestamp=$(date +%Y%m%d_%H%M%S)
    MIGRATION_WORK_DIR="$migration_base/$timestamp"
    
    mkdir -p "$MIGRATION_WORK_DIR"
    debug_log "MIGRATE" "Work directory initialized: $MIGRATION_WORK_DIR"
    
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞĞ²Ñ‚Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Bedolaga ---
migration_auto_find_archive() {
    debug_log "MIGRATE" "Auto-searching for Bedolaga archive..."
    
    local found_archive=""
    local search_paths=()
    
    # 1) Ğ’ Ğ¿Ğ°Ğ¿ĞºĞµ RWP-Shop Ğ±Ğ¾Ñ‚Ğ° (ĞµÑĞ»Ğ¸ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ°)
    if [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
        search_paths+=("$BOT_PATH")
    fi
    
    # 2) Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸
    search_paths+=(
        "/opt/private-remnawave-telegram-shop-bot"
        "/opt/rwp-shop"
        "/opt/bedolaga"
        "/opt/vpn-bot"
        "/root"
        "/tmp"
        "$HOME"
    )
    
    # 3) ĞŸĞ°Ğ¿ĞºĞ° Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ² LAZARUS
    [[ -d "$BACKUP_DIR" ]] && search_paths+=("$BACKUP_DIR")
    
    local all_archives=()
    
    for path in "${search_paths[@]}"; do
        [[ ! -d "$path" ]] && continue
        
        # Ğ˜Ñ‰ĞµĞ¼ Ğ°Ñ€Ñ…Ğ¸Ğ²Ñ‹ backup_*.tar.gz Ğ˜ backup_*.tar.zip (Ğ·Ğ°Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ½Ğ½Ñ‹Ğµ)
        while IFS= read -r -d '' archive; do
            all_archives+=("$archive")
        done < <(find "$path" -maxdepth 3 -type f \( -name "backup_*.tar.gz" -o -name "backup_*.tar.zip" -o -name "backup_*.zip" \) -print0 2>/dev/null)
    done
    
    if [[ ${#all_archives[@]} -eq 0 ]]; then
        debug_log "MIGRATE" "No archives found"
        return 1
    fi
    
    # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğµ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ (Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼Ğ¸)
    local sorted_archives
    sorted_archives=$(printf '%s\n' "${all_archives[@]}" | xargs -I {} stat --format='%Y %n' {} 2>/dev/null | sort -rn | head -5 | awk '{print $2}')
    
    # Ğ‘ĞµÑ€Ñ‘Ğ¼ ÑĞ°Ğ¼Ñ‹Ğ¹ Ğ½Ğ¾Ğ²Ñ‹Ğ¹
    found_archive=$(echo "$sorted_archives" | head -1)
    
    if [[ -n "$found_archive" && -f "$found_archive" ]]; then
        echo "$found_archive"
        debug_log "MIGRATE" "Found archive: $found_archive"
        return 0
    fi
    
    return 1
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° (Ğ±ĞµĞ· Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²ĞºĞ¸) ---
migration_quick_analyze() {
    local archive="$1"
    local password="${2:-$BEDOLAGA_BACKUP_PASSWORD}"
    
    if [[ ! -f "$archive" ]]; then
        return 1
    fi
    
    # Ğ£Ğ±ĞµĞ¶Ğ´Ğ°ĞµĞ¼ÑÑ Ñ‡Ñ‚Ğ¾ unzip ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ (Ğ´Ğ»Ñ ZIP Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ²)
    ensure_unzip_installed 2>/dev/null
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ¿Ğ°Ğ¿ĞºÑƒ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
    local temp_dir=$(mktemp -d)
    TEMP_DIRS+=("$temp_dir")
    
    local db_json=""
    local archive_type=$(detect_bedolaga_archive_type "$archive" 2>/dev/null || echo "unknown")
    
    case "$archive_type" in
        "tar.gz")
            # Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ database.json
            if ! tar -xzf "$archive" -C "$temp_dir" "database.json" 2>/dev/null; then
                # ĞœĞ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ² Ğ¿Ğ¾Ğ´Ğ¿Ğ°Ğ¿ĞºĞµ
                tar -xzf "$archive" -C "$temp_dir" --wildcards "*/database.json" 2>/dev/null
            fi
            db_json=$(find "$temp_dir" -name "database.json" -type f 2>/dev/null | head -1)
            ;;
        "tar")
            tar -xf "$archive" -C "$temp_dir" "database.json" 2>/dev/null || \
            tar -xf "$archive" -C "$temp_dir" --wildcards "*/database.json" 2>/dev/null
            db_json=$(find "$temp_dir" -name "database.json" -type f 2>/dev/null | head -1)
            ;;
        "zip")
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ¾Ğ»Ñ
            if is_archive_password_protected "$archive" 2>/dev/null; then
                if [[ -z "$password" ]]; then
                    rm -rf "$temp_dir"
                    return 1  # ĞĞµÑ‚ Ğ¿Ğ°Ñ€Ğ¾Ğ»Ñ
                fi
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ AES ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
                if is_zip_aes_encrypted "$archive"; then
                    if ! ensure_7z_installed; then
                        rm -rf "$temp_dir"
                        return 1
                    fi
                    local cmd_7z=$(get_7z_command)
                    $cmd_7z x -p"$password" -o"$temp_dir" "$archive" -y &>/dev/null
                else
                    unzip -P "$password" -q "$archive" -d "$temp_dir" 2>/dev/null
                fi
            else
                unzip -q "$archive" -d "$temp_dir" 2>/dev/null
            fi
            
            # Ğ˜Ñ‰ĞµĞ¼ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ğ²
            local inner_archive=$(find "$temp_dir" -type f \( -name "*.tar.gz" -o -name "*.tar" \) 2>/dev/null | head -1)
            if [[ -n "$inner_archive" ]]; then
                local inner_dir="$temp_dir/inner"
                mkdir -p "$inner_dir"
                if [[ "$inner_archive" == *.tar.gz ]]; then
                    tar -xzf "$inner_archive" -C "$inner_dir" 2>/dev/null
                else
                    tar -xf "$inner_archive" -C "$inner_dir" 2>/dev/null
                fi
                db_json=$(find "$inner_dir" -name "database.json" -type f 2>/dev/null | head -1)
            else
                db_json=$(find "$temp_dir" -name "database.json" -type f 2>/dev/null | head -1)
            fi
            ;;
        *)
            rm -rf "$temp_dir"
            return 1
            ;;
    esac
    
    if [[ -z "$db_json" || ! -f "$db_json" ]]; then
        rm -rf "$temp_dir"
        return 1
    fi
    
    # ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· Python
    local python_cmd=""
    if command -v python3 &>/dev/null; then python_cmd="python3"
    elif command -v python &>/dev/null; then python_cmd="python"
    else
        rm -rf "$temp_dir"
        return 1
    fi
    
    local analysis
    analysis=$($python_cmd - "$db_json" << 'PYEOF'
import sys, json

try:
    with open(sys.argv[1], 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    tables = data.get('data', data)
    
    users = tables.get('users', [])
    transactions = tables.get('transactions', [])
    promocodes = tables.get('promocodes', [])
    subscriptions = tables.get('subscriptions', [])
    tickets = tables.get('tickets', [])
    
    # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ² (ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‡Ñ‚Ğ¾ balance Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ² Ñ€ÑƒĞ±Ğ»ÑÑ…, balance_kopeks - Ğ² ĞºĞ¾Ğ¿ĞµĞ¹ĞºĞ°Ñ…)
    total_balance_kopeks = 0
    users_with_balance = 0
    for u in users:
        bal_kop = u.get('balance_kopeks', 0) or 0
        bal_rub = u.get('balance', 0) or 0
        # Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ balance_kopeks â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ĞµĞ³Ğ¾, Ğ¸Ğ½Ğ°Ñ‡Ğµ ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ balance Ğ¸Ğ· Ñ€ÑƒĞ±Ğ»ĞµĞ¹
        if bal_kop != 0:
            total_balance_kopeks += bal_kop
            users_with_balance += 1
        elif bal_rub != 0:
            total_balance_kopeks += int(float(bal_rub) * 100)
            users_with_balance += 1
    
    # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»Ğ¾Ğ²
    referrals = sum(1 for u in users if u.get('referred_by_id'))
    
    print(f"users:{len(users)}")
    print(f"transactions:{len(transactions)}")
    print(f"promocodes:{len(promocodes)}")
    print(f"subscriptions:{len(subscriptions)}")
    print(f"tickets:{len(tickets)}")
    print(f"referrals:{referrals}")
    print(f"total_balance_kopeks:{total_balance_kopeks}")
    print(f"users_with_balance:{users_with_balance}")
    
except Exception as e:
    print(f"error:{e}", file=sys.stderr)
    sys.exit(1)
PYEOF
)
    
    rm -rf "$temp_dir"
    echo "$analysis"
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ² ÑˆĞ°Ğ¿ĞºĞµ Ğ¼ĞµĞ½Ñ ---
migration_show_status() {
    local box_width=58  # Ğ¨Ğ¸Ñ€Ğ¸Ğ½Ğ° ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ Ñ€Ğ°Ğ¼ĞºĞ¸ (60 - 2 Ğ½Ğ° Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹)
    
    # Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼
    print_box_line() {
        local content="$1"
        # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ ANSI escape-ĞºĞ¾Ğ´Ñ‹ Ğ¸ ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ ÑˆĞ¸Ñ€Ğ¸Ğ½Ñƒ Ñ‡ĞµÑ€ĞµĞ· wc -L (ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Unicode)
        local stripped=$(echo -e "$content" | sed 's/\x1b\[[0-9;]*m//g')
        # LC_ALL=C.UTF-8 Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Unicode-ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²
        local visual_width=$(LC_ALL=C.UTF-8 echo -n "$stripped" | wc -L 2>/dev/null || echo ${#stripped})
        local padding=$((box_width - visual_width))
        [[ $padding -lt 0 ]] && padding=0
        local spaces=$(printf '%*s' "$padding" '')
        echo -e "${CYAN}â•‘${RESET}${content}${spaces}${CYAN}â•‘${RESET}"
    }
    
    echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${RESET}"
    print_box_line "  ${BOLD}Ğ¢Ğ•ĞšĞ£Ğ©Ğ˜Ğ™ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡${RESET}"
    echo -e "${CYAN}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${RESET}"
    
    # Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº
    if [[ "$MIGRATION_SOURCE_TYPE" == "archive" && -n "$MIGRATION_SOURCE_BACKUP" && -f "$MIGRATION_SOURCE_BACKUP" ]]; then
        local archive_name=$(basename "$MIGRATION_SOURCE_BACKUP")
        local archive_size=$(du -h "$MIGRATION_SOURCE_BACKUP" 2>/dev/null | cut -f1)
        local archive_type=$(detect_bedolaga_archive_type "$MIGRATION_SOURCE_BACKUP" 2>/dev/null || echo "unknown")
        
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¸ĞºĞ¾Ğ½ĞºÑƒ Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ñƒ
        local type_icon=""
        case "$archive_type" in
            "zip")
                if is_archive_password_protected "$MIGRATION_SOURCE_BACKUP" 2>/dev/null; then
                    type_icon="ğŸ”’"
                    [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]] && type_icon="ğŸ”“"
                else
                    type_icon="ğŸ“¦"
                fi
                ;;
            "tar.gz") type_icon="ğŸ“¦" ;;
            "tar")    type_icon="ğŸ“" ;;
            *)        type_icon="â“" ;;
        esac
        
        print_box_line "  Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº:  ${GREEN}âœ… $type_icon $archive_name${RESET} ($archive_size)"
        
        # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
        if [[ -n "$MIGRATION_DATA_ANALYSIS" ]]; then
            local users=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^users:" | cut -d: -f2)
            local tx=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^transactions:" | cut -d: -f2)
            local promo=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^promocodes:" | cut -d: -f2)
            print_box_line "             ${GRAY}ğŸ“Š users: $users | tx: $tx | promo: $promo${RESET}"
        fi
        
        # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ¿Ğ°Ñ€Ğ¾Ğ»Ñ Ğ´Ğ»Ñ Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ñ‘Ğ½Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ²
        if [[ "$archive_type" == "zip" ]] && is_archive_password_protected "$MIGRATION_SOURCE_BACKUP" 2>/dev/null; then
            if [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                print_box_line "             ${GREEN}ğŸ”‘ ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½${RESET}"
            else
                print_box_line "             ${YELLOW}âš ï¸  Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ (Ğ¿ÑƒĞ½ĞºÑ‚ 2)${RESET}"
            fi
        fi
    elif [[ -n "$MIGRATION_SOURCE_CONTAINER" ]]; then
        print_box_line "  Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº:  ${GREEN}âœ… Docker: $MIGRATION_SOURCE_CONTAINER${RESET}"
    else
        print_box_line "  Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº:  ${RED}âŒ ĞĞµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
    fi
    
    # ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº
    if [[ -n "$MIGRATION_TARGET_CONTAINER" ]]; then
        if docker ps --format '{{.Names}}' 2>/dev/null | grep -q "^${MIGRATION_TARGET_CONTAINER}$"; then
            print_box_line "  ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº:  ${GREEN}âœ… Docker: $MIGRATION_TARGET_CONTAINER${RESET} (Ğ‘Ğ”: $MIGRATION_TARGET_DB)"
        else
            print_box_line "  ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº:  ${YELLOW}âš ï¸  $MIGRATION_TARGET_CONTAINER${RESET} (ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½)"
        fi
    else
        print_box_line "  ĞŸÑ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº:  ${RED}âŒ ĞĞµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
    fi
    
    echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ±ÑĞºĞ°Ğ¿ Ğ‘Ğ” RWP-Shop Ğ¿ĞµÑ€ĞµĞ´ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸ĞµĞ¹ ---
migration_backup_target_db() {
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        print_message "ERROR" "ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ¿Ñ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸ĞºĞ° Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½"
        return 1
    fi
    
    local backup_file="$MIGRATION_WORK_DIR/pre_migration_backup_$(date +%Y%m%d_%H%M%S).sql"
    mkdir -p "$MIGRATION_WORK_DIR"
    
    print_message "INFO" "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ±ÑĞºĞ°Ğ¿Ğ° Ğ‘Ğ” RWP-Shop..."
    
    if docker exec "$MIGRATION_TARGET_CONTAINER" pg_dump -U "$MIGRATION_TARGET_USER" "$MIGRATION_TARGET_DB" > "$backup_file" 2>/dev/null; then
        local size=$(du -h "$backup_file" | cut -f1)
        print_message "SUCCESS" "Ğ‘ÑĞºĞ°Ğ¿ ÑĞ¾Ğ·Ğ´Ğ°Ğ½: $backup_file ($size)"
        MIGRATION_AUTO_BACKUP="$backup_file"
        return 0
    else
        print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ±ÑĞºĞ°Ğ¿ Ğ‘Ğ”"
        return 1
    fi
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ğ°Ğ¿ĞºÑƒ NOT_MIGRATED Ñ README ---
migration_create_not_migrated_dir() {
    MIGRATION_NOT_MIGRATED_DIR="$MIGRATION_WORK_DIR/NOT_MIGRATED"
    mkdir -p "$MIGRATION_NOT_MIGRATED_DIR"
    
    cat > "$MIGRATION_NOT_MIGRATED_DIR/README.txt" << 'EOF'
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Ğ”ĞĞĞĞ«Ğ•, ĞšĞĞ¢ĞĞ Ğ«Ğ• ĞĞ• Ğ‘Ğ«Ğ›Ğ˜ ĞŸĞ•Ğ Ğ•ĞĞ•Ğ¡Ğ•ĞĞ« ĞĞ’Ğ¢ĞĞœĞĞ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜
  LAZARUS Migration Tool
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ğ­Ñ‚Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ñ‹ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Bedolaga, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ½Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸
Ğ¿ĞµÑ€ĞµĞ½ĞµÑĞµĞ½Ñ‹ Ğ² RWP-Shop Ğ¸Ğ·-Ğ·Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ¸Ğ¹ Ğ² Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ Ğ±Ğ¾Ñ‚Ğ¾Ğ².

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ user_balances.csv (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
   Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚: Ğ‘Ğ°Ğ»Ğ°Ğ½ÑÑ‹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ² ĞšĞĞŸĞ•Ğ™ĞšĞĞ¥
   
   ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°: Ğ’ RWP-Shop Ğ±Ğ°Ğ»Ğ°Ğ½Ñ Ğ½Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑÑ Ğ² Ñ€ÑƒĞ±Ğ»ÑÑ….
   
   Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹:
   â€¢ Ğ’Ñ€ÑƒÑ‡Ğ½ÑƒÑ Ğ½Ğ°Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ÑŒ Ğ´Ğ½Ğ¸ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ°Ğ´Ğ¼Ğ¸Ğ½-Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ
   â€¢ Ğ¡Ğ²ÑĞ·Ğ°Ñ‚ÑŒÑÑ Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑĞ¼Ğ¸ Ğ´Ğ»Ñ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ°/ĞºĞ¾Ğ¼Ğ¿ĞµĞ½ÑĞ°Ñ†Ğ¸Ğ¸
   â€¢ ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ² Ğ´Ğ½Ğ¸ Ğ¿Ğ¾ Ğ²Ğ°ÑˆĞµĞ¼Ñƒ ĞºÑƒÑ€ÑÑƒ

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ referral_balances.csv (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
   Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚: Ğ ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ±Ğ°Ğ»Ğ°Ğ½ÑÑ‹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹
   
   ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°: Ğ’ RWP-Shop Ğ½ĞµÑ‚ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ°.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ promocodes_balance_type.csv (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
   Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚: ĞŸÑ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ñ‹, Ğ´Ğ°ÑÑ‰Ğ¸Ğµ Ğ´ĞµĞ½ÑŒĞ³Ğ¸ Ğ½Ğ° Ğ±Ğ°Ğ»Ğ°Ğ½Ñ
   Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: code, bonus_kopeks, bonus_rub, max_uses, current_uses, is_active
   
   ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°: Ğ’ RWP-Shop Ğ½ĞµÑ‚ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹.
            ĞŸÑ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ñ‹ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ½Ğ¸ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ¸ Ğ¸Ğ»Ğ¸ ÑĞºĞ¸Ğ´ĞºÑƒ.
   
   Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹:
   â€¢ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ñ‹ Ğ½Ğ° Ğ´Ğ½Ğ¸ (Ğ¿ĞµÑ€ĞµÑÑ‡Ğ¸Ñ‚Ğ°Ğ² Ñ€ÑƒĞ±Ğ»Ğ¸ Ğ² Ğ´Ğ½Ğ¸)
   â€¢ Ğ¡Ğ²ÑĞ·Ğ°Ñ‚ÑŒÑÑ Ñ Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†Ğ°Ğ¼Ğ¸ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ğ¾Ğ² Ğ´Ğ»Ñ ĞºĞ¾Ğ¼Ğ¿ĞµĞ½ÑĞ°Ñ†Ğ¸Ğ¸

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ unknown_payments.csv (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
   Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚: Ğ¢Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ½ĞµĞ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ Ğ¿Ğ»Ğ°Ñ‚Ñ‘Ğ¶Ğ½Ñ‹Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹
   ĞŸĞ»Ğ°Ñ‚Ñ‘Ğ¶ĞºĞ¸: heleket, pal24, mulenpay, cloudpayments, manual
   
   ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°: RWP-Shop Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ ÑÑ‚Ğ¸ Ğ¿Ğ»Ğ°Ñ‚Ñ‘Ğ¶Ğ½Ñ‹Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹.
   
   Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ° Ğ´Ğ»Ñ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ lost_settings.json (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
   Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚: ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Bedolaga Ğ±ĞµĞ· Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ² RWP-Shop
   
   ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹: PRICE_PER_DEVICE, TRAFFIC_PACKAGES_CONFIG

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹? Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ issue: https://github.com/UnderGut/LAZARUS-Backup-Manager

EOF
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ´Ğ°Ñ‚Ñƒ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ² README
    sed -i "2a\\  Ğ”Ğ°Ñ‚Ğ° Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸: $(date '+%Y-%m-%d %H:%M:%S')" "$MIGRATION_NOT_MIGRATED_DIR/README.txt"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— HEALTHCHECK FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ° Ğ²ÑĞµÑ… ÑÑ‚Ğ°Ğ¿Ğ°Ñ… Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ñ‚Ğ¸Ğ¿ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Bedolaga ---
# Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚: tar.gz | zip | tar | unknown
detect_bedolaga_archive_type() {
    local archive_path="$1"
    local file_name=$(basename "$archive_path")
    
    # Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ magic bytes Ğ±ĞµĞ· xxd
    get_magic_bytes() {
        local file="$1"
        local len="${2:-2}"
        if command -v xxd &>/dev/null; then
            xxd -l"$len" -p "$file" 2>/dev/null
        elif command -v od &>/dev/null; then
            od -An -tx1 -N"$len" "$file" 2>/dev/null | tr -d ' \n'
        else
            # Fallback: head + hexdump-like Ñ‡ĞµÑ€ĞµĞ· printf
            head -c"$len" "$file" 2>/dev/null | od -An -tx1 2>/dev/null | tr -d ' \n'
        fi
    }
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ğ¾ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ñ + magic bytes
    
    # ZIP: Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ .zip Ğ¸Ğ»Ğ¸ .tar.zip
    if [[ "$file_name" == *.tar.zip ]] || [[ "$file_name" == *.zip ]]; then
        local magic=$(get_magic_bytes "$archive_path" 2)
        if [[ "$magic" == "504b" ]]; then  # PK
            echo "zip"
            return 0
        fi
    fi
    
    # TAR.GZ: Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ .tar.gz Ğ¸Ğ»Ğ¸ .tgz
    if [[ "$file_name" == *.tar.gz ]] || [[ "$file_name" == *.tgz ]]; then
        local magic=$(get_magic_bytes "$archive_path" 2)
        if [[ "$magic" == "1f8b" ]]; then  # gzip magic
            echo "tar.gz"
            return 0
        fi
    fi
    
    # Plain TAR
    if [[ "$file_name" == *.tar ]]; then
        echo "tar"
        return 0
    fi
    
    # Ğ•ÑĞ»Ğ¸ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ Ğ½Ğµ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ»Ğ¾ â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ¾ magic bytes
    local magic=$(get_magic_bytes "$archive_path" 2)
    case "$magic" in
        504b)  echo "zip"; return 0 ;;      # PK (ZIP)
        1f8b)  echo "tar.gz"; return 0 ;;   # gzip
    esac
    
    echo "unknown"
    return 1
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ unzip ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ ---
ensure_unzip_installed() {
    # Ğ•ÑĞ»Ğ¸ ÑƒĞ¶Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ â€” Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ´ĞµĞ»Ğ°ĞµĞ¼
    command -v unzip &>/dev/null && return 0
    
    debug_log "MIGRATE" "unzip not found, attempting auto-install"
    
    # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ°
    if command -v apt-get &>/dev/null; then
        apt-get update -qq 2>/dev/null && apt-get install -y -qq unzip >/dev/null 2>&1
    elif command -v yum &>/dev/null; then
        yum install -y -q unzip >/dev/null 2>&1
    elif command -v dnf &>/dev/null; then
        dnf install -y -q unzip >/dev/null 2>&1
    elif command -v apk &>/dev/null; then
        apk add --quiet unzip >/dev/null 2>&1
    elif command -v pacman &>/dev/null; then
        pacman -S --noconfirm --quiet unzip >/dev/null 2>&1
    elif command -v zypper &>/dev/null; then
        zypper install -y -q unzip >/dev/null 2>&1
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚ÑŒ
    if command -v unzip &>/dev/null; then
        debug_log "MIGRATE" "unzip installed successfully"
        return 0
    else
        debug_log "MIGRATE" "Failed to install unzip"
        return 1
    fi
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ 7z (p7zip) ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ ---
# 7z Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ğ»Ñ AES-Ğ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ZIP Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ² (unzip Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ AES)
ensure_7z_installed() {
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ Ğ¸Ğ¼Ñ‘Ğ½
    command -v 7z &>/dev/null && return 0
    command -v 7za &>/dev/null && return 0
    command -v 7zr &>/dev/null && return 0
    
    debug_log "MIGRATE" "7z not found, attempting auto-install"
    
    # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ°
    if command -v apt-get &>/dev/null; then
        apt-get update -qq 2>/dev/null && apt-get install -y -qq p7zip-full >/dev/null 2>&1
    elif command -v yum &>/dev/null; then
        yum install -y -q p7zip p7zip-plugins >/dev/null 2>&1
    elif command -v dnf &>/dev/null; then
        dnf install -y -q p7zip p7zip-plugins >/dev/null 2>&1
    elif command -v apk &>/dev/null; then
        apk add --quiet p7zip >/dev/null 2>&1
    elif command -v pacman &>/dev/null; then
        pacman -S --noconfirm --quiet p7zip >/dev/null 2>&1
    elif command -v zypper &>/dev/null; then
        zypper install -y -q p7zip >/dev/null 2>&1
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚ÑŒ
    if command -v 7z &>/dev/null || command -v 7za &>/dev/null; then
        debug_log "MIGRATE" "7z installed successfully"
        return 0
    else
        debug_log "MIGRATE" "Failed to install 7z"
        return 1
    fi
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ 7z ---
get_7z_command() {
    command -v 7z &>/dev/null && echo "7z" && return 0
    command -v 7za &>/dev/null && echo "7za" && return 0
    command -v 7zr &>/dev/null && echo "7zr" && return 0
    return 1
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ»Ğ¸ ZIP AES ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ---
is_zip_aes_encrypted() {
    local archive_path="$1"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· file command
    if file "$archive_path" 2>/dev/null | grep -qi "AES"; then
        return 0  # AES ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
    fi
    
    # ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· unzip -v
    if unzip -v "$archive_path" 2>&1 | grep -qi "AES"; then
        return 0
    fi
    
    return 1  # ĞĞµ AES
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ, Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ»Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ğ² Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ ---
# ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚:
#   1) ZIP Ñ ZipCrypto ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ (unzip)
#   2) ZIP Ñ AES ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ (7z)
is_archive_password_protected() {
    local archive_path="$1"
    local archive_type=$(detect_bedolaga_archive_type "$archive_path")
    
    if [[ "$archive_type" != "zip" ]]; then
        return 1  # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ ZIP Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ñ‘Ğ½ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ AES ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ (unzip Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ AES!)
    if is_zip_aes_encrypted "$archive_path"; then
        debug_log "MIGRATE" "Archive uses AES encryption"
        return 0  # AES = Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ
    fi
    
    # Ğ£Ğ±ĞµĞ¶Ğ´Ğ°ĞµĞ¼ÑÑ Ñ‡Ñ‚Ğ¾ unzip ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½
    ensure_unzip_installed || return 1
    
    # Ğ”Ğ»Ñ ZipCrypto â€” Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ±ĞµĞ· Ğ¿Ğ°Ñ€Ğ¾Ğ»Ñ
    local temp_dir=$(mktemp -d)
    
    if unzip -o -q "$archive_path" -d "$temp_dir" 2>/dev/null; then
        # ZIP Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ»ÑÑ Ğ±ĞµĞ· Ğ¿Ğ°Ñ€Ğ¾Ğ»Ñ â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ
        if find "$temp_dir" -name "database.json" 2>/dev/null | grep -q . || \
           find "$temp_dir" -name "*.tar.gz" 2>/dev/null | grep -q .; then
            rm -rf "$temp_dir"
            return 1  # ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ ĞĞ• Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ
        fi
    fi
    
    rm -rf "$temp_dir"
    return 0  # Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Healthcheck Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Bedolaga ---
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚: Ñ†ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°, Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ database.json, ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ JSON
# ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚: tar.gz, tar, zip (Ğ² Ñ‚.Ñ‡. Ğ·Ğ°Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹)
migration_healthcheck_archive() {
    local archive_path="${1:-$MIGRATION_SOURCE_BACKUP}"
    local verbose="${2:-true}"
    local errors=0
    local warnings=0
    
    # Ğ£Ğ±ĞµĞ¶Ğ´Ğ°ĞµĞ¼ÑÑ Ñ‡Ñ‚Ğ¾ unzip ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ (Ğ´Ğ»Ñ ZIP Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ²)
    ensure_unzip_installed 2>/dev/null
    
    [[ "$verbose" == "true" ]] && echo -e "\n${CYAN}â”â”â” ğŸ¥ HEALTHCHECK: ĞÑ€Ñ…Ğ¸Ğ² Bedolaga â”â”â”${RESET}\n"
    
    # 1) Ğ¤Ğ°Ğ¹Ğ» ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚
    if [[ ! -f "$archive_path" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: $archive_path"
        return 1
    fi
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ¤Ğ°Ğ¹Ğ» ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚"
    
    # 2) Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ñ„Ğ°Ğ¹Ğ»Ğ° > 0
    local file_size=$(stat -c%s "$archive_path" 2>/dev/null || stat -f%z "$archive_path" 2>/dev/null)
    if [[ -z "$file_size" || "$file_size" -eq 0 ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} Ğ¤Ğ°Ğ¹Ğ» Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹"
        return 1
    fi
    local size_human=$(numfmt --to=iec-i --suffix=B "$file_size" 2>/dev/null || echo "${file_size} bytes")
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ñ„Ğ°Ğ¹Ğ»Ğ°: $size_human"
    
    # 3) ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
    local archive_type=$(detect_bedolaga_archive_type "$archive_path")
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ¢Ğ¸Ğ¿ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°: $archive_type"
    
    if [[ "$archive_type" == "unknown" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°"
        return 1
    fi
    
    # 4) ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ ZIP)
    local needs_password=false
    if [[ "$archive_type" == "zip" ]]; then
        if is_archive_password_protected "$archive_path"; then
            needs_password=true
            [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}ğŸ”’${RESET} ĞÑ€Ñ…Ğ¸Ğ² Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ñ‘Ğ½ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼"
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ
            if [[ -z "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}â—‹${RESET} ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²ĞºĞµ"
                ((warnings++))
            else
                [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½"
            fi
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} ĞÑ€Ñ…Ğ¸Ğ² Ğ½Ğµ Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ñ‘Ğ½ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼"
        fi
    fi
    
    # 5) ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ†ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸
    case "$archive_type" in
        "tar.gz")
            if ! gzip -t "$archive_path" 2>/dev/null; then
                [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞŸĞ¾Ğ²Ñ€ĞµĞ¶Ğ´Ñ‘Ğ½ gzip Ğ°Ñ€Ñ…Ğ¸Ğ²"
                return 1
            fi
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ¦ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ gzip: OK"
            
            if ! tar -tzf "$archive_path" &>/dev/null; then
                [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞŸĞ¾Ğ²Ñ€ĞµĞ¶Ğ´Ñ‘Ğ½ tar Ğ°Ñ€Ñ…Ğ¸Ğ²"
                return 1
            fi
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ¦ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ tar: OK"
            ;;
        "tar")
            if ! tar -tf "$archive_path" &>/dev/null; then
                [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞŸĞ¾Ğ²Ñ€ĞµĞ¶Ğ´Ñ‘Ğ½ tar Ğ°Ñ€Ñ…Ğ¸Ğ²"
                return 1
            fi
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ¦ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ tar: OK"
            ;;
        "zip")
            # Ğ”Ğ»Ñ Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ñ‘Ğ½Ğ½Ñ‹Ñ… ZIP Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼ ĞµÑĞ»Ğ¸ Ğ¾Ğ½ ĞµÑÑ‚ÑŒ
            if [[ "$needs_password" == "true" ]]; then
                if [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                    # ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ñ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· 7z Ğ¸Ğ»Ğ¸ unzip
                    local integrity_ok=false
                    if is_zip_aes_encrypted "$archive_path"; then
                        # AES â€” Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ 7z
                        if ensure_7z_installed; then
                            local cmd_7z=$(get_7z_command)
                            if $cmd_7z t -p"$BEDOLAGA_BACKUP_PASSWORD" "$archive_path" &>/dev/null; then
                                integrity_ok=true
                            fi
                        fi
                    else
                        # ZipCrypto â€” unzip
                        if unzip -t -P "$BEDOLAGA_BACKUP_PASSWORD" "$archive_path" &>/dev/null; then
                            integrity_ok=true
                        fi
                    fi
                    
                    if [[ "$integrity_ok" == "true" ]]; then
                        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ¦ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ ZIP: OK (Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ¾ Ñ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼)"
                    else
                        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞÑˆĞ¸Ğ±ĞºĞ° Ñ†ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸Ğ»Ğ¸ Ğ½ĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ"
                        ((errors++))
                    fi
                else
                    [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}â—‹${RESET} Ğ¦ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ ZIP: Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸"
                    ((warnings++))
                fi
            else
                if ! unzip -t "$archive_path" &>/dev/null; then
                    [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞŸĞ¾Ğ²Ñ€ĞµĞ¶Ğ´Ñ‘Ğ½ ZIP Ğ°Ñ€Ñ…Ğ¸Ğ²"
                    return 1
                fi
                [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ¦ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ ZIP: OK"
            fi
            ;;
    esac
    
    # 6) ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğ³Ğ¾ (database.json)
    local temp_dir=$(mktemp -d)
    TEMP_DIRS+=("$temp_dir")
    local json_file=""
    
    case "$archive_type" in
        "tar.gz")
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ database.json
            if ! tar -tzf "$archive_path" | grep -q "database.json"; then
                [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ database.json Ğ² Ğ°Ñ€Ñ…Ğ¸Ğ²Ğµ"
                rm -rf "$temp_dir"
                return 1
            fi
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} database.json Ğ¿Ñ€Ğ¸ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚"
            
            # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ JSON
            tar -xzf "$archive_path" -C "$temp_dir" --wildcards '*/database.json' 2>/dev/null || \
            tar -xzf "$archive_path" -C "$temp_dir" 'database.json' 2>/dev/null
            json_file=$(find "$temp_dir" -name "database.json" -type f 2>/dev/null | head -1)
            ;;
        "tar")
            if ! tar -tf "$archive_path" | grep -q "database.json"; then
                [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ database.json Ğ² Ğ°Ñ€Ñ…Ğ¸Ğ²Ğµ"
                rm -rf "$temp_dir"
                return 1
            fi
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} database.json Ğ¿Ñ€Ğ¸ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚"
            
            tar -xf "$archive_path" -C "$temp_dir" --wildcards '*/database.json' 2>/dev/null || \
            tar -xf "$archive_path" -C "$temp_dir" 'database.json' 2>/dev/null
            json_file=$(find "$temp_dir" -name "database.json" -type f 2>/dev/null | head -1)
            ;;
        "zip")
            if [[ "$needs_password" == "true" ]]; then
                # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½Ğ½Ñ‹Ğ¼ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼
                if [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ AES ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
                    local is_aes="false"
                    if is_zip_aes_encrypted "$archive_path"; then
                        is_aes="true"
                    fi
                    
                    # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ğ² (7z Ğ´Ğ»Ñ AES, unzip Ğ´Ğ»Ñ ZipCrypto)
                    if [[ "$is_aes" == "true" ]]; then
                        if ! ensure_7z_installed; then
                            [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} 7z Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ (Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ AES)"
                            rm -rf "$temp_dir"
                            return 1
                        fi
                        local cmd_7z=$(get_7z_command)
                        $cmd_7z x -p"$BEDOLAGA_BACKUP_PASSWORD" -o"$temp_dir" "$archive_path" -y &>/dev/null
                    else
                        unzip -P "$BEDOLAGA_BACKUP_PASSWORD" -q "$archive_path" -d "$temp_dir" 2>/dev/null
                    fi
                    
                    # Ğ˜Ñ‰ĞµĞ¼ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ tar.gz
                    local inner_archive=$(find "$temp_dir" -name "*.tar.gz" -o -name "*.tar" 2>/dev/null | head -1)
                    if [[ -n "$inner_archive" ]]; then
                        local inner_temp="$temp_dir/inner"
                        mkdir -p "$inner_temp"
                        if [[ "$inner_archive" == *.tar.gz ]]; then
                            tar -xzf "$inner_archive" -C "$inner_temp" 2>/dev/null
                        else
                            tar -xf "$inner_archive" -C "$inner_temp" 2>/dev/null
                        fi
                        json_file=$(find "$inner_temp" -name "database.json" -type f 2>/dev/null | head -1)
                    else
                        json_file=$(find "$temp_dir" -name "database.json" -type f 2>/dev/null | head -1)
                    fi
                    
                    if [[ -z "$json_file" ]]; then
                        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ database.json Ğ² Ğ°Ñ€Ñ…Ğ¸Ğ²Ğµ"
                        rm -rf "$temp_dir"
                        return 1
                    fi
                    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} database.json Ğ¿Ñ€Ğ¸ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚"
                else
                    [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}â—‹${RESET} database.json: Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸"
                    ((warnings++))
                fi
            else
                # Ğ‘ĞµĞ· Ğ¿Ğ°Ñ€Ğ¾Ğ»Ñ â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ
                if ! unzip -l "$archive_path" 2>/dev/null | grep -q "database.json"; then
                    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ğ²
                    unzip -q "$archive_path" -d "$temp_dir" 2>/dev/null
                    local inner_archive=$(find "$temp_dir" -name "*.tar.gz" -o -name "*.tar" 2>/dev/null | head -1)
                    if [[ -n "$inner_archive" ]]; then
                        if [[ "$inner_archive" == *.tar.gz ]]; then
                            if ! tar -tzf "$inner_archive" | grep -q "database.json"; then
                                [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ database.json"
                                rm -rf "$temp_dir"
                                return 1
                            fi
                        fi
                    else
                        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ database.json"
                        rm -rf "$temp_dir"
                        return 1
                    fi
                fi
                [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} database.json Ğ¿Ñ€Ğ¸ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚"
            fi
            ;;
    esac
    
    # Ğ•ÑĞ»Ğ¸ json_file Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ¸ Ğ½ĞµÑ‚ Ğ¿Ğ°Ñ€Ğ¾Ğ»Ñ â€” Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºÑƒ JSON
    if [[ -z "$json_file" || ! -f "$json_file" ]]; then
        if [[ "$needs_password" == "true" && -z "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
            [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}â—‹${RESET} ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° JSON ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹: Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ"
            ((warnings++))
            rm -rf "$temp_dir"
            
            # Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸ĞµĞ¼
            if [[ "$verbose" == "true" ]]; then
                echo ""
                echo -e "  ${YELLOW}${BOLD}âš ï¸  ĞĞ Ğ¥Ğ˜Ğ’ Ğ¢Ğ Ğ•Ğ‘Ğ£Ğ•Ğ¢ ĞŸĞĞ ĞĞ›Ğ¬${RESET}"
                echo -e "  ${YELLOW}   Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸${RESET}"
            fi
            
            debug_log "HEALTHCHECK" "Archive check: password required, path=$archive_path"
            return 0  # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ ÑƒÑĞ¿ĞµÑ…, Ñ‚.Ğº. Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¿Ñ€Ğ¾Ğ¹Ğ´ĞµĞ½Ñ‹
        fi
        
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ database.json"
        rm -rf "$temp_dir"
        return 1
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚Ğ¸ JSON Ñ‡ĞµÑ€ĞµĞ· Python
    local python_cmd="${PYTHON_CMD:-python3}"
    if ! $python_cmd -c "import json; json.load(open('$json_file'))" 2>/dev/null; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} database.json Ğ½Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¼ JSON"
        rm -rf "$temp_dir"
        return 1
    fi
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} JSON ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ°"
    
    # 7) ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†
    # Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° JSON: {"metadata": {...}, "data": {"users": [...], ...}}
    # Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ½Ğ°Ñ…Ğ¾Ğ´ÑÑ‚ÑÑ Ğ² d['data'], Ğ½Ğµ Ğ² ĞºĞ¾Ñ€Ğ½Ğµ!
    local required_tables=("users")
    local optional_tables=("transactions" "promocodes" "subscriptions" "tickets")
    
    for table in "${required_tables[@]}"; do
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ² d['data']['table'] (Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚) Ğ¸Ğ»Ğ¸ d['table'] (ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚)
        if $python_cmd -c "
import json
d = json.load(open('$json_file'))
data = d.get('data', d)  # Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ 'data' - Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ĞµĞ³Ğ¾, Ğ¸Ğ½Ğ°Ñ‡Ğµ ĞºĞ¾Ñ€ĞµĞ½ÑŒ
exit(0 if '$table' in data else 1)
" 2>/dev/null; then
            local count=$($python_cmd -c "
import json
d = json.load(open('$json_file'))
data = d.get('data', d)
print(len(data.get('$table', [])))
" 2>/dev/null)
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° '$table': $count Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ°: $table"
            ((errors++))
        fi
    done
    
    for table in "${optional_tables[@]}"; do
        if $python_cmd -c "
import json
d = json.load(open('$json_file'))
data = d.get('data', d)
exit(0 if '$table' in data else 1)
" 2>/dev/null; then
            local count=$($python_cmd -c "
import json
d = json.load(open('$json_file'))
data = d.get('data', d)
print(len(data.get('$table', [])))
" 2>/dev/null)
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° '$table': $count Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}â—‹${RESET} Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° '$table' Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)"
            ((warnings++))
        fi
    done
    
    rm -rf "$temp_dir"
    
    # Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
    if [[ "$verbose" == "true" ]]; then
        echo ""
        if [[ $errors -eq 0 ]]; then
            echo -e "  ${GREEN}${BOLD}âœ… ĞĞ Ğ¥Ğ˜Ğ’ Ğ’ĞĞ›Ğ˜Ğ”Ğ•Ğ${RESET}"
            [[ $warnings -gt 0 ]] && echo -e "  ${YELLOW}   (Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹: $warnings)${RESET}"
        else
            echo -e "  ${RED}${BOLD}âŒ ĞĞ Ğ¥Ğ˜Ğ’ ĞĞ•Ğ’ĞĞ›Ğ˜Ğ”Ğ•Ğ${RESET} (Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº: $errors)"
        fi
    fi
    
    debug_log "HEALTHCHECK" "Archive check: errors=$errors, warnings=$warnings, path=$archive_path"
    
    return $errors
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Healthcheck Ğ‘Ğ” Ğ¿ĞµÑ€ĞµĞ´ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ¼ ---
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚: Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ, Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†, Ğ¿Ñ€Ğ°Ğ²Ğ° Ğ½Ğ° Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ
migration_healthcheck_db_pre() {
    local verbose="${1:-true}"
    local errors=0
    local warnings=0
    
    [[ "$verbose" == "true" ]] && echo -e "\n${CYAN}â”â”â” ğŸ¥ HEALTHCHECK: Ğ‘Ğ” RWP-Shop (PRE-IMPORT) â”â”â”${RESET}\n"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ·Ğ°Ğ´Ğ°Ğ½
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞĞµ Ğ·Ğ°Ğ´Ğ°Ğ½ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ”"
        return 1
    fi
    
    # 1) ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½
    if ! docker ps --format '{{.Names}}' | grep -q "^${MIGRATION_TARGET_CONTAINER}$"; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½: $MIGRATION_TARGET_CONTAINER"
        return 1
    fi
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½: $MIGRATION_TARGET_CONTAINER"
    
    # 2) Healthcheck ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° (pg_isready)
    local db_user="${MIGRATION_TARGET_USER:-postgres}"
    local db_name="${MIGRATION_TARGET_DB:-postgres}"
    
    if ! docker exec "$MIGRATION_TARGET_CONTAINER" pg_isready -U "$db_user" &>/dev/null; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} PostgreSQL Ğ½Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ² (pg_isready failed)"
        return 1
    fi
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} PostgreSQL Ğ³Ğ¾Ñ‚Ğ¾Ğ² Ğº Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ"
    
    # 3) ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Ğ‘Ğ”
    if ! docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -c "SELECT 1" &>/dev/null; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğº Ğ‘Ğ”: $db_name"
        return 1
    fi
    [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Ğ‘Ğ”: $db_name"
    
    # 4) ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†
    local required_tables=("customer" "promo" "purchase")
    local optional_tables=("referral" "promo_usage" "support_ticket" "support_message" "broadcast")
    
    for table in "${required_tables[@]}"; do
        local exists=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
            "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = '$table')" 2>/dev/null)
        if [[ "$exists" == "t" ]]; then
            local count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
                "SELECT COUNT(*) FROM $table" 2>/dev/null)
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° '$table': $count Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ°: $table"
            ((errors++))
        fi
    done
    
    for table in "${optional_tables[@]}"; do
        local exists=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
            "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = '$table')" 2>/dev/null)
        if [[ "$exists" == "t" ]]; then
            local count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
                "SELECT COUNT(*) FROM $table" 2>/dev/null)
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° '$table': $count Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}â—‹${RESET} Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° '$table' Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚"
            ((warnings++))
        fi
    done
    
    # 5) ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ñ€Ğ°Ğ² Ğ½Ğ° Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ (ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¸ ÑƒĞ´Ğ°Ğ»ÑĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¾Ğ²ÑƒÑ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ)
    local write_test=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
        "CREATE TEMP TABLE _lazarus_write_test (id int); INSERT INTO _lazarus_write_test VALUES (1); SELECT COUNT(*) FROM _lazarus_write_test;" 2>&1)
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹ Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
    write_test=$(echo "$write_test" | tr -d '[:space:]')
    if [[ "$write_test" == "1" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} ĞŸÑ€Ğ°Ğ²Ğ° Ğ½Ğ° Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ: OK"
    elif [[ "$write_test" =~ "ERROR" ]] || [[ -z "$write_test" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞĞµÑ‚ Ğ¿Ñ€Ğ°Ğ² Ğ½Ğ° Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ Ğ² Ğ‘Ğ”"
        ((errors++))
    else
        # Ğ”Ñ€ÑƒĞ³Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ â€” Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ OK
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} ĞŸÑ€Ğ°Ğ²Ğ° Ğ½Ğ° Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ: OK"
    fi
    
    # 6) ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑÑ‚Ğ° Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğµ
    local disk_free=$(docker exec "$MIGRATION_TARGET_CONTAINER" df -h /var/lib/postgresql/data 2>/dev/null | tail -1 | awk '{print $4}')
    if [[ -n "$disk_free" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ¡Ğ²Ğ¾Ğ±Ğ¾Ğ´Ğ½Ğ¾Ğµ Ğ¼ĞµÑÑ‚Ğ¾: $disk_free"
    fi
    
    # Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
    if [[ "$verbose" == "true" ]]; then
        echo ""
        if [[ $errors -eq 0 ]]; then
            echo -e "  ${GREEN}${BOLD}âœ… Ğ‘Ğ” Ğ“ĞĞ¢ĞĞ’Ğ Ğš Ğ˜ĞœĞŸĞĞ Ğ¢Ğ£${RESET}"
            [[ $warnings -gt 0 ]] && echo -e "  ${YELLOW}   (Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹: $warnings)${RESET}"
        else
            echo -e "  ${RED}${BOLD}âŒ Ğ‘Ğ” ĞĞ• Ğ“ĞĞ¢ĞĞ’Ğ${RESET} (Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº: $errors)"
        fi
    fi
    
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ÑÑ‡Ñ‘Ñ‚Ñ‡Ğ¸ĞºĞ¸ Ğ”Ğ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ
    HEALTHCHECK_PRE_COUNTS=""
    for table in customer promo purchase referral; do
        local count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
            "SELECT COUNT(*) FROM $table" 2>/dev/null || echo "0")
        HEALTHCHECK_PRE_COUNTS+="$table:$count "
    done
    
    debug_log "HEALTHCHECK" "DB pre-import: errors=$errors, warnings=$warnings, counts=$HEALTHCHECK_PRE_COUNTS"
    
    return $errors
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Healthcheck Ğ‘Ğ” Ğ¿Ğ¾ÑĞ»Ğµ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° ---
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚: Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ ÑÑ‡Ñ‘Ñ‚Ñ‡Ğ¸ĞºĞ¾Ğ², Ñ†ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ FK, Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ orphans
migration_healthcheck_db_post() {
    local verbose="${1:-true}"
    local errors=0
    local warnings=0
    
    [[ "$verbose" == "true" ]] && echo -e "\n${CYAN}â”â”â” ğŸ¥ HEALTHCHECK: Ğ‘Ğ” RWP-Shop (POST-IMPORT) â”â”â”${RESET}\n"
    
    local db_user="${MIGRATION_TARGET_USER:-postgres}"
    local db_name="${MIGRATION_TARGET_DB:-postgres}"
    
    # 1) Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ ÑÑ‡Ñ‘Ñ‚Ñ‡Ğ¸ĞºĞ¾Ğ² (Ğ´Ğ¾/Ğ¿Ğ¾ÑĞ»Ğµ)
    [[ "$verbose" == "true" ]] && echo -e "  ${BLUE}ğŸ“Š Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹:${RESET}"
    
    for table in customer promo purchase referral; do
        local pre_count=$(echo "$HEALTHCHECK_PRE_COUNTS" | grep -oP "$table:\K\d+")
        local post_count=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
            "SELECT COUNT(*) FROM $table" 2>/dev/null || echo "0")
        local diff=$((post_count - pre_count))
        
        if [[ $diff -gt 0 ]]; then
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} $table: $pre_count â†’ $post_count (+$diff)"
        elif [[ $diff -eq 0 ]]; then
            [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}â—‹${RESET} $table: $pre_count â†’ $post_count (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} $table: $pre_count â†’ $post_count ($diff) - Ğ£ĞœĞ•ĞĞ¬Ğ¨Ğ˜Ğ›ĞĞ¡Ğ¬!"
            ((warnings++))
        fi
    done
    
    # 2) ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° FK integrity (orphan referrals)
    [[ "$verbose" == "true" ]] && echo -e "\n  ${BLUE}ğŸ”— ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ†ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞ²ÑĞ·ĞµĞ¹:${RESET}"
    
    # Orphan referrals (referrer_id Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ² customer)
    local orphan_referrers=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
        "SELECT COUNT(*) FROM referral r WHERE NOT EXISTS (SELECT 1 FROM customer c WHERE c.telegram_id = r.referrer_id)" 2>/dev/null || echo "0")
    if [[ "$orphan_referrers" -eq 0 ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} referral.referrer_id â†’ customer: OK"
    else
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} referral.referrer_id â†’ customer: $orphan_referrers orphans"
        ((warnings++))
    fi
    
    # Orphan referees
    local orphan_referees=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
        "SELECT COUNT(*) FROM referral r WHERE NOT EXISTS (SELECT 1 FROM customer c WHERE c.telegram_id = r.referee_id)" 2>/dev/null || echo "0")
    if [[ "$orphan_referees" -eq 0 ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} referral.referee_id â†’ customer: OK"
    else
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} referral.referee_id â†’ customer: $orphan_referees orphans"
        ((warnings++))
    fi
    
    # Orphan promo_usage
    local orphan_promo=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
        "SELECT COUNT(*) FROM promo_usage pu WHERE NOT EXISTS (SELECT 1 FROM promo p WHERE p.id = pu.promo_id)" 2>/dev/null || echo "0")
    if [[ "$orphan_promo" -eq 0 ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} promo_usage.promo_id â†’ promo: OK"
    else
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} promo_usage.promo_id â†’ promo: $orphan_promo orphans"
        ((warnings++))
    fi
    
    # 3) ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° NULL Ğ² Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»ÑÑ…
    [[ "$verbose" == "true" ]] && echo -e "\n  ${BLUE}âš ï¸  ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:${RESET}"
    
    local null_telegram_id=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
        "SELECT COUNT(*) FROM customer WHERE telegram_id IS NULL" 2>/dev/null || echo "0")
    if [[ "$null_telegram_id" -eq 0 ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} customer.telegram_id: Ğ½ĞµÑ‚ NULL"
    else
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} customer.telegram_id: $null_telegram_id NULL Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹"
        ((errors++))
    fi
    
    # 4) ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ² telegram_id
    local dup_telegram=$(docker exec "$MIGRATION_TARGET_CONTAINER" psql -U "$db_user" -d "$db_name" -tAc \
        "SELECT COUNT(*) FROM (SELECT telegram_id FROM customer GROUP BY telegram_id HAVING COUNT(*) > 1) t" 2>/dev/null || echo "0")
    if [[ "$dup_telegram" -eq 0 ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} customer.telegram_id: Ğ½ĞµÑ‚ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²"
    else
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} customer.telegram_id: $dup_telegram Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²"
        ((errors++))
    fi
    
    # Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
    if [[ "$verbose" == "true" ]]; then
        echo ""
        if [[ $errors -eq 0 && $warnings -eq 0 ]]; then
            echo -e "  ${GREEN}${BOLD}âœ… Ğ˜ĞœĞŸĞĞ Ğ¢ ĞŸĞ ĞĞ¨ĞĞ› Ğ£Ğ¡ĞŸĞ•Ğ¨ĞĞ${RESET}"
        elif [[ $errors -eq 0 ]]; then
            echo -e "  ${YELLOW}${BOLD}âš ï¸  Ğ˜ĞœĞŸĞĞ Ğ¢ Ğ—ĞĞ’Ğ•Ğ Ğ¨ĞĞ Ğ¡ ĞŸĞ Ğ•Ğ”Ğ£ĞŸĞ Ğ•Ğ–Ğ”Ğ•ĞĞ˜Ğ¯ĞœĞ˜${RESET} ($warnings)"
        else
            echo -e "  ${RED}${BOLD}âŒ ĞĞ‘ĞĞĞ Ğ£Ğ–Ğ•ĞĞ« ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ«${RESET} (Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº: $errors, Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹: $warnings)"
        fi
    fi
    
    debug_log "HEALTHCHECK" "DB post-import: errors=$errors, warnings=$warnings"
    
    return $errors
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Healthcheck CSV Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² ---
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚: Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ², Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸, ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑÑ‚Ñ€Ğ¾Ğº
migration_healthcheck_csv() {
    local export_dir="${1:-$MIGRATION_WORK_DIR/export}"
    local verbose="${2:-true}"
    local errors=0
    local warnings=0
    local total_records=0
    
    [[ "$verbose" == "true" ]] && echo -e "\n${CYAN}â”â”â” ğŸ¥ HEALTHCHECK: Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ CSV â”â”â”${RESET}\n"
    
    if [[ ! -d "$export_dir" ]]; then
        [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} ĞŸĞ°Ğ¿ĞºĞ° ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°: $export_dir"
        return 1
    fi
    
    # ĞĞ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
    local required_files=("users.csv")
    local optional_files=("transactions.csv" "promocodes.csv" "subscriptions.csv" "referrals.csv" 
                          "promocode_uses.csv" "tickets.csv" "ticket_messages.csv")
    
    for file in "${required_files[@]}"; do
        if [[ -f "$export_dir/$file" ]]; then
            local lines=$(wc -l < "$export_dir/$file")
            local records=$((lines - 1))  # Ğ¼Ğ¸Ğ½ÑƒÑ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº
            total_records=$((total_records + records))
            
            if [[ $records -gt 0 ]]; then
                [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} $file: $records Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹"
            else
                [[ "$verbose" == "true" ]] && echo -e "  ${YELLOW}â—‹${RESET} $file: Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº)"
                ((warnings++))
            fi
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} $file: ĞĞ• ĞĞĞ™Ğ”Ğ•Ğ (Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹)"
            ((errors++))
        fi
    done
    
    for file in "${optional_files[@]}"; do
        if [[ -f "$export_dir/$file" ]]; then
            local lines=$(wc -l < "$export_dir/$file")
            local records=$((lines - 1))
            total_records=$((total_records + records))
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} $file: $records Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${DIM}â—‹${RESET} $file: Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)"
        fi
    done
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ² CSV
    [[ "$verbose" == "true" ]] && echo -e "\n  ${BLUE}ğŸ“‹ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ²:${RESET}"
    
    if [[ -f "$export_dir/users.csv" ]]; then
        local header=$(head -1 "$export_dir/users.csv")
        if echo "$header" | grep -q "telegram_id"; then
            [[ "$verbose" == "true" ]] && echo -e "  ${GREEN}âœ“${RESET} users.csv: Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚ĞµĞ½"
        else
            [[ "$verbose" == "true" ]] && echo -e "  ${RED}âœ—${RESET} users.csv: Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ telegram_id Ğ² Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞµ"
            ((errors++))
        fi
    fi
    
    # Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
    if [[ "$verbose" == "true" ]]; then
        echo ""
        echo -e "  ${BLUE}Ğ’ÑĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°:${RESET} $total_records"
        echo ""
        if [[ $errors -eq 0 ]]; then
            echo -e "  ${GREEN}${BOLD}âœ… CSV Ğ¤ĞĞ™Ğ›Ğ« Ğ’ĞĞ›Ğ˜Ğ”ĞĞ«${RESET}"
        else
            echo -e "  ${RED}${BOLD}âŒ ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ« Ğ¡ CSV${RESET} (Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº: $errors)"
        fi
    fi
    
    debug_log "HEALTHCHECK" "CSV check: errors=$errors, total_records=$total_records, dir=$export_dir"
    
    return $errors
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ healthcheck (Ğ²ÑĞµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸) ---
migration_healthcheck_full() {
    local verbose="${1:-true}"
    local archive_ok=0
    local db_pre_ok=0
    local csv_ok=0
    local archive_needs_password=0
    
    echo -e "\n${MAGENTA}${BOLD}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${RESET}"
    echo -e "${MAGENTA}${BOLD}â•‘        ğŸ¥ ĞŸĞĞ›ĞĞ«Ğ™ HEALTHCHECK ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ˜                  â•‘${RESET}"
    echo -e "${MAGENTA}${BOLD}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    
    # ĞÑ€Ñ…Ğ¸Ğ²
    if [[ -n "$MIGRATION_SOURCE_BACKUP" ]]; then
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ğ½ÑƒĞ¶ĞµĞ½ Ğ»Ğ¸ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ Ğ½Ğ¾ Ğ½Ğµ Ğ²Ğ²ĞµĞ´Ñ‘Ğ½
        local archive_type=$(detect_bedolaga_archive_type "$MIGRATION_SOURCE_BACKUP" 2>/dev/null)
        if [[ "$archive_type" == "zip" ]] && is_archive_password_protected "$MIGRATION_SOURCE_BACKUP" 2>/dev/null; then
            if [[ -z "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                archive_needs_password=1
            fi
        fi
        
        migration_healthcheck_archive "$MIGRATION_SOURCE_BACKUP" "$verbose" && archive_ok=1
    else
        [[ "$verbose" == "true" ]] && echo -e "\n  ${YELLOW}â—‹${RESET} ĞÑ€Ñ…Ğ¸Ğ² Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½ - Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞº Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸"
    fi
    
    # Ğ‘Ğ”
    if [[ -n "$MIGRATION_TARGET_CONTAINER" ]]; then
        migration_healthcheck_db_pre "$verbose" && db_pre_ok=1
    else
        [[ "$verbose" == "true" ]] && echo -e "\n  ${YELLOW}â—‹${RESET} ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ‘Ğ” Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½ - Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞº Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸"
    fi
    
    # CSV (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
    if [[ -d "$MIGRATION_WORK_DIR/export" ]]; then
        migration_healthcheck_csv "$MIGRATION_WORK_DIR/export" "$verbose" && csv_ok=1
    fi
    
    # Ğ˜Ñ‚Ğ¾Ğ³
    echo -e "\n${BLUE}â”â”â” Ğ˜Ğ¢ĞĞ“ â”â”â”${RESET}\n"
    
    # ĞÑ€Ñ…Ğ¸Ğ²: ĞµÑĞ»Ğ¸ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ â€” Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ OK
    if [[ $archive_needs_password -eq 1 ]]; then
        echo -e "  ${YELLOW}âš ${RESET} ĞÑ€Ñ…Ğ¸Ğ²: Ğ¢Ğ Ğ•Ğ‘Ğ£Ğ•Ğ¢Ğ¡Ğ¯ ĞŸĞĞ ĞĞ›Ğ¬"
    elif [[ $archive_ok -eq 1 ]]; then
        echo -e "  ${GREEN}âœ“${RESET} ĞÑ€Ñ…Ğ¸Ğ²: OK"
    else
        echo -e "  ${RED}âœ—${RESET} ĞÑ€Ñ…Ğ¸Ğ²: ĞĞ¨Ğ˜Ğ‘ĞšĞ"
    fi
    
    [[ $db_pre_ok -eq 1 ]] && echo -e "  ${GREEN}âœ“${RESET} Ğ‘Ğ”: OK" || echo -e "  ${RED}âœ—${RESET} Ğ‘Ğ”: ĞĞ¨Ğ˜Ğ‘ĞšĞ"
    [[ -d "$MIGRATION_WORK_DIR/export" ]] && { [[ $csv_ok -eq 1 ]] && echo -e "  ${GREEN}âœ“${RESET} CSV: OK" || echo -e "  ${RED}âœ—${RESET} CSV: ĞĞ¨Ğ˜Ğ‘ĞšĞ"; }
    
    echo ""
    return 0
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ½ĞµĞ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ğ¼Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ---
migration_save_not_migrated_data() {
    [[ -z "$MIGRATION_NOT_MIGRATED_DIR" ]] && migration_create_not_migrated_dir
    
    local export_dir="$MIGRATION_WORK_DIR/export"
    
    # 1) Ğ‘Ğ°Ğ»Ğ°Ğ½ÑÑ‹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
    if [[ -f "$export_dir/user_balances.csv" ]]; then
        cp "$export_dir/user_balances.csv" "$MIGRATION_NOT_MIGRATED_DIR/"
        print_message "INFO" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ±Ğ°Ğ»Ğ°Ğ½ÑÑ‹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ â†’ NOT_MIGRATED/"
    fi
    
    # 2) Ğ ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ±Ğ°Ğ»Ğ°Ğ½ÑÑ‹
    if [[ -f "$export_dir/referral_balances.csv" ]]; then
        cp "$export_dir/referral_balances.csv" "$MIGRATION_NOT_MIGRATED_DIR/"
        print_message "INFO" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ±Ğ°Ğ»Ğ°Ğ½ÑÑ‹ â†’ NOT_MIGRATED/"
    fi
    
    # 3) ĞŸÑ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ñ‹ Ğ½Ğ° Ğ±Ğ°Ğ»Ğ°Ğ½Ñ (Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ Ğ² RWP-Shop)
    if [[ -f "$export_dir/promocodes_balance_type.csv" ]]; then
        local balance_promo_count=$(($(wc -l < "$export_dir/promocodes_balance_type.csv") - 1))
        if [[ $balance_promo_count -gt 0 ]]; then
            cp "$export_dir/promocodes_balance_type.csv" "$MIGRATION_NOT_MIGRATED_DIR/"
            print_message "INFO" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ñ‹ Ğ½Ğ° Ğ±Ğ°Ğ»Ğ°Ğ½Ñ ($balance_promo_count) â†’ NOT_MIGRATED/"
        fi
    fi
    
    # 4) ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğµ Ğ¿Ğ»Ğ°Ñ‚ĞµĞ¶Ğ¸ (ÑĞ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¸Ğ· transactions)
    if [[ -f "$export_dir/transactions.csv" ]]; then
        # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¸ Ñ unknown payment_method
        head -1 "$export_dir/transactions.csv" > "$MIGRATION_NOT_MIGRATED_DIR/unknown_payments.csv"
        grep ",unknown," "$export_dir/transactions.csv" >> "$MIGRATION_NOT_MIGRATED_DIR/unknown_payments.csv" 2>/dev/null
        
        local unknown_count=$(wc -l < "$MIGRATION_NOT_MIGRATED_DIR/unknown_payments.csv")
        unknown_count=$((unknown_count - 1))
        
        if [[ $unknown_count -gt 0 ]]; then
            print_message "INFO" "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğµ Ğ¿Ğ»Ğ°Ñ‚ĞµĞ¶Ğ¸ ($unknown_count) â†’ NOT_MIGRATED/"
        else
            rm -f "$MIGRATION_NOT_MIGRATED_DIR/unknown_payments.csv"
        fi
    fi
    
    debug_log "MIGRATE" "Not migrated data saved to $MIGRATION_NOT_MIGRATED_DIR"
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ---
migration_show_detailed_analysis() {
    if [[ -z "$MIGRATION_SOURCE_BACKUP" || ! -f "$MIGRATION_SOURCE_BACKUP" ]]; then
        print_message "ERROR" "ĞÑ€Ñ…Ğ¸Ğ² Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½"
        return 1
    fi
    
    clear_screen
    local archive_name=$(basename "$MIGRATION_SOURCE_BACKUP")
    echo -e "${CYAN}${BOLD}+----------------------------------------------------------------------+${RESET}"
    printf "${CYAN}${BOLD}|  ĞĞĞĞ›Ğ˜Ğ— Ğ”ĞĞĞĞ«Ğ¥: %-51s |${RESET}\n" "$archive_name"
    echo -e "${CYAN}${BOLD}+----------------------------------------------------------------------+${RESET}"
    echo ""
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ»Ğ¸ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ
    local archive_type=$(detect_bedolaga_archive_type "$MIGRATION_SOURCE_BACKUP" 2>/dev/null)
    local is_aes=false
    
    if [[ "$archive_type" == "zip" ]] && is_zip_aes_encrypted "$MIGRATION_SOURCE_BACKUP" 2>/dev/null; then
        is_aes=true
    fi
    
    if [[ "$archive_type" == "zip" ]] && is_archive_password_protected "$MIGRATION_SOURCE_BACKUP" 2>/dev/null; then
        if [[ -z "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
            echo -e "${YELLOW}  âš ï¸  ĞÑ€Ñ…Ğ¸Ğ² Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ñ‘Ğ½ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼${RESET}"
            echo ""
            if [[ "$is_aes" == "true" ]]; then
                print_message "INFO" "ğŸ”’ Ğ¨Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: AES-256"
            fi
            read -ersp "  Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ: " BEDOLAGA_BACKUP_PASSWORD
            echo ""
            echo ""
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ
            if [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
                local temp_dir=$(mktemp -d)
                TEMP_DIRS+=("$temp_dir")
                local password_ok=false
                
                print_message "INFO" "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ğ°Ñ€Ğ¾Ğ»Ñ..."
                
                if [[ "$is_aes" == "true" ]]; then
                    # AES â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ 7z
                    if ! ensure_7z_installed; then
                        print_message "ERROR" "Ğ”Ğ»Ñ AES-Ğ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ² Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ 7z (p7zip)"
                        print_message "INFO" "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ: apt install p7zip-full"
                        rm -rf "$temp_dir"
                        BEDOLAGA_BACKUP_PASSWORD=""
                        return 1
                    fi
                    
                    local cmd_7z=$(get_7z_command)
                    if $cmd_7z x -p"$BEDOLAGA_BACKUP_PASSWORD" -o"$temp_dir" "$MIGRATION_SOURCE_BACKUP" -y &>/dev/null; then
                        if find "$temp_dir" -name "database.json" 2>/dev/null | grep -q . || \
                           find "$temp_dir" -type f \( -name "*.tar.gz" -o -name "*.gz" \) 2>/dev/null | grep -q .; then
                            password_ok=true
                        fi
                    fi
                else
                    # ZipCrypto â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ unzip
                    ensure_unzip_installed 2>/dev/null
                    if unzip -P "$BEDOLAGA_BACKUP_PASSWORD" -o -q "$MIGRATION_SOURCE_BACKUP" -d "$temp_dir" 2>/dev/null; then
                        if find "$temp_dir" -name "database.json" 2>/dev/null | grep -q . || \
                           find "$temp_dir" -type f \( -name "*.tar.gz" -o -name "*.gz" \) 2>/dev/null | grep -q .; then
                            password_ok=true
                        fi
                    fi
                fi
                
                rm -rf "$temp_dir"
                
                if [[ "$password_ok" == "true" ]]; then
                    print_message "SUCCESS" "âœ… ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ Ğ²ĞµÑ€Ğ½Ñ‹Ğ¹"
                    echo ""
                else
                    print_message "ERROR" "âŒ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ"
                    BEDOLAGA_BACKUP_PASSWORD=""
                    return 1
                fi
            else
                print_message "ERROR" "ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ Ğ½Ğµ Ğ²Ğ²ĞµĞ´Ñ‘Ğ½"
                return 1
            fi
        fi
    fi
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
    if [[ -z "$MIGRATION_DATA_ANALYSIS" ]]; then
        print_message "INFO" "ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°..."
        MIGRATION_DATA_ANALYSIS=$(migration_quick_analyze "$MIGRATION_SOURCE_BACKUP" "$BEDOLAGA_BACKUP_PASSWORD")
    fi
    
    if [[ -z "$MIGRATION_DATA_ANALYSIS" ]]; then
        print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ²"
        echo ""
        echo "  Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹:"
        echo "  â€¢ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ (Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ² Ğ·Ğ°Ğ½Ğ¾Ğ²Ğ¾ â€” Ğ¿ÑƒĞ½ĞºÑ‚ 2)"
        echo "  â€¢ ĞŸĞ¾Ğ²Ñ€ĞµĞ¶Ğ´Ñ‘Ğ½Ğ½Ñ‹Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ğ²"
        echo "  â€¢ ĞÑ€Ñ…Ğ¸Ğ² Ğ½Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ database.json"
        echo ""
        return 1
    fi
    
    # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
    local users=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^users:" | cut -d: -f2)
    local transactions=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^transactions:" | cut -d: -f2)
    local promocodes=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^promocodes:" | cut -d: -f2)
    local subscriptions=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^subscriptions:" | cut -d: -f2)
    local tickets=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^tickets:" | cut -d: -f2)
    local referrals=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^referrals:" | cut -d: -f2)
    local total_balance=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^total_balance_kopeks:" | cut -d: -f2)
    local users_with_balance=$(echo "$MIGRATION_DATA_ANALYSIS" | grep "^users_with_balance:" | cut -d: -f2)
    
    # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ¾Ğ¿ĞµĞ¹ĞºĞ¸ Ğ² Ñ€ÑƒĞ±Ğ»Ğ¸ (Ğ±ĞµĞ· bc, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ awk)
    local balance_rub
    if [[ -n "$total_balance" && "$total_balance" != "0" ]]; then
        balance_rub=$(awk "BEGIN {printf \"%.2f\", ${total_balance}/100}")
    else
        balance_rub="0.00"
    fi
    
    echo -e "${GREEN}  Ğ‘Ğ£Ğ”Ğ•Ğ¢ ĞŸĞ•Ğ Ğ•ĞĞ•Ğ¡Ğ•ĞĞ:${RESET}"
    echo ""
    printf "    %-40s %10s   %s\n" "Bedolaga" "Ğ—Ğ°Ğ¿Ğ¸ÑĞµĞ¹" "RWP-Shop"
    echo "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    printf "    %-40s %10s   %s\n" "users" "${users:-0}" "-> customer"
    printf "    %-40s %10s   %s\n" "referrals" "${referrals:-0}" "-> referral"
    printf "    %-40s %10s   %s\n" "subscriptions (active)" "${subscriptions:-0}" "-> customer.*"
    printf "    %-40s %10s   %s\n" "transactions" "${transactions:-0}" "-> purchase"
    printf "    %-40s %10s   %s\n" "promocodes" "${promocodes:-0}" "-> promo"
    printf "    %-40s %10s   %s\n" "tickets" "${tickets:-0}" "-> support_ticket"
    echo ""
    
    if [[ "${users_with_balance:-0}" -gt 0 ]]; then
        echo -e "${YELLOW}  ĞĞ• Ğ‘Ğ£Ğ”Ğ•Ğ¢ ĞŸĞ•Ğ Ğ•ĞĞ•Ğ¡Ğ•ĞĞ (ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑÑ Ğ² CSV):${RESET}"
        echo ""
        printf "    %-40s %10s   %s\n" "balances ($users_with_balance users)" "${balance_rub} RUB" "-> NOT_MIGRATED/"
        echo ""
    fi
    
    echo -e "  ${GRAY}ĞĞµĞ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ğ¼Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑÑ Ğ²: NOT_MIGRATED/${RESET}"
    echo ""
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Ğ¸Ğ· ÑĞ¿Ğ¸ÑĞºĞ° ---
migration_select_archive() {
    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ÑĞµ Ğ°Ñ€Ñ…Ğ¸Ğ²Ñ‹
    local search_paths=(
        "$BOT_PATH"
        "/opt/private-remnawave-telegram-shop-bot"
        "/opt/rwp-shop"
        "/opt/bedolaga"
        "/opt/vpn-bot"
        "/root"
        "$BACKUP_DIR"
        "$HOME"
    )
    
    local all_archives=()
    
    for path in "${search_paths[@]}"; do
        [[ ! -d "$path" ]] && continue
        # Ğ˜Ñ‰ĞµĞ¼ tar.gz Ğ˜ tar.zip (Ğ·Ğ°Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ½Ğ½Ñ‹Ğµ)
        while IFS= read -r -d '' archive; do
            all_archives+=("$archive")
        done < <(find "$path" -maxdepth 3 -type f \( -name "backup_*.tar.gz" -o -name "backup_*.tar.zip" -o -name "backup_*.zip" \) -print0 2>/dev/null)
    done
    
    if [[ ${#all_archives[@]} -eq 0 ]]; then
        clear_screen
        echo -e "${CYAN}${BOLD}â•â•â• Ğ’Ğ«Ğ‘ĞĞ  ĞĞ Ğ¥Ğ˜Ğ’Ğ BEDOLAGA â•â•â•${RESET}"
        echo ""
        echo -e "${YELLOW}ĞÑ€Ñ…Ğ¸Ğ²Ñ‹ backup_*.tar.gz / backup_*.tar.zip Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹${RESET}"
        echo ""
        echo "ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹:"
        echo "  â€¢ backup_*.tar.gz      â€” Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ğ²"
        echo "  â€¢ backup_*.tar.zip     â€” Ğ·Ğ°Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ğ²"
        echo ""
        echo "Ğ“Ğ´Ğµ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ğ²:"
        echo "  â€¢ Ğ¡ĞºĞ°Ñ‡Ğ°Ğ¹Ñ‚Ğµ Ğ±ÑĞºĞ°Ğ¿ Ğ¸Ğ· Telegram (ĞµÑĞ»Ğ¸ Ğ±Ğ¾Ñ‚ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞ»)"
        echo "  â€¢ Ğ¡ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ¸Ğ· Ğ¿Ğ°Ğ¿ĞºĞ¸ Bedolaga: /opt/bedolaga/backups/"
        echo "  â€¢ ĞŸĞ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚Ğµ Ğ² Ğ¿Ğ°Ğ¿ĞºÑƒ RWP-Shop Ğ±Ğ¾Ñ‚Ğ°"
        echo ""
        read -erp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ°Ñ€Ñ…Ğ¸Ğ²Ñƒ (Enter - Ğ½Ğ°Ğ·Ğ°Ğ´): " manual_path
        [[ -z "$manual_path" ]] && return 1
        
        if [[ -f "$manual_path" ]]; then
            _migration_set_archive "$manual_path"
            return 0
        else
            print_message "ERROR" "Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: $manual_path"
            return 1
        fi
    fi
    
    # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ°Ñ€Ñ…Ğ¸Ğ²Ñ‹ Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğµ
    local sorted_archives=()
    while IFS= read -r archive; do
        sorted_archives+=("$archive")
    done < <(printf '%s\n' "${all_archives[@]}" | xargs -I {} stat --format='%Y %n' {} 2>/dev/null | sort -rn | awk '{print $2}')
    
    local total_count=${#sorted_archives[@]}
    local show_limit=5
    local show_filenames=false
    
    while true; do
        clear_screen
        echo -e "${CYAN}${BOLD}â•â•â• Ğ’Ğ«Ğ‘ĞĞ  ĞĞ Ğ¥Ğ˜Ğ’Ğ BEDOLAGA â•â•â•${RESET}"
        echo -e "Ğ’ÑĞµĞ³Ğ¾ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ²: ${CYAN}$total_count${RESET}"
        echo ""
        
        local loop_limit=$show_limit
        [[ $loop_limit -gt $total_count ]] && loop_limit=$total_count
        
        for (( i=0; i<loop_limit; i++ )); do
            local archive="${sorted_archives[$i]}"
            local num=$((i + 1))
            
            # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿ Ğ¸ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹
            local type_icon="ğŸ“¦"
            local archive_type=$(detect_bedolaga_archive_type "$archive" 2>/dev/null || echo "unknown")
            if [[ "$archive_type" == "zip" ]]; then
                if is_archive_password_protected "$archive" 2>/dev/null; then
                    type_icon="ğŸ”’"
                fi
            fi
            
            if [[ "$show_filenames" == "true" ]]; then
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ
                local size=$(du -h "$archive" 2>/dev/null | cut -f1)
                if [[ $i -eq 0 ]]; then
                    echo -e "  ${GREEN}$num. $type_icon $archive${RESET}"
                    echo -e "     ${GREEN}($size) â† Ğ Ğ•ĞšĞĞœĞ•ĞĞ”Ğ£Ğ•Ğ¢Ğ¡Ğ¯${RESET}"
                else
                    echo "  $num. $type_icon $archive ($size)"
                fi
            else
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
                local name=$(basename "$archive")
                local size=$(du -h "$archive" 2>/dev/null | cut -f1)
                local mtime=$(stat -c '%y' "$archive" 2>/dev/null | cut -d'.' -f1)
                
                # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ğ´Ğ°Ñ‚Ñƒ Ğ¸Ğ· Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ° backup_YYYYMMDD_HHMMSS
                local date_str=""
                if [[ "$name" =~ backup_([0-9]{4})([0-9]{2})([0-9]{2})_([0-9]{2})([0-9]{2})([0-9]{2}) ]]; then
                    date_str="${BASH_REMATCH[1]}-${BASH_REMATCH[2]}-${BASH_REMATCH[3]} ${BASH_REMATCH[4]}:${BASH_REMATCH[5]}"
                else
                    date_str="$mtime"
                fi
                
                if [[ $i -eq 0 ]]; then
                    echo -e "  ${GREEN}$num. $type_icon $date_str${RESET} ($size) ${GREEN}â† Ğ Ğ•ĞšĞĞœĞ•ĞĞ”Ğ£Ğ•Ğ¢Ğ¡Ğ¯${RESET}"
                else
                    echo "  $num. $type_icon $date_str ($size)"
                fi
            fi
        done
        
        echo ""
        if [[ $show_limit -lt $total_count ]]; then
            echo -e " 888. ${GRAY}ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ²ÑĞµ ($total_count ÑˆÑ‚)${RESET}"
        else
            echo -e " 888. ${GRAY}ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ¿-5${RESET}"
        fi
        if [[ "$show_filenames" == "false" ]]; then
            echo -e " 999. ${GRAY}ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸${RESET}"
        else
            echo -e " 999. ${GRAY}ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ´Ğ°Ñ‚Ñ‹${RESET}"
        fi
        echo ""
        echo "   0. Ğ’Ğ²ĞµÑÑ‚Ğ¸ Ğ¿ÑƒÑ‚ÑŒ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ"
        echo ""
        echo -e "  ${GRAY}ğŸ”’ = Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ñ‘Ğ½ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼${RESET}"
        echo ""
        read -erp "ĞĞ¾Ğ¼ĞµÑ€ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ¸Ğ»Ğ¸ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° (Enter - ĞĞ°Ğ·Ğ°Ğ´): " choice
        
        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°
        [[ -z "$choice" || "$choice" == "q" || "$choice" == "Q" ]] && return 1
        
        case "$choice" in
            888)
                if [[ $show_limit -lt $total_count ]]; then
                    show_limit=$total_count
                else
                    show_limit=5
                fi
                continue
                ;;
            999)
                if [[ "$show_filenames" == "false" ]]; then
                    show_filenames=true
                else
                    show_filenames=false
                fi
                continue
                ;;
            0)
                read -erp "ĞŸÑƒÑ‚ÑŒ Ğº Ğ°Ñ€Ñ…Ğ¸Ğ²Ñƒ: " manual_path
                if [[ -f "$manual_path" ]]; then
                    _migration_set_archive "$manual_path"
                    return 0
                else
                    print_message "ERROR" "Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½"
                fi
                ;;
            *)
                if [[ "$choice" =~ ^[0-9]+$ ]] && (( choice >= 1 && choice <= total_count )); then
                    local idx=$((choice - 1))
                    _migration_set_archive "${sorted_archives[$idx]}"
                    return 0
                else
                    print_message "ERROR" "ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€"
                    sleep 1
                fi
                ;;
        esac
    done
}

# --- Ğ’ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ: Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ² Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ ---
_migration_set_archive() {
    local archive_path="$1"
    
    MIGRATION_SOURCE_BACKUP="$archive_path"
    MIGRATION_SOURCE_TYPE="archive"
    MIGRATION_DATA_ANALYSIS=""  # Ğ¡Ğ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ ĞºÑÑˆ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
    BEDOLAGA_BACKUP_PASSWORD=""  # Ğ¡Ğ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ»Ğ¸ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ
    local archive_type=$(detect_bedolaga_archive_type "$archive_path" 2>/dev/null || echo "unknown")
    local is_aes=false
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ AES ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
    if [[ "$archive_type" == "zip" ]] && is_zip_aes_encrypted "$archive_path"; then
        is_aes=true
        debug_log "MIGRATE" "Archive uses AES encryption, will use 7z"
    fi
    
    if [[ "$archive_type" == "zip" ]] && is_archive_password_protected "$archive_path" 2>/dev/null; then
        echo ""
        if [[ "$is_aes" == "true" ]]; then
            print_message "INFO" "ğŸ”’ ĞÑ€Ñ…Ğ¸Ğ² Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ñ‘Ğ½ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼ (AES-256 ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ)"
        else
            print_message "INFO" "ğŸ”’ ĞÑ€Ñ…Ğ¸Ğ² Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ñ‘Ğ½ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¼"
        fi
        read -ersp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ: " BEDOLAGA_BACKUP_PASSWORD
        echo ""
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ°Ñ€Ğ¾Ğ»Ñ
        if [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
            local temp_dir=$(mktemp -d)
            TEMP_DIRS+=("$temp_dir")
            local password_ok=false
            
            if [[ "$is_aes" == "true" ]]; then
                # AES ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ â€” Ğ½ÑƒĞ¶ĞµĞ½ 7z
                if ! ensure_7z_installed; then
                    print_message "ERROR" "Ğ”Ğ»Ñ AES-Ğ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ² Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ 7z (p7zip)"
                    print_message "INFO" "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ: apt install p7zip-full"
                    rm -rf "$temp_dir"
                    BEDOLAGA_BACKUP_PASSWORD=""
                    return 1
                fi
                
                local cmd_7z=$(get_7z_command)
                debug_log "MIGRATE" "Using 7z command: $cmd_7z"
                
                # Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ 7z
                if $cmd_7z x -p"$BEDOLAGA_BACKUP_PASSWORD" -o"$temp_dir" "$archive_path" -y &>/dev/null; then
                    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ»Ğ¾ÑÑŒ
                    if find "$temp_dir" -name "database.json" 2>/dev/null | grep -q .; then
                        password_ok=true
                    else
                        # Ğ˜Ñ‰ĞµĞ¼ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ tar.gz
                        local inner=$(find "$temp_dir" -type f \( -name "*.tar.gz" -o -name "*.gz" \) 2>/dev/null | head -1)
                        if [[ -n "$inner" ]] && tar -tzf "$inner" &>/dev/null; then
                            password_ok=true
                        fi
                    fi
                fi
            else
                # ZipCrypto â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ unzip
                ensure_unzip_installed 2>/dev/null
                
                if unzip -P "$BEDOLAGA_BACKUP_PASSWORD" -o -q "$archive_path" -d "$temp_dir" 2>/dev/null; then
                    if find "$temp_dir" -name "database.json" 2>/dev/null | grep -q .; then
                        password_ok=true
                    else
                        local inner=$(find "$temp_dir" -type f \( -name "*.tar.gz" -o -name "*.gz" \) 2>/dev/null | head -1)
                        if [[ -n "$inner" ]] && tar -tzf "$inner" &>/dev/null; then
                            password_ok=true
                        fi
                    fi
                fi
            fi
            
            if [[ "$password_ok" == "true" ]]; then
                print_message "SUCCESS" "âœ… ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ Ğ²ĞµÑ€Ğ½Ñ‹Ğ¹"
            else
                print_message "ERROR" "âŒ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ"
                BEDOLAGA_BACKUP_PASSWORD=""
            fi
            
            rm -rf "$temp_dir"
        fi
    fi
    
    print_message "SUCCESS" "ĞÑ€Ñ…Ğ¸Ğ² Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½: $(basename "$archive_path")"
    
    # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    if [[ "$archive_type" != "zip" ]] || [[ -n "$BEDOLAGA_BACKUP_PASSWORD" ]]; then
        MIGRATION_DATA_ANALYSIS=$(migration_quick_analyze "$archive_path" 2>/dev/null)
    fi
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ¿ĞµÑ€ĞµĞ´ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ¼ ---
migration_show_import_warning() {
    echo ""
    echo -e "${RED}${BOLD}â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”${RESET}"
    echo -e "${RED}${BOLD}â”‚  âš ï¸  Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•! Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ• Ğ‘ĞĞ—Ğ« Ğ”ĞĞĞĞ«Ğ¥                               â”‚${RESET}"
    echo -e "${RED}${BOLD}â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤${RESET}"
    echo -e "${RED}${BOLD}â”‚${RESET}                                                                    ${RED}${BOLD}â”‚${RESET}"
    echo -e "${RED}${BOLD}â”‚${RESET}  Ğ¡ĞµĞ¹Ñ‡Ğ°Ñ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ²Ğ½ĞµÑĞµĞ½Ñ‹ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ² Ğ‘Ğ” RWP-Shop:                    ${RED}${BOLD}â”‚${RESET}"
    echo -e "${RED}${BOLD}â”‚${RESET}                                                                    ${RED}${BOLD}â”‚${RESET}"
    echo -e "${RED}${BOLD}â”‚${RESET}  â€¢ ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€: ${YELLOW}$MIGRATION_TARGET_CONTAINER${RESET}"
    echo -e "${RED}${BOLD}â”‚${RESET}  â€¢ Ğ‘Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: ${YELLOW}$MIGRATION_TARGET_DB${RESET}"
    echo -e "${RED}${BOLD}â”‚${RESET}                                                                    ${RED}${BOLD}â”‚${RESET}"
    if [[ -n "$MIGRATION_AUTO_BACKUP" ]]; then
        echo -e "${RED}${BOLD}â”‚${RESET}  ${GREEN}ğŸ”’ Ğ‘ÑĞºĞ°Ğ¿ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ Ğ‘Ğ” ÑĞ¾Ğ·Ğ´Ğ°Ğ½:${RESET}"
        echo -e "${RED}${BOLD}â”‚${RESET}     ${GRAY}$MIGRATION_AUTO_BACKUP${RESET}"
        echo -e "${RED}${BOLD}â”‚${RESET}                                                                    ${RED}${BOLD}â”‚${RESET}"
    fi
    echo -e "${RED}${BOLD}â”‚${RESET}  Ğ”Ğ»Ñ Ğ¾Ñ‚ĞºĞ°Ñ‚Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ:                                            ${RED}${BOLD}â”‚${RESET}"
    echo -e "${RED}${BOLD}â”‚${RESET}  ${GRAY}docker exec -i $MIGRATION_TARGET_CONTAINER psql -U $MIGRATION_TARGET_USER < backup.sql${RESET}"
    echo -e "${RED}${BOLD}â”‚${RESET}                                                                    ${RED}${BOLD}â”‚${RESET}"
    echo -e "${RED}${BOLD}â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜${RESET}"
    echo ""
}

# --- Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ: ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ (Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ğ°Ñ Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸) ---
migration_run_automatic() {
    clear_screen
    echo -e "${GREEN}${BOLD}â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”${RESET}"
    echo -e "${GREEN}${BOLD}â”‚  ğŸš€ ĞĞ’Ğ¢ĞĞœĞĞ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ¯                                        â”‚${RESET}"
    echo -e "${GREEN}${BOLD}â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜${RESET}"
    echo ""
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸
    if [[ -z "$MIGRATION_SOURCE_TYPE" || -z "$MIGRATION_SOURCE_BACKUP" ]]; then
        print_message "ERROR" "Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ°Ñ€Ñ…Ğ¸Ğ² Bedolaga (Ğ¿ÑƒĞ½ĞºÑ‚ 2)"
        return 1
    fi
    
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        print_message "ERROR" "Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹Ñ‚Ğµ Ğ¿Ñ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº (Ğ¿ÑƒĞ½ĞºÑ‚ 3)"
        return 1
    fi
    
    echo "Ğ‘ÑƒĞ´ÑƒÑ‚ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ñ‹ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ:"
    echo ""
    echo "  [1/10] ğŸ¥ Healthcheck Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Ğ¸ Ğ‘Ğ”"
    echo "  [2/10] ğŸ” ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Bedolaga"
    echo "  [3/10] ğŸ’¾ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ±ÑĞºĞ°Ğ¿Ğ° Ğ‘Ğ” RWP-Shop"
    echo "  [4/10] ğŸ“¤ Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°"
    echo "  [5/10] ğŸ’° ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ²"
    echo "  [6/10] ğŸ”„ Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"
    echo "  [7/10] ğŸ“¥ Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ² RWP-Shop"
    echo "  [8/10] âš™ï¸  ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)"
    echo "  [9/10] ğŸ“ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ğ¼Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"
    echo "  [10/10] ğŸ“‹ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ° + Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ healthcheck"
    echo ""
    
    echo -e "${YELLOW}âš ï¸  ĞŸĞĞ’Ğ•Ğ”Ğ•ĞĞ˜Ğ• ĞŸĞ Ğ˜ ĞšĞĞĞ¤Ğ›Ğ˜ĞšĞ¢ĞĞ¥:${RESET}"
    echo "  â€¢ customer: ĞŸÑ€Ğ¸ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¸ telegram_id â†’ ĞĞ‘ĞĞĞ’Ğ˜Ğ¢ username, Ğ¸Ğ¼Ñ, ÑÑ‚Ğ°Ñ‚ÑƒÑ"
    echo "  â€¢ promo: ĞŸÑ€Ğ¸ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¸ code â†’ ĞĞ‘ĞĞĞ’Ğ˜Ğ¢ ÑÑ‡Ñ‘Ñ‚Ñ‡Ğ¸Ğº Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹"
    echo "  â€¢ purchase: ĞŸÑ€Ğ¸ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¸ id â†’ ĞŸĞ ĞĞŸĞ£Ğ¡Ğ¢Ğ˜Ğ¢ (ON CONFLICT DO NOTHING)"
    echo "  â€¢ referral: ĞŸÑ€Ğ¸ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¸ â†’ ĞŸĞ ĞĞŸĞ£Ğ¡Ğ¢Ğ˜Ğ¢"
    echo ""
    echo -e "${YELLOW}âš ï¸  ĞĞ• ĞŸĞ•Ğ Ğ•ĞĞĞ¡Ğ¯Ğ¢Ğ¡Ğ¯ (ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑÑ Ğ² NOT_MIGRATED/):${RESET}"
    echo "  â€¢ Ğ‘Ğ°Ğ»Ğ°Ğ½ÑÑ‹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ (Ğ² RWP-Shop Ğ½ĞµÑ‚ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ°)"
    echo "  â€¢ Ğ ĞµÑ„ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ±Ğ°Ğ»Ğ°Ğ½ÑÑ‹"
    echo "  â€¢ ĞŸÑ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ñ‹ Ğ½Ğ° Ğ±Ğ°Ğ»Ğ°Ğ½Ñ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ñ‹ Ğ½Ğ° Ğ´Ğ½Ğ¸)"
    echo "  â€¢ Ğ¢Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¸ Ğ½ĞµĞ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ñ… Ğ¿Ğ»Ğ°Ñ‚Ñ‘Ğ¶ĞµĞº"
    echo ""
    
    read -erp "ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ? (y/N): " confirm
    [[ ! "$confirm" =~ ^[Yy]$ ]] && return 0
    
    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‡ĞµĞ¹ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸
    migration_detect_target_path
    migration_init_work_dir
    migration_create_not_migrated_dir
    
    local start_time=$(date +%s)
    
    # [1/10] HEALTHCHECK (Ğ°Ñ€Ñ…Ğ¸Ğ² + Ğ‘Ğ”)
    echo ""
    print_message "INFO" "[1/10] Healthcheck Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Ğ¸ Ğ‘Ğ”..."
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
    if ! migration_healthcheck_archive "$MIGRATION_SOURCE_BACKUP" "true"; then
        print_message "ERROR" "ĞÑ€Ñ…Ğ¸Ğ² Ğ½Ğµ Ğ¿Ñ€Ğ¾ÑˆÑ‘Ğ» Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºÑƒ!"
        read -erp "ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸? (y/N): " force_archive
        [[ ! "$force_archive" =~ ^[Yy]$ ]] && return 1
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ‘Ğ”
    if ! migration_healthcheck_db_pre "true"; then
        print_message "ERROR" "Ğ‘Ğ” Ğ½Ğµ Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºÑƒ!"
        read -erp "ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸? (y/N): " force_db
        [[ ! "$force_db" =~ ^[Yy]$ ]] && return 1
    fi
    
    print_message "SUCCESS" "Healthcheck Ğ¿Ñ€Ğ¾Ğ¹Ğ´ĞµĞ½"
    
    # [2/10] ĞĞ½Ğ°Ğ»Ğ¸Ğ·
    print_message "INFO" "[2/10] ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Bedolaga..."
    if ! migration_quick_analyze "$MIGRATION_SOURCE_BACKUP" > /dev/null; then
        print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°"
        return 1
    fi
    print_message "SUCCESS" "ĞÑ€Ñ…Ğ¸Ğ² Ğ²Ğ°Ğ»Ğ¸Ğ´ĞµĞ½"
    
    # [3/10] Ğ‘ÑĞºĞ°Ğ¿ Ğ‘Ğ”
    print_message "INFO" "[3/10] Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ±ÑĞºĞ°Ğ¿Ğ° Ğ‘Ğ” RWP-Shop..."
    if ! migration_backup_target_db; then
        echo -e "${YELLOW}ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ Ğ±ĞµĞ· Ğ±ÑĞºĞ°Ğ¿Ğ°? (y/N):${RESET} "
        read -r skip_backup
        [[ ! "$skip_backup" =~ ^[Yy]$ ]] && return 1
    fi
    
    # [4/10] Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚
    print_message "INFO" "[4/10] Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°..."
    if ! migrate_export_data; then
        print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ°!"
        return 1
    fi
    
    # Healthcheck CSV Ğ¿Ğ¾ÑĞ»Ğµ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ°
    print_message "INFO" "       ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…..."
    if ! migration_healthcheck_csv "$MIGRATION_WORK_DIR/export" "false"; then
        print_message "WARN" "ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞµ CSV"
    fi
    
    # [5/10] Ğ‘Ğ°Ğ»Ğ°Ğ½ÑÑ‹
    print_message "INFO" "[5/10] ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ² Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹..."
    # ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ export_csv Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ
    BALANCE_HANDLING_MODE="export_csv"
    if ! migrate_handle_balances; then
        print_message "WARN" "ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ²"
    fi
    
    # [6/10] Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ
    print_message "INFO" "[6/10] Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…..."
    if ! migrate_transform_data; then
        print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸!"
        return 1
    fi
    
    # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ²
    migrate_apply_balance_handling 2>/dev/null
    
    # Healthcheck Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… CSV (Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ import)
    print_message "INFO" "       ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…..."
    if ! migration_healthcheck_csv "$MIGRATION_WORK_DIR/import" "false"; then
        print_message "WARN" "ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸"
    fi
    
    # [7/10] Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ - Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ!
    migration_show_import_warning
    
    read -erp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ 'IMPORT' Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°: " import_confirm
    if [[ "$import_confirm" != "IMPORT" ]]; then
        print_message "INFO" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¾Ñ‚Ğ¼ĞµĞ½Ñ‘Ğ½. Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ²: $MIGRATION_WORK_DIR"
        return 0
    fi
    
    print_message "INFO" "[7/10] Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ² RWP-Shop..."
    if ! migrate_import_data; then
        print_message "ERROR" "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°!"
        echo ""
        echo -e "${YELLOW}Ğ”Ğ»Ñ Ğ¾Ñ‚ĞºĞ°Ñ‚Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ±ÑĞºĞ°Ğ¿:${RESET}"
        echo "  docker exec -i $MIGRATION_TARGET_CONTAINER psql -U $MIGRATION_TARGET_USER $MIGRATION_TARGET_DB < $MIGRATION_AUTO_BACKUP"
        return 1
    fi
    
    # [8/10] Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ğ¼Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    print_message "INFO" "[8/10] Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ğ¼Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…..."
    migration_save_not_migrated_data
    
    # [9/10] ĞÑ‚Ñ‡Ñ‘Ñ‚ + Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ healthcheck
    print_message "INFO" "[9/10] Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ° + Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ healthcheck..."
    migrate_generate_report
    
    # Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ healthcheck Ğ‘Ğ”
    migration_healthcheck_db_post "true"
    
    # [10/10] ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
    echo ""
    print_message "INFO" "[10/10] ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº..."
    echo ""
    echo -e "${CYAN}Ğ¥Ğ¾Ñ‚Ğ¸Ñ‚Ğµ Ğ¿ĞµÑ€ĞµĞ½ĞµÑÑ‚Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸Ğ· Bedolaga Ğ² RWP-Shop?${RESET}"
    echo "  â€¢ Ğ‘ÑƒĞ´ÑƒÑ‚ Ğ¿ĞµÑ€ĞµĞ½ĞµÑĞµĞ½Ñ‹: Ñ‚Ğ¾ĞºĞµĞ½ Ğ±Ğ¾Ñ‚Ğ°, ĞºĞ°Ğ½Ğ°Ğ»Ñ‹, Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñ‹, Ñ‚ĞµĞºÑÑ‚Ñ‹ Ğ¸ Ğ´Ñ€."
    echo "  â€¢ Ğ¡ÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ² .env Ğ±ÑƒĞ´ÑƒÑ‚ Ğ·Ğ°Ğ¼ĞµĞ½ĞµĞ½Ñ‹"
    echo ""
    read -erp "ĞœĞ¸Ğ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸? (y/n): " migrate_settings_confirm
    if [[ "$migrate_settings_confirm" == "y" || "$migrate_settings_confirm" == "Y" ]]; then
        if migrate_settings_execute; then
            print_message "SUCCESS" "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¼Ğ¸Ğ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹"
        else
            print_message "WARN" "ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° Ñ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸"
        fi
    else
        print_message "INFO" "ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ°"
    fi
    
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    echo ""
    echo -e "${GREEN}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo -e "${GREEN}${BOLD}  âœ… ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ¯ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ!                                            ${RESET}"
    echo -e "${GREEN}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo ""
    echo "  Ğ’Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ: ${duration}Ñ"
    echo "  Ğ Ğ°Ğ±Ğ¾Ñ‡Ğ°Ñ Ğ¿Ğ°Ğ¿ĞºĞ°: $MIGRATION_WORK_DIR"
    [[ -d "$MIGRATION_NOT_MIGRATED_DIR" ]] && echo "  ĞĞµĞ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ğ¼Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ: $MIGRATION_NOT_MIGRATED_DIR"
    echo ""
    echo -e "${YELLOW}âš ï¸  ĞĞµ Ğ·Ğ°Ğ±ÑƒĞ´ÑŒÑ‚Ğµ:${RESET}"
    echo "  â€¢ ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ±Ğ¾Ñ‚Ğ°"
    echo "  â€¢ ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ±Ğ¾Ñ‚Ğ°: docker compose restart"
    echo ""
    
    log_message "SUCCESS" "Migration completed in ${duration}s: Bedolaga â†’ RWP-Shop"
    
    return 0
}

# --- Ğ“Ğ»Ğ°Ğ²Ğ½Ğ¾Ğµ Ğ¼ĞµĞ½Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ ---
menu_migration() {
    # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ disclaimer Ğ¾Ğ´Ğ¸Ğ½ Ñ€Ğ°Ğ·
    migration_show_disclaimer
    
    # ĞĞ²Ñ‚Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ Ğ²Ñ…Ğ¾Ğ´Ğµ
    if [[ -z "$MIGRATION_SOURCE_BACKUP" ]]; then
        local auto_archive
        auto_archive=$(migration_auto_find_archive)
        if [[ -n "$auto_archive" ]]; then
            MIGRATION_SOURCE_BACKUP="$auto_archive"
            MIGRATION_SOURCE_TYPE="archive"
            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
            MIGRATION_DATA_ANALYSIS=$(migration_quick_analyze "$auto_archive" 2>/dev/null)
        fi
    fi
    
    # ĞĞ²Ñ‚Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ñ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸ĞºĞ°
    if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
        for pattern in "rwp_shop_db" "telegram-shop-db"; do
            MIGRATION_TARGET_CONTAINER=$(docker ps --format '{{.Names}}' 2>/dev/null | grep -iE "^$pattern$" | head -1)
            [[ -n "$MIGRATION_TARGET_CONTAINER" ]] && break
        done
        MIGRATION_TARGET_DB="${MIGRATION_TARGET_DB:-postgres}"
        MIGRATION_TARGET_USER="${MIGRATION_TARGET_USER:-postgres}"
    fi
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ Ğº RWP-Shop Ğ¸ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€Ğ°Ğ±Ğ¾Ñ‡ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ
    migration_detect_target_path
    if [[ -z "$MIGRATION_WORK_DIR" || ! -d "$MIGRATION_WORK_DIR" ]]; then
        migration_init_work_dir
    fi
    
    while true; do
        clear_screen
        echo -e "${MAGENTA}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
        echo -e "${MAGENTA}${BOLD}       ğŸ”„ ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ¯: Bedolaga â†’ RWP-Shop Private                    ${RESET}"
        echo -e "${MAGENTA}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
        echo ""
        
        # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ
        migration_show_status
        echo ""
        
        # ĞœĞµĞ½Ñ
        echo -e " ${GREEN}â”€â”€â”€ Ğ‘Ğ«Ğ¡Ğ¢Ğ Ğ«Ğ™ Ğ¡Ğ¢ĞĞ Ğ¢ â”€â”€â”€${RESET}"
        echo -e " ${GREEN}${BOLD} 1. ğŸš€ ĞĞ’Ğ¢ĞĞœĞĞ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ¯${RESET} (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ)"
        echo -e "    ${GRAY}ĞŸĞµÑ€ĞµĞ½ĞµÑÑ‘Ñ‚ Ğ²ÑĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸ĞµĞ¼ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ¿Ğµ${RESET}"
        echo ""
        
        echo " â”€â”€â”€ ĞŸĞĞ¨ĞĞ“ĞĞ’Ğ«Ğ™ Ğ Ğ•Ğ–Ğ˜Ğœ â”€â”€â”€"
        echo " 2. ğŸ“¥ Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ² Bedolaga"
        echo " 3. ğŸ¯ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº (RWP-Shop)"
        echo " 4. ğŸ“Š ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (Ğ¿Ñ€ĞµĞ²ÑŒÑ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸)"
        echo -e " 5. ğŸ¥ ${CYAN}Healthcheck${RESET} (Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ² Ğ¸ Ğ‘Ğ”)"
        echo ""
        
        echo " â”€â”€â”€ Ğ Ğ£Ğ§ĞĞĞ• Ğ£ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ• â”€â”€â”€"
        echo " 6. â–¶ï¸  Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"
        echo " 7. ğŸ”„ Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ"
        echo " 8. ğŸ“¥ Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ² Ğ‘Ğ”"
        echo " 9. ğŸ’° ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ² Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹"
        echo ""
        
        echo -e " â”€â”€â”€ ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜ â”€â”€â”€"
        echo -e " ${CYAN}10. âš™ï¸  ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº Ğ±Ğ¾Ñ‚Ğ°${RESET}"
        echo ""
        
        echo " â”€â”€â”€ ĞŸĞĞ¡Ğ›Ğ• ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ˜ â”€â”€â”€"
        echo " 11. ğŸ“‹ ĞŸĞ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚"
        echo " 12. ğŸ“ ĞÑ‚ĞºÑ€Ñ‹Ñ‚ÑŒ Ğ¿Ğ°Ğ¿ĞºÑƒ NOT_MIGRATED"
        echo ""
        
        echo " 0. â† ĞĞ°Ğ·Ğ°Ğ´ Ğ² Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğµ Ğ¼ĞµĞ½Ñ"
        echo ""
        read -erp "Ğ’Ñ‹Ğ±Ğ¾Ñ€ (Enter - ĞĞ°Ğ·Ğ°Ğ´): " opt
        [[ -z "$opt" || "$opt" == "q" || "$opt" == "Q" ]] && return
        
        case "$opt" in
            1)
                # ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ
                migration_run_automatic
                read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
                ;;
            2)
                # Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° (Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ 0 Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğµ, 1 Ğ¿Ñ€Ğ¸ Ğ¾Ñ‚Ğ¼ĞµĞ½Ğµ)
                migration_select_archive
                ;;
            3)
                # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿Ñ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸ĞºĞ°
                migrate_configure_target
                ;;
            4)
                # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
                migration_show_detailed_analysis
                read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
                ;;
            5)
                # Healthcheck
                migration_healthcheck_full "true"
                read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
                ;;
            6)
                # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚
                if [[ -z "$MIGRATION_SOURCE_TYPE" ]]; then
                    print_message "ERROR" "Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ°Ñ€Ñ…Ğ¸Ğ² (Ğ¿ÑƒĞ½ĞºÑ‚ 2)"
                    read -erp "Enter..." dummy
                    continue
                fi
                # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€Ğ°Ğ±Ğ¾Ñ‡ÑƒÑ Ğ¿Ğ°Ğ¿ĞºÑƒ ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ°
                if [[ -z "$MIGRATION_WORK_DIR" || ! -d "$MIGRATION_WORK_DIR" ]]; then
                    migration_init_work_dir
                fi
                
                echo ""
                echo -e "${CYAN}${BOLD}â•â•â• Ğ¨ĞĞ“ 1/3: Ğ­ĞšĞ¡ĞŸĞĞ Ğ¢ Ğ”ĞĞĞĞ«Ğ¥ â•â•â•${RESET}"
                echo -e "${GRAY}Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Bedolaga Ğ² CSV Ñ„Ğ°Ğ¹Ğ»Ñ‹${RESET}"
                echo ""
                
                migrate_export_data
                
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ healthcheck CSV Ğ¿Ğ¾ÑĞ»Ğµ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ°
                migration_healthcheck_csv "$MIGRATION_WORK_DIR/export" "true"
                
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸Ñ‚Ğ¾Ğ³
                echo ""
                echo -e "${GREEN}${BOLD}â•â•â• Ğ­ĞšĞ¡ĞŸĞĞ Ğ¢ Ğ—ĞĞ’Ğ•Ğ Ğ¨ĞĞ â•â•â•${RESET}"
                echo ""
                echo -e "  ğŸ“ Ğ¤Ğ°Ğ¹Ğ»Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ²:"
                echo -e "     ${CYAN}$MIGRATION_WORK_DIR/export/${RESET}"
                echo ""
                echo -e "  ğŸ“‹ Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑˆĞ°Ğ³:"
                echo -e "     ${YELLOW}ĞŸÑƒĞ½ĞºÑ‚ 7${RESET} â†’ Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ (ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ²)"
                echo ""
                read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
                ;;
            7)
                # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ
                if [[ -z "$MIGRATION_WORK_DIR" || ! -d "$MIGRATION_WORK_DIR/export" ]]; then
                    print_message "ERROR" "Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚ (Ğ¿ÑƒĞ½ĞºÑ‚ 6)"
                    if [[ -n "$MIGRATION_WORK_DIR" ]]; then
                        debug_log "MIGRATE" "Export dir not found: $MIGRATION_WORK_DIR/export"
                    fi
                    read -erp "Enter..." dummy
                    continue
                fi
                
                echo ""
                echo -e "${CYAN}${BOLD}â•â•â• Ğ¨ĞĞ“ 2/3: Ğ¢Ğ ĞĞĞ¡Ğ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ â•â•â•${RESET}"
                echo -e "${GRAY}ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹ Bedolaga â†’ RWP-Shop${RESET}"
                echo ""
                
                migrate_transform_data
                
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ healthcheck CSV Ğ¿Ğ¾ÑĞ»Ğµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ (Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ import)
                migration_healthcheck_csv "$MIGRATION_WORK_DIR/import" "true"
                
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸Ñ‚Ğ¾Ğ³
                echo ""
                echo -e "${GREEN}${BOLD}â•â•â• Ğ¢Ğ ĞĞĞ¡Ğ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ â•â•â•${RESET}"
                echo ""
                echo -e "  ğŸ“ Ğ¤Ğ°Ğ¹Ğ»Ñ‹ Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°:"
                echo -e "     ${CYAN}$MIGRATION_WORK_DIR/import/${RESET}"
                echo ""
                echo -e "  ğŸ“‹ Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑˆĞ°Ğ³:"
                echo -e "     ${YELLOW}ĞŸÑƒĞ½ĞºÑ‚ 8${RESET} â†’ Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ² Ğ‘Ğ” RWP-Shop"
                echo ""
                read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
                ;;
            8)
                # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚
                if [[ -z "$MIGRATION_WORK_DIR" || ! -d "$MIGRATION_WORK_DIR/import" ]]; then
                    print_message "ERROR" "Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ (Ğ¿ÑƒĞ½ĞºÑ‚ 7)"
                    read -erp "Enter..." dummy
                    continue
                fi
                if [[ -z "$MIGRATION_TARGET_CONTAINER" ]]; then
                    print_message "ERROR" "Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹Ñ‚Ğµ Ğ¿Ñ€Ğ¸Ñ‘Ğ¼Ğ½Ğ¸Ğº (Ğ¿ÑƒĞ½ĞºÑ‚ 3)"
                    read -erp "Enter..." dummy
                    continue
                fi
                
                echo ""
                echo -e "${CYAN}${BOLD}â•â•â• Ğ¨ĞĞ“ 3/3: Ğ˜ĞœĞŸĞĞ Ğ¢ Ğ’ Ğ‘Ğ” â•â•â•${RESET}"
                echo -e "${GRAY}Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ² PostgreSQL RWP-Shop${RESET}"
                echo ""
                
                # Healthcheck Ğ‘Ğ” Ğ¿ĞµÑ€ĞµĞ´ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ¼
                migration_healthcheck_db_pre "true"
                
                # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ±ÑĞºĞ°Ğ¿ Ğ¿ĞµÑ€ĞµĞ´ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ¼
                migration_backup_target_db
                migration_show_import_warning
                
                read -erp "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ 'IMPORT' Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ: " confirm
                if [[ "$confirm" == "IMPORT" ]]; then
                    migrate_import_data
                    # Healthcheck Ğ‘Ğ” Ğ¿Ğ¾ÑĞ»Ğµ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°
                    migration_healthcheck_db_post "true"
                    
                    # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸Ñ‚Ğ¾Ğ³
                    echo ""
                    echo -e "${GREEN}${BOLD}â•â•â• ĞœĞ˜Ğ“Ğ ĞĞ¦Ğ˜Ğ¯ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ â•â•â•${RESET}"
                    echo ""
                    echo -e "  âœ… Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ² RWP-Shop"
                    echo ""
                    echo -e "  ğŸ“‹ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ:"
                    echo -e "     â€¢ ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ±Ğ¾Ñ‚Ğ°"
                    echo -e "     â€¢ ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ¿ÑƒĞ½ĞºÑ‚ ${YELLOW}12${RESET} (NOT_MIGRATED) Ğ´Ğ»Ñ Ğ½ĞµÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"
                    echo ""
                else
                    print_message "INFO" "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¾Ñ‚Ğ¼ĞµĞ½Ñ‘Ğ½"
                fi
                read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
                ;;
            9)
                # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¾Ğ²
                if [[ -z "$MIGRATION_SOURCE_TYPE" ]]; then
                    print_message "ERROR" "Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ°Ñ€Ñ…Ğ¸Ğ² (Ğ¿ÑƒĞ½ĞºÑ‚ 2)"
                    read -erp "Enter..." dummy
                    continue
                fi
                # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€Ğ°Ğ±Ğ¾Ñ‡ÑƒÑ Ğ¿Ğ°Ğ¿ĞºÑƒ ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ°
                if [[ -z "$MIGRATION_WORK_DIR" || ! -d "$MIGRATION_WORK_DIR" ]]; then
                    migration_init_work_dir
                fi
                # Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ°Ñ€Ñ…Ğ¸Ğ² ĞµÑĞ»Ğ¸ ĞµÑ‰Ñ‘ Ğ½Ğµ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½
                if [[ "$MIGRATION_SOURCE_TYPE" == "archive" ]]; then
                    if [[ -z "$MIGRATION_EXTRACTED_DIR" || ! -f "$MIGRATION_EXTRACTED_DIR/database.json" ]]; then
                        if ! extract_bedolaga_backup "$MIGRATION_SOURCE_BACKUP"; then
                            print_message "ERROR" "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ²"
                            read -erp "Enter..." dummy
                            continue
                        fi
                    fi
                fi
                if migrate_handle_balances; then
                    # ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ» Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ, Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼
                    if [[ -n "$BALANCE_HANDLING_MODE" && "$BALANCE_HANDLING_MODE" != "none" ]]; then
                        migrate_apply_balance_handling
                    fi
                    read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
                fi
                # Ğ•ÑĞ»Ğ¸ return 1 (Ğ½Ğ°Ğ·Ğ°Ğ´) â€” Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼ Ñ†Ğ¸ĞºĞ» Ğ¼ĞµĞ½Ñ
                ;;
            10)
                # ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº
                menu_migrate_settings
                ;;
            11)
                # ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚
                local report_file="$MIGRATION_WORK_DIR/migration_report.txt"
                if [[ -f "$report_file" ]]; then
                    clear_screen
                    cat "$report_file"
                else
                    # Ğ˜Ñ‰ĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚
                    local latest_report=$(find "$BACKUP_DIR" -name "migration_report.txt" -type f 2>/dev/null | head -1)
                    if [[ -n "$latest_report" ]]; then
                        clear_screen
                        cat "$latest_report"
                    else
                        print_message "WARN" "ĞÑ‚Ñ‡Ñ‘Ñ‚ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ."
                    fi
                fi
                read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
                ;;
            12)
                # ĞÑ‚ĞºÑ€Ñ‹Ñ‚ÑŒ Ğ¿Ğ°Ğ¿ĞºÑƒ NOT_MIGRATED
                local not_migrated_dir="$MIGRATION_WORK_DIR/NOT_MIGRATED"
                if [[ -d "$not_migrated_dir" ]]; then
                    echo ""
                    echo "Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ Ğ¿Ğ°Ğ¿ĞºĞ¸ NOT_MIGRATED:"
                    echo ""
                    ls -la "$not_migrated_dir"
                    echo ""
                    echo "ĞŸÑƒÑ‚ÑŒ: $not_migrated_dir"
                else
                    # Ğ˜Ñ‰ĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ¿Ğ°Ğ¿ĞºÑƒ
                    local latest_dir=$(find "$BACKUP_DIR" -name "NOT_MIGRATED" -type d 2>/dev/null | head -1)
                    if [[ -n "$latest_dir" ]]; then
                        echo ""
                        echo "Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ Ğ¿Ğ°Ğ¿ĞºĞ¸ NOT_MIGRATED:"
                        echo ""
                        ls -la "$latest_dir"
                        echo ""
                        echo "ĞŸÑƒÑ‚ÑŒ: $latest_dir"
                    else
                        print_message "WARN" "ĞŸĞ°Ğ¿ĞºĞ° NOT_MIGRATED Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°."
                        echo "ĞĞ½Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ñ€Ğ¸ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸."
                    fi
                fi
                read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter..." dummy
                ;;
            0) return ;;
        esac
    done
}

cleanup_old_backups() {
    clear_screen; echo -e "${RED}ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° ÑÑ‚Ğ°Ñ€Ñ‹Ñ… Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²${RESET}"
    
    local del_full=0; local del_db=0; local del_files=0
    local size_exceeded=false

    echo -e "Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸: ${YELLOW}$DELETE_MODE${RESET}"
    if [[ "$DELETE_MODE" == "count" ]]; then
        echo "Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ: $MAX_BACKUPS_COUNT ÑˆÑ‚."
    else
        echo -e "Ğ¡Ñ€Ğ¾Ğº Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ: ${YELLOW}$RETENTION_DAYS Ğ´Ğ½ĞµĞ¹${RESET}"
    fi
    echo -e "Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°: ${YELLOW}$(format_size_mb "$MAX_BACKUP_SIZE_MB")${RESET}"
    echo ""
    
    if [[ "$DELETE_MODE" == "count" ]]; then
        del_full=$(rotate_backups_by_count "lazarus_full" "ĞŸĞ¾Ğ»Ğ½Ñ‹Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹" "false" | tail -n1)
        del_db=$(rotate_backups_by_count "lazarus_db" "Ğ‘Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…" "false" | tail -n1)
        del_files=$(rotate_backups_by_count "lazarus_files" "ĞÑ€Ñ…Ğ¸Ğ²Ñ‹ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²" "false" | tail -n1)
    else
        # time-based
        del_full=$(rotate_backups_by_age "lazarus_full" "ĞŸĞ¾Ğ»Ğ½Ñ‹Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹" "$RETENTION_DAYS" "false" | tail -n1)
        del_db=$(rotate_backups_by_age "lazarus_db" "Ğ‘Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…" "$RETENTION_DAYS" "false" | tail -n1)
        del_files=$(rotate_backups_by_age "lazarus_files" "ĞÑ€Ñ…Ğ¸Ğ²Ñ‹ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²" "$RETENTION_DAYS" "false" | tail -n1)
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ° Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° (Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ)
    if [[ -n "$MAX_BACKUP_SIZE_MB" && "$MAX_BACKUP_SIZE_MB" != "0" ]]; then
        local current_size_bytes=$(du -sb "$BACKUP_DIR" 2>/dev/null | awk '{print $1}')
        local limit_bytes=$((MAX_BACKUP_SIZE_MB * 1024 * 1024))
        if [[ $current_size_bytes -gt $limit_bytes ]]; then
            size_exceeded=true
            rotate_backups_by_size "false"  # ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ±ĞµĞ· ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ
        else
            rotate_backups_by_size "false"  # ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ñ‡Ñ‚Ğ¾ Ğ² Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ñ… Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ°
        fi
    fi

    echo ""
    # normalize empty to 0
    del_full=${del_full:-0}; del_db=${del_db:-0}; del_files=${del_files:-0}
    local total_del=$((del_full + del_db + del_files))

    if [[ "$total_del" -eq 0 && "$size_exceeded" != "true" ]]; then
        print_message "SUCCESS" "Ğ§Ğ¸ÑÑ‚ĞºĞ° Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ. Ğ’ÑĞµ Ğ² Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ñ… Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ°."
        read -erp "Enter..." dummy
        return
    fi

    if [[ "$DRY_RUN" == "true" ]]; then
        print_message "WARN" "[DRY-RUN] ĞšĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ: $total_del"
    else
        if [[ "$size_exceeded" == "true" ]]; then
            print_message "WARN" "ĞŸÑ€ĞµĞ²Ñ‹ÑˆĞµĞ½ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°! Ğ¡Ñ‚Ğ°Ñ€Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ±ÑƒĞ´ÑƒÑ‚ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ñ‹."
        fi
        if [[ "$total_del" -gt 0 ]]; then
            print_message "WARN" "Ğ‘ÑƒĞ´ĞµÑ‚ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¾ ÑÑ‚Ğ°Ñ€Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ²: $total_del"
        fi
    fi
    # support non-interactive auto-confirm
    if [[ "$AUTO_CONFIRM" == "true" ]]; then
        confirm="y"
    else
        read -erp "Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ñ‹? (y/N): " confirm
    fi

    if [[ "$DRY_RUN" == "true" ]]; then
        # In dry-run we never delete
        log_message "INFO" "[DRY_RUN] Cleanup preview (mode=$DELETE_MODE, retention_days=$RETENTION_DAYS, max_count=$MAX_BACKUPS_COUNT, candidates=$total_del)"
        if [[ "$REPORT_TO_TG" == "true" && "$SEND_TO_TELEGRAM" == "true" ]]; then
            send_telegram_text "$(escape_markdown_v2 "ğŸ§¹ DRY-RUN Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ°: ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ²=$total_del, mode=$DELETE_MODE")"
        fi
        read -erp "Enter..." dummy
        return
    fi

    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        echo ""
        if [[ "$DELETE_MODE" == "count" ]]; then
            rotate_backups_by_count "lazarus_full" "ĞŸĞ¾Ğ»Ğ½Ñ‹Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹" "true" > "$SILENT_LOG"
            rotate_backups_by_count "lazarus_db" "Ğ‘Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…" "true" > "$SILENT_LOG"
            rotate_backups_by_count "lazarus_files" "ĞÑ€Ñ…Ğ¸Ğ²Ñ‹ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²" "true" > "$SILENT_LOG"
        else
            rotate_backups_by_age "lazarus_full" "ĞŸĞ¾Ğ»Ğ½Ñ‹Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹" "$RETENTION_DAYS" "true" > "$SILENT_LOG"
            rotate_backups_by_age "lazarus_db" "Ğ‘Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…" "$RETENTION_DAYS" "true" > "$SILENT_LOG"
            rotate_backups_by_age "lazarus_files" "ĞÑ€Ñ…Ğ¸Ğ²Ñ‹ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²" "$RETENTION_DAYS" "true" > "$SILENT_LOG"
        fi
        # Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¿Ğ¾ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñƒ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°
        if [[ "$size_exceeded" == "true" ]]; then
            rotate_backups_by_size "true"
        fi
        echo ""; print_message "SUCCESS" "ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°."
        log_message "INFO" "Cleanup completed (mode=$DELETE_MODE, retention_days=$RETENTION_DAYS, max_count=$MAX_BACKUPS_COUNT, deleted=$total_del)"
        if [[ "$REPORT_TO_TG" == "true" && "$SEND_TO_TELEGRAM" == "true" ]]; then
            send_telegram_text "$(escape_markdown_v2 "ğŸ§¹ ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°: ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¾=$total_del, mode=$DELETE_MODE")"
        fi
    else
        echo ""; print_message "INFO" "ĞÑ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾."
    fi
    read -erp "Enter..." dummy
}

# --- MAIN LOOP ---
rotate_internal_log
check_dependencies
install_script
load_or_create_config
check_config_mismatch # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¹ Docker image
check_and_warn_version_mismatch() {
    local result=$(check_image_version_match 2>/dev/null)
    local status=$?
    
    debug_log "VERSION" "Version check result: $result (status=$status)"
    
    case "$result" in
        MATCH:*)
            # Ğ’ĞµÑ€ÑĞ¸Ğ¸ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ÑÑ‚ - Ğ²ÑÑ‘ Ğ¾Ğº
            debug_log "VERSION" "Versions match"
            ;;
        UPGRADE:*)
            # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ’Ğ«Ğ¨Ğ• Ñ‡ĞµĞ¼ Ğ² compose - Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ
            local compose_ver=$(echo "$result" | cut -d: -f2)
            local loaded_ver=$(echo "$result" | cut -d: -f3)
            local image_name=$(echo "$result" | cut -d: -f4)
            # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑĞºÑ€Ğ°Ğ½ Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ±Ñ‹Ğ»Ğ¾ Ğ²Ğ²ĞµÑ€Ñ…Ñƒ
            clear_screen
            show_version_mismatch_warning "$compose_ver" "$loaded_ver" "true" "$image_name"
            if [[ "$IS_INTERACTIVE" == true ]]; then
                offer_compose_update "$compose_ver" "$loaded_ver" "$image_name"
            fi
            ;;
        DOWNGRADE:*)
            # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ ĞĞ˜Ğ–Ğ• Ñ‡ĞµĞ¼ Ğ² compose - Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ
            local compose_ver=$(echo "$result" | cut -d: -f2)
            local loaded_ver=$(echo "$result" | cut -d: -f3)
            local image_name=$(echo "$result" | cut -d: -f4)
            # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑĞºÑ€Ğ°Ğ½ Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ±Ñ‹Ğ»Ğ¾ Ğ²Ğ²ĞµÑ€Ñ…Ñƒ
            clear_screen
            show_version_mismatch_warning "$compose_ver" "$loaded_ver" "false" "$image_name"
            if [[ "$IS_INTERACTIVE" == true ]]; then
                read -erp "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ..." dummy
            fi
            ;;
        NOT_FOUND)
            # Image Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ - ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°
            echo ""
            print_message "ERROR" "Docker image Ğ±Ğ¾Ñ‚Ğ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½!"
            print_message "INFO" "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ image ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ¾Ğ¹: curl + docker load"
            echo ""
            ;;
        *)
            # ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ - Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ (Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ±Ğ¾Ñ‚ Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½)
            debug_log "VERSION" "Could not determine version match (bot not configured?)"
            ;;
    esac
}

# Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºÑƒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ±Ğ¾Ñ‚ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½
if [[ -n "$BOT_PATH" && -d "$BOT_PATH" ]]; then
    check_and_warn_version_mismatch
fi

# --- Global CLI flags parsing ---
# Support calling like: lazarus --yes --dry-run cleanup
DRY_RUN="false"
REPORT_TO_TG="false"

# Build new argv stripping known global flags
_NEWARGS=()
for _a in "$@"; do
    case "$_a" in
        --yes|-y) AUTO_CONFIRM="true" ;;
        --dry-run|-n) DRY_RUN="true" ;;
        --report-tg) REPORT_TO_TG="true" ;;
        --debug|-d) DEBUG_MODE=true ;;
        *) _NEWARGS+=("$_a") ;;
    esac
done
set -- "${_NEWARGS[@]}"

# Debug mode banner
if [[ "$DEBUG_MODE" == true ]]; then
    SILENT_LOG="/dev/stderr"
    CURL_SILENT="-v"
    WGET_SILENT=""
    echo -e "${MAGENTA}${BOLD}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${RESET}"
    echo -e "${MAGENTA}${BOLD}â•‘                    DEBUG MODE ENABLED                          â•‘${RESET}"
    echo -e "${MAGENTA}${BOLD}â•‘  All operations will be logged in detail to console           â•‘${RESET}"
    echo -e "${MAGENTA}${BOLD}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo ""
    echo -e "${CYAN}=== SYSTEM INFO ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} LAZARUS Version: $VERSION"
    echo -e "${MAGENTA}[DEBUG]${RESET} Bash Version: $BASH_VERSION"
    echo -e "${MAGENTA}[DEBUG]${RESET} User: $(whoami) (UID: $EUID)"
    echo -e "${MAGENTA}[DEBUG]${RESET} Hostname: $(hostname)"
    echo -e "${MAGENTA}[DEBUG]${RESET} Date: $(date '+%Y-%m-%d %H:%M:%S %Z')"
    echo ""
    echo -e "${CYAN}=== CONFIG ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Config file: $CONFIG_FILE"
    echo -e "${MAGENTA}[DEBUG]${RESET} Install dir: $INSTALL_DIR"
    echo -e "${MAGENTA}[DEBUG]${RESET} Backup dir: $BACKUP_DIR"
    echo -e "${MAGENTA}[DEBUG]${RESET} Log file: $LOG_FILE"
    echo ""
    echo -e "${CYAN}=== BOT CONFIG ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Bot path: ${BOT_PATH:-<not set>}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Bot container: ${BOT_CONTAINER_NAME:-<not set>}"
    echo -e "${MAGENTA}[DEBUG]${RESET} DB container: ${DB_CONTAINER_NAME:-<not set>}"
    echo -e "${MAGENTA}[DEBUG]${RESET} DB user: ${DB_USER:-postgres}"
    echo ""
    echo -e "${CYAN}=== TELEGRAM ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Notifications: $SEND_TO_TELEGRAM"
    echo -e "${MAGENTA}[DEBUG]${RESET} Send file: $TG_SEND_FILE"
    # ĞœĞ°ÑĞºĞ¸Ñ€ÑƒĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½: Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 4 Ğ¸ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 4 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°
    _masked_token="<not set>"
    if [[ -n "$BOT_TOKEN" ]]; then
        if [[ ${#BOT_TOKEN} -gt 10 ]]; then
            _masked_token="${BOT_TOKEN:0:4}****${BOT_TOKEN: -4}"
        else
            _masked_token="<set>"
        fi
    fi
    echo -e "${MAGENTA}[DEBUG]${RESET} Bot token: $_masked_token"
    # ĞœĞ°ÑĞºĞ¸Ñ€ÑƒĞµĞ¼ Chat ID: Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 4 Ğ¸ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 3 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°
    _masked_chat="<not set>"
    if [[ -n "$CHAT_ID" ]]; then
        if [[ ${#CHAT_ID} -gt 8 ]]; then
            _masked_chat="${CHAT_ID:0:4}***${CHAT_ID: -3}"
        else
            _masked_chat="<set>"
        fi
    fi
    echo -e "${MAGENTA}[DEBUG]${RESET} Chat ID: $_masked_chat"
    echo -e "${MAGENTA}[DEBUG]${RESET} Thread ID: ${TG_MESSAGE_THREAD_ID:-<not set>}"
    echo ""
    echo -e "${CYAN}=== REMOTE STORAGE ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Type: $REMOTE_STORAGE_TYPE"
    echo -e "${MAGENTA}[DEBUG]${RESET} Enabled: $SEND_TO_REMOTE"
    # ĞœĞ°ÑĞºĞ¸Ñ€ÑƒĞµĞ¼ URL: Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ» Ğ¸ Ğ´Ğ¾Ğ¼ĞµĞ½
    _masked_url="<not set>"
    if [[ -n "$REMOTE_STORAGE_URL" ]]; then
        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ» Ğ¸ Ñ…Ğ¾ÑÑ‚, ÑĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ Ğ¸ ĞºÑ€ĞµĞ´Ñ‹
        _url_proto=$(echo "$REMOTE_STORAGE_URL" | grep -oP '^[a-z]+://' || echo "")
        _url_host=$(echo "$REMOTE_STORAGE_URL" | sed -E 's|^[a-z]+://([^@]*@)?([^/]+).*|\2|')
        if [[ -n "$_url_host" ]]; then
            _masked_url="${_url_proto}${_url_host}/***"
        else
            _masked_url="<set>"
        fi
    fi
    echo -e "${MAGENTA}[DEBUG]${RESET} URL: $_masked_url"
    echo ""
    echo -e "${CYAN}=== ROTATION ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Delete mode: $DELETE_MODE"
    echo -e "${MAGENTA}[DEBUG]${RESET} Retention days: $RETENTION_DAYS"
    echo -e "${MAGENTA}[DEBUG]${RESET} Max backups: $MAX_BACKUPS_COUNT"
    echo ""
    echo -e "${CYAN}=== ENCRYPTION ===${RESET}"
    # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ñ‚Ğ¾ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½, Ğ±ĞµĞ· Ñ‡Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞºÑ€Ñ‹Ñ‚Ğ¸Ñ
    _masked_pass="<not set>"
    [[ -n "$BACKUP_PASSWORD" ]] && _masked_pass="<set> (${#BACKUP_PASSWORD} chars)"
    echo -e "${MAGENTA}[DEBUG]${RESET} Password: $_masked_pass"
    echo ""
    echo -e "${CYAN}=== EXCLUSIONS ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Exclude dirs: ${EXCLUDE_DIRS:-<none>}"
    echo -e "${MAGENTA}[DEBUG]${RESET} Max file size: ${MAX_FILE_SIZE_MB} MB"
    echo ""
    echo -e "${CYAN}=== DEBUG OUTPUT SETTINGS ===${RESET}"
    echo -e "${MAGENTA}[DEBUG]${RESET} SILENT_LOG: $SILENT_LOG"
    echo -e "${MAGENTA}[DEBUG]${RESET} CURL_SILENT: $CURL_SILENT"
    echo -e "${MAGENTA}[DEBUG]${RESET} IS_INTERACTIVE: $IS_INTERACTIVE"
    echo ""
    echo -e "${MAGENTA}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo ""
fi

case "$1" in
    backup_full) create_backup "full" ;;
    backup_db)   create_backup "db_only" ;;
    backup_files) create_backup "files_only" ;;
    cleanup|cleanup_old_backups)
        cleanup_old_backups ;;
    restore) menu_restore ;;
    check_update) check_for_updates ;;
    auto_update) auto_update_bot "$2" ;;
    *)
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½ĞµÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ cron Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°
        check_cron_mismatch
        
        # === ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ Ğ¢Ğ Ğ•Ğ‘ĞĞ’ĞĞĞ˜Ğ™ Ğ›Ğ˜Ğ¦Ğ•ĞĞ—Ğ˜Ğ˜ Ğ”Ğ›Ğ¯ Ğ‘ĞĞ¢Ğ v3.25.5+ ===
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ±Ğ¾Ñ‚Ğ° Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ°Ñ€Ñ‚Ğµ ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ°
        if [[ -n "$BOT_PATH" ]]; then
            local current_bot_version=$(get_current_bot_version 2>/dev/null)
            if [[ -n "$current_bot_version" ]] && version_gte "$current_bot_version" "3.25.5"; then
                local has_key=false
                local has_mid=false
                has_license_key && has_key=true
                has_machine_id_volume && has_mid=true
                
                if [[ "$has_key" == "false" || "$has_mid" == "false" ]]; then
                    clear_screen
                    echo -e "${RED}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
                    echo -e "${RED}${BOLD}  âš ï¸  Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•: Ğ¢Ğ Ğ•Ğ‘Ğ£Ğ•Ğ¢Ğ¡Ğ¯ ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ Ğ›Ğ˜Ğ¦Ğ•ĞĞ—Ğ˜Ğ˜${RESET}"
                    echo -e "${RED}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
                    echo ""
                    echo -e "Ğ‘Ğ¾Ñ‚ Ğ²ĞµÑ€ÑĞ¸Ğ¸ ${CYAN}$current_bot_version${RESET} Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ LICENSE_KEY Ğ¸ machine-id."
                    echo ""
                    echo -e "${YELLOW}${BOLD}Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸:${RESET}"
                    if [[ "$has_key" == "true" ]]; then
                        echo -e "  LICENSE_KEY:     ${GREEN}âœ“ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
                    else
                        echo -e "  LICENSE_KEY:     ${RED}âœ— Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ² .env${RESET}"
                    fi
                    if [[ "$has_mid" == "true" ]]; then
                        echo -e "  machine-id:      ${GREEN}âœ“ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½${RESET}"
                    else
                        echo -e "  machine-id:      ${RED}âœ— Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ² compose${RESET}"
                    fi
                    echo ""
                    echo -e "ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ĞºĞ»ÑÑ‡: ${CYAN}https://t.me/rwp_shop_bot${RESET}"
                    echo ""
                    read -erp "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ ÑĞµĞ¹Ñ‡Ğ°Ñ? [Y/n]: " setup_now
                    if [[ ! "$setup_now" =~ ^[Nn]$ ]]; then
                        if [[ "$has_key" == "false" ]]; then
                            ensure_license_key
                        fi
                        if [[ "$has_mid" == "false" ]]; then
                            ensure_machine_id_volume
                        fi
                    fi
                fi
            fi
        fi
        
        while true; do
            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑÑ‹ Ğ¸Ğ· cron
            CRON_STATUS_FULL=$(get_cron_status "full")
            CRON_STATUS_DB=$(get_cron_status "db")
            CRON_STATUS_FILES=$(get_cron_status "files")
            
            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²
            get_backup_stats
            
            # Ğ¦Ğ²ĞµÑ‚Ğ¾Ğ²Ğ°Ñ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ¾Ğ² cron
            # Full Ğ¸ DB â€” Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ (ĞºÑ€Ğ°ÑĞ½Ñ‹Ğµ ĞµÑĞ»Ğ¸ Ğ²Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½Ñ‹ Ğ¾Ğ±Ğ°), Files â€” Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ (ÑĞµÑ€Ñ‹Ğ¹ ĞµÑĞ»Ğ¸ Ğ²Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½)
            NO_CRITICAL_BACKUP=false
            [[ "$CRON_STATUS_FULL" == "Ğ’Ñ‹ĞºĞ»" && "$CRON_STATUS_DB" == "Ğ’Ñ‹ĞºĞ»" ]] && NO_CRITICAL_BACKUP=true
            
            COLOR_FULL="$GRAY"; [[ "$CRON_STATUS_FULL" != "Ğ’Ñ‹ĞºĞ»" ]] && COLOR_FULL="$YELLOW"
            COLOR_DB="$GRAY"; [[ "$CRON_STATUS_DB" != "Ğ’Ñ‹ĞºĞ»" ]] && COLOR_DB="$YELLOW"
            COLOR_FILES="$GRAY"; [[ "$CRON_STATUS_FILES" != "Ğ’Ñ‹ĞºĞ»" ]] && COLOR_FILES="$YELLOW"
            
            BOT_VERSION=$(get_bot_version_display)
            CONTAINER_STATUS=$(get_container_status)
            
            # Ğ¦Ğ²ĞµÑ‚ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ°
            STATUS_COLOR="$GREEN"
            [[ "$CONTAINER_STATUS" != "Online" ]] && STATUS_COLOR="$RED"
            
            clear_screen
            echo -e "${GREEN}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
            echo -e "${GREEN}${BOLD}  LAZARUS Backup Manager v${VERSION}${RESET}"
            echo -e "${GREEN}${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
            echo -e "Ğ‘Ğ¾Ñ‚: ${CYAN}${BOT_VERSION}${RESET} | ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€: ${STATUS_COLOR}${CONTAINER_STATUS}${RESET}"
            echo ""
            
            # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²
            echo -e "Ğ‘ÑĞºĞ°Ğ¿Ñ‹: ${STATS_FULL} Full | ${STATS_DB} DB | ${STATS_FILES} Files | ${BOLD}${STATS_SIZE}${RESET} Ğ²ÑĞµĞ³Ğ¾"
            if [[ -n "$STATS_LAST" ]]; then
                echo -e "ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹: ${STATS_LAST} (${STATS_LAST_AGO})"
            fi
            echo ""
            
            # ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ°Ğ²Ñ‚Ğ¾-Ğ±ÑĞºĞ°Ğ¿Ğ¾Ğ²
            if [[ "$NO_CRITICAL_BACKUP" == true ]]; then
                echo -e "${RED}${BOLD}âš ï¸  Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•: ĞĞ²Ñ‚Ğ¾-Ğ±ÑĞºĞ°Ğ¿ Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½!${RESET}"
                echo -e "${RED}   Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ Ğ²ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Full Ğ¸Ğ»Ğ¸ DB Ğ±ÑĞºĞ°Ğ¿${RESET}"
                echo ""
            fi
            
            echo -e "ĞĞ²Ñ‚Ğ¾-Ğ±ÑĞºĞ°Ğ¿ (cron):"
            echo -e " â€¢ Full:  ${COLOR_FULL}${CRON_STATUS_FULL}${RESET}"
            echo -e " â€¢ DB:    ${COLOR_DB}${CRON_STATUS_DB}${RESET}"
            echo -e " â€¢ Files: ${COLOR_FILES}${CRON_STATUS_FILES}${RESET}"
            echo ""
            echo " --- Ğ”Ğ•Ğ™Ğ¡Ğ¢Ğ’Ğ˜Ğ¯ ---"
            echo " 1. Ğ ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ±ĞµĞºĞ°Ğ¿ (Full / DB / Files)"
            echo " 2. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾-Ğ±ĞµĞºĞ°Ğ¿"
            echo " 3. Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ¸Ğ· Ğ±ÑĞºĞ°Ğ¿Ğ°"
            echo " 4. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ (ĞŸÑƒÑ‚Ğ¸ / Ğ¢Ğ¾ĞºĞµĞ½Ñ‹ / Ğ Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ)"
            
            CLEANUP_LABEL=""
            if [[ "$DELETE_MODE" == "time" ]]; then
                CLEANUP_LABEL="(>$RETENTION_DAYS Ğ´Ğ½ĞµĞ¹)"
            else
                CLEANUP_LABEL="(>$MAX_BACKUPS_COUNT ÑˆÑ‚.)"
            fi
            echo " 5. Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹ $CLEANUP_LABEL"
            echo -e " 6. ${CYAN}ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ±Ğ¾Ñ‚Ğ°${RESET}"
            echo -e " 7. ${MAGENTA}ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ±Ğ¾Ñ‚Ğ°Ğ¼Ğ¸${RESET}"
            echo ""
            echo -e " 8. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ°"
            echo -e "${RED} 666. Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ (Uninstall)${RESET}"
            echo " 0. Ğ’Ñ‹Ñ…Ğ¾Ğ´"
            echo ""
            read -erp "Ğ’Ñ‹Ğ±Ğ¾Ñ€ (Enter - Ğ²Ñ‹Ñ…Ğ¾Ğ´): " opt; [[ -z "$opt" ]] && exit 0
            case $opt in
                1) menu_manual_backup ;; 2) menu_automation ;; 3) menu_restore ;; 
                4) menu_settings ;; 5) cleanup_old_backups ;; 6) update_bot ;; 
                7) menu_migration ;; 8) check_for_updates ;; 666) uninstall_script ;; 0) exit 0 ;;
            esac
        done
        ;;
esac
